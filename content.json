[{"title":"孙工给的AI书签","date":"2025-05-23T03:04:10.000Z","path":"孙工给的AI书签.html","text":"AI 书签部分平台工具是国外的平台和工具，需要挂梯子。 AI 平台与工具 DeepSeek 开放平台 - 深度求索公司推出的AI开放平台，提供大模型API接口和开发工具 SQL Query Builder &amp; Generator - 基于AI的SQL查询构建器和生成器，帮助用户快速生成SQL语句 Pulumi - 支持多种编程语言的基础设施即代码(IaC)平台，简化云资源管理 Swimm（自动文档生成） - 自动生成和维护代码文档的工具，帮助团队保持文档与代码同步 Applitools （视觉测试） - 基于AI的视觉测试平台，用于自动化UI测试和视觉回归测试 主页 - MasterGo - 在线设计协作平台，支持团队实时协作设计 ScriptEcho | AI生成生产级代码 | - AI驱动的代码生成工具，可生成生产级别的代码 Figma to Code (HTML, Tailwind, Flutter, SwiftUI) | Figma - Figma插件，可将设计直接转换为多种框架的代码 用Figma插件,生成高质量前端页面 _ Figma AI to Code - 介绍如何使用Figma AI插件生成前端代码的教程视频 AI 编辑器与开发工具 Cursor - The AI Code Editor - 集成AI功能的代码编辑器，提供智能代码补全和生成功能 Features | Cursor - The AI Code Editor - Cursor编辑器的功能详细介绍 Settings | Cursor - The AI Code Editor - Cursor编辑器的设置选项 Pricing | Cursor - The AI Code Editor - Cursor编辑器的价格方案 Claude - Anthropic公司开发的AI助手，擅长自然语言处理和代码生成 CodeGeeX - 支持多种编程语言的代码生成工具，由清华大学开发 Trae - AI 原生 IDE - 专为AI开发设计的集成开发环境 Claude 3.7 sonnet国内如何使用（保姆级指南） - 详细介绍如何在国内使用Claude 3.7 sonnet模型的指南 Intro to Ghostwriter - Replit平台的AI编程助手Ghostwriter介绍 Otter Notes - Otter.ai - AI驱动的会议记录和笔记工具，可自动转录和总结会议内容（实测中文支持不怎么滴，垃圾） 本地部署大模型 本地部署大模型的工具汇总 - 汇总了各种用于本地部署大模型的工具和平台 DeepSeek本地部署 - 详细介绍如何在本地部署DeepSeek大模型 本地部署大模型的三种工具 - 介绍三种可用于本地部署大模型的工具 本地部署大型语言模型：常用工具总结和推荐 - 总结和推荐用于本地部署大型语言模型的常用工具 Langchain入门到精通实战教程 - Langchain框架从入门到精通的实战教程视频 Spring AISpring-AI-Alibaba相关资料在百炼平台分类，需要查看往下翻。 Spring AI - Spring框架的AI扩展，简化AI应用开发 AI Concepts :: Spring AI Reference - Spring AI的核心概念和参考文档 Spring AI - Spring AI的详细介绍和使用方法 Spring AI-Function Call（八） - Spring AI中函数调用的详细教程 MCP协议+SpringAI实战 - 结合MCP协议和Spring AI的实战教程视频 Ollama 与 LangChain Ollama 英特尔优化版 · 模型库 - 英特尔优化的Ollama模型库，提供高性能本地大模型部署 library - Ollama官方模型库，提供多种可下载的大模型 qwen3 - 通义千问3模型在Ollama平台的版本 LangChain4j比SpringAI强在哪？ - 比较LangChain4j和SpringAI的优缺点 LangChain4j Naive RAG - LangChain4j中Naive RAG和文档分割器的使用教程 RAG (Retrieval-Augmented Generation) | LangChain4j - LangChain4j中检索增强生成(RAG)的官方文档 langchain4j&#x2F;langchain4j · GitHub - LangChain4j的文件系统文档加载器测试代码 langchain4j+poi读取文档 - 使用LangChain4j和POI读取文档的教程 langchain4j的MCP讲解 - 探讨LangChain4j对模型上下文协议(MCP)的支持 MCP 相关 5个开源MCP服务器：扩展AI助手能力 - 介绍5个开源的MCP服务器，用于扩展AI助手能力 Model Context Protocol(MCP) 编程极速入门简介 - MCP协议的快速入门指南 Sequential Thinking | Smithery - Smithery平台的顺序思考服务器，基于MCP协议 Smithery MCP 工具库 - Smithery提供的MCP工具库，用于构建AI应用 Introduction - Model Context Protocol - MCP协议的官方介绍文档 Model Context Protocol · GitHub - MCP协议的GitHub仓库 MCP Servers - MCP服务器的官方平台 MCP市场 - 中国区的MCP市场，提供各种MCP服务和工具 GitHub’s official MCP Server - GitHub官方的MCP服务器实现 Model Context Protocol Servers - MCP协议服务器的官方仓库 jingfeng-linksprite&#x2F;demos · GitHub - 使用MCP和SQL代理的示例项目 其他 AI 工具 Grok - xAI公司开发的AI助手，提供实时信息访问能力 DeepSeek | 深度求索 - 深度求索公司官网，提供AI大模型和开发工具 DeepSeek 开放平台 - DeepSeek的开放平台使用指南 Kimi AI助手 - 月之暗面公司开发的AI助手，擅长推理和深度思考 新对话 - 豆包 - 字节跳动开发的AI助手豆包 PingCode - 智能研发管理平台，集成了AI功能 Polymer - 基于AI的数据分析和可视化平台 Tabnine AI Code Assistant - 提供私有化部署的AI代码助手 Windsurf (formerly Codeium) - 强大的AI代码编辑器，前身为Codeium JetBrains AI Service and In-IDE AI Assistant - JetBrains IDE集成的AI助手服务 关于TensorFlow | TensorFlow中文官网 - Google开发的深度学习框架TensorFlow的中文官网 OpenRouter - 提供多种AI模型API的统一访问平台 阿里云百炼 百炼控制台 - 阿里云百炼平台的官方控制台 无影AgentBay云服务-阿里云帮助中心 - 阿里云无影AgentBay云服务的帮助文档 【MCP教程系列】阿里云开发者社区 - 使用阿里云百炼平台进行数据分析和可视化的教程 Spring AI Alibaba 对接百炼平台大模型使用详解 - 详细介绍如何使用Spring AI Alibaba对接百炼平台大模型 使用Spring AI Alibaba集成阿里云百炼大模型应用 - 阿里云官方文档：使用Spring AI Alibaba集成百炼大模型 Spring AI Alibaba 官网 - Spring AI Alibaba的官方网站 模型列表 - 阿里云百炼平台提供的模型列表 用户指南（模型） - 阿里云百炼平台的模型使用指南 其他资源 自动翻译基于I18N - 基于I18N的自动翻译工具 用AI做数据分析：12个强力AI数据分析工具分享 - 介绍12个强大的AI数据分析工具 AI方案库-传递最新AI落地解决方案｜AIGCLINK - 提供最新AI落地解决方案的平台 cline开放MCP开源AI应用商店（AIAgent） - 介绍cline开放MCP开源AI应用商店的视频 Ollama + DeepSeek本地部署 - 详细介绍DeepSeek本地部署的教程","tags":[{"name":"AI","slug":"AI","permalink":"https://vitsumoc.github.io/tags/AI/"}]},{"title":"Go项目日志实践","date":"2024-12-18T01:43:51.000Z","path":"Go项目日志实践.html","text":"伴随着项目的成长，代码的规模越来越大、组件的关系越来越繁杂、部署的点位也越来越多，人肉运维逐渐难以维护项目的运行，日志的重要性的越发体现出来。 这次的改造涉及到项目中的多个 Go 程序，需要实现下列功能： 将程序运行时的信息写入日志文件 将程序崩溃时的错误写入日志文件 日志文件可以滚动更新 为了实现上述功能，使用了一些标准库和开源库，分别是： runtime: 用来获得 panic 信息 lumberjack: 实现了滚动日志文件写入 代码实现有了上述这些库的帮助，实际上我要做的事情已经很少了，大概还有这些： 配置开源库，文件大小、保存位置、保存数量等等 实现日志分级，在需要的时候开启 DEBUG，平时就输出 INFO 和 ERROR gin 框架 recovery 时写入日志，主程序 panic 时写入日志 最终的实现是这样： runlog.gopackage vlog import ( \"fmt\" \"net/http\" \"runtime/debug\" \"time\" \"github.com/gin-gonic/gin\" \"gopkg.in/natefinch/lumberjack.v2\" ) var RunLogger *lumberjack.Logger var VRunLogLevel RunLogLevel = RL_INFO // 运行日志初始化 func InitRunLog() &#123; RunLogger = &amp;lumberjack.Logger&#123; Filename: \"./logs/col_run.log\", MaxSize: 50, // mb MaxBackups: 20, // 最大文件保留 MaxAge: 30, // 最大天数保留 LocalTime: false, // 使用UTC时间 Compress: false, // 不压缩 &#125; RunLog(RL_INFO, \"运行日志初始化...\") &#125; // 日志等级 type RunLogLevel int const ( RL_DEBUG RunLogLevel = iota RL_INFO RL_ERROR ) // 写入日志 func RunLog(level RunLogLevel, format string, a ...any) &#123; if level &lt; VRunLogLevel &#123; return &#125; // 获取当前时间 now := time.Now() timeStr := fmt.Sprintf(\"[%d-%02d-%02d %02d:%02d:%02d.%03d] \", now.Year(), now.Month(), now.Day(), now.Hour(), now.Minute(), now.Second(), now.Nanosecond()/1000000) // 日志等级 var levelStr string switch level &#123; case RL_DEBUG: levelStr = \"[DEBUG] \" case RL_INFO: levelStr = \"[INFO] \" case RL_ERROR: levelStr = \"[ERROR] \" &#125; // 写入日志 RunLogger.Write([]byte(timeStr + levelStr + fmt.Sprintf(format, a...) + \"\\n\")) fmt.Println(timeStr + levelStr + fmt.Sprintf(format, a...)) &#125; // WEB恢复 func WebRecovery() gin.HandlerFunc &#123; return func(c *gin.Context) &#123; defer func() &#123; if err := recover(); err != nil &#123; // 记录错误信息，可以使用自己喜欢的日志库 RunLog(RL_ERROR, \"发生panic:\\n%v\", err) stack := debug.Stack() RunLog(RL_ERROR, \"调用栈信息:\\n%s\", stack) // 设置响应状态码为500 c.JSON(http.StatusInternalServerError, gin.H&#123;\"error\": \"内部服务器错误\"&#125;) &#125; &#125;() // 继续执行下一个中间件或路由处理函数 c.Next() &#125; &#125; // Panic 记录 func LogPanic() &#123; stack := debug.Stack() RunLog(RL_ERROR, \"主程序异常退出\") RunLog(RL_ERROR, \"调用栈信息:\\n%s\", stack) &#125; 在使用日志服务前，需要进行全局初始化： main.go// ... vlog.InitRunLog() // ... WebRecovery 是写给 gin 框架的回调，用来记录 HTTP 服务执行过程中发生的 panic，使用时需要配置到 gin 框架中，用法如下： web.gor := gin.Default() r.Use(vlog.WebRecovery(), gin.LoggerWithConfig(gin.LoggerConfig&#123; Output: vlog.RunLogger, &#125;)) 如果程序本身崩溃了，那么也需要记录到日志中，可以通过 main 函数的 defer 实现这一点： main.gofunc main() &#123; defer vlog.LogPanic() // 其他初始化 &#125; DEBUG 等级的日志正常不会被记录或显示，可以在程序运行时通过 flag 开启，如下： main.godebug := flag.Bool(\"debug\", false, \"是否开启调试模式\") flag.Parse() if *debug &#123; vlog.VRunLogLevel = vlog.RL_DEBUG &#125; 最后，我们可以在程序各处埋点，添加不同级别的日志，例如： task.govlog.RunLog(vlog.RL_INFO, \"任务线程初始化...\") // ... vlog.RunLog(vlog.RL_ERROR, \"[任务循环] License校验失败\"+err.Error())","tags":[{"name":"项目实践","slug":"项目实践","permalink":"https://vitsumoc.github.io/tags/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"name":"Go","slug":"Go","permalink":"https://vitsumoc.github.io/tags/Go/"}]},{"title":"github常见用法示例","date":"2024-11-28T02:54:22.000Z","path":"github常见用法示例.html","text":"本文总结了一些 github 最常见的使用场景，包括： 使用他人的项目 创建自己的项目 参与他人的项目 维护分支 使用他人项目使用——clone项目代码是在 github 网站上的，我们要将网站上的代码下载到本地，可以点击网站仓库中的下载按钮，也可以使用 git clone 操作。 点击下载按钮会直接下载一个项目仓库的 ZIP 包，解压就可以使用，这种是不会在本地创建一个仓库的，也就是说您获得的是纯粹的源码。 而使用 git clone 操作会获得一个带有 .git 文件夹的项目，这样您就会得到一个带版本控制功能的仓库！ 更新项目——pull使用 git clone 操作后，您就可以使用 git pull 命令更新项目了。 git pull 命令会从远程仓库拉取最新的代码，并合并到当前分支中，这样您就可以获得项目作者提供的各种更新。 创建自己的项目可以在 github 网站创建自己的项目仓库，之后使用 git clone 命令克隆到本地，就可以使用 git 管理自己的项目了。 提交修改——add、commitgit clone 命令会在本地建立一个仓库，那么对项目的修改也应该首先提交到本地，之后再推送到 github。 使用 git add 命令将修改的文件添加到暂存区，使用 git commit 命令将暂存区的修改提交到本地仓库。 推送修改——push使用 git push 命令可以将本地仓库的修改推送到 github。 参与他人的项目——fork这里分为两种情况，如果您只是想要稍微改动他人的项目自己使用，那么您只需要下载、修改、使用就可以了。（需要注意项目的 License 是否允许您这么做） 但是如果您想要参与项目，贡献代码，那么一般的流程是这样： 和作者沟通您的想法——issueissue 在 github 的项目页面里，就像一个论坛，您可以直接发 issue 和作者沟通想法。也许您的想法并不符合项目的方向，也许您的想法作者已经考虑到了，总之在参与项目之前先沟通总是个好习惯。 创建属于您的仓库——fork使用 github 页面上的 fork 按钮可以创建一个属于您的项目仓库，这个仓库会标记 forked from xxxx，您可以 clone 这个仓库，进行修改，随后 commit 提交，随您喜欢。 如果您只是想维护一个自己的分支，那么这样就足够了，但是如果您想将您的修改推送到项目主仓库，那么还需要一个操作： 贡献修改——pull request当您将本地的修改使用 git commit git push 推送到您的 fork 仓库后，github 页面上会看到一个 open Pull Request 的按钮，可以将您的修改请求推送给主仓库。如果主仓库的持有者同意，那么您的修改就会被合并到主仓库中，您也就完成了一次代码贡献。 维护分支当然，假设您需要——在本地拥有两个分支（branch），一个用来同步线上的主仓库，另一个用来维护自己的修改，同时两个仓库都接受主仓库的更新，那么您可以： 创建分支——branch使用 git branch 命令可以创建一个分支，例如 git branch zh 会创建一个名为 zh 的分支。 切换分支——checkout使用 git checkout 命令可以切换到某个分支，例如 git checkout zh 会切换到 zh 分支。 使用 git branch 会显示本地仓库的分支列表，以及当前正在使用的分支。 追踪主仓库的更新假设主仓库为： xxx&#x2F;master 而我们的仓库是： vc&#x2F;master （从主仓库 fork） vc&#x2F;zh （这是我们自己创建的分支） 主仓库更新后，我们可以在 github 页面（vc&#x2F;master）点击 Update branch 按钮，这样会让我们的 master 分支获得最新的代码。 随后我们需要在本地使用 git pull 命令拉取主仓库的更新，这样我们本地的 vc&#x2F;master 分支也会获得最新的代码。 合并分支——merge使用 git checkout zh 命令切换到我们自己的修改分支，使用 git merge master 命令将主仓库的更新合并到当前分支中。 这样我们自行修改的分支也会获得最新的代码。","tags":[{"name":"豆知识","slug":"豆知识","permalink":"https://vitsumoc.github.io/tags/%E8%B1%86%E7%9F%A5%E8%AF%86/"},{"name":"github","slug":"github","permalink":"https://vitsumoc.github.io/tags/github/"}]},{"title":"[翻译]无痛项目进度表","date":"2024-11-19T09:46:13.000Z","path":"无痛项目进度表.html","text":"原文 Painless Software Schedules 去年十月，美国东北充满了 Acela 的广告，这是一条从波士顿到华盛顿的新高铁。电视里、海报上和路边广告牌随处可见，您 可能 会觉得这些宣传会给美国高铁拉来更多的生意。 好吧，可能会，但可惜的是美国高铁没机会进行验证了。Acela 的运行一次又一次延期，甚至直到营销活动结束，高铁也没开通。这让我想起了曾经的一位市场经理，他的宣传工作取得了巨大的成功，但是距离产品上市还有一个月：“宣发完美！但是他妈的这东西根本 买不到！” 有些酷炫狂拽屌炸天的游戏公司喜欢在他们的官网上宣布他们的下一款游戏的发布时间是“制作完成后”。——进度表？哥们才不在乎什么进度表！哥们是最酷的游戏程序员！——好吧，但是大部分公司没资格这样干。您可以去问问 Lotus，当他们第一次对 123 3.0 版本进行宣发时，需要客户配置 80286 计算机，在当时这还是挺先进的稀有配置。随后他们的产品跳票了 16 个月（为了适应 8086 计算机的 640K 内存限制），等到他们完成时，微软的 Excel 已经发布了 16 个月了。（而且，讽刺的是，8086 在那时已经过时了） 在我写这篇文章时，Netscape 5.0 浏览器已经跳票两年了。其中大部分原因要归功于他们犯了一个自杀式的错误——抛弃所有的代码然后从零开始开发——同样的错误也注定了 Ashton-Tate、Lotus 和苹果的 MacOS 被扫入历史的垃圾堆。Netscape 眼睁睁的看着他们的市场份额从 80% 掉落到 20%，但是他们根本没法还击，因为此时此刻他们的核心软件产品已经被拆解成了一千个零部件平铺在地上等待组装。单单这一个错误就超过了其他所有的决策失败，成功的成为了 Netscape 引爆自己的核弹。（Jamie Zawinski 的那篇 举世闻名的小作文 中有详细说明） 因此，您必须制定进度表。即便不想做项目进度表已经成了所有程序员的共识。在我的经验里，绝大多数程序员会完全逃避制作进度表，少数程序员则是在老板的要求下勉强的、半推半就的、不情不愿的、制作了一份及其含糊其辞的进度表。实际上除了高层管理以外，从一开始就 没人拿这个进度表当回事 。（顺带提一句，这帮高管们还坚信 UFO 是真实存在的） 所以为什么大家都讨厌做项目进度表？有两个关键原因。第一，做项目进度表很痛苦。第二，大家都觉得项目进度表没用。如果说项目进度表最终没办法体现项目的进度，那为什么我们还要为此费力呢？既然大家都觉得项目进度表没用，而且随着项目的推进会错的越来越离谱，那为啥还要费力气做进度表呢？ 以下是一个简单、无痛、有效的项目进度表编写方法 1) 就用 Excel。不要整 Microsoft Project 这样的花活。Microsoft Project 这种工具的最大问题是您需要花很多时间来处理所谓的“依赖关系”，也就是项目中不同任务的先后次序。而我发现在软件项目中依赖关系非常显而易见，没必要专门去进行管理。 Project 的另一个问题是他假设您需要一个“一键重排进度表”的按钮，这个功能则不可避免地将工作重新分配给不同的人。对于软件项目来说，这个功能是完全不可用的，程序员的工作具有极大的连续性，而非即插即用。让 John 去修复 Rita 的 bug 会比让 Rita 自己来修复多消耗 7 倍的工时。假设您安排您的 UI 师傅去处理 WinSock 问题的话，那么她大概率需要先花两周时间去学习新知识。总而言之，Project 是给盖大楼项目用的管理软件，而不是给软件项目用的。 2）保持简单。我的项目进度表的基础格式甚至您看一眼就可以记住，只需要 7 列： 如果您有多个开发人员，您可以给他们每个人安排一个 sheet，或者您也可以添加一列用来记录任务负责人。 3）每个功能都应由若干任务构成。功能就是类似于在“程序中添加拼写检查”这种东西。而“添加拼写检查”这件事则由一系列需要程序员执行的小任务组成。编写项目进度表最重要的工作就是要列出这些任务清单。核心规则包括： 4）让干活的程序员来评估工时。任何由管理层编造进度表，要求程序员去执行的项目都是注定失败的。只有具体去实施的程序员才能搞清楚完成任务需要哪些步骤，因此也只有干活的程序员自己能弄明白每个任务需要多长时间。 5）任务时间精度要足够小。这是让进度表能生效的绝招。您的任务必须按小时计时，而非按天计时。（当我看到一个进度表以天为单位安排任务，或者甚至以周为单位，我就知道这东西根本不真实）。您是不是觉得任务时间精度高的收益只是 统计更加精准？错了！大错特错！当您尝试将大块的目标拆分成精细的目标时，您会发现得到的结果和之前全然不同，不仅仅是任务被更加细分，甚至 总工时也全然不同。这究竟是怎么回事？ 当您开始拆分细颗粒度任务时，您实际上是在强迫自己真正思考功能实现的步骤。编写 foo 子程序、创建某某对话框、读取 wawa 文件等等。这些任务的工时很容易预估，因为您真的编写过子程序、创建过对话框、也读取过 wawa 文件。 相反，如果您粗心大意的安排“整块”任务（“实现语法纠正”），其实表示了 您没有仔细思考过要做什么。而如果您没有思考过要做什么，那么您当然无法获得准确的工时预估。 根据经验，每个任务应该在 2 到 16 小时之间。如果您的进度表上有一个 40 小时（一周）的任务，说明您的分解还不够细。 拆分细颗粒度任务还有另一个原因：这将强迫您去 设计 该死的功能。如果您只有一个随手写的 “互联网集成” 功能而且您安排了 3 周的工时，哥们你完了。如果您 必须搞清楚需要编写哪些子程序，那么您就必须要 确定 这个功能内容。通过（被迫）在编写项目进度表时的提前计划，您可以排除软件项目中的许多不确定因素。 6）持续跟踪原始预估工时和当前预估工时。当您第一次将某个任务添加到进度表时，请估算任务需要的工时并将其填入原始预估（OrigEst）和当前预估（CurrEst）两列中。随着时间的流逝，如果您觉得某个任务所需的工时大于或小于您所想的，您可以随时更新当前预估的值。这是您通过时间学会工时估算的最好方式。大部分程序员不知道该如何预估工时，没关系，您只需要不断地尝试，不断地更新进度表，最终都能学会。（您可能必须砍掉某些功能或是延迟发布，但是进度表仍然在起作用，至少他能够告诉您何时需要砍掉功能或是做好延迟发布的准备）。据我观察，大部分程序员大约需要一年的时间来学会较为准确的评估工时。 在任务完成时，当前预估列和已用时间（Elapsed）列的值应当相同，而剩余时间（Remain）列则会自动计算为0. 7）每天更新已用时间。您无需掐着秒表编程，只需要在回家之前（或者对于那些极客就是在桌子下面睡觉之前），假装您已经工作了八小时，回头想想您今天做了哪些工作，然后在已用时间中把这八小时加上。剩余时间列则会被 Excel 自动计算。 同时，根据现实情况来更新当前预估工时。每天更新进度表大概只需要消耗您两分钟时间，这就是为啥我把这个方法叫做 无痛进度表方法——又快又简单。 8）为休假和节假日添加条目。如果您的项目需要一年的时间，那么每个程序员都可能会有 10 - 15 天用于休假。您应该在进度表中添加休假和节假日，以及任何其他的导致程序员不上班的事项。随后您可以通过加总剩余时间列后除以 40 的方式来计算出发布日期——也就是剩余多少周的时间，包含所有事情在内。 9）将调试时间加入进度表！调试时间是最难估算的。回头想想您的上一个项目吧。调试所用的时间很可能会是开发所用时间的 100% – 200%。调试必须在进度表中有一席之地，而且很可能是占用最多时间的内容。 调试时间是这样用的。假设有一个程序哥正在进行 wawa 功能的开发，原始预估工时是 16 小时，但至今为止他已经工作了 20 小时而且看起来还需要额外的 10 个小时。因此程序哥在当前预估列中输入 30 并且在已用时间中输入 20。 在项目快要到达节点时，所有这些 “延期” 加在一起可能已经积累了很多。理论上，为了赶上项目节点，我们必须砍掉一些功能。幸运的是，我们之前已经预留了一个测试条目，并且预留的时间非常充足，很适合被砍。 原则上，每一个程序员都应该在写编写代码后就地测试。程序员们永远不应该在还有 bug 需要处理的情况下去编写新的代码。bug 遗留的数量必须越少越好，有两个原因： 在写代码的当天修复 bug 更容易。而在一个月后，当您已经忘记代码具体如何工作时，修复 bug 可能会非常困难和耗时。 修复 bug 就像做科研，您无法估计何时会有突破并解决 bug。如果任何时候只有一两个未解决的 bug，就很容易估算产品的交付时间，因为剩余需要科研的内容就那么点。另一方面，如果您有数百或数千个未解决的 bug，就不可能预测他们何时能被全部修复。 如果程序员们总是一边开发一边 debug，那么为啥我们还需要为调试预留大量时间呢？好吧，实际上即使您在开发时已经修复了所有您已经发现的bug，到了每个里程碑节点的时候，您的产品仍将不可避免的会被测试人员（公司内部的或是 beta 客户）发现一些 真正难搞 的 bug。 10）将集成时间加入进度表。如果您的团队超过一名程序员，那么不可避免的，他们产出的内容会存在冲突。有可能是他们都为了类似的功能各自实现了对话框。需要有人负责检查所有的菜单、快捷键、工具栏等等…清理和组织大家随意添加的各种菜单项。当两个程序员一起提交代码时编译器可能会出现编译错误。这些都需要修复，而且应该作为进度表中的一个条目。 11）在进度表中加入缓冲（buffer）时间。事情的发展总是和我们预想的不同，至少有两种重要的缓冲您需要考虑。第一：为那些实际消耗时间比原始预估时间更长的任务预留缓冲。第二：为那些您没有考虑到的工作预留缓冲，例如管理层临时决定将 wawa 作为软件的重要功能而且必须在此版本发布。 您可能会发现：休假、节假日、测试、集成和缓冲的时间加起来比实际开发时间多得多。如果您对此感到惊讶，那说明您编程的时间还不长，对吧？忽视这些后果自负。 12）永远不要允许管理层压缩程序员预估的工期。很多菜鸟经理觉得通过压缩工期可以“激励”程序员来尽快完成工作，我觉得这帮人就是纯弱智。实际上当我的进度落后于进度表时，我只会感觉到沮丧、没动力、项目注定失败。进度表不是给这些弱智玩心理游戏的地方。 如果您的上级执意要您压缩工期，您可以试试这个办法：在进度表中创建一个新的列叫做 Rick 的预估工期（这里假设您就是 Rick），在其中填入您对项目工期的预估。此后把 当前预估时间 列交由您的上级处置，随便他怎么填。当项目结束后，再看看谁的预估时间更加接近现实情况。我发现只需要和上级 提及 这个想法就能有效地威慑他们，特别是当他们意识到这种比较实际上就是在 比谁工作的更慢 的时候。 为什么无能的领导总在试图压缩程序员的工期？ 在项目开始时，技术管理人员和商务开会，最后列出一份 他觉得 能在 3 个月内完成的功能清单，但实际需要 9 个月。当您只需要考虑架构层面的东西而并不考虑所有的实现步骤时，往往您觉得需要 n 天的工作，实际上大约需要 3n 天。随后当您开始编写项目进度表时，您将所有的步骤都写入表中然后逐渐意识到所需的时间远远超过预期。现实情况逐渐浮出水面。 无能的领导这时候灵光一闪，心想：如果我能让程序员们工作得更快，那么我就能让他们在 3 个月内完成工作！ 好吧，然而这并不现实。随后他又想到也许可以招聘更多人来工作，但招来的人需要适应，需要熟悉项目，在最初几个月的时间里这些新来的哥们往往只能产出 50% 的生产力（而且还得让现有的熟练工花时间带他们）。不管怎么说吧，据我观察，现在新招的程序员往往要半年时间才能达到满产状态。 您可以通过对程序严格考核来增加大约 10% 的产出，这带来的结果就是让他们筋疲力尽。收益很小，长期亏损很大，这种行为就像是农民把留种的种子吃掉一样愚蠢。 您也可以通过让程序员 996 来增加大约 20% 的产出。boom！bug 率超高，调试时间翻倍，半年内离职率激增，而且您失去的都是那些高产员工，留下一群工作表演艺术家陪您 996 奋斗（毕竟真正工作的大脑不可能一天高强度运行 12 小时）。最后您得到的是延期的项目、低效的团队、破产的公司。一种绝妙的因果报应的方式适得其反。 无论怎么样，您都不可能在 n 个时间里产出 3n 的工作量，如果您仍然坚信您可以，那么请赶快把您公司的股票代码告诉我，我现在就去做空。 13）进度表就像木块。如果您有一堆木块，然后无法把他们装进一个盒子里，那么您只有两个选择：要么换一个大点的盒子，要么就是放弃一些木块。如果您需要在 6 个月内交付产品，但您的进度表上却有 12 个月，您要么延期交付，要么就是删除一些功能。您就是没办法压缩那些木块，如果您假装可以，那么实际上您也只是在对自己看到的事实说谎，剥夺了自己 真正面对问题 的机会。 而且您也已经了解了，维护进度表的另一个好处是 强迫 您删除一些功能。为啥说这这是好处呢？假设您有两个功能：其中一个真的很有用而且会让您的产品走的更远（例如：Netscape 2.0 中的表格），另一个则是简单又好玩，程序员们非常想要加进去（例如：BLINK 标签），但是这玩意实际上没啥用，对市场也没啥帮助。 如果您没有项目进度表，程序员们总是会先去实现那些简单又好玩的功能。他们会在这些游乐场里耗尽所有的时间，一直到最后，您不得不为了那些有用又重要的功能延期。 而如果您制定了项目进度表，那么在工作开始前，您就会意识到您必须砍掉一部分功能（来保证交期），因此您当然会保留那些有用又重要的功能，砍掉那些简单又好玩的功能。通过强迫自己在功能之间做出选择，您最终会获得一个更强大，更好的产品，组合了最最重要的功能，而且能够按时发布。 我记得在开发 Excel 5 的时候，我们最初计划的功能列表无比庞大，会远远的超过预定的工期。当时我们觉得这些功能都是超级重要的功能！没有宏编辑向导我们怎么活啊？！ 事实证明，我们别无选择，最终我们把进度表砍的只剩骨架，每个人都对这些功能被砍感到不快。为了安抚我们自己，我们告诉自己这些功能只重要性稍低，将延后到 Excel 6 再实现。 当 Excel 5 接近完成时，我开始和同事 Eric Michelman 一起制定 Excel 6 的规格。我们坐下来查看从 Excel 5 进度表中削减的\"Excel 6\"功能列表。我们完全震惊地发现，被削减的功能列表是我们能想象到的最糟糕的功列表。这些功能没有一个值得做。我认为即使在接下来的三个版本中，这些功能中也没有一个被实现。为适应进度表而筛选功能是我们能做的最好的事情。如果我们没有这样做，Excel 5 会花费两倍的时间，并包含 50% 无用的垃圾功能。（我完全确信这正是 Netscape 5/Mozilla 发生的事情：他们没有进度表，没有明确的功能列表，没人愿意削减任何功能，他们就是没有发布。当他们发布时，他们会有很多像 IRC 客户端这样他们根本不应该花时间的次要功能。） 附录：关于 Excel 您应该知道的事情 Excel 之所以成为处理软件进度表的绝佳产品，原因之一是大多数 Excel 开发者使用 Excel 的唯一目的就是维护他们的软件进度表！（他们中没多少人在运行业务假设情景分析…这里说的是程序员！） 共享列表 使用文件&#x2F;共享列表命令允许每个人同时打开文件并同时编辑内容。由于您的整个团队应该持续更新进度表，这真的很有帮助。 自动筛选 这是筛选进度表的好方法，例如，您只看到分配给您的所有功能。结合自动排序，您可以看到按优先级排序的分配给您的所有功能，这实际上就是您的”待办事项”列表。很酷！ 数据透视表 这是查看汇总和交叉表的好方法。例如，您可以制作一个图表，显示每个开发人员在每个优先级上的剩余时间。数据透视表就像切片面包和巧克力奶昔。您必须学会如何使用它们，因为它们让 Excel 的功能强大了一百万倍。 WORKDAY 函数 是Excel 分析工具包中的无痛进度表中获取日历日期的好方法。","tags":[{"name":"翻译","slug":"翻译","permalink":"https://vitsumoc.github.io/tags/%E7%BF%BB%E8%AF%91/"},{"name":"软件项目","slug":"软件项目","permalink":"https://vitsumoc.github.io/tags/%E8%BD%AF%E4%BB%B6%E9%A1%B9%E7%9B%AE/"}]},{"title":"底层原理与新鲜工具","date":"2024-11-06T02:05:57.000Z","path":"底层原理与新鲜工具.html","text":"在大众眼中，程序员们似乎总有着这样的形象：他们一直在钻研某些技术的底层实现、他们一直在探索解决问题的新鲜工具。然而，对于那些与工作切实相关，被程序员称为“业务”的部分——他们却常常不屑一顾：“这不过是为了工资不得不做的事”。 底层原理？经过一段时间的工作后，我逐渐发现所谓的“底层原理”并非是一个固定的范围，而是一类知识的统称，具有以下三个特点： 我的当前工作所依赖的 我的知识范围能够触及的 我有兴趣去学习的 “底层原理”就是这么个很主观的东西：业务员觉得运维支持老哥很底层、运维老哥觉得开发人员很底层、开发人员觉得做编译器的人很底层、编译器老哥觉得做操作系统的很底层、操作系统老哥……好吧，他们真的很底层，但是他们也依赖于CPU老哥、CPU老哥依赖于研究半导体和芯片制造的老哥、然后这些人又依赖于物理学家和数学家。 我们都有好奇心，每当好奇心推动我们去探索一些事物的时候，我们就把这些事物称为“底层原理”，其实就是这样。 新鲜工具不同于底层原理带来的缓慢提升，新鲜工具则是能立竿见影的带来收益，当然，也伴随着风险。 我觉得最好的获取新鲜工具的过程是这样的： 在做业务的过程中，遇到了一个棘手的问题 自己尝试去解决，在这个过程中经历了很多思考 领导点拨或突然偶遇新鲜工具，感慨是最佳实践，从此豁然开朗 只有先经历过问题和思考，才能深刻理解答案的珍贵。从我自己的经验来看，第一次接触 redis、MQTT、时序库的时候，都曾给我带来如梦初醒的感觉。 业务的价值因此，业务的价值也不仅仅是完成本分并拿到工资，更重要的是在业务开发的过程中，驱使着我们的好奇心去探索“底层”，给我们设置难题促使我们找寻“工具”，进而一步一步的实现更有价值的自己。","tags":[{"name":"想想","slug":"想想","permalink":"https://vitsumoc.github.io/tags/%E6%83%B3%E6%83%B3/"}]},{"title":"部署Prometheus并监控Caddy","date":"2024-11-05T06:58:26.000Z","path":"部署Prometheus并监控Caddy.html","text":"普罗米修斯（Prometheus） 是一套开源的监控系统，可以用来监控并存储软件程序运行中的各项指标。 部署下载、解压。 修改文件夹中的 prometheus.yml，配置对自身指标的监控： prometheus.ymlglobal: scrape_interval: 15s # By default, scrape targets every 15 seconds. # Attach these labels to any time series or alerts when communicating with # external systems (federation, remote storage, Alertmanager). external_labels: monitor: 'codelab-monitor' # A scrape configuration containing exactly one endpoint to scrape: # Here it's Prometheus itself. scrape_configs: # The job name is added as a label `job=&lt;job_name>` to any timeseries scraped from this config. - job_name: 'prometheus' # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: ['localhost:9090'] 运行 prometheus，默认服务端口号即为 9090，已经可以通过 WEB 查看服务。 查看指标通过表达式（expression） 筛选想要查询的内容，例如 prometheus_target_interval_length_seconds 用来查询普罗米修斯对系统每次指标采集的间隔。 条件筛选表达式&#123;key=&quot;value&quot;&#125; 的方式筛选，例如 &#123;job=&quot;prometheus&quot;, quantile=&quot;0.99&quot;&#125;，表示采集任务是 prometheus（监控自己），获得其中 0.99 分位数的指标（即 99% 的数据延迟都低于该值）。 监控CaddyCaddy 中的 admin 服务已经按照普罗米修斯指标标准实现了一套监控指标，只需在全局选项中打开： &#123; servers &#123; metrics &#125; &#125; 然后在普罗米修斯中添加任务： prometheus.ymlscrape_configs: - job_name: caddy static_configs: - targets: ['localhost:2019'] 之后就能用表达式查看 caddy 提供的数据，例如这样的：go_gc_duration_seconds&#123;job=&quot;caddy&quot;&#125;。 简单总结指标监控是各种系统中都非常常见的一项需求，而普罗米修斯提供了一套标准化的解决方案。 至于能否在生产环境中满足具体项目的指标要求，则还是需要在项目开始前对具体情况进行考察和测试。","tags":[{"name":"运维","slug":"运维","permalink":"https://vitsumoc.github.io/tags/%E8%BF%90%E7%BB%B4/"},{"name":"caddy","slug":"caddy","permalink":"https://vitsumoc.github.io/tags/caddy/"},{"name":"prometheus","slug":"prometheus","permalink":"https://vitsumoc.github.io/tags/prometheus/"}]},{"title":"[解决]在NAT背后使用Caddy提供HTTPS服务","date":"2024-10-30T09:08:59.000Z","path":"[解决]在NAT背后使用Caddy提供HTTPS服务.html","text":"在 问题 的最后，我突然想到可以用 frp 代理一个 HTTP 服务出去，这样虽然不能使用 https 的功能，但是起码可以访问其他的基础功能。 于是我做了这个： http:&#x2F;&#x2F;192.168.34.197:10443 &#123; encode zstd gzip reverse_proxy https:&#x2F;&#x2F;192.168.34.197 &#123; header_up Host &#123;upstream_hostport&#125; transport http &#123; tls_insecure_skip_verify &#125; &#125; &#125; https:&#x2F;&#x2F;192.168.34.197 &#123; encode zstd gzip tls &#x2F;home&#x2F;caddy&#x2F;herong&#x2F;tls&#x2F;19216834197-cert.pem &#x2F;home&#x2F;caddy&#x2F;herong&#x2F;tls&#x2F;19216834197-key.pem handle &#123; root * &#x2F;home&#x2F;caddy&#x2F;herong&#x2F;web&#x2F;dist file_server &#125; &#125; 发现只能内网访问，通过 frp 代理地址还是不能访问（只有 HTTP ok，没有内容）。 这个事实一下就打破了我原有的想法，我原本以为是网络和 TLS 问题，现在看来不是，然后注意到 http://192.168.34.197:10443，我开始怀疑是 caddy 的路由没匹配上。 改成 :10443 后，frp 可用了。 后来把 Caddyfile 改成这样，直接按端口提供服务，一切问题都解决了： :443 &#123; encode zstd gzip tls &#x2F;home&#x2F;caddy&#x2F;herong&#x2F;tls&#x2F;19216834197-cert.pem &#x2F;home&#x2F;caddy&#x2F;herong&#x2F;tls&#x2F;19216834197-key.pem handle &#123; root * &#x2F;home&#x2F;caddy&#x2F;herong&#x2F;web&#x2F;dist file_server &#125; &#125; 也不需要按照浏览器的公网地址生成证书，反正都是信任不安全的证书，只要用内网地址生成一个证书就可以了。 总结其实 Caddy 的文档中早有说明： If you specify a hostname, only requests with a matching Host header will be honored. In other words, if the site address is localhost, then Caddy will not match requests to 127.0.0.1.","tags":[{"name":"项目实践","slug":"项目实践","permalink":"https://vitsumoc.github.io/tags/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"name":"运维","slug":"运维","permalink":"https://vitsumoc.github.io/tags/%E8%BF%90%E7%BB%B4/"},{"name":"HTTPS","slug":"HTTPS","permalink":"https://vitsumoc.github.io/tags/HTTPS/"},{"name":"caddy","slug":"caddy","permalink":"https://vitsumoc.github.io/tags/caddy/"}]},{"title":"[问题]在NAT背后使用Caddy提供HTTPS服务","date":"2024-10-28T06:02:49.000Z","path":"[问题]在NAT背后使用Caddy提供HTTPS服务.html","text":"前段时间，我尝试了 在内网中使用 HTTPS 部署，但立刻就在随后的实践中发现了一个问题。 我的领导告诉我，客户并不想运行我的证书安装程序，客户只是想打开浏览器输入地址就可以访问系统（因为这样比较方便）。 于是我就使用服务器的内网地址签发了一张证书，这样在内网通过 https://ip 的方式就可以访问系统了，虽然浏览器会提示不安全，但是所有功能也都可以正常使用，问题就算解决了。 随后，我想把这个服务通过一台路由设备代理到外网，也通过 https 访问，这样我可以方便的进行一些运维测试之类的工作。我就这样掉进了坑里。 环境涉及到的设备包括： 公网客户端（有公网地址的普通电脑一台） 路由器（用来做 NAT，只有基本的 NAT 能力） 服务器（在内网提供服务） 涉及到的网络地址包括： 路由器公网地址：36.33.xx.xx 路由器内网地址：192.168.34.1 服务器内网地址：192.168.34.197 当前已经可以在内网使用 https://192.168.34.197 访问服务，目标是通过配置路由器 NAT 和服务器上的 caddy，使公网客户端可以使用 https://36.33.xx.xx 访问服务。 公网地址的 443 端口确定可用，之前测试过 失败的尝试公网地址 443 端口代理到服务器 443最开始的思路比较简单，直接配置路由器将公网 443 端口映射到服务器 443 端口。 Caddyfile的配置也很简单： https:&#x2F;&#x2F;192.168.34.197 &#123; encode zstd gzip tls &#x2F;home&#x2F;caddy&#x2F;herong&#x2F;tls&#x2F;19216834197-cert.pem &#x2F;home&#x2F;caddy&#x2F;herong&#x2F;tls&#x2F;19216834197-key.pem handle &#123; root * &#x2F;home&#x2F;caddy&#x2F;herong&#x2F;web&#x2F;dist file_server &#125; &#125; 这种情况下，浏览器在报安全验证之后就可以进入网页，但请求不返回任何内容。观察 response 发现： content-length: 0 server: Caddy 服务到达了 caddy，但是没有提供网站内容，接下来查看 caddy 的日志发现： 2024/10/30 07:05:56.420 DEBUG http.stdlib http: TLS handshake error from 36.33.xx.xx:65222: remote error: tls: unknown certificate 2024/10/30 07:05:56.422 DEBUG events event &#123;\"name\": \"tls_get_certificate\", \"id\": \"9a9f30ec-e627-48e4-b7ee-52beb6bad236\", \"origin\": \"tls\", \"data\": &#123;\"client_hello\":&#123;\"CipherSuites\":[10794,4865,4866,4867,49195,49199,49196,49200,52393,52392,49171,49172,156,157,47,53],\"ServerName\":\"\",\"SupportedCurves\":[64250,25497,29,23,24],\"SupportedPoints\":\"AA==\",\"SignatureSchemes\":[1027,2052,1025,1283,2053,1281,2054,1537],\"SupportedProtos\":[\"h2\",\"http/1.1\"],\"SupportedVersions\":[60138,772,771],\"RemoteAddr\":&#123;\"IP\":\"36.33.xx.xx\",\"Port\":65223,\"Zone\":\"\"&#125;,\"LocalAddr\":&#123;\"IP\":\"192.168.34.197\",\"Port\":443,\"Zone\":\"\"&#125;&#125;&#125;&#125; 2024/10/30 07:05:56.422 DEBUG tls.handshake choosing certificate &#123;\"identifier\": \"192.168.34.197\", \"num_choices\": 1&#125; 2024/10/30 07:05:56.422 DEBUG tls.handshake default certificate selection results &#123;\"identifier\": \"192.168.34.197\", \"subjects\": [\"192.168.34.197\", \"*.192.168.34.197\"], \"managed\": false, \"issuer_key\": \"\", \"hash\": \"00c8e2e97b167d3f278fe71d0a962cd29174fec485fe2c00f25bb718e345f961\"&#125; 2024/10/30 07:05:56.422 DEBUG tls.handshake matched certificate in cache &#123;\"remote_ip\": \"36.33.xx.xx\", \"remote_port\": \"65223\", \"subjects\": [\"192.168.34.197\", \"*.192.168.34.197\"], \"managed\": false, \"expiration\": \"2094/10/31 03:05:40.000\", \"hash\": \"00c8e2e97b167d3f278fe71d0a962cd29174fec485fe2c00f25bb718e345f961\"&#125; 从日志里可以看到 remote error: tls: unknown certificate，我猜想是客户端不认证书，然后看到证书的 subjects 是 192.168.34.197，我就觉得是因为客户端输入的地址和证书提供的 CN 或者 SAN 不匹配导致的问题。 然后我就觉得，如果服务器能够提供 36.33.xx.xx 的证书就好了。 使用公网地址的证书然后就按照公网地址制作了证书，修改 Caddyfile： https:&#x2F;&#x2F;192.168.34.197 &#123; encode zstd gzip tls &#x2F;home&#x2F;caddy&#x2F;herong&#x2F;tls&#x2F;3633xxxx-cert.pem &#x2F;home&#x2F;caddy&#x2F;herong&#x2F;tls&#x2F;3633xxxx-key.pem handle &#123; root * &#x2F;home&#x2F;caddy&#x2F;herong&#x2F;web&#x2F;dist file_server &#125; &#125; 这下连 443 端口都没起来，查看日志是这样的： 2024/10/30 07:16:40.600 WARN tls stapling OCSP &#123;\"error\": \"no OCSP stapling for [36.33.xx.xx *.36.33.xx.xx]: no OCSP server specified in certificate\"&#125; 2024/10/30 07:16:40.600 DEBUG events event &#123;\"name\": \"cached_unmanaged_cert\", \"id\": \"ca1f1002-a94b-4af4-a7fe-a88960129791\", \"origin\": \"tls\", \"data\": &#123;\"sans\":[\"36.33.xx.xx\",\"*.36.33.xx.xx\"]&#125;&#125; 2024/10/30 07:16:40.600 DEBUG tls.cache added certificate to cache &#123;\"subjects\": [\"36.33.xx.xx\", \"*.36.33.xx.xx\"], \"expiration\": \"2094/10/31 03:01:19.000\", \"managed\": false, \"issuer_key\": \"\", \"hash\": \"15f7c42ab20c2daa817947d6d066a353fea00e6e69e2c873c33d3ebd2542257a\", \"cache_size\": 1, \"cache_capacity\": 10000&#125; 2024/10/30 07:16:40.600 INFO http.auto_https enabling automatic HTTP->HTTPS redirects &#123;\"server_name\": \"srv0\"&#125; 2024/10/30 07:16:40.600 DEBUG http.auto_https adjusted config &#123;\"tls\": &#123;\"automation\":&#123;\"policies\":[&#123;\"subjects\":[\"192.168.34.197\"]&#125;,&#123;&#125;]&#125;&#125;, \"http\": &#123;\"servers\":&#123;\"remaining_auto_https_redirects\":&#123;\"listen\":[\":80\"],\"routes\":[&#123;&#125;,&#123;&#125;]&#125;,\"srv0\":&#123;\"listen\":[\":443\"],\"routes\":[&#123;\"handle\":[&#123;\"handler\":\"subroute\",\"routes\":[&#123;\"handle\":[&#123;\"encodings\":&#123;\"gzip\":&#123;&#125;,\"zstd\":&#123;&#125;&#125;,\"handler\":\"encode\",\"prefer\":[\"zstd\",\"gzip\"]&#125;,&#123;\"handler\":\"subroute\",\"routes\":[&#123;\"handle\":[&#123;\"handler\":\"vars\",\"root\":\"/home/caddy/herong/web/dist\"&#125;,&#123;\"handler\":\"file_server\",\"hide\":[\"./Caddyfile\"]&#125;]&#125;]&#125;]&#125;]&#125;],\"terminal\":true&#125;],\"tls_connection_policies\":[&#123;\"match\":&#123;\"sni\":[\"192.168.34.197\"]&#125;,\"certificate_selection\":&#123;\"any_tag\":[\"cert0\"]&#125;&#125;,&#123;&#125;],\"automatic_https\":&#123;&#125;&#125;&#125;&#125;&#125; 怀疑是证书中的地址和 caddy 配置中的地址对不上。 于是就再签了一张 SAN 同时包括两个地址的证书。 同时包含公网和私网的证书制作了 CN 为 36.33.xx.xx，SAN 同时包括 36.33.xx.xx 和 192.168.34.197 的证书，使用后 443 端口算是能够起来了，caddy 配置文件也只改了证书： https:&#x2F;&#x2F;192.168.34.197 &#123; encode zstd gzip tls &#x2F;home&#x2F;caddy&#x2F;herong&#x2F;tls&#x2F;3633xxxxw197-cert.pem &#x2F;home&#x2F;caddy&#x2F;herong&#x2F;tls&#x2F;3633xxxxw197-key.pem handle &#123; root * &#x2F;home&#x2F;caddy&#x2F;herong&#x2F;web&#x2F;dist file_server &#125; &#125; 但是！客户端访问的问题依然存在，问题现象也和之前一模一样。只不过这次从客户端看到的证书的 CN 和 SAN 都是 36.33.xx.xx，这一点倒是符合预期。 查看 caddy 的日志，发现连报错都一样： 2024/10/30 07:25:45.013 DEBUG http.stdlib http: TLS handshake error from 36.33.xx.xx:49913: remote error: tls: unknown certificate 2024/10/30 07:25:45.015 DEBUG events event &#123;\"name\": \"tls_get_certificate\", \"id\": \"aa9a98f8-1058-4331-a1d9-e642f0645cf4\", \"origin\": \"tls\", \"data\": &#123;\"client_hello\":&#123;\"CipherSuites\":[19018,4865,4866,4867,49195,49199,49196,49200,52393,52392,49171,49172,156,157,47,53],\"ServerName\":\"\",\"SupportedCurves\":[60138,25497,29,23,24],\"SupportedPoints\":\"AA==\",\"SignatureSchemes\":[1027,2052,1025,1283,2053,1281,2054,1537],\"SupportedProtos\":[\"h2\",\"http/1.1\"],\"SupportedVersions\":[51914,772,771],\"RemoteAddr\":&#123;\"IP\":\"36.33.xx.xx\",\"Port\":49914,\"Zone\":\"\"&#125;,\"LocalAddr\":&#123;\"IP\":\"192.168.34.197\",\"Port\":443,\"Zone\":\"\"&#125;&#125;&#125;&#125; 2024/10/30 07:25:45.015 DEBUG tls.handshake choosing certificate &#123;\"identifier\": \"192.168.34.197\", \"num_choices\": 1&#125; 2024/10/30 07:25:45.015 DEBUG tls.handshake default certificate selection results &#123;\"identifier\": \"192.168.34.197\", \"subjects\": [\"36.33.xx.xx\", \"192.168.34.197\"], \"managed\": false, \"issuer_key\": \"\", \"hash\": \"109ba9582f4bde945134e6794168af4c947a3cdf6d0391388cb09310fb811def\"&#125; 2024/10/30 07:25:45.015 DEBUG tls.handshake matched certificate in cache &#123;\"remote_ip\": \"36.33.xx.xx\", \"remote_port\": \"49914\", \"subjects\": [\"36.33.xx.xx\", \"192.168.34.197\"], \"managed\": false, \"expiration\": \"2094/10/31 07:24:23.000\", \"hash\": \"109ba9582f4bde945134e6794168af4c947a3cdf6d0391388cb09310fb811def\"&#125; 其他的失败尝试例如另起一个服务端口，然后使用反向代理提供服务： https:&#x2F;&#x2F;192.168.34.197:10443 &#123; encode zstd gzip tls &#x2F;home&#x2F;caddy&#x2F;herong&#x2F;tls&#x2F;3633xxxx-cert.pem &#x2F;home&#x2F;caddy&#x2F;herong&#x2F;tls&#x2F;3633xxxx-key.pem reverse_proxy https:&#x2F;&#x2F;192.168.34.197 &#123; header_up Host &#123;upstream_hostport&#125; &#125; &#125; https:&#x2F;&#x2F;192.168.34.197 &#123; encode zstd gzip tls &#x2F;home&#x2F;caddy&#x2F;herong&#x2F;tls&#x2F;19216834197-cert.pem &#x2F;home&#x2F;caddy&#x2F;herong&#x2F;tls&#x2F;19216834197-key.pem handle &#123; root * &#x2F;home&#x2F;caddy&#x2F;herong&#x2F;web&#x2F;dist file_server &#125; &#125; 我期望着第一个服务能够提供公网地址的证书，但是不行。 甚至用 HTTP 都不行： http:&#x2F;&#x2F;192.168.34.197:10443 &#123; encode zstd gzip reverse_proxy https:&#x2F;&#x2F;192.168.34.197 &#123; header_up Host &#123;upstream_hostport&#125; &#125; &#125; https:&#x2F;&#x2F;192.168.34.197 &#123; encode zstd gzip tls &#x2F;home&#x2F;caddy&#x2F;herong&#x2F;tls&#x2F;19216834197-cert.pem &#x2F;home&#x2F;caddy&#x2F;herong&#x2F;tls&#x2F;19216834197-key.pem handle &#123; root * &#x2F;home&#x2F;caddy&#x2F;herong&#x2F;web&#x2F;dist file_server &#125; &#125; 思考 是不是提供 HTTPS 服务的设备必须同时拥有地址和证书？ 大型企业是否会遇到这样的问题？他们是怎么解决的？是不是有相关解决方案的供应商？ 如果在更低层的网络上进行编程，能否解决这个问题？例如在服务器的 TCP 层进行编程？是否已经有相关的解决方案？ 好像可以用 frp 解决？？！！","tags":[{"name":"项目实践","slug":"项目实践","permalink":"https://vitsumoc.github.io/tags/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"name":"运维","slug":"运维","permalink":"https://vitsumoc.github.io/tags/%E8%BF%90%E7%BB%B4/"},{"name":"HTTPS","slug":"HTTPS","permalink":"https://vitsumoc.github.io/tags/HTTPS/"},{"name":"caddy","slug":"caddy","permalink":"https://vitsumoc.github.io/tags/caddy/"}]},{"title":"WEB项目集成人脸识别","date":"2024-10-22T08:32:48.000Z","path":"WEB项目集成人脸识别.html","text":"前端开发的一大痛点就是参考资料太多，css，h5 标准，浏览器的各种规范等等。AI 的出现真的很大程度上缓解了这些问题，让我这种半桶水的前端也能够快速的定位到我需要的文档。 项目中需要让客户使用人脸识别验证身份，很自然的想到如下实现思路： 浏览器调用摄像头，获得视频 视频截图，发往后端 后端将照片和系统现有用户比对 浏览器调用摄像头托 AI 的福，很快就查到了关键词：摄像头调用使用 navigator.mediaDevices 相关接口，视频播放使用 video 元素。 视频截图直接用 canvas 把 video 内容画上来，当成图片发给后端就好。 后端比对使用 github 的 face_recognition 仓库，该仓库可以使用命令行进行人脸比对，用 go 稍微封装一下就好了。 再次感谢无数开源作者为世界做出的贡献。 前端代码示例用 vue2 做了一个简易的人脸识别弹窗： &lt;template&gt; &lt;div class&#x3D;&quot;app-container&quot;&gt; 选择您的摄像头设备 &lt;el-button-group&gt; &lt;el-button v-for&#x3D;&quot;(camera, x) in cameras&quot; :key&#x3D;&quot;x&quot; @click&#x3D;&quot;playThis(camera)&quot;&gt;&#123;&#123; camera.label &#125;&#125;&lt;&#x2F;el-button&gt; &lt;&#x2F;el-button-group&gt; &lt;video id&#x3D;&quot;video&quot;&gt;&lt;&#x2F;video &gt; &lt;canvas id&#x3D;&quot;photo&quot; width&#x3D;&quot;640&quot; height&#x3D;&quot;420&quot; &#x2F;&gt; &lt;&#x2F;div&gt; &lt;&#x2F;template&gt; &lt;script&gt; export default &#123; data() &#123; return &#123; cameras: [], &#x2F;&#x2F; 摄像头列表 video_dom: undefined, timeHandler: undefined &#125; &#125;, mounted() &#123; const self &#x3D; this this.video_dom &#x3D; document.getElementById(&#39;video&#39;) navigator.mediaDevices.enumerateDevices().then(function(devices) &#123; devices.forEach(device &#x3D;&gt; &#123; if (device.kind &#x3D;&#x3D;&#x3D; &#39;videoinput&#39;) &#123; self.cameras.push(device) &#125; &#125;) &#125;).catch(function(err) &#123; alert(&#39;你的浏览器无法获摄像头设备列表&#39;) this.$emit(&#39;cancel&#39;) &#125;) &#125;, methods: &#123; playThis(camera) &#123; this.atClose() const self &#x3D; this navigator.mediaDevices.getUserMedia(&#123; video: &#123; deviceId: camera.deviceId &#125; &#125;).then(function(stream) &#123; const video &#x3D; document.getElementById(&#39;video&#39;) video.srcObject &#x3D; stream video.play() self.toPhoto() &#125;).catch(function(err) &#123; console.log(&#39;获取摄像头媒体流时出现错误：&#39;, err) alert(&#39;你的浏览器无法获取此设备流&#39;) self.$emit(&#39;cancel&#39;) &#125;) &#125;, toPhoto() &#123; let self &#x3D; this const canvas &#x3D; document.getElementById(&#39;photo&#39;) const context &#x3D; canvas.getContext(&#39;2d&#39;) const video &#x3D; document.getElementById(&#39;video&#39;) this.timeHandler &#x3D; setTimeout(function() &#123; context.drawImage(video, 0, 0, 640, 420) let img &#x3D; canvas.toDataURL(&#39;image&#x2F;jpg&#39;) img &#x3D; img.split(&#39;,&#39;)[1] &#x2F;&#x2F; 照片的 base64 &#x2F;&#x2F; TODO 发到后端做人脸识别判断 self.toPhoto() &#125;,300) &#125;, atClose() &#123; clearTimeout(this.timeHandler) const video &#x3D; document.getElementById(&#39;video&#39;) if (video &amp;&amp; video.srcObject) &#123; let stream &#x3D; video.srcObject let tracks &#x3D; stream.getTracks() tracks.forEach(function(track) &#123; track.stop() &#125;) video.srcObject &#x3D; null &#125; &#125; &#125; &#125; &lt;&#x2F;script&gt; &lt;style lang&#x3D;&quot;scss&quot;&gt; #video &#123; width: 640px; height: 420px; background: #333; margin-top: 20px; &#125; #photo &#123; width: 640px; height: 420px; display: none; &#125; &lt;&#x2F;style&gt;","tags":[{"name":"项目实践","slug":"项目实践","permalink":"https://vitsumoc.github.io/tags/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"}]},{"title":"内网项目添加HTTPS支持","date":"2024-10-22T02:43:29.000Z","path":"内网项目添加HTTPS支持.html","text":"公司实施了一些部署在客户内网的项目，思来想去还是用 HTTPS 访问服务器比较好，既解决了很多数据安全的问题，又满足了很多浏览器功能的安全性要求。 实现路径大致如下： 创建和签名SSL&#x2F;TLS证书 部署 HTTPS 服务 修改 DNS 或客户端 host，让客户端可将域名解析到服务器 客户端安装证书 创建和签名 SSL&#x2F;TLS 证书 参考参考 CA私钥和自签证书 openssl req -x509 -newkey rsa:4096 -days 25568 -keyout ca-key.pem -out ca-cert.pem -subj \"/C=cn/ST=shenzhen/L=shenzhen/O=msj/OU=msj/CN=msj\" Enter PEM pass phrase:****** 服务器私钥和请求 openssl req -newkey rsa:4096 -nodes -keyout battery-cap-key.pem -out battery-cap-req.pem -subj \"/C=cn/ST=shenzhen/L=shenzhen/O=msj/OU=msj/CN=battery-cap.msj\" -reqexts SAN -config openssl.cnf CA 签署服务器证书 openssl ca -in battery-cap-req.pem -md sha256 -days 25568 -keyfile ca-key.pem -cert ca-cert.pem -extensions SAN -config openssl.cnf -out battery-cap-cert.pem 部署 HTTPS 服务 参考 可以先部署静态站点进行测试 battery-cap.msj &#123; encode zstd gzip tls &#x2F;home&#x2F;caddy&#x2F;herong&#x2F;tls&#x2F;battery-cap-cert.pem &#x2F;home&#x2F;caddy&#x2F;herong&#x2F;tls&#x2F;battery-cap-key.pem handle &#123; root * &#x2F;home&#x2F;caddy&#x2F;herong&#x2F;web&#x2F;dist file_server &#125; &#125; 手动修改hostC:\\Windows\\System32\\drivers\\etc\\hosts 192.168.34.197 battery-cap.msj 客户端手动安装证书参考 自动修改host、安装证书通过一个程序将修改 host 文件和安装证书两件事情放到一起，方便实施同事交付。 func main() &#123; domain := \"battery-cap.msj\" address := \"192.168.34.197\" cert := \"msj-cert.pem\" // 日志 file, err := os.Create(\"证书安装.log\") if err != nil &#123; MessageBoxPlain(\"提示\", \"失败\") log.Fatal(err) &#125; defer file.Close() logger := log.New(file, \"\", log.LstdFlags) // 参数回显 logger.Println(\"域名：\" + domain) logger.Println(\"地址：\" + address) logger.Println(\"证书：\" + cert) // 改host logger.Println(\"修改 host 文件\") hostFile, err := os.OpenFile(\"C:/Windows/System32/drivers/etc/hosts\", os.O_WRONLY|os.O_APPEND, 0600) if err != nil &#123; MessageBoxPlain(\"提示\", \"失败\") logger.Fatal(err) return &#125; defer hostFile.Close() hostFile.WriteString(address + \" \" + domain + \"\\n\") logger.Println(\"ok\") // 安装证书 logger.Println(\"安装证书\") cmd := exec.Command(\"cmd\", \"/C\", \"certmgr.exe /c /add \"+cert+\" /s root\") output, err := cmd.CombinedOutput() if err != nil &#123; MessageBoxPlain(\"提示\", \"失败\") logger.Fatal(err) &#125; logger.Println(output) logger.Println(\"ok\") MessageBoxPlain(\"提示\", \"完成\") &#125;","tags":[{"name":"项目实践","slug":"项目实践","permalink":"https://vitsumoc.github.io/tags/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"name":"运维","slug":"运维","permalink":"https://vitsumoc.github.io/tags/%E8%BF%90%E7%BB%B4/"},{"name":"HTTPS","slug":"HTTPS","permalink":"https://vitsumoc.github.io/tags/HTTPS/"},{"name":"caddy","slug":"caddy","permalink":"https://vitsumoc.github.io/tags/caddy/"}]},{"title":"在Ubuntu上安装SVN服务","date":"2024-09-11T05:22:06.000Z","path":"在Ubuntu上安装SVN服务.html","text":"参考 安装 SVN 服务sudo apt-get install subversion 创建根目录文件夹mkdir /root/svn 创建仓库文件夹mkdir /root/svn/shidian 创建仓库svnadmin create /root/svn/shidian 仓库创建成功文件夹中生成了下列内容： conf db format hooks locks README.txt 启动服务svnserve -d -r &#x2F;root&#x2F;svn –listen-port 17749 创建全局的账号密码和权限文件touch /root/svn/passwd touch /root/svn/authz 添加账号密码vi /root/svn/passwd passwd[users] user1 = password 添加权限配置vi /root/svn/authz 可按分组或按用户配置： authz[groups] coder = user1,user2 [shidian:/] @coder = rw * = r [u1:/] user1 = rw 在仓库中配置鉴权vi /root/svn/shidian/conf/svnserve.conf 修改下列四行 svnserve.confanon-access &#x3D; none auth-access &#x3D; write password-db &#x3D; &#x2F;root&#x2F;svn&#x2F;passwd authz-db &#x3D; &#x2F;root&#x2F;svn&#x2F;authz","tags":[{"name":"运维","slug":"运维","permalink":"https://vitsumoc.github.io/tags/%E8%BF%90%E7%BB%B4/"}]},{"title":"[转]netperf和iperf网络性能测试小结","date":"2024-08-28T03:16:48.000Z","path":"[转]netperf和iperf网络性能测试小结.html","text":"原文","tags":[{"name":"网络工具","slug":"网络工具","permalink":"https://vitsumoc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7/"},{"name":"运维","slug":"运维","permalink":"https://vitsumoc.github.io/tags/%E8%BF%90%E7%BB%B4/"}]},{"title":"Caddy常用配置示例","date":"2024-08-27T01:31:29.000Z","path":"Caddy常用配置示例.html","text":"Caddy常用配置示例最近将公司部分业务从 nginx 迁移到 caddy，为了避免翻车，总结了几个最常见的用法 端口固定响应 用来测试运维同事有没有正确开放 7000 端口。 :7000 &#123; respond &quot;Hello, im 7000！&quot; &#125; 代理静态站点和后端服务 前端页面存放在 /home/lenovo/vc/ywyl/web 后台服务接口格式 http://127.0.0.1/m/user/info :7000 &#123; # 静态站点根目录 root * &#x2F;home&#x2F;lenovo&#x2F;vc&#x2F;ywyl&#x2F;web # 后端服务, 真实地址是 http:&#x2F;&#x2F;127.0.0.1:9090&#x2F;m&#x2F;user&#x2F;info handle &#x2F;m&#x2F;* &#123; reverse_proxy http:&#x2F;&#x2F;127.0.0.1:9090 &#125; # 静态站点服务 handle &#123; file_server &#125; &#125; 自定义前缀用来区分业务 将 http://localhost:7000/ecard/info 代理到 http://ipServer:80/info :7000 &#123; handle_path &#x2F;ecard&#x2F;* &#123; reverse_proxy http:&#x2F;&#x2F;ipServer:80 &#125; &#125; 自定义前缀, 匹配一个有后缀的服务 将 http://127.0.0.1:8090/test2/tt2 代理到 http://127.0.0.1:8080/tt1/tt2 :8090 &#123; # 8090&#x2F;test2&#x2F;tt2 -&gt; 8080&#x2F;tt1&#x2F;tt2 handle_path &#x2F;test2&#x2F;* &#123; rewrite * &#x2F;tt1&#123;uri&#125; reverse_proxy http:&#x2F;&#x2F;127.0.0.1:8080 &#125; &#125; 后端服务是 HTTPS, 或是会校验 Host 头的情况 需要求改请求头, 否则请求不成功 example.com &#123; reverse_proxy https:&#x2F;&#x2F;example.com &#123; header_up Host &#123;upstream_hostport&#125; &#125; &#125; 添加前缀, 代理某后端的 GET 请求, 处理路径问题 :8090/comm/?p=aaa -&gt; https://example.com/index.php?p=aaa 此处可以使用 uri[1:] 语法手动处理 url :8090 &#123; handle_path &#x2F;comm&#x2F;* &#123; rewrite * &#x2F;index.php&#123;uri[1:]&#125; reverse_proxy https:&#x2F;&#x2F;example.com &#123; header_up Host &#123;upstream_hostport&#125; &#125; &#125; &#125; 一些排查问题的方法使用 apt install 安装后，caddy 的服务配置文件默认放置在 /lib/systemd/system。 caddy 会默认创建一个 caddy 用户用来执行服务，并将此用户的 $HOME 设置为 /var/lib/caddy，这意味着相关的证书、自动存储的配置文件会被保存在这里。 如果是排查和证书相关的问题，使用 root 用户和 caddy 用户的环境可能不同，此时可以切换到 caddy 用户检查： 先使用 root 授权，让普通用户也可以使用 caddy 程序占用 80 和 443 端口： setcap 'cap_net_bind_service=+ep' /usr/bin/caddy 再进入 caddy 用户，手动运行程序，记得在配置文件前先打开 debug 显示： su -s /bin/bash caddy cd /etc/caddy caddy run -c Caddyfile","tags":[{"name":"项目实践","slug":"项目实践","permalink":"https://vitsumoc.github.io/tags/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"name":"运维","slug":"运维","permalink":"https://vitsumoc.github.io/tags/%E8%BF%90%E7%BB%B4/"},{"name":"caddy","slug":"caddy","permalink":"https://vitsumoc.github.io/tags/caddy/"}]},{"title":"一个自动投票的小工具","date":"2024-08-01T11:05:15.000Z","path":"一个自动投票的小工具.html","text":"起因公司要参加某个物联网展，展方为了宣传做了一个带拉票功能的宣传页，就是那种很常见的点开链接可以为自己支持的公司投票的那种。公司的前台姐姐把投票链接发到了群里，我很顺手的就投了一票，然后又顺手看了一眼网络请求： 投票动作是一个 POST 请求，请求体格式是 FormData，内容很简单 token: C791752B7C5342703C6B0635212FBAC309AAF52717C5557BAE2FB8D4FC3BE5E8BBBDD5D6F8CFBD15 id: 980943910375260160 我就在群里说了一句：“好像可以刷票哦”，前台姐姐立刻给我安排了一波情绪价值：“哇，你好厉害哦”之类的。得了，这个活就算接下来了。 思考过程 先拿 PostMan 胡乱测了一下，同样的请求内容不能再发，服务端会报错：您已经投票看来是对同一 token 投同一 id 的频率做了限制了。 修改 id 可以投票成功，但是就投给别的公司了 &#x3D;。&#x3D;，这显然不符合需求。 修改 token 以后调接口会报错，看来必须使用服务端生成的 token 才行。 用手机打开链接，又可以投一次，看来没有账号绑定之类的机制，换了设备就能投。 手机和电脑都连的公司的 Wifi，看来也没有 IP 地址限制。 用电脑换了个浏览器也能投，看来没有设备指纹之类的东西，应该就是认浏览器。 在浏览器里到处找，发现 local_sotrage 存了个这个：token:Qzc5MTc1MkI3QzUzNDI3MDNDNkIwNjM1MjEyRkJBQzMwOUFBRjUyNzE3QzU1NTdCQUUyRkI4RDRGQzNCRTVFOEJCQkRENUQ2RjhDRkJEMTU= 等号结尾，有点眼熟，base64解一下，果然和发请求的 token 对上了。 把这些乱七八糟的缓存都清了，重新打开页面，发现得到了一个新的 token，又能投一票。 行了，路线通了，这下不会让前台姐姐失望了。 实现本人不是 python 程序员，也没有什么爬虫经验，所有代码都是 AI 帮忙写的。 其实只有两个步骤，一个是打开浏览器获得新 token： 获得tokendef getToken(): global token options = Options() options.headless = True driver = webdriver.Chrome(options=options) driver.get(openUrl) # 拿 token script = \"return localStorage.getItem('token');\" tokenB64 = driver.execute_script(script) driver.quit() # 获取token decoded_bytes = base64.b64decode(tokenB64) token = decoded_bytes.decode('utf-8') 然后就是投票： 投票def vote(): global id global token # 刷票 print(\"准备投一票：\", time.ctime()) # id 代表公司 print(\"id：\", id) # 获得的 token print(\"token：\", token) # 组装请求 data = &#123; \"id\": id, \"token\": token &#125; headers = &#123; # \":authority:\": \"api.iotexpo.com.cn\", # \":method:\": \"POST\", # \":path:\": \"/Expo/ProVoteByMinApp\", # \":scheme:\": \"https\", \"Accept\": \"application/json, text/javascript, */*; q=0.01\", \"Accept-Encoding\": \"gzip, deflate, br, zstd\", \"Accept-Language\": \"zh-CN,zh;q=0.9\", \"Content-Length\": \"108\", \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\", \"Origin\": \"https://www.iotexpo.com.cn\", \"Priority\": \"u=1, i\", \"Referer\": \"https://www.iotexpo.com.cn/\", \"Sec-Ch-Ua\": \"\\\"Not/A)Brand\\\";v=\\\"8\\\", \\\"Chromium\\\";v=\\\"126\\\", \\\"Google Chrome\\\";v=\\\"126\\\"\", \"Sec-Ch-Ua-Mobile\": \"?0\", \"Sec-Ch-Ua-Platform\": \"\\\"Windows\\\"\", \"Sec-Fetch-Dest\": \"empty\", \"Sec-Fetch-Mode\": \"cors\", \"Sec-Fetch-Site\": \"same-site\", \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\", &#125; # 发送 response = requests.post(voteUrl, data=data, headers=headers) # 打印结果 resp = json.loads(response.text) print(\"结果：\") print(resp) 然后定时投票就行了。 很小的案例，关键是又成功刷了一波好感度 &#x3D;。&#x3D;","tags":[{"name":"小玩具","slug":"小玩具","permalink":"https://vitsumoc.github.io/tags/%E5%B0%8F%E7%8E%A9%E5%85%B7/"},{"name":"python","slug":"python","permalink":"https://vitsumoc.github.io/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://vitsumoc.github.io/tags/%E7%88%AC%E8%99%AB/"}]},{"title":"[译]GP2040-CE FAQ","date":"2024-07-30T06:27:46.000Z","path":"[译]GP2040-CE FAQ.html","text":"GP2040-CE 是一个基于树莓派（或其他） RP 2040 微处理器的开源游戏控制器固件项目，支持多种输入模式，适配多个平台。本文译自 GP2040-CE 项目官网，FAQ 页面。 常见问题我应该使用哪种输入模式？这取决于您使用的平台： 使用 XInput Mode 作为 PC 游戏和第三方主机适配的首选模式 在 PS4 或 PS5 中运行 PS4 游戏时，使用 PS4 Mode 在 PS3 或 PS4 中使用传统模式时，使用 PS3 Mode 在任天堂 Switch 上使用 Switch Mode 在 MAME cabinets 或是 PC 音游等场景使用 Keyboard Mode 如果您配置了 USB 主机端口、启用了直通功能以及适当的验证设备，则可以在以下情况下使用 GP2040-CE 控制器。 在支持 categorized 控制器（例如街机摇杆、赛车方向盘、飞行模拟操纵杆等）的 PS5 系统上的 PS5 游戏上使用 PS4 Input Mode 在 Xbox One、Xbox Series X 和 Xbox Series S 上使用 Xbox One Input Mode 如果您使用的是经典或迷你主机，则还有其他 USB 输入模式可与这些模拟主机一起使用。 Sega Genesis&#x2F;MegaDrive Mini NEOGEO Mini PC Engine&#x2F;Turbografx 16 Mini EGRET II Mini ASTROCITY Mini Playstation Classic GP2040-CE 是否原生支持 PS5，PS4 或 Xbox Series 主机？这些主机实现了一些安全措施用来阻止未经授权的控制器接入，破解或绕过这些措施的过程可能涉及到一些法律问题。如果找到用户友好且完全合法的实现方法，例如 PS4 Input Mode 的实现，将来会支持这些主机。 目前通过直通身份验证支持 PS5、Xbox One 和 Xbox Series 主机 PS5 目前仅支持使用直通身份验证；请参阅 PS5 Input Mode。 Xbox One 和 Xbox Series 主机仅支持使用直通身份验证；请参阅 Xbox One Input Mode。 我能在一个设备上使用多个 GP2040-CE 控制器吗？是的！每个 GP2040-CE 板都被视为一个单独的控制器。但您需要注意，确保同一时间只运行了一个 Web 配置页面。 如果您需要在街机中安装基于 GP2040-CE 的控制板，请查看 Player Number add-on 用来强制指定每个玩家的编号。 GP2040-CE 的输入延迟真的低于 1ms？是的！如果您的平台支持 1000 Hz USB 轮询，输入延迟将小于 1 毫秒。GP2040-CE 在所有模式下默认配置为 1000 Hz&#x2F;1 ms 轮询，但某些系统会覆盖或忽略控制器请求的轮询速率。1000 Hz 轮询率已确认适用于 PC 和 MiSTer。即使您的平台不支持高速 USB 轮询，GP2040-CE 仍会以目标系统允许的最大速度读取和处理您的输入。 RGB LED、玩家 LED 和 OLED 显示屏等附加功能是否会影响性能？完全不会！Pico 的 RP2040 处理器有两个内核，GP2040-CE 将其中一个核心专门用于读取、处理和发送玩家输入，所有辅助功能（例如 LED 和显示器）都在辅助核心上运行。无论集成了多少功能，GP2040-CE 都不会引入额外的输入延迟。 为什么按键会使用 B3，A1，S2 这种奇怪的标签？GP2040-CE 使用通用系统来处理按钮输入，类似于带有一些额外按钮的传统 Play Station 控制器布局。 4 方向键 (B1-B4) 4 肩键 (L1，L2，R1，R2) 选择和启动（S1，S2）摇杆按下（L3，R3） 两个辅助键（A1，A2）用于引导、PS键、触摸屏、Home 键或者截图键等 GP2040-CE 文档和 Web 配置器都提供了一个下拉菜单，用于将按钮标签更改为更熟悉的控制器布局。您可以参考 GP2040-CE 说明书 上的按键映射表。 技术问题内建的 Web 配置页面是什么魔术？这里没有什么魔法，只是一些很酷的库一起工作： 使用 React 和 Bootstrap 的单页应用程序嵌入在 GP2040-CE 固件中 TinyUSB 库通过 RNDIS 提供虚拟网络连接 lwIP 库提供了一个 HTTP 服务器，为嵌入式 React 应用程序和 Web 配置 API 提供服务 ArduinoJson 库用于Web API请求的序列化和反序列化","tags":[{"name":"豆知识","slug":"豆知识","permalink":"https://vitsumoc.github.io/tags/%E8%B1%86%E7%9F%A5%E8%AF%86/"},{"name":"嵌入式","slug":"嵌入式","permalink":"https://vitsumoc.github.io/tags/%E5%B5%8C%E5%85%A5%E5%BC%8F/"}]},{"title":"[转][译]写给工程师：关于证书（certificate）和公钥基础设施（PKI）的一切 （SmallStep, 2018）","date":"2024-07-22T07:55:29.000Z","path":"[译]写给工程师：关于证书（certificate）和公钥基础设施（PKI）的一切 （SmallStep, 2018）.html","text":"原作者：MIKE MALONE，发布于： Everything you should know about certificates and PKI but are too afraid to ask 译者：ArthurChiao，发布于： [译] 写给工程师：关于证书（certificate）和公钥基础设施（PKI）的一切（SmallStep, 2018）","tags":[{"name":"转载","slug":"转载","permalink":"https://vitsumoc.github.io/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"HTTPS","slug":"HTTPS","permalink":"https://vitsumoc.github.io/tags/HTTPS/"}]},{"title":"简单实现windows下的应用热备","date":"2024-07-03T02:44:12.000Z","path":"简单实现windows下的应用热备.html","text":"在项目开发中遇到了应用系统需要热备的需求，于是按照以前做过 VRRP 的经验，在 IP 地址可以切换的前提条件下设计了一些应用层的切换方式，等到应用层都准备完毕、项目即将上线的时候，突然傻眼了，发现 Windows 不支持 VRRP。 我当然知道，强大的 WindowsServer 系统肯定是能支持这种 IP 地址切换的功能的，只是我确实对 WindowsServer 的管理一无所知，上网搜索一番后也没有什么收获，又觉得自己需要的切换功能实在很简单，于是决定自己做一个简单的实现。 需求大概需求是这样： 有两台服务器，主机和备机。 有三个IP地址，主机IP，备机IP，业务IP。 客户通过业务IP访问服务。 业务IP平时配置在主机上，当主机不可用（断电或断网）时则配置在备机上。 思路有了这样的需求，思路就很简单了，主机始终保持自己有业务IP，备机持续对主机 ping 包，在主机不可用时给自己配置业务IP，在主机可用后把自己的业务IP删除就行了。那么需要解决的问题就变成了这些： 程序通过配置文件了解自己是主机还是备机 程序可以添加或者删除IP配置 程序可以ping包并了解结果 上网搜了一下，添加或者删除 IP 配置都可以通过命令解决： netsh interface ip add address name=\"Ethernet\" addr=192.168.34.200 mask=255.255.255.0 gateway=192.168.34.1 netsh interface ip delete address name=\"Ethernet\" addr=192.168.34.200 而 ping 包这件事可以通过一个库来解决 go-fastping 按照以上思路，很快一个可以切换 IP 的程序就制作完成了，再使用 nssm 把他和应用服务什么的都注册到一起，轻松完成需求。 踩坑测试过程中发现，主机切换到备机始终正常，备机切换主机一直失败。 观察发现，备机切换主机的过程中，会有短时间的主备机同时在线且同时拥有虚IP的情况。切换主机后（也就是备机删除虚 IP 配置），主机虚 IP 不可用，主机本机也 ping 不通虚 IP。 并不清楚原理，可能是 windows 系统会自己禁用这种地址冲突的子 IP。 发现只要主机重新配置一次子 IP 就可以正常使用，于是给主机添加了一个接收通知的接口，当备机让出虚拟 IP 的所有权后，给主机发送一条通知，主机收到通知后执行一次把虚拟 IP 删除再重新添加的动作，随后虚拟 IP 可以正常使用。 实现最终的实现也放到 github 啦，在这里vwinvrrp。","tags":[{"name":"项目实践","slug":"项目实践","permalink":"https://vitsumoc.github.io/tags/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"}]},{"title":"使用garble混淆Go程序","date":"2024-07-02T08:59:54.000Z","path":"使用garble混淆Go程序.html","text":"最近在做的一个产品，走的是私有化部署的路线，需要给很多客户部署服务，然后卖 License 的模式。 很自然的，就遇到了如何防止客户破解的问题，毕竟一个 License 也不便宜，客户破解的动机和经费还是很充足的。 最后决定使用这个库： https://github.com/burrowers/garble 可以对 Go 项目编译出的可执行程序进行混淆，删除额外信息，混淆代码中的明文字符串等等。 当然，我也知道没有什么方案能够完全防止软件破解，只是这种方法可以增大破解难度，只要黑客的报价比我的 License 更贵就可以了。","tags":[{"name":"项目实践","slug":"项目实践","permalink":"https://vitsumoc.github.io/tags/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"name":"Go","slug":"Go","permalink":"https://vitsumoc.github.io/tags/Go/"}]},{"title":"mysql bin_log 塞满了磁盘","date":"2024-06-26T02:39:35.000Z","path":"mysql bin_log 塞满了磁盘.html","text":"项目制的开发就是这样，你能从中获得一些宝贵的一手经验，但代价是每一次经验背后都有一个“事故”。 问题客户告诉我，服务器磁盘增长速度异常，项目上线二十天，mysql 文件夹的磁盘占用就超过 700G。 非常非常感谢这位能够提前帮我们发现问题的客户，责任心和专业性都很强。 经检查，是 mysql&#x2F;data 文件夹中出现了大量的 binlog.xxxxxx 文件，每个文件大小大约 1GB，每天产生若干个文件。 查阅资料后，发现该文件是 mysql 的二进制日志，可以用来进行数据恢复、数据备份等操作。（在我这个项目中用不到，另有备份机制）。 处理解决方案是这样的： 在 mysql 命令行中查找 log_bin 相关的配置 show variables like &#39;%log_bin%&#39;; 发现输出包括 log_bin ON，表示二进制日志功能已经被打开。 通过 PURGE BINARY LOGS BEFORE &#39;2024-06-26 10:00:00&#39;; 删除原有的日志文件 必须在日志功能开启的情况下执行上述命令删除文件，否则命令无效 在 mysql 启动脚本中添加参数 --disable-log-bin，重启 mysql 服务，再次检查 log_bin 配置 发现输出包括 log_bin OFF，表示二进制日志功能已经被关闭，后续不再产生日志。 参考文档 Binary Logging Options and Variables MySQL的binlog日志详解","tags":[{"name":"项目实践","slug":"项目实践","permalink":"https://vitsumoc.github.io/tags/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"}]},{"title":"关闭Windows程序弹窗","date":"2024-06-18T09:22:21.000Z","path":"关闭Windows程序弹窗.html","text":"本文记录了一个使用工具寻找弹窗、分析弹窗、修改程序的过程，对于理解 Windows 编程有一些作用本文中的内容全部来自于此 视频 通过 spy++ 获得弹窗的窗口类spy++ 随着 Visual Studio 一同安装，在工具菜单中。 通过其中的窗口搜索功能，可以搜索到弹出窗口的窗口名称和窗口类，例如在我的 WinRAR 中： 广告弹窗可以看到窗口类为 RarReminder 句柄：001E0A8C 窗口名称：WinRAR 6.24b1 Expired Notification | Your Free Trial Period has Ended! 窗口类：RarReminder 注册弹窗是 Dialog， 句柄：007A0950 窗口名称：Please purchase WinRAR license 窗口类：#32770 (对话框) 通过 apimonitor 截取软件对系统 api 的调用从 这里 下载工具。 查找并监控 CreateWindow 相关函数，Dialog 相关函数。 选择被监控程序 WinRAR 并启动，可以看到程序调用 api 的所有记录。 广告弹窗调用类为： RarReminder 注册弹窗的调用为： DialogBoxParamW ( 0x00007ff643070000, “REMINDER”, 0x0000000000600b84, 0x00007ff64316d600, 0 ) 查看堆栈，记录顶部偏移地址，分别为： 0xbf3cc 0xbf46d 使用 IDA Pro 修改对应位置的机器码使用 IDA Pro 查找对应位置的机器码，应该是创建窗口或弹窗的内容。 使用十六进制编辑器，编辑可执行文件，将此处的机器码全部修改为 0x90 （空转）","tags":[{"name":"豆知识","slug":"豆知识","permalink":"https://vitsumoc.github.io/tags/%E8%B1%86%E7%9F%A5%E8%AF%86/"},{"name":"windows","slug":"windows","permalink":"https://vitsumoc.github.io/tags/windows/"}]},{"title":"简单的Linux服务管理","date":"2024-05-22T07:30:38.000Z","path":"简单的Linux服务管理.html","text":"在这里记录一些基础的 Linux 服务管理维护方式，作为程序员，总是会用到的。 手动运行以一个 Java Web 项目为例，手动运行 Jar 包可能是这样的： nohup java -jar YongWang-1.0-SNAPSHOT.jar > /dev/null 2>&amp;1 &amp; 这样程序就可以在后台运行，但是有一些缺点： 系统重启后程序不会启动 只能通过 ps 查询进程状态 想要关闭程序的话，需要通过 ps 查找进程号，然后手动 kill 难以接入各种自动化工具 因此，将程序注册为服务是一个更好的选择。 使用 root 用户操作系统级服务注册服务如果想将我们的程序注册为服务，首先需要编写一个配置文件，这个文件可以放在 /etc/systemd/system/ 路径下。 文件的名称一般参考服务的名称，并以 .server 结尾，因此在这个例子中，我的文件名为 yongwang.service： yongwang.service[Unit] Description=YongWang Server [Service] WorkingDirectory=/home/vc/ywyl/server/ ExecStart=java -jar YongWang-1.0-SNAPSHOT.jar [Install] WantedBy=multi-user.target 之后，需要通过命令注册服务 systemctl daemon-reload 服务管理命令后续我们对服务的管理，一般包括： 启动服务 systemctl start yongwang 停止服务 systemctl stop yongwang 查看服务状态 systemctl status yongwang 设置开机自启 systemctl enable yongwang 取消开机自启 systemctl disable yongwang 使用普通用户注册用户级服务注册服务对于非 root 用户，也可以使用自身的权限注册用户级服务，将配置文件编写在 /etc/systemd/user/ 路径下： yongwangapp.service[Unit] Description=YongWang Server [Service] WorkingDirectory=/home/lenovo/vc/ywyl/server/ ExecStart=java -jar YongWang-1.0-SNAPSHOT.jar [Install] WantedBy=multi-user.target 服务管理命令普通用户的服务管理命令与 root 用户相似，但都需要添加 --user 参数，例如： systemctl --user start yongwang","tags":[{"name":"Linux","slug":"Linux","permalink":"https://vitsumoc.github.io/tags/Linux/"},{"name":"运维","slug":"运维","permalink":"https://vitsumoc.github.io/tags/%E8%BF%90%E7%BB%B4/"}]},{"title":"使用Jenkins自动部署项目","date":"2024-05-17T07:09:35.000Z","path":"使用Jenkins自动部署项目.html","text":"前言笔者近期遭遇了一些运维上的困扰。 当项目实例部署到很多站点以后，每一次想要更新项目都需要远程连接进入服务器，进行一系列繁琐的运维操作，这样很耽误时间，而且容易犯错，当服务器网络环境不好的时候更是让人非常狂躁。 当时就想做一个简易的部署工具来解决这个问题，后来又意识到这应该是一个普遍的需求，很可能已经拥有了成熟的工具，向朋友打听后，朋友推荐了 jenkins。 基本概念jenkins 是一个自动化运维工具，在业内应该是被称为 持续集成(Continuous integration) 工具，还有一些什么持续部署，持续交付之类的概念，总之就是一套把程序员的代码变成产品交付给客户的东西。 jenkins 是一个 JavaWeb 程序，支持非常丰富的插件，而且绝大部分 动作 都是由插件来完成，对了，动作 是我随便用的词，总之就是我们手动部署中的每一个最小化步骤，例如拉代码、打包、上传，我都称为 动作。 jenkins 里有 项目(Project) 的概念，其实就是一个完整的项目部署过程啦，显而易见的，项目是顺序 动作 的集合。 jenkins 中的 项目 可以被 执行(Build)，执行 一般就是从代码仓库拉代码、构建项目、部署项目这样三个大的步骤（当然是自动的），每一次 执行 都会有自己的执行结果，执行日志。 jenkins 中很重要的部分是 插件(plugin)，插件 也是由全世界各地的开发者开发的，很多 动作 环境 甚至 项目 还有很多其他各种各样的东西，都是由 插件 提供的，因此当你想使用 jenkins 进行某事情的时候，往往会以 装个插件 作为起点。 使用案例拉 SVN 代码，通过 npm 打包，部署到 windows 服务器这个例子是一个前端项目，代码存放在 SVN，通过 npm 打包成 dist 文件夹，之后部署到境外的 Windows 服务器上。 这个例子里，jenkins 直接被安装在了目标服务器上，因此部署操作只需替换文件夹即可。 svn 相关 安装 Subversion Plug-in 插件 全局配置可用账号密码 在项目中配置代码仓库 npm 打包相关 安装 Node 插件 全局添加 Node 版本环境 在项目中选择 Node 环境 配置打包指令 npm -g install npm run build 对于麻烦的 npm 依赖问题，可以直接把开发环境的 node_modules 拷贝到 jenkins 的工作目录 部署 删除原文件夹的内容 del /f /s /q D:\\arctech-3.1-pak\\server\\arctech\\dist 1&gt;nul 删除原文件夹 rd /s /q D:\\arctech-3.1-pak\\server\\arctech\\dist(老版本的windowsServer系统可能有点问题，必须先删内容后删文件夹，参考 这里) 复制新文件夹 echo d | xcopy dist D:\\arctech-3.1-pak\\server\\arctech\\dist /E 拉 SVN 代码，使用 maven 打 jar 包，部署到 windows 服务器从 SVN 拉代码，使用 maven 构建，部署到本机 windows 系统。 拉代码步骤略过。 maven相关 安装 Maven Integration plugin 插件 配置 pom 文件路径 配置 mvn 命令 install 配置 Post Steps，仅当 maven 构建成功时执行后续的步骤 部署 停用服务 net stop arctech-scada-server 替换文件 copy /Y target\\ZXBoPlatform-3.1-SNAPSHOT.jar D:\\vc\\arctech-3.0-pak\\server\\ZXBoPlatform\\ZXBoPlatform-3.1-SNAPSHOT.jar 启动服务 net start arctech-scada-server 通过 SSH 部署到 Linux 服务器通过 SVN 拉代码，使用 maven 构建，部署到远端 Linux 系统。 拉代码和构建步骤略过。 通过SSH部署 安装 SSH 部署插件 Publish Over SSH 在 jenkins system 下，配置 SSH 服务器 在 maven 项目的构建后步骤中，添加 Send build artifacts over SSH 设置源文件 target/YongWang-1.0-SNAPSHOT.jar 设置目标路径 /ywyl/server_temp 设置部署命令 mv /home/vc/ywyl/server_temp/target/YongWang-1.0-SNAPSHOT.jar /home/vc/ywyl/server/YongWang-1.0-SNAPSHOT.jar &amp;&amp; systemctl restart yongwang 总结将打包部署工作自动化以后，对于笔者而言获得了这些收益： 省去了打包，部署的时间 降低了项目部署中犯错的可能性 对于网络环境较差的服务器，提升了部署的成功率 能够将多个项目实例集中管理起来 让大家更爱提交代码 参考 jenkins 通过SVN钩子，实现提交触发部署 使用maven插件构建maven项目 使用SSH插件，向目标服务器部署","tags":[{"name":"运维","slug":"运维","permalink":"https://vitsumoc.github.io/tags/%E8%BF%90%E7%BB%B4/"}]},{"title":"使用tun2socks进行全局网络代理","date":"2024-04-29T02:20:55.000Z","path":"使用tun2socks进行全局网络代理.html","text":"tun2socks (tunnel to socks) 是一种将 tunnel 流量转发到 socks 代理的工具，通常可以用来进行全局流量代理，也可以配合路由表设置，进行一些特定网段的流量代理。 简介在介绍 tun2socks 之前，需要先了解一些基本概念的含义： tunnel：来自于 TUN&#x2F;TAP，其中的 TUN 表示 tunnel，可以理解为三层代理，而 TAP 可以被理解为二层代理。 socks：一种应用层代理技术，将进入其中的流量代理到远端服务器。 虚拟网卡：由 TUN&#x2F;TAP 实现的，操作系统创建的虚拟网络设备，可以像普通网卡一样处理应用程序的流量。 tunnel2socks：连通虚拟网卡和 socks 服务的工具。 以下是 xjasonlyu&#x2F;tun2socks 项目中的功能介绍，后续的示例中我们也会使用该项目作为例子： 全局代理: 处理来自本设备的任意网络应用的所有网络流量并通过代理转发。 代理协议: 通过 HTTP&#x2F;Socks4&#x2F;Socks5&#x2F;Shadowsocks 远程连接且支持鉴权。 跨平台性: 具有 Linux&#x2F;macOS&#x2F;Windows&#x2F;FreeBSD&#x2F;OpenBSD 特定优化的多平台支持。 网关模式: 作为第三层网关处理来自同一网络中其他设备的所有网络流量。 IPv6 支持: 所有功能都可以在 IPv6 中工作，允许通过 IPv6 代理转发 IPv4 连接，反之亦然。 TCP&#x2F;IP 栈: 由来自 Google 容器应用程序内核 gVisor 的用户空间 TCP&#x2F;IP 网络栈强力驱动。 环境为了方便理解，介绍一下笔者所在的网络环境，和本次实验相关的设备共有 3 台： 笔记本： windows系统 地址 192.138.34.17/24 网关 192.168.34.1，网关是一台普通路由器 有互联网连接 内网服务器： linux系统 地址 192.168.34.197/24 网关为 192.168.34.1 有互联网连接 运行着一个 socks5 服务，服务地址为 0.0.0.0:1080，socks5 服务和远端服务器已连接 外网服务器： linux系统 地址为 xx.xx.xx.xx，负责处理通过内网服务器 socks5 服务发来的流量 测试接下来的测试按照 xjasonlyu&#x2F;tun2socks 项目提供的 示例 进行。 下载 wintunwintun 是一个在 windows 系统中创建三层 TUN 的库，只需下载 dll 文件并放在 tun2socks 同文件夹下。 创建虚拟网卡并设置代理 tun2socks -device wintun -proxy socks5:&#x2F;&#x2F;192.168.34.197:1080 -interface “以太网” 以上命令会开启 tun2socks 进程，创建名为 wintun 的虚拟网卡，并将通过此网卡的流量通过指定的 socks5 服务器代理，通过原有 以太网 网卡转发。 配置虚拟网卡在新的命令行窗口中键入命令，进行虚拟网卡配置： netsh interface ipv4 set address name&#x3D;”wintun” source&#x3D;static addr&#x3D;192.168.123.1 mask&#x3D;255.255.255.0 netsh interface ipv4 set dnsservers name&#x3D;”wintun” static address&#x3D;8.8.8.8 register&#x3D;none validate&#x3D;no 上述两条命令设置网卡的地址、掩码、DNS 服务器，让他看起来像一个正常的网卡。 配置默认路由 netsh interface ipv4 add route 0.0.0.0&#x2F;0 “wintun” 192.168.123.1 metric&#x3D;1 通过上述命令添加一条经过虚拟网卡的默认路由，之后全局流量都会通过虚拟网卡转发。 问题 测试时使用了一个不支持 UDP 的 socks5 代理，导致 DNS 解析功能受阻，如果想使用完整全局代理功能，需要另选 socks5 代理软件。 后来使用支持 udp_over_tcp 的代理套了一层，解决了惯用 socks 代理不能代理 UDP 的问题。 参考 tun2socks wintun [教程] 在 Windows 上使用 tun2socks 进行全局代理 TUN&#x2F;TAP","tags":[{"name":"网络工具","slug":"网络工具","permalink":"https://vitsumoc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7/"}]},{"title":"在Go中嵌入静态文件","date":"2024-04-25T07:48:11.000Z","path":"在Go中嵌入静态文件.html","text":"本文内容来自于 embed 概述embed 包提供了在 Go 程序中嵌入静态文件以及访问 Go 程序中静态文件的能力。 Go 程序可以通过引入 embed 包并使用 &#x2F;&#x2F;go:embed 指令在编译期将类型为 string、[]byte 或 FS 的变量初始化为文件或文件夹的内容。 例如，这里提供了三种嵌入 hello.txt 文件并打印内容的示例。 将单个文件嵌入为 string： import _ \"embed\" //go:embed hello.txt var s string print(s) 将单个文件嵌入为 bytes 切片： import _ \"embed\" //go:embed hello.txt var b []byte print(string(b)) 将一个或多个文件嵌入为文件系统（FS）： import \"embed\" //go:embed hello.txt var f embed.FS data, _ := f.ReadFile(\"hello.txt\") print(string(data)) 指令变量声明上方的 &#x2F;&#x2F;go:embed 指令使用一条或多条 path.Match 模板指定要嵌入的文件。 指令必须直接位于单个变量声明的上方，在指令和变量声明之间只允许存在空行或 &#x2F;&#x2F; 开头的行注释。 变量的类型必须是 string、byte 切片或者 FS（或者 FS 的别名）。 例如： package server import \"embed\" // content holds our static web server content. //go:embed image/* template/* //go:embed html/index.html var content embed.FS Go 构建系统将识别指令并安排声明的变量（在上面的示例中为 content）用文件系统中的匹配文件填充。 为了简洁起见，&#x2F;&#x2F;go:embed 指令允许在一行中使用多个空格分隔的模板，同时为了避免当模板太多时造成过长的行，指令也允许被分为多行。模板使用源文件包所在的相对路径解析，使用 &#x2F; 分隔路径，即便在 Windows 系统中也是如此。模板不能包含 ‘.’ ‘..’ 或空路径元素，也不能以 &#x2F; 开始或结尾。如果需要匹配当前路径中的所有元素，请使用 ‘*’ 而不是 ‘.’。为了允许支持名称中包含空格的文件，可以将模板写为 Go 格式的双引号或反引号字符串。 如果模板内容是文件夹名称，则文件夹中所有的内容都会被嵌入（递归），除了以 ‘.’ 或 ‘_’ 开头的文件。因此上述例子中的变量声明等同于： // content is our static web server content. //go:embed image template html/index.html var content embed.FS 区别在于 ‘image&#x2F;*’ 嵌入了 ‘image&#x2F;.tempfile’ 而 ‘image’ 不会嵌入，两种写法都不会嵌入 ‘image&#x2F;dir&#x2F;.tempfile’。 如果模板使用 ‘all:’ 前缀开头，则在遍历时会加入 ‘.’ 和 ‘_’ 开始的文件，例如，’all:image’ 既可以嵌入 ‘image&#x2F;.tempfile’ 也可以嵌入 ‘image&#x2F;dir&#x2F;.tempfile’。 &#x2F;&#x2F;go:embed 指令既可以用于导出的或不导出的变量，这取决于包是否想将数据内容提供给其他包使用。指令只能被用于包层级的变量，不能被用于本地变量。 模板不能用来匹配包之外的文件，例如 ‘.git&#x2F;*’ 或是应用链接，模板不能用来匹配名称带有特殊字符的文件，\" * < > ? ` ' | / \\ :，对空文件夹的匹配会被忽略，此外，每个 &#x2F;&#x2F;go:embed 行中的模板至少需要匹配到一个文件或者一个非空的文件夹。 如果模板无效或匹配内容无效，构建将会失败。 Strings 和 Bytes匹配 string 或 []byte 类型变量的 &#x2F;&#x2F;go:embed 指令必须只包含一个模板，而且模板必须只匹配到一个文件。string 或 []byte 变量的值将被初始化为文件的内容。 使用 &#x2F;&#x2F;go:embed 指令需要先引入 embed 包，即便是仅使用 string 或 []byte，不使用 embed.FS。此时可以使用空标识符引入（import _ “embed”）。 File Systems对于单个文件的嵌入，最佳方式往往是 string 或 []byte。FS 类型允许嵌入一组树状结构的文件，例如一个静态 WEB 服务器的内容，就像上文中例子里提到过的那样。 FS 实现了 io&#x2F;fs 包中的 FS 接口，因此它可以被任何理解该接口的包使用，例如 net&#x2F;http，text&#x2F;template 和 html&#x2F;template。 例如，通过使用上文例子中的 content 变量，我们可以： http.Handle(\"/static/\", http.StripPrefix(\"/static/\", http.FileServer(http.FS(content)))) template.ParseFS(content, \"*.tmpl\") 工具为了支持 Go 包分析工具，&#x2F;&#x2F;go:embed 指令中的模板也会在 “go list” 输出中可见，请查看 “go help list” 中的 EmbedPatterns，TestEmbedPatterns 和 XTestEmbedPatterns 部分。 完整示例package main import ( \"embed\" \"log\" \"net/http\" ) //go:embed internal/embedtest/testdata/*.txt var content embed.FS func main() &#123; mux := http.NewServeMux() mux.Handle(\"/\", http.FileServer(http.FS(content))) err := http.ListenAndServe(\":8080\", mux) if err != nil &#123; log.Fatal(err) &#125; &#125;","tags":[{"name":"Go","slug":"Go","permalink":"https://vitsumoc.github.io/tags/Go/"}]},{"title":"[翻译]无痛功能规格说明书——Part4：提示","date":"2024-04-22T01:02:13.000Z","path":"无痛功能规格说明书——Part4：提示.html","text":"原文 Painless Functional Specifications – Part 4: Tips .greenTitle { color: #008000; } 我们已经讨论过了 为什么您需要规格说明，规格说明中应该有什么，以及 谁负责编写规格说明。在本系列的第四章也是最终章，我将要分享一些关于编写规格说明的建议。 在一个经常编写规格说明的团队中，您常常能听到最大抱怨是“压根没人去读他们”，如果规格说明真的没人读，那么负责编写规格说明的人难免会变得愤世嫉俗。这就像一个经典的 Dilbert 漫画，里面工程师们用厚达 4 英寸的规格说明文档堆砌成隔板来扩展他们的工作隔间。在典型的大公司里，每个人都要花上好几个月的时间来撰写枯燥乏味的规格说明。一旦规格说明完成，他就会被束之高阁，再也不会被翻阅，最终产品会从头开始开发，完全不顾及规格说明的内容，因为根本没人会去读他，因为他实在让人昏昏欲睡。撰写规格说明的过程本身可能是一项有益的练习，因为他迫使每个人至少都去思考相关的问题。但问题在于，当规格说明完成后，他失去了作用（无人阅读，无人喜爱），这会让人觉得所有付出的努力都白费了。 另外，如果您的规格说明从未被仔细阅读，那么最终产品交付时就会带来很多争论。 某个人（可能是管理层、营销人员或客户）会说：“等等！你答应过我会有一个蛤蜊蒸锅功能！蛤蜊蒸锅呢？” 程序员则会回应：“不，实际上，如果你查看规格说明的第 3 章、第 4 小节、第 2.3.0.1 段，你会发现他明确写着‘没有蛤蜊蒸锅’。” 但这并不能让客户满意，因为“顾客永远是对的”，所以脾气暴躁的程序员不得不回去给产品强行添加一个蛤蜊蒸锅功能（这让他们更加愤世嫉俗地看待规格说明）。同样的情况也可能发生在管理层身上。例如，一位经理可能会说：“所有对话框里的文字都太冗长了，每个对话框顶部都应该放一个广告。” 然后沮丧的程序员会辩解道：“但是你批准了规格说明，里面精确地列出了每个对话框的布局和内容！” 然而，经理当然没有真正读过规格说明，因为在他尝试阅读时，他大脑里的内容满的都快要从眼眶里渗出来，而且这还影响了他周二的打高尔夫球计划。 综上所述，规格说明书是好东西，但是如果没人阅读他就毫无作用。作为一名规格说明的编写者，您必须引诱别人来阅读您的作品，您还必须小心谨慎，不要向别人小小的脑袋里塞太多东西，避免那些东西从他们的眼眶里渗出来。 引诱别人来阅读您的作品意味着您需要写出好作品，但是如果我只是撂下一句“要成为一个好作者”那显然有些不公。这里有四条规则，您 必须 要遵守，这样才能写出容易被人阅读的规格说明书。 规则一：有趣 引诱别人来阅读您的规格说明的第一条规则就是要让阅读体验变得有趣，别跟我说什么您天生无聊，我不买这个帐。每个人在每个时刻都有一些有趣的想法，他们只是自我审查一番之后觉得这些东西“上不得台面”，emmm，有时您必须打破规则。 如果您阅读过我在本站上写的 volumes of garbage，您就会发现我零星散落着一些各种搞笑的尝试，就在几段话前我还在调侃管理人员的脑容量和他们打高尔夫的事情。即使我不是真的很有趣，我也在努力的去尝试，而且这种笨拙的搞笑尝试本身也会让别人觉得好笑，就像是悲伤的小丑一样。当您编写规格说明时，一个很容易逗笑读者的地方是示例部分。每当您需要通过一个故事来阐述某种功能原理时，不要这样： 用户输入 Ctrl+N 以创建新的雇员表，并开始输入雇员名称。 而是应该这样： 佩奇小姐用眼线笔戳着键盘，因为她胖乎乎的小手指太胖了，无法按单个按键，她键入 Ctrl+N 创建一个新的男友表，并键入单个记录“Kermit”。 如果您曾大量阅读过 Dave Barry，您会发现有一种简单的搞笑方式就是在不必要的情况下加入大量具体的细节。“精力充沛的哈巴狗”比“狗”更有趣、“佩奇小姐”比“用户”更有趣，与其说“利益相关方”，不如说“左撇子的鳄梨农夫”，与其说“那些拒绝清理狗屎的人应该收到惩罚”，不如说他们应该被“关进那种孤独到让他们想上自己的狗的监狱”。 哦，对了，如果您认为加入幽默元素显得不够专业，那很遗憾，只能说您没有幽默感。（别否认了，没有幽默感的人总是会否认，你骗不了我。）如果您所在的公司因为您的规格说明轻松有趣、易于阅读而降低了对您的尊重，那么就去 找另一家公司 吧，因为人生苦短，实在没必要在如此严肃悲惨的环境里浪费宝贵的时间。 规则二：编写规格说明就像是编写大脑可执行的代码 这就是我觉得程序员在编写规格说明的路上可能遇到的阻碍。 当您编写 代码 时，您的受众是 编译器，是的，我知道别人也可以去读代码，但是这 对他们来说很难。对于大部分程序员来说编写能够被编译器正确阅读和解释的代码已经足够难了，而编写人类能够阅读的代码更是成了一种奢求。无论是您编写： void print_count( FILE* a, char * b, int c )&#123; fprintf(a, “there are %d %s\\n”, c, b);&#125; main()&#123; int n; n = 10; print_count(stdout, “employees”, n) /* code deliberately obfuscated */ &#125; 还是 printf(“there are 10 employees\\n”); 您得到的输出都是 相同的，这就是为什么，如果您仔细想想，您会发现程序员往往会写出这种东西： 假设函数 AddressOf(x) 定义为基于 RFC-822 说明的合法的 ANSI 字符串邮箱地址对用户 x 的映射。假设有用户 A 和用户 B，当用户 A 想要发送邮件给用户 B 时，A 初始化一个新的消息（使用别处定义的，但并非使用全部的技术），之后将 AddressOf(B) 输入至 To: 编辑框。 这段话也可以这样写： 佩奇小姐想要去吃午饭了，因此她创建了一封新邮件并将 Kermit 的邮箱地址输入到 To: 中。 技术旁注：邮箱地址必须符合 RFC-822 规范。 理论上，他们都“表达”相同的一件事，但是第一个例子您必须仔细 解码 后才能理解，而第二个例子则非常容易理解。程序员往往喜欢把规格说明写得像学术论文。他们总是觉得一份“正确”的规格说明必须做到“技术上”正确，这样他们就精准的完成了自己的工作（也无需承担更多责任）。 这里的关键在于当您编写一个规格说明时，除了要保持正确之外，还必须 能够被理解，用程序员的术语来说的话，意思是规范必须被编写的能够被人脑“编译”。电脑和人脑的最大区别之一就是电脑会坐在那里静静的等待您进行各种各样的预定义，而除非您激发了读者的兴趣，否则人脑根本不会知道您在说啥。人们压根不想进行任何解码理解，他们只想要按顺序阅读下去并且理解全部事情。对于人类来说，您必须先和他们描绘一幅模糊的总体图景之后再填充细节，而对于电脑程序来说，您可以让代码从头一直执行到底，细节内容出现在他们需要的地方。电脑不会在意您的变量名是否具有含义，而人脑则更适合通过故事来理解一幅生动的图景，即便是一个故事的片段，因为我们的大脑已经进化到了可以理解故事的程度。 如果您摆出一副实战中局的棋盘，一位经验丰富的棋手只需要花一两秒钟就可以记住每个棋子的位置。但是如果您将几个棋子移动到了正常情况下他们不会出现的位置（例如，把一些兵放在第一行，或者将两个黑象都放在黑格中），对于棋手来说记忆这个棋盘就变得困难了很多很多，这就是人脑和电脑思维方式的差别，对于记录棋盘的电脑程序来说，棋子的位置合理与否与他的记忆功能毫无关系。人脑的工作方式不是随机存取的，在面对常见的情况时，我们的大脑通路会得到加强，理解事情的能力也会变强。 因此，编写规格说明时，请尝试想象您的目标读者是谁，并设身处地思考他们理解每个步骤需要哪些信息。逐句审视，扪心自问读者是否能深刻理解该句子，以及它和您之前所述内容之间的关联。如果目标受众中的一部分人不知道什么是 RFC-822，那么您既可以定义它，或者至少将它放在技术注释中，这样管理层在阅读规格说明时，就算遇到生僻的技术术语也不会放弃继续阅读。 规则三：尽可能地简单 不要由于您认为使用简单的句子写作显得不够专业而刻意的使用呆板、正式的语言，您要尽可能的使用简单的语言。 有些人使用“功能规格说明书”这种词汇是因为他们觉得“功能文档”看起来不专业。（这里又一次提及到了词汇“不专业”，任何时候当有人告诉您不应该做某事只是因为他“看起来不专业”时，您就应该知道他们已经找到不到您事实上的缺陷了）。事实上我观察发现很多人觉得把文档写的简单易读就意味着有问题。 把事情分解成短句，如果一句话解释不清楚，就用两三句话。 避免文本墙（整页都是文字），读者会被你吓到然后“太长不看”。您上次在时尚杂志或者新闻报纸上看到整页都是文本是多久以前的事了？杂志甚至会从文章中引用并以巨大的字体打印在页面中间，只是为了避免出现整页文本。使用编号或项目符号列表、图片、图表、表格和大量空白，使阅读“看起来”更蓬松。 “杂志甚至会从文章中引用并以巨大的字体打印在页面中间，只是为了避免出现整页文本。” 没有什么比大量的截屏更能提升规格说明的可读性，一图胜千言。任何为 Windows 上运行的软件编写规格说明的人都应该买一份 Visual Basic，学习如何使用他 至少 能用来表达原型设计，（对于 Mac 电脑，可以使用 REAL Basic；对于 Web 页面，可以使用 Front Page 或者 Dreamweaver），之后截图并把图片放在您的文档中。 规则四：多次校对 emmm，好吧，我本来打算在这里对这个规则进行长篇大论的描述，但是这个规则实在是太简单了，多校对几次，就这样就行。当您觉得某句话难以理解时，就把他改写的简单一些。 规则四实在太简单了，我打算加一个规则五。 规则五：有害的模板 要拒绝制作一个标准规格说明模板的诱惑，一开始您可能只是觉得让“每个规格说明都具有相同的格式”这很重要，但事实上：不要。但为什么不应如此呢？您家书架上的每本书看起来是否相同呢？您是否想让他们看起来相同呢？ 更糟糕的是，一旦您拥有了模板，您就会开始有一些每个功能点都需要填写的“必备章节”。例如：Bill 老大规定，从现在开始，每个 Microsquish 产品都应该有互联网组件，因此现在规格说明书模板被添加了被称为“互联网组件”的章节，任何时候只要有人在编写规格说明，不管是否相关，他都必须填写这个被称为“互联网组件”的章节，即使他所写的规格说明只是用来描述 Microsquish 键盘。（您开始疑惑为什么那些无用的互联网商城按钮像蘑菇一样开始在键盘上疯长）。 随着这种章节的累计，模板会变得越发庞大。（这里有一个非常非常坏的规格说明书的 例子，老天，谁需要带着参考书看规范？或者说带着词汇表？）这种大模板带来的麻烦之一就是会吓跑那些需要写规格说明的人，这份工作看起来实在是太可怕了。 归根结底，规格说明就是一份您希望别人去阅读的文档，他和《纽约客》上的散文或者大学里的论文没什么本质上区别。您是否听说过大学教授为学生发放论文模板？您是否听说过两篇优秀的散文能套入同一个模板？放弃这种念头吧。","tags":[{"name":"翻译","slug":"翻译","permalink":"https://vitsumoc.github.io/tags/%E7%BF%BB%E8%AF%91/"},{"name":"软件项目","slug":"软件项目","permalink":"https://vitsumoc.github.io/tags/%E8%BD%AF%E4%BB%B6%E9%A1%B9%E7%9B%AE/"}]},{"title":"[翻译]无痛功能规格说明书——Part3：谁去做？","date":"2024-04-20T01:46:31.000Z","path":"无痛功能规格说明书——Part3：谁去做？.html","text":"原文 Painless Functional Specifications – Part 3: But… How? .greenTitle { color: #008000; } 现在，您应该已经阅读了 为什么要写规格说明 和 什么是规格说明，接下来让我们聊聊谁去编写规格说明。 谁去编写规格说明？ 允许我和您谈一点微软的历史，在微软认真发展的 1980 年代，微软的每个人都阅读过 人月神话，那是软件管理领域的经典著作（如果您还没有读过，我强烈推荐您阅读）。那本书中的主要观点之一就是当您向一个延误的项目增加程序员人手时，项目反而会延误的更加严重。假设您的开发团队有 n 个程序员，那么沟通路径的条数会是 n(n-1)&#x2F;2，以 O(n^2) 的速度增长。 因此，如何去编写越来越庞大的软件成了微软的一个挑战，当时流行的观点是增加程序员的数目会让事情变得更糟。 Charles Simonyi，彼时微软的“首席架构师”，提出了一个名为 大师级程序员 的概念。基本理论是一个大师级程序员应该负责编写所有的代码，但是他可以组织一帮初级程序员作为他的“码农”，这样他就不必要操心调试每个函数，大师级程序员只需要进行每个函数的原型设计、创建简单的程序轮廓，之后丢给码农们去实现。（当然，Simonyi 自己会是“特级大师级程序员”）。考虑到“大师级程序员”这个词过于中世纪，微软将他改名为“程序经理”（Program Manager）。 理论上说，这应该可以解决人月神话问题，因为程序员之间不再必须相互沟通——每个码农只需要和他的程序经理沟通，因此沟通成本的增速度从 O(n^2) 降低到了 O(n)。 好吧，Simonyi 可能非常了解 匈牙利命名法，但是他不太了解人心，没人甘于当个码农，这套系统根本没法运作。最终，微软意识到尽管据称他们打破了人月神话，他们确实可以通过向团队里增加聪明的小伙子来增加产出，但是这种效果是边际递减的。在我还在那边工作的时候，Excel 团队拥有 50 名程序员，这个团队的生产力比 25 人团队要高一些——但是远远不到两倍。 这种 编程大师&#x2F;码农 的架构备受指责，但是微软仍然保留了程序经理这个岗位名称。一个叫做 Jabe Blumenthal 的聪明人基本上重塑了程序经理的定位。从他以后，程序经理将负责产品设计和产品规格说明书。 从那时开始，微软的程序经理负责收集需求，搞清楚代码究竟需要用来支持什么，并 编写功能规格说明书。一般来说每个程序经理会配有 5 个程序员，这些程序员负责使用代码实现程序经理已经在规格说明中使用文档实现的内容。程序经理还需要去协调市场、文档、测试、本地化，等等一切程序员不该浪费时间的工作。最后，微软的程序经理需要顾全公司的“大局”，而程序员则可以自由的专注于让他们的代码完全正确。 程序经理至关重要。如果您曾经抱怨过程序员只考虑代码实现而根本不懂市场影响，您需要一个程序经理。如果您曾经抱怨过能写出好代码的人为什么总是写不出好文档，您需要一个程序经理。如果您曾经抱怨过您的产品方向似乎总是左右摇摆，您需要一个程序经理。 您如何雇佣一位程序经理？ 让我感到失望的一点是，大部分公司甚至都还没有程序经理的概念。在我上班的时候，由强大的程序经理带领的微软团队制作了很多成功的产品：Excel、Windos 95、Access 等等。但是有些其他的团队（例如 MSN 1.0 或者 Windows NT 1.0）在开发的过程中则忽略了他们的程序经理（这些程序经理能力一般，被忽略也许情有可原），他们的产品就没有这么成功。 这里是需要避免的三件事。 1. 不要直接将程序员晋升为程序经理 程序经理的核心能力（清晰的文档表达、外交能力、市场意识、用户同理心和UI设计能力）和成长为一名优秀程序员没有什么关系，确实，有些人既是优秀的程序员，也具备这些能力，但是这种人很稀缺。把优秀的程序员 晋升 到一个他不熟悉的领域，本来他是写 C++ 的，现在开始写文档了，这是 Peter Principle 的经典案例：人们会被晋升到他实际上不擅长的岗位。 2. 不要让市场部的员工去当程序经理 无意冒犯，但是我认为我的读者会赞同这个观点：市场部的员工通常无法掌握产品设计过程中的技术问题。 基本上，程序经理是一个单独的路径，所有的程序经理都必须对技术了如指掌，但是他们不必成为优秀的程序员。程序经理需要学习 UI 设计，会见客户，编写规格说明。他们需要与各种各样的人相处——从“白痴”客户，到穿着《星际迷航》cos服上班的二次元程序员，到穿着 2000 美元西装套装的浮夸销售人员。从某些方面来说，程序经理是软件团队的粘合剂，他的个人魅力至关重要。 3. 不要让程序员向程序经理汇报 这是一个很容易被忽视的错误。我在微软担任程序经理时，设计了 Excel 的 Visual Basic 应用程序 (VBA) 策略，并详细制定了 VBA 在 Excel 中的实现规范，这份规格说明书细致到每个细节，足足有 500 多页。在 Excel 5.0 开发高峰期，我估计每天早上有 250 人上班后，基本上都是参照我写的那份庞大规范工作的。我根本不知道这些人是谁，但仅 Visual Basic 团队就有大约十几个人专门负责这项工作的文档编写（更不用说 Excel 团队的文档编写人员，以及负责帮助文件中超链接的全职人员了）。奇怪的是，我在汇报架构中处于“底层”，是的，没人向我汇报工作。如果我想让人们做某件事，我必须说服他们，让他们相信这是正确的做法。当首席开发人员 Ben Waldman 不想做我规格说明中的某些内容时，他直接就可以不做。当测试人员抱怨我设计的内容无法完全测试时，我就得进行简化。如果这里的任何一个人需要向我汇报，那么产品都不会像最终成功那么出色。有些人可能会认为质疑上级是不合适的，另一些时候，我可能会出于自负或目光短浅，直接命令他们按照我的方式去做。但实际情况是，我别无选择，只能努力达成共识，这种决策方式才是做出正确决定的最佳途径。 我关于规格说明系列文章的 最后一篇 讨论了如何编写一个人们愿意去阅读的规格说明书。","tags":[{"name":"翻译","slug":"翻译","permalink":"https://vitsumoc.github.io/tags/%E7%BF%BB%E8%AF%91/"},{"name":"软件项目","slug":"软件项目","permalink":"https://vitsumoc.github.io/tags/%E8%BD%AF%E4%BB%B6%E9%A1%B9%E7%9B%AE/"}]},{"title":"[翻译]无痛功能规格说明书——Part2：什么是规格说明书？","date":"2024-04-19T01:06:38.000Z","path":"无痛功能规格说明书——Part2：什么是规格说明书？.html","text":"原文 Painless Functional Specifications – Part 2: What’s a Spec? .greenTitle { color: #008000; } (您是否已经阅读了 Part1？如果没有，请点击 这里。) 这一系列文章探讨的内容是 功能规格说明书，而非 技术规格说明书，人们总是混淆这两个概念。我不太清楚是否有标准化术语，但是当 我 提到这两个词时，意思分别是： 功能规格说明书 描述了在用户视角中的产品如何工作，他并不在意具体实现方式。他讨论的是产品功能，他决定了屏幕上的显示内容、菜单内容、弹窗，等等这些。 技术规格说明书 描述了程序内部的实现，他讨论的是数据结构、关系型数据库模型、编程语言和框架的选择、算法，等等这些。 当您设计一个产品时，无论他是内部的还是对外的，最要紧的事情就是锁定用户体验：屏幕上显示的是什么、用户可以如何使用、用户用产品做什么，随后，您开始考虑无处不在的弹窗和组件细节。在您完全决定这些内容之前根本不需要考虑使用什么编程语言，在这一系列文章中，我只讨论这一部分，也就是 功能规格说明书。 我写了一个简短的功能规格说明书示例，用来给您演示。在我们进行下一步之前，请 阅读示例。（示例中的 流程图） 您已经阅读了吗？ 您还没读吧&#x3D;。&#x3D;，去 读完示例 再回来，这样我们才能去聊一个好的规格说明应该包含什么或者不包含什么。我会在这里等着你的，感谢。 （耐心等待中…） 啊，太好了，您回来了。 以下是一些我在每个规格说明书中都惯例添加的内容。 免责申明 纯粹的自我保护作用，如果您写了一段类似于“这个规格说明书尚未完整”，人们才不会冲进你的办公室咬你的头。随着时间的推移，当规格说明逐渐完整的时候，您可以将其改为“按照我目前的了解，该规格说明书已经完成，但如果我遗漏了任何事情，请联系我。”，这也提醒了我，每一个规格说明书都需要： 有且只有一个作者 有些公司觉得文档应该由一个 团队 完成，但是如果您尝试过集体写作，您就应该知道这事有多操蛋。把集体写作这个活留给那些拥有大批哈佛应届生军团的管理咨询公司吧，他们需要做大量忙碌的工作来证明他们的收费是合理的，而您的规格说明只需要 一个人 负责编写，如果您有一个大项目，那就把他拆成小块，每一块由一个人负责编写规格说明。还有些公司觉得让某一个人在规格说明上署名是一种“自负”或者说“窃取了团队的荣誉”，废话，对某件事 负责任 的人理所当然的拥有对这件事的 处置权。如果规格说明中的有些内容写错了，就必须有一个该规格说明的拥有者，一个把自己名字写在规格说明上的人，负责去修复他。 应用场景 当您在设计产品时，您需要在脑海中设想一些人们在现实生活中使用您产品的场景。否则您最终只会设计出对现实世界没有任何作用的产品（例如 Cue?Cat）。考虑您的产品受众，为您产品的每种类型用户假设一个虚构的、完全基于想象的刻板印象。在我的 UI 设计书（免费在线 阅读）的 第九章 谈到了如何创建虚构的用户和场景。将这些基于想象的用户带入您的场景，场景越生动具体，您为用户设计的细节就会越好，这就是为什么我倾向于设置大量虚拟细节。 非目标 当您与一个团队一起开发产品时，每个人都倾向于往里塞一些他们最钟爱的、赖以生存的、真实的或者基于想象的宠物功能，如果您接受了所有这些功能，您的产品开发只会需求无限的工期和无限的金钱。您必须立刻开始剔除这些功能，而做这件事最好的方法就是在规格说明中添加“非目标”章节，明确的表示不打算做的事。非目标可以用来表达您不计划实现的功能（“不支持脑电波交互！”）或者更常规的（“我们不在乎这个版本的性能。这个产品运行的很慢，但是只要能用就行。如果我们有时间开发 2.0，我们会找机会修一下。”）这些非目标的内容可能会引起一些争议，但是重要的是赶快明确并公开。“我们没打算做这个！”就像 George Sr. 说过的。 总览 这就像您规格说明中的内容目录，可以是一个简单的流程图，也可以是一个架构的细致讨论。每个人都会阅读总览部分来了解整体架构，然后再去阅读细节部分才会更容易理解。 细节，细节，还有细节 最终，您开始处理细节，在需要了解某些具体的细节实现前，大部分读者不会仔细的阅读这些内容。当您在设计一个基于 web 的服务时，一个很好的做法是给每一个页面分配一个规范的名称，并使用一个单独的章节来描述这个页面中所有令人麻木的细节。 细节 是规格说明书中最重要的内容。您应该已经注意到了在示范的规格说明书中我如何使用 令人发指的 详细方式来描述登录中的错误处理。当 email 地址不合法时如何处理？当密码不正确时如何处理？所有这些情况都对应着后续实施中真的需要编写的代码，而且，更重要的是，这些情况对应着事情该怎么做的决定。总有人需要负责决定当用户忘记密码以后该如何处理，如果没有决定，代码就无法编写，规格说明的职责之一就是记录这些决定。 开放讨论 在初版规格说明放置开放讨论是完全没有问题的，当我编写第一版的草稿时，我通常会放置大量开放问题，但我会标记他们（使用某种特殊的格式以便我后期检索），而且如果合适的话，我会加一些自己的建议方案。在程序员开始工作之前，所有这些开放讨论都必须被拍板。（您可能觉得可以让程序员先从简单、已经明确的部分开始施工，随后您再去解决剩下的开放问题，但这其实是个蠢主意，因为除了那些您事先已经了解到而且应该解决的问题外，随着代码实现工作的开始，您还会遇到无数个新的需要解决的问题。另外，您对任何问题解决方式的决议都有可能对代码的设计和编写产生影响）。 旁注 当您在编写规格说明时，请记住您的读者群体是多样化的：程序员、测试员、市场同事、文档哥等等。在您编写规格说明时，您可能会想到一些只对其中某一组人有用的内容。例如，我通常把写个程序员的一些关于技术实现细节的探讨标记为 “技术旁注”，这样市场方向的同事就会忽略这些内容，而程序员则会阅读他们。我的规格说明中常常充满了类似于 “测试旁注”，“市场旁注” 或者 “文档旁注” 之类的内容。 规格说明是活的 有些编程队伍采用“瀑布式”流程：一次性搞定程序设计，编写规范，打印出来，扔给程序员然后下班回家。对于这种团队我想说：“呵呵”。 这种工作方式就是规格说明书声名不好的原因。有很多人这样对我说过：“规格说明书没啥用，因为根本没有人会去遵守，他们最后总是过时的，根本无法反映出产品。” 抱歉啊，也许 您的 规格说明书过时了，而且没法反应产品情况。但是 我的 规格说明书可是更新的十分频繁。我的规格说明书随着产品的开发进度和新的决策不断更新，我的规格说明书随时可以反映团队对于产品方向的最佳共识，只有当产品代码已经完成时（所有功能开发完成，仍然遗留有测试和 debug 工作）他才会被冻结。 为了让大家活的轻松点，我不会每天更新规格说明。我常常是在服务器上保持一个最新的版本，以便团队可以将其视作引用的参考。在偶尔的里程碑中，我会打印一份带有修订标记的规范副本，这样人们就不必重新阅读整个内容——他们可以扫描修订标记以查看进行了哪些更改。 那么谁应该负责写规格说明？请参考 Part3。","tags":[{"name":"翻译","slug":"翻译","permalink":"https://vitsumoc.github.io/tags/%E7%BF%BB%E8%AF%91/"},{"name":"软件项目","slug":"软件项目","permalink":"https://vitsumoc.github.io/tags/%E8%BD%AF%E4%BB%B6%E9%A1%B9%E7%9B%AE/"}]},{"title":"[翻译]无痛功能规格说明书——Part1：何必麻烦？","date":"2024-04-18T06:24:06.000Z","path":"无痛功能规格说明书——Part1：何必麻烦？.html","text":"原文 Painless Functional Specifications – Part 1: Why Bother? 当 Joel测试 刚面市的时候，读者反馈的最大痛点之一就是写规格说明。写规格说明看起来就像是用牙线：大家都知道自己应该写文档，但是大家都不写。 为什么人们不写规格说明？他们声称不写规格说明可以节约时间，他们表现得就好像编写规格说明这件事是专门为了 NASA 航天飞机工程师或者是大型保险公司人员保留的奢侈品，扯淡。首先，不编写规格说明就是你引入项目的 最大不必要风险，这就像只穿着T恤就出发去穿越莫哈韦沙漠，然后寄希望于“车到山前必有路”一样愚蠢。不写规格说明就直接开始进行项目的程序员以为自己是很酷的枪手，随手掏枪就能击中目标，但实际上他们不是。他们只是编写糟糕的代码，生产劣质的软件，通过承担完全没有必要的风险来威胁他们的项目。 我相信，在任何重要的项目上（指的是超过一周的编码时间或者超过一个程序员的投入），如果您没有编写规格说明，那么您 一定 会最终花费更多的时间，而且收获低质量的代码。原因如下。 规格说明最重要的功能是去 设计 程序，即便是程序中所有的代码都由您独立完成，您编写的规格说明只有您自己一位读者，编写规格说明的过程——在微小的细节层面描述程序的原理——也会强制您真正的设计去设计程序。 让我们来采访我想象中的两位来自不同公司的程序员。Speedy，来自 Hasty Bananas Software，她从来不写规格说明，“规格说明？我们用不着那种东西！”。与此同时，Rogers 先生，是一位来自 The Well-Tempered Software Company 的程序员，他在规格说明定稿前坚决不会写代码。这两位只是我想象中众多朋友中的其中之二。 Speedy 和 Rogers 先生有一个共同点：他们都在负责各自产品 2.0 版本的向后兼容性。 Speedy 认为保证向后兼容的最佳方案就是写一个可以把 1.0 版本文件转换成 2.0 版本文件的转换器。她迅速开工，热火朝天，大约两周后，她确实完成了一个可用的转换器，但她的客户不太满意，Speedy 的代码迫使他们必须将公司里每一个人的软件都升级到新版本。Speedy 的最大客户 Nanner Splits Unlimited 甚至拒绝购买这个新版软件。Nanner Splits 要求软件的 2.0 版本应该直接兼容 1.0 版本的文件，而非必须进行转换。Speedy 决定再写一个向后兼容的转换器，并且把他集成到“保存”功能里。这里开始有点混乱，因为当客户使用 2.0 版本的特性数据后，使用 2.0 版本格式保存是没有问题的，但使用 1.0 格式保存时可能会提示客户编写的数据不兼容 1.0 版本的保存格式（此时客户已经在软件上奋战了半个小时，最后却可能无法保存）。总之后面这个版本的转换又使用了两个星期的时间，而且也不是很好用，整个项目的耗时是四周。 现在，就职于 Well-Tempered Software Company（简称 “WellTemperSoft”）的 Rogers 先生，他是著名的不懂变通之人，他 拒绝 在明确规格说明之前编写任何代码。他大概花了 20 分钟设计了一个和 Speedy 相同的向后兼容方案，并编写了一份规格说明，内容非常简单： 当使用新版本软件打开旧版本文件时，文件立刻被转换为新版本的格式。 这份规格说明书被发给了客户，客户立刻反馈：“稍等！我们并没有打算让每个人都立刻升级新版软件！”，Rogers 先生进行了一些思考，之后修改了他的规格说明： 当使用新版本软件打开旧版本文件时，文件在内存中被改为新格式。当保存文件时，用户可以选择是否将其保存为旧格式。 至此再次花费了 20 分钟。 Rogers 先生的老板是一位面向对象程序员，他看了这个说明书后感觉有些地方不太对，然后提出了一种他建议的架构。 将代码拆分成两种接口：V1 和 V2。V1 包括了所有 1.0 版本软件的功能，V2 继承了 V1，添加了新的功能。这样 V1::Save 可以用来保证向上兼容，V2::Save 可以用来存储新的数据。当客户打开 V1 版本的文件而视图使用 V2 版本的新功能时，程序会立刻提醒客户，客户必须选择将文件转换为 V2 版本或者放弃使用 V2 版本的新功能。 这里又花费了 20 分钟。 Rogers 先生感到有点暴躁，因为这种重构需要消耗他 3 周的工时，他自己的方案原本只需要 2 周！但是这个方案确实使用一种优雅的方式解决了所有客户的问题，所以 Rogers 还是这样做了。 最终，Rogers 先生耗时 3 周零 1 小时，Speedy 耗时 4周，而且 Speedy 的代码更糟糕。 这个故事的寓意是，通过编造的例子，你可以证明任何事。emmm，No，我不是这个意思。这个故事的意思是当您使用人类语言描述您的产品时，只需要几分钟的时间您就可以思考多种可能性，修改或改进您的设计。没有人会因为删除文档中的一段话而感到失落，但当您通过编程语言设计您的产品时，这意味着每次您需要花费数周的时间来迭代设计。更糟糕的是，往往一个只花了两周时间编写代码的程序员会非常执着于他的代码，无论代码有多么糟糕。不管 Speedy 的老板或者客户说什么都没办法说服她丢掉她的转换器代码，即使那些代码被设计的很糟糕。最终导致的结果就是，交付的产品往往是最初的错误设计和后续的理想设计中间的折中方案，最后就是“这是我们能做到的最好方案，因为我们不能丢掉我们的老代码”，这显然不如“这就是我们最好的方案，句号”。 以上，就是需要写规格说明的第一个原因。第二个原因是规格说明有助于节约沟通时间，当您编写了一份规格说明，您只需要写一次文档，表述程序如何正确的工作。随后团队中的每个人都可以阅读这份规格说明，QA 同事阅读后了解了程序预期中应该如何工作以及如何测试程序；市场同事阅读后可以编写一些模糊的产品白皮书并发布到网站上；商务开发同事误读了它，对这个产品如何治疗秃头、疣之类的东西产生了奇怪的幻想，但他吸引了投资者，所以没关系；程序员同事阅读后了解了代码应该怎么写；客户阅读了以后知道了我们正在创造一个他们会愿意付款的产品；文档哥（反正就是团队里负责写技术文档的人）阅读后会去写一篇漂亮的手册（最后会丢掉或者扔掉，但那就是 另一个故事 了）；经理们阅读后可以在管理会议上假装自己对一切了如指掌；诸如此类。 而当您没有编写规格说明时，这些沟通仍然会发生，但他们是多次偶发的。QA 同事随意的探索程序，当程序看起来有点怪时，他们就会跑过来 一次又一次 的打断程序员并且 一遍又一遍 的询问一些关于程序预期运行状态的愚蠢问题。这除了会 破坏程序员的生产力 外，程序员还倾向于给出符合他们代码预期的答案，而非“正确答案”。因此 QA 实际上是在依据程序来测试程序，而非依据设计来测试程序，这显然不太靠谱。 当您没有编写规格说明时，可怜的文档哥的遭遇是最好笑的（以一种悲伤的方式）。文档哥一般不被允许打断程序员的工作，在很多公司里，如果文档哥养成了打断程序员的工作去问问题的习惯，程序员就会跑去找他们的经理哭诉说都是因为[脏话删除]的文档哥打断工作，搞得他根本没法完成任务，经理出于对项目进度的考虑，只能命令文档哥 再也不要 去打扰那些程序员的 宝贵 时间。您可以轻松的识别出这种公司，因为他们的帮助文件和用户手册中提供的信息并不会比您在软件屏幕上自己看到的多。比如当您在屏幕上看到这样一条消息： 是否开启 LRF-1914 支持? … 然后您就点击 “帮助”，随后弹出一个可悲又可笑的帮助内容，比如： 允许您选择开启 LRF-1914 支持（默认）或是关闭 LRF-1914 支持。如果您希望开启 LRF-1914 支持，请点击 YES 或是输入 Y，如果您不希望开始 LRF-1914 支持，请点击 No 或是输入 N。 emmm，感谢帮助，但是此处文档哥想要掩盖他其实并不了解 LRF-1914 的意图太明显了。他们也没办法跑去问程序员，因为：（a）他们很内向，或者（b）程序员在海得拉巴然后文档哥在伦敦，或者（c）他们被禁止打扰程序员的工作，当然或者是由于各种各样的公司病，不胜枚举，但是最最根本的问题是 没有规格说明书。 需要编写规格说明的第三个原因是，如果没有详细的规格说明，那么就不可能制作项目进度表。如果您是在读博士或者是想花 14 年时间来成就某些事情的话，那么不做项目进度表也无所谓（或者说您正在开发《毁灭公爵》续作，“we’ll ship when we’re good and ready”）。但是对于几乎所有现实中的生意来说，您就是需要知道事情需要多少时间，因为开发项目需要花钱。您不可能在不问价格的情况下去买牛仔裤，那么又怎么可能在不知道产品需要多少开发时间，或者说不知道需要投入多少钱的情况下，去做一个可靠的商业决策？关于项目进度表的更多信息，可以阅读 Painless Software Schedules。 一个常见的错误是在设计阶段对一件事情进行讨论，但 永远得不到结论。Windows 2000 的开发领导人 Brian Valentine 有一句出名的 座右铭，“Decisions in 10 minutes or less, or the next one is free”（必须在 10 分钟内做出决定）。 在太多太多的编程组织中，每当出现了关于设计的争执，通常是处于政治的原因，没有人能够做出定论，因此程序员只能先去做没有争议的工作。随着时间的推移，所有的艰难选择都被留在了最后，这种项目是 最可能失败 的项目。如果您在围绕着某种新技术创建了一家新公司，而且您发现您的公司很难以做出决策，您最好尽早关门，把钱还给投资者，因为您最终无法交付任何产品。 编写规格说明是给这些争议（无论大小）下定论的最好方法，如果您不编写规格说明，有些争议甚至无法被发现。即使是细枝末节的决定也可以通过文档来规范。例如，如果您在创建一个会员制的 web 系统，您一定会赞成在用户忘记密码时可以通过邮件找回。很好，但是这些不足以支撑代码，为了编写代码，您甚至必须精确到邮件中的文本内容。在大多数公司里，程序员并不会被赋予撰写用户可见文本信息的任务 (这通常也是合理的)。因此，产品文案通常需要由市场营销人员、公关人员或其他擅长英语表达的人员来完成。“亲爱的用户，这里是您丢失的密码，以后请别这么粗心了。”当您开始强迫自己编写一个明确且全面的规格说明（关于这个，随后我会聊很多）时，您会注意到所有的这些细节，要么您会解决他们，要么至少打一个大大的红标。 好的，我们现在达成共识了。规格说明就像美国苹果饼一样，人人爱吃。我相信大多数人都理解这一点，我的一番抱怨虽然有趣，但并没有教给你任何新知识。那么为什么人们不写规格说明呢？这并不是为了节省时间，因为这并不能节省时间，而且我认为大多数程序员其实心里有数。（在大多数组织中，唯一存在的“规格说明”都是程序员在编写代码并向三百个人解释该功能之后，用记事本敲出的一段简短的文本。） 我认为本质原因就是大多数人讨厌写作，在一片空白的屏幕上从头开始码字会让人感到沮丧。就我个人来说，我是通过在大学里参加了每周需要提交 3-5 页论文的课程克服了我对写作的恐惧。写作就像是肌肉训练，您写的越多，您的写作能力就会越强。如果您需要去写规格说明但是您没有这方面的能力，开始写日记，开始写 weblog，报一个创意写作班，或者给您已经四年没联系过的大学室友写一封信。任何需要将文字写到纸上的事情都能提升您写规格说明的水平。如果您是软件开发部门经理，然后您手下的小弟对于写文档一窍不通，您可以把他们送去参加两个星期的封闭式写作训练营。 如果您在一家从来不写功能规格说明书的公司工作，也许您确实没见过功能规格说明书长什么样。在本系列的下一章中，我会给您展示一个简短的功能规格说明书，并且和您一起探讨一个好的功能规格说明书的写作要点。继续阅读！","tags":[{"name":"翻译","slug":"翻译","permalink":"https://vitsumoc.github.io/tags/%E7%BF%BB%E8%AF%91/"},{"name":"软件项目","slug":"软件项目","permalink":"https://vitsumoc.github.io/tags/%E8%BD%AF%E4%BB%B6%E9%A1%B9%E7%9B%AE/"}]},{"title":"[翻译]Joel测试：12步获得更好的代码","date":"2024-04-15T02:24:27.000Z","path":"Joel测试：12步获得更好的代码.html","text":"原文 The Joel Test: 12 Steps to Better Code 本文写于 2000 年，文中的很多理念值得我们学习，但文中的一些软件和硬件早已不是现在的主流 您是否听说过 SEMA？那是一个相当深奥的系统，用于衡量软件团队的优秀程度。但是， 等等！别去学那套东西！ 理解那套东西大概需要您 六年 的时间。因此，我想出了我自己的、非常不负责任的、草率的测试来评估软件团队的质量。最重要的是，整个过程只需要 3 分钟，省下来的时间足够您读一个医学学位。 Joel测试 您是否使用了源码控制？ 您能否一键构建？ 您是否进行每日例行构建？ 您是否拥有 bug 数据库？ 您是否在写新代码之前修复 bug？ 您是否拥有最新的的项目进度表？ 您是否拥有规格说明？ 程序员的工作环境是否安静？ 您是否在使用最先进的生产工具？ 团队中有测试人员吗？ 招募新人的时候会让他们在面试时写代码吗？ 您会进行走廊可用性测试吗？ Joel 测试的妙处在于，每个问题都可以使用 是 或 否 来回答。您压根不用去计算每日平均代码数或者每版本平均BUG数什么的，只需每个 是 计一分。当然，Joel 测试的坏处在于，您 不应该 用他来确保您的核电站控制软件的安全性。 12 分是完美结果，11 分也可以接受，但是 10 分或以下就意味着您已经遭遇了一些严肃的问题。实际上大部分软件组织的得分只有 2 或者 3，他们需要 严肃的 帮助，因为像微软这样的公司会在任何时候都以 12 分的状态运行。 当然，这些不是决定成败的唯一因素：在现实中，如果您拥有一个伟大的团队但是在制造一个没人需求的产品，那么，确实也不会有市场。同时，也可以想象一群才华横溢的“枪手”，他们虽然不遵循这些流程，却能做出改变世界的惊人软件。但是，在其他条件相同的情况下，如果您把这 12 件事做好，您就会拥有一支纪律严明、能够持续交付的团队。 1. 您是否使用了源码控制？我曾经用过商用的代码控制软件，也用过免费的 CVS，我会告诉您，免费的 CVS 也很好用。但是如果您没有源码控制的话，您会在让程序员协同工作的过程中遇到各种阻碍。程序员们无法知道别人做了些什么，错误也没办法被回滚。源码控制系统带来的另一个优点是，源码会被检出到每一个程序员的硬盘上——我从未听说过使用了源码控制的项目遭遇大量源码丢失的事故。 2. 您能否一键构建？这里我的意思是：从最新的代码到可交付产品需要多少个步骤？在一个好的团队中，会有一个单独的脚本，他可以从头开始检查代码、重新构建代码、为所有的分支版本和语言或者 #ifdef 约束条件构建可执行文件，创建安装包，然后将其发送到最终的媒介——光盘或者下载网站等等。 如果这个过程无法一键执行，那就带来了犯错的机会。而且您的项目越接近交付，您往往需要更快速的迭代部署来处理“最后的” bug，创建最终的可执行文件，等等。如果这个过程需要耗费20步，相信我，您一定会感受到痛苦，而且会犯下很多愚蠢的操作错误。 正是因为这个原因，我工作的上一家公司从 WISI 转向了 InstallShield：我们希望安装程序能在夜间使用 NT scheduler 通过一个脚本自动运行，而 WISE 无法在夜间自动运行，因此我们淘汰了他。（WISE 的开发人员向我保证他们的最新版本已经支持了夜间构建。） 3. 您是否进行每日例行构建？当您在使用了源码控制后，有时某个程序员无意中提交了一些错误的代码导致项目无法构建。例如，他添加了一个新的源文件，在他自己的机器上编译都没有问题，但是他忘记把他的文件提交到代码库了。之后这哥们关机回家了，浑然不觉，心满意足。但是其他人就没法干活了，因此其他人也被迫回家了。 导致项目无法构建的错误非常的糟糕（但是也非常常见），这导致了我们需要进行每日构建，用来检查有没有构建错误。在一个大团队中，一个用来定位构建问题的很好的方式是在每天的午餐时间进行每日例行构建。每个团队成员都在午餐前尽可能多的提交代码，而当他们吃完饭回来时，构建已经完成了。如果例行构建成功，那非常好，每个人都可以将代码更新到最新版本然后继续工作。如果构建失败，您需要修复问题，但是其他人仍然可以在上次成功构建的版本上继续工作。 在开发 Excel 时我们定下了一个规则，谁的代码打破了构建，那么作为“惩罚”，就由他负责处理构建过程，直到另一个程序员又打破了构建。这是一个鼓励大家不要打破构建的好办法，也是一个让大家轮流参与构建过程，了解构建过程工作原理的好办法。 可以在我的文章 Daily Builds are Your Friend 中了解更多和每日例行构建相关的内容。 4. 您是否拥有 bug 数据库？无论您做何辩解，但是只要您是在写代码，无论是团队工作还是独立开发，如果没有一个数据库来组织所有的已知 bug 的话，您的代码交付质量一定不高。有很多程序员觉得他们可以吧 bug 列表记在脑子里，这完全不靠谱。我的脑子现在连三个 bug 都记不住，而且每次睡一觉过后，或者是随着交付的压力，程序员早就把 bug 列表忘的一干二净了。你绝对需要使用工具正式的进行 bug 追踪。 Bug 数据库可以设计的复杂一点或者简单一点，但是最简单的可以用 bug 数据库也应该为每个 bug 包含下列字段： 完整的复现步骤 预期行为 观察到的（出bug的）行为 分配给谁处理 是否已经修复 如果说 bug 追踪软件的复杂度导致了您不想使用他们，那您可以使用上述五列的简单表格来开始您的 bug 追踪工作。 更多关于 bug 追踪的知识，可以阅读 Painless Bug Tracking。 5. 您是否在写新代码之前修复 bug？第一个版本的微软 Windows 版 Word 被称为“死亡竞速”项目。整个过程漫长而坎坷，一再延期。整个团队都加班加点到离谱的地步，项目一次又一次地推迟，压力也大得让人难以置信。这该死的项目最终在发布时已经比原计划晚了数年。微软公司把整个团队送到坎昆去度假放松一下，随后坐下来进行深刻的反省。 他们认识到，项目经理们一直如此执着于遵守“进度表”，以至于程序员们为了赶进度，只匆匆完成了编码过程，写出了非常糟糕的代码，因为修复漏洞并不是正式进度表的一部分，恰恰相反，当时并没有指标尝试控制漏洞数量。据传闻，一位程序员需要编写计算文本行高的代码，他干脆直接写了“return 12;” 这段代码，然后等着关于这个函数并不总是正确的漏洞报告出现。进度表变成了一份等待变成漏洞的功能清单。在事后分析中，这种做法被戏称为“无限缺陷方法论”。 为了纠正这个问题，微软在整个公司范围内实施了一种名为“零缺陷方法论”的东西。公司里的许多程序员都对此嗤之以鼻，因为这听起来像是管理层认为他们可以通过行政命令来减少漏洞数量。实际上，“零缺陷”意味着在任何给定时间，最高优先级都是在编写任何新代码之前消除漏洞。原因如下： 普遍上，修复 bug 前等待的时间越长，修复的成本（时间和金钱）就越高。 例如，当您犯了编译器捕获的拼写错误或语法 bug 时，修复它基本上是微不足道的。 当您第一次尝试运行代码时发现代码中有 bug 时，您将能够立即修复它，因为所有代码在您的脑海中仍然记忆犹新。 如果您在几天前编写的某些代码中发现 bug，您将需要一段时间才能找到它，但是当您重读您编写的代码时，您会记住所有内容，并且能够在合理的时间内修复该 bug。 但是如果您发现的 bug 是在您 几个月 前编写的代码中出现的，您很可能基本上已经把代码中的事情忘光了，这样 bug 修复工作就会变的很难，这种感觉就像是在修复其他人的代码，而且那哥们现在正在阿鲁巴度假。在这种情况下，修复 bug 就像是一种考古工作：您必须缓慢的，有条理的，细致的处理，而且您还无法确定需要多长时间才能取得成果。 如果您在已经交付的产品中发现了 bug，那么您可能需要花费相当高昂的代价来修复他。 这就是为什么要立刻修复 bug 的原因：因为这样最省时间。这里还有另一个原因，关乎到一个事实情况，就是编写新代码所消耗的工时比修复 bug 消耗的工时更加容易预测。例如，如果我请您预测需要花费多少时间来编写一个对列表进行排序的代码，您可以反馈给我一个精准的评估。但是如果我请您预测需要花费多少时间来处理您的代码在用户安装了 Internet Explorer 5.5 后无法运行的 bug，您可能无法估算，因为您压根不知道 bug 发生的原因。寻找 bug 的成因也许需要三天，也有可能只需要两分钟。 这意味着如果您拥有一个项目进度表，但是表上的完成项目都包含有大量需要被处理的 bug，那么这个项目进度表就完全不靠谱。但是如果您已经处理了所有已知的 bug，剩余的工作只有新需求的开发，那么您的项目进度表就会更加精准。 将未处理 bug 数量保持为 0 的另一大好处是您可以更快速的响应竞争，有些程序员认为这种行为表示产品随时处于可交付状态。如果您的竞争对手发布了一个杀手级的功能来偷取您的客户，您可以立刻实现该功能并且随后马上跟进发布，无需等待处理堆积如山的遗留 bug。 6. 您是否拥有最新的的项目进度表？既然我们已经聊到了项目进度表，如果您的代码交付和商务有关，那么商务同事会有无数个理由来询问您的项目进度。程序员在制定进度表时的暴躁众所周知 “等我做完了就能交付了！” 他们用这样的语言回怼他们的商务同事。 不幸的是，这样没法解决问题。在代码交付前，商务同事需要做很多很多的事：demo 展示、举办展会、投放广告，等等。这些事情都需要项目进度表的支持，而且项目进度表要尽可能的更新而且准确。 关于使用项目进度表的另一个至关重要的原因是，他可以帮助你决定接下来需要开发哪些软件功能，而且他还会强迫你筛选出最不重要的功能，移除他们，而不是陷入功能炎（featuritis）（也被称为 scope creep）。 保持您的项目进度表简单易读，参考我的文章 Painless Software Schedules，这里描述了如何通过简单的方式运用项目进度表。 7. 您是否拥有规格说明？编写规格说明书就像使用牙线：每个人都赞成这是件好事，但就是没人去做。 我不确定这事的成因，但是最大的可能性就是大部分程序员仇恨写文档。因此，当仅由程序员组成的团队解决问题时，他们更喜欢用代码而不是文档来表达他们的解决方案。他们更愿意深入研究并编写代码，而不是先制定规范。 在设计阶段，当您发现问题时，只需要寥寥几行文本就可以将问题解决。一旦代码已经完成，修复问题的开销就急剧增加，无论是情感上的（人们厌恶抛弃已经完成的代码），还是时间上的，因此程序员会产生对抗情绪。没有规格说明的项目往往以糟糕的设计和无法控制的进度收场。这似乎是 Netscape 犯过的错误，前四个版本变得如此混乱，以至于管理层 愚蠢地决定 扔掉代码并重新开始。然后他们在 Mozilla 上再次犯了这个错误，创造了一个失控的怪物，花了 好几年 才进入 alpha 阶段。 我的理论是，这个问题可以通过把程序员送去参加 写作集中培训 来降低他们对写文档的抵触情绪，或者是聘用有能力的项目经理来编写规格说明。无论如何，您都需要遵循简单的规则“先写规范后写代码”。 了解更多如何书写规格说说明的支持，参考我的另一篇 文章。 8. 程序员的工作环境是否安静？关于为知识工作者提供空间、安静和隐私能够提升生产效率的文章已经很广泛了，经典的软件管理书籍 Peopleware 大量记载了这些关于生产力提升的理论。 这里有个小问题。我们都知道知识工作者的最佳工作状态是“心流”，或者被称为“在领域中”，这种情况下他们完全专注于工作而且屏蔽外界的环境。他们忘记了时间，通过绝对的专注创造出伟大的作品。这是他们完成所有富有成效的工作的时候。作家、程序员、科学家甚至篮球运动员都会告诉你这种心流的感觉。 问题在于，进入心流状态并不简单。当您尝试观测时，您会发现平均需要 15 分钟才能进入最高效率的工作状态。有时候，如果您累了或者那天已经做了很多创造性的工作，您就是无法进入状态，您就把工作日剩下的时间花在闲逛、阅读网页、玩俄罗斯方块上。 另一个问题是，心流状态非常容易被打断。噪音、电话、出门吃午饭、需要出去买咖啡，或者被同事打扰——特别是被同事打扰——这些情况都会打断您的心流状态。如果同事问您一个问题，只造成了 1 分钟的中断，但这会让您脱离心流状态，需要半个小时才能再次恢复工作效率，那么你的整体工作效率就会遇到严重问题。如果您处于一个嘈杂的牛棚环境中，就像含有咖啡因的网络公司所喜欢创造的那样，营销人员在程序员旁边打电话尖叫，那么您的生产力将会下降，因为知识工作者一次又一次地被打扰，永远无法进入状态。 对于程序员来说，这种情况尤为严重。生产力依赖于能够同时处理短期记忆中的许多小细节。任何微小的打扰都会造成这些细节的崩溃。当您恢复工作时，您无法无法完整的回忆起这些细节（例如本地的变量名称，或者您正在实现该搜索算法时要达到的目的）您必须不断地寻回这些细节，在此之前您的工作速度都会被严重降低。 这是个简单的代数问题，我们认为（基于我们观测到的证据）只要我们打断了程序员的工作，哪怕只有一分钟，我们至少浪费了十五分钟的生产力。例如，有两个程序员，Jeff 和 Mutt， 待在标准 Dilbert 小牛育肥农场中彼此相邻的开放式小隔间中。Mutt 忘记了 strcpy 函数的 Unicode 版本的名称，他可以选择自己查询，这会消耗他 30 秒，他也可以选择询问 Jeff，这会消耗他 15 秒。由于他的座位就在 Jeff 旁边，他选择了询问 Jeff。Jeff 由于被打断工作而损失了 15 分钟的生产力（用来为 Mutt 节省 15 秒）。 现在，让我们把他们搬到有墙壁和门的单独办公室去。此时当 Mutt 记不得函数的名称时，他可以选择自己查询，这依然会消耗他 30 秒，或者他也可以选择询问 Jeff，但这次需要消耗他 45 秒，而且他还必须站起来（考虑到程序员的平均身体素质，这不是一件容易的事！），因此他选择了自己查询。这次 Mutt 损失了 30 秒的生产力，但是 Jeff 节约了 15 分钟。 9. 您是否在使用最先进的生产工具？使用编译型语言写代码是最后仍然无法立刻在普通家用计算机上完成的事情之一。如果您的编译过程超过了几秒钟，改用最新款的电脑可以节省您的时间。如果编译过程达到了 15 秒，程序员就会等的无聊然后跑去刷 洋葱新闻，一不留神就会刷好几个小时。 使用单个显示器对 GUI 软件进行 Debug 也不是不可能，但是过程非常痛苦。如果您在编写 GUI 代码，两台显示器会让事情变的简单许多。 大部分程序员最终都必须操作位图来制作图标和菜单，然而大部分程序员并没有一个好用的位图编辑器。“用 Windows 画图来处理位图”听起来像个笑话，但是实际上很多程序员都不得不这样做。 在 我的最后一份工作 中，运维老大持续的给我发垃圾邮件来抱怨我在服务器上使用了超过（大约）220M的硬盘空间。我则是这样告诉他，考虑到现在的硬盘价格，我使用这些硬盘来存储的成本明显要低于我使用卫生纸来存储。即便是花 10 分钟来让我清理一下我的文件夹，那也是对我生产力的一种浪费。 顶尖的开发团队不会折磨他们的程序员。即使是由于工具不好用带来的微小挫败感，积累起来也会让程序员变得暴躁和不开心。而一个带有负面情绪的程序员实际上就是一个毫无生产力的程序员。 除此之外…其实程序员很容易被最新最酷的电子产品吸引。用这种方式引诱他们为你工作比起涨工资便宜的多。 10. 团队中有测试人员吗？如果您的团队没有专职的测试人员，或者没有至少为每两到三个项目配一个测试员，那么要么你就是在交付充满 BUG 的产品，要么你就是在让时薪 100 美金的程序员在干时薪 30 美金的测试员的活。在测试员身上降低支出是一种令人发指的“虚假节约”，很多人没有意识到这一点，这让我很震惊。 阅读 Top Five (Wrong) Reasons You Don’t Have Testers，这篇文章里我详细介绍了这个主题。 11. 招募新人的时候会让他们在面试时写代码吗？您会在雇佣一名魔术师的时候不让他为您展示一些魔术技巧吗？当然不是。 您会在雇佣婚礼厨师的时候不品尝他们的食物吗？我觉得也不是。（除非您雇佣的是 Marge 阿姨，而且如果您不让她制作她“出名的”碎肝饼的话，她会恨您一辈子的）。 然而，每时每刻，都有程序员会因为他感人的简历或者在面试时表现出的言谈举止被雇佣。或者他们只是被问了一些无关紧要的编程细节（“CreateDialog() 和 DialogBox() 的区别是什么？”），这种东西只要查查文档就行了。您不应该在乎他能否记得住成百上千个细节，您应该在乎的是他有没有能力写代码。或者说，更糟糕的情况下，他们会被询问“AHA！”问题：就是那种您知道了答案就特别简单，但是不知道答案也完全无所谓的问题。 请不要再做这种事情了。您可以在面试的时候安排任何环节，但千万记得要让受试者写一些代码。（参考我的文章 Guerrilla Guide to Interviewing，了解更多建议）。 12. 您会进行走廊可用性测试吗？走廊可用性测试指的是您在走廊随便抓一个人，让后强迫他试用您刚写完的代码。如果您对五个人这样做，您就会学到关于代码可用性问题中 95% 的知识。 好的 UI 设计没有您想的那么难，而这对于客户选择并钟情您的产品至关重要。您可阅读我的 free online book on UI design，这是为程序员准备的一个简短的入门书籍。 但是关于 UI 最重要的一点是，只需将您的程序展示给几个用户（实际上，五到六个人就完全足够了），您立刻就会发现用户关注的最大问题。这篇文章 Jakob Nielsen’s article 阐述了这个现象的成因。即便您缺乏关于 UI 设计的技巧，只要您坚持进行走廊测试（这也没啥成本），您的 UI 就会变得好很多，很多。","tags":[{"name":"翻译","slug":"翻译","permalink":"https://vitsumoc.github.io/tags/%E7%BF%BB%E8%AF%91/"},{"name":"软件项目","slug":"软件项目","permalink":"https://vitsumoc.github.io/tags/%E8%BD%AF%E4%BB%B6%E9%A1%B9%E7%9B%AE/"}]},{"title":"在 Windows 环境使用 proxifyre 代理应用程序","date":"2024-04-15T01:03:38.000Z","path":"在 Windows 环境使用 proxifyre 代理应用程序.html","text":"wiresock&#x2F;proxifyre 项目链接 适用场景proxifyre 适用于，当您已经拥有一个可用的 socks5 代理，但却不了解如何让某个应用程序通过此代理收发包的情况。 简介proxifyre 用于指定一些应用程序的网络流量通过 socks5 代理。 proxifyre 是基于 Windows 包过滤器 socksify demo 做的增强，加入了 UDP 能力，简化了配置。 proxifyre 支持被注册为 Windows 服务。 依赖使用 proxifyre 前需要安装两个依赖： Windows Packet Filter (WinpkFilter) Visual Studio Runtime Libraries(Visual Studio 2022 redistributable download page) 配置proxifyre 默认配置文件名为 app-config.json，将配置文件放到 proxifyre 执行目录下会被直接使用，配置文件示例如下： &#123; \"logLevel\": \"None\", \"proxies\": [ &#123; \"appNames\": [\"chrome\", \"C:\\\\Program Files\\\\WindowsApps\\\\ROBLOXCORPORATION.ROBLOX\"], \"socks5ProxyEndpoint\": \"158.101.205.51:1080\", \"username\": \"username1\", \"password\": \"password1\", \"supportedProtocols\": [\"TCP\", \"UDP\"] &#125; ] &#125; logLevel: 日志等级，可选项为：None Info Deb All proxies：代理配置列表 appNames：被代理程序名，采用模糊匹配，例如 chrome 会匹配到包含 chrome 字符串的所有程序。如果使用路径则可以精确匹配。 socks5ProxyEndpoint：socks5 服务位置，地址+端口。 username：如果 socks5 服务用户名，可不填。 password：socks5 服务密码，可不填。 supportedProtocols：被代理的网络协议，支持 TCP UDP。 使用完成配置后，直接运行 ProxiFyre.exe 即可使用，日志文件会生成在 /logs 路径。 也可以通过下列命令进行服务的注册、启动、停止和卸载，通过 Windows 服务管理： ProxiFyre.exe install ProxiFyre.exe start ProxiFyre.exe stop ProxiFyre.exe uninstall 当然也可以通过 nssm 工具将 ProxiFyre.exe 注册为 Windows 服务。","tags":[{"name":"网络工具","slug":"网络工具","permalink":"https://vitsumoc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7/"}]},{"title":"[翻译]Go教程：泛型入门","date":"2024-04-12T02:42:27.000Z","path":"Go教程：泛型入门.html","text":"原文 Tutorial: Getting started with generics .indentation { margin-left: 2rem; } 这篇教程介绍了 Go 中泛型的基础。通过泛型，您可以定义和使用一些函数或类型，这些函数或类型可以用于处理调用代码提供的任意类型集合。 在这个教程中，您将声明两个简单的非泛型函数，随后在一个单一的泛型函数中实现同样的逻辑。 您将按照如下步骤进行： 为您的代码创建文件夹。 一个非泛型的函数。 添加一个可以处理多种类型的泛型函数。 在调用泛型函数时删除类型参数。 声明一个类型约束。 备注：其他教程请查看链接。 备注：如果您需要的话，您也可以使用 “Go dev branch” 模式的 Go playground 来编辑和运行您的程序。 准备工作 Go 1.18 及以上。有关安装说明，请参考 Installing Go。 代码编辑工具。任何文本编辑器均可。 命令行终端。Go 可以在 Linux 和 Mac 的终端中运行，也可以在 Windows 的 PowerShell 或 cmd 中运行。 创建文件夹为了开始一切，先创建文件夹用来存放您即将编写的代码。 打开一个命令提示符并切换到您的家目录。 在 Linux 或者 Mac 上： $ cd 在 Windows 上： C:\\&gt; cd %HOMEPATH% 教程的剩余部分我们都会将 $ 作为提示符。您使用的命令在 Windows 中也会生效。 在命令提示符中，为您的代码创建名为 generics 的文件夹。 $ mkdir generics $ cd generics 为您的代码创建一个模块。 运行 go mod init 命令，为他提供您的新代码的模块路径。 $ go mod init example/generics go: creating new go.mod: module example/generics 备注：对于用于生产的代码，您最好根据您的需要去选择模块路径。有关更多消息，请参考Managing dependencies。 接下来，您会添加一些处理 map 的简单代码。 非泛型函数在这一步中，您会创建两个函数，他们都会将 map 中的值加总，并返回结果。 您声明两个函数，而非一个，因为您需要处理两种不同类型的 map：一个存储 int64 类型的值，另一个存储 float64 类型的值。 编写代码 使用您的文本编辑器，在 generics 文件夹中创建一个名为 main.go 文件。您将要在这里编写您的 Go 代码。 打开 main.go，粘贴如下包声明。 package main 独立的程序（而非库）始终使用 main 包。 在包声明下方，粘贴如下两个函数声明。 // SumInts adds together the values of m. func SumInts(m map[string]int64) int64 &#123; var s int64 for _, v := range m &#123; s += v &#125; return s &#125; // SumFloats adds together the values of m. func SumFloats(m map[string]float64) float64 &#123; var s float64 for _, v := range m &#123; s += v &#125; return s &#125; 在上述代码中，您完成了： 声明了两个将 map 中的值加总并返回的函数。 SumFloats 接收类型为 [string]float64 的 map。 SumInts 接收类型为 [string]int64 的 map。 在 main.go 文件的顶部，包声明的下方，粘贴 main 函数，他初始化两个 map，并将他们当作您之前声明的函数的参数来使用。 func main() &#123; // Initialize a map for the integer values ints := map[string]int64&#123; \"first\": 34, \"second\": 12, &#125; // Initialize a map for the float values floats := map[string]float64&#123; \"first\": 35.98, \"second\": 26.99, &#125; fmt.Printf(\"Non-Generic Sums: %v and %v\\n\", SumInts(ints), SumFloats(floats)) &#125; 在上述代码中，您： 初始化了 float64 值的 map 和 int64 值的 map，每个都有两条数据。 调用之前定义的两个函数，查询两个 map 各自的总值。 打印结果 在 main.go 的顶部附近，在包声明的下方，引入您代码中需要的包。 将文件顶部修改为： package main import \"fmt\" 保存 main.go。 运行代码在命令行中，main.go 文件所在的文件夹路径下，运行命令。 $ go run . Non-Generic Sums: 46 and 62.97 通过泛型，您可以只编写一个函数，而非两个。接下来，您会添加一个单独的泛型函数，他可以用于 int64 类型的 map 或 float64 类型的 map。 泛型函数在这一节中，您将要添加一个泛型函数，他可以接收整数或者浮点数类型的 map 作为参数，他可以用来替代您之前编写的两个函数。 为了同时支持两种类型的值，这个函数需要通过一种方式来声明他支持的类型。从另一方面来说，调用代码需要有一种方式来指定他使用何种类型的 map 来调用该函数。 为了实现这个目标，您声明的函数除了有普通的函数参数外，还需要有 类型参数（type parameters）。正是这些类型参数支撑了泛型函数，让他们能够应付不同类型的参数。您在调用泛型函数时需要同时传入类型参数和函数参数。 每个类型参数都有一个 类型约束（type constraint） 来扮演他的元类型。每个类型约束指定了调用函数在传入各类型参数时允许使用的类型参数范围。 虽然类型参数约束往往提供了多种类型，但在编译时类型参数只代表一种类型——调用代码所提供的类型。如果调用代码提供的类型不满足类型参数约束，那么编译就会失败。 请记住，类型参数必须支持泛型代码中的任何操作。例如，如果您泛型函数中的代码包含字符串的操作（例如取索引），但您的类型参数约束包括了数字类型，那么编译就会失败。 在您接下来要编写的代码中，您将实现供同时允许整数和浮点数的类型参数约束。 编写代码 在您之前添加的两个函数下方，粘贴如下泛型函数。 // SumIntsOrFloats sums the values of map m. It supports both int64 and float64 // as types for map values. func SumIntsOrFloats[K comparable, V int64 | float64](m map[K]V) V &#123; var s V for _, v := range m &#123; s += v &#125; return s &#125; 在这段代码中，您： 声明了带有两个类型参数（在中括号中）的 SumIntsOrFloats 函数，类型参数是 K 和 V，同时声明了一个使用类型参数定义的函数参数 m，他的类型是 map[K]V。函数返回值的类型也是 V。 将类型参数 K 的类型约束指定为可比较的（comparable）。Go 中的 comparable 约束就是专门为了这种情况定义的，他表示允许所有支持 &#x3D;&#x3D; 和 !&#x3D; 的类型。Go 要求 map 的键必须是可比较的，因此您必须将 K 声明为 comparable，他才可以作为 map 中的 key。这也同时确保了调用代码需要使用合理的类型作为 map 的键。 将类型参数 V 的类型约束指定为两种类型，int64 和 float64。使用 | 分隔两种类型，表示这两种类型都可以被使用。在调用代码中使用任何一种都可以成功编译。 指定函数参数 m 的类型为 map[K]V，其中 K 和 V 是之前指定的类型参数。请注意，我们现在知道 map[K]V 是一个合法的 map，因为 K 必须是一个可比较类型。如果我们之前没有将 K 声明为可比较类型，编译器会拒绝引用 map[K]V。 在 main.go 中，您已有代码的下方，粘贴如下代码。 fmt.Printf(\"Generic Sums: %v and %v\\n\", SumIntsOrFloats[string, int64](ints), SumIntsOrFloats[string, float64](floats)) 在这段代码中，您： 调用了您之前申明的泛型函数，传入了您之前创建的 map。 指定类型参数——将类型名称放入方括号中——用来指明成为您当前调用的函数中的类型参数。 正如您即将在下一小节中看到的，您往往可以省略调用函数时的类型参数。Go 可以通过您的代码推断他们。 打印函数的加总结果。 运行代码在命令行中，main.go 文件所在的文件夹路径下，运行命令。 $ go run . Non-Generic Sums: 46 and 62.97 Generic Sums: 46 and 62.97 为了运行您的代码，编译器会在每次调用时将类型参数替换为调用时设置的具体类型。 在调用您的泛型函数的过程中，编译器会使用您指定的类型参数替换函数中的类型参数。正如您即将在下一小节中看到的，在很多情况下您可以省略类型参数，因为编译器会自动推断他们。 删除调用泛型函数时的类型参数在这一小节，您将添加一个新版本的对泛型函数的调用，通过一些微小的改动来简化调用代码。您将会删除类型参数，实际上在这个例子中他们确实是不必要的。 当 Go 编译器可以推断您想要使用的类型时，您可以在调用代码中省略类型参数。编译器通过函数参数的类型来推断类型参数。 请记住，这并不总是可行的。例如，如果您希望调用一个没有函数参数的泛型函数，您就必须在调用时包含类型参数。 编写代码 在 main.go 中，您现有代码的下方，粘贴如下代码。 fmt.Printf(\"Generic Sums, type parameters inferred: %v and %v\\n\", SumIntsOrFloats(ints), SumIntsOrFloats(floats)) 在这段代码中，您： 调用泛型函数，并省略了类型参数。 运行代码在命令行中，main.go 文件所在的文件夹路径下，运行命令。 $ go run . Non-Generic Sums: 46 and 62.97 Generic Sums: 46 and 62.97 Generic Sums, type parameters inferred: 46 and 62.97 接下来，您会通过将整数和浮点数设置为一种可复用的类型约束来进一步简化函数。 声明类型约束在这个最后的小节中，您将要把您之前定义的约束做成一个接口，这样您就可以在更多地方复用他们。通过这种方式声明约束有助于精简代码，特别是当约束的内容逐渐复杂时。 您可以将类型约束声明为一个接口，这种约束允许任何类型来实现这个接口。例如，如果您声明了一个有三种方法的类型约束接口，并将他应用为一个泛型函数的类型参数，那么用于调用此函数的类型必须实现所有这些方法。 约束接口也可以指定特定的类型，就像您即将在本节中看到的那样。 编写代码 在 main 函数之前，引入语句之后，粘贴下列用于声明类型约束的代码。 type Number interface &#123; int64 | float64 &#125; 在这段代码中，您： 声明了 Number 接口作为类型约束。 在 Number 接口中声明了 int64 和 float64。 在本质上，您只是将函数中的类型声明换了个地方。此时，当您想要表示 int64 或 float64 的类型时，您可以直接使用 Number 类型，而非 int64 | float64。 在您之前定义的函数下方，粘贴 SunNumbers 泛型函数。 // SumNumbers sums the values of map m. It supports both integers // and floats as map values. func SumNumbers[K comparable, V Number](m map[K]V) V &#123; var s V for _, v := range m &#123; s += v &#125; return s &#125; 在这段代码中，您： 声明了一个和原有泛型函数逻辑相同的泛型函数，但使用接口类型取代了原来的类型约束。就像之前一样，您使用类型参数作为函数参数和返回值的类型。 在 main.go 中，您现有的代码下方，粘贴如下代码。 fmt.Printf(\"Generic Sums with Constraint: %v and %v\\n\", SumNumbers(ints), SumNumbers(floats)) 在这段代码中，您： 调用 SubNumbers，并用之前定义的 map 作为参数，打印每个加总的值。 就像在前面章节中提到的，您在调用泛型函数时省略了类型参数（其中的类型需要被中括号包裹）。Go 编译器可以通过其他参数来推断类型参数。 运行代码在命令行中，main.go 文件所在的文件夹路径下，运行命令。 $ go run . Non-Generic Sums: 46 and 62.97 Generic Sums: 46 and 62.97 Generic Sums, type parameters inferred: 46 and 62.97 Generic Sums with Constraint: 46 and 62.97 结论很好，您已经靠自己掌握了 Go 中的泛型。 向您推荐这些主题： Go Tour 是一个非常优秀的对 Go 的介绍。 您可以在 Effective Go 和 How to write Go code 中找到很多关于 Go 的最佳实践。 完整代码您可以通过在 Go playground 中点击 Run 按钮来运行这些代码。 package main import \"fmt\" type Number interface &#123; int64 | float64 &#125; func main() &#123; // Initialize a map for the integer values ints := map[string]int64&#123; \"first\": 34, \"second\": 12, &#125; // Initialize a map for the float values floats := map[string]float64&#123; \"first\": 35.98, \"second\": 26.99, &#125; fmt.Printf(\"Non-Generic Sums: %v and %v\\n\", SumInts(ints), SumFloats(floats)) fmt.Printf(\"Generic Sums: %v and %v\\n\", SumIntsOrFloats[string, int64](ints), SumIntsOrFloats[string, float64](floats)) fmt.Printf(\"Generic Sums, type parameters inferred: %v and %v\\n\", SumIntsOrFloats(ints), SumIntsOrFloats(floats)) fmt.Printf(\"Generic Sums with Constraint: %v and %v\\n\", SumNumbers(ints), SumNumbers(floats)) &#125; // SumInts adds together the values of m. func SumInts(m map[string]int64) int64 &#123; var s int64 for _, v := range m &#123; s += v &#125; return s &#125; // SumFloats adds together the values of m. func SumFloats(m map[string]float64) float64 &#123; var s float64 for _, v := range m &#123; s += v &#125; return s &#125; // SumIntsOrFloats sums the values of map m. It supports both floats and integers // as map values. func SumIntsOrFloats[K comparable, V int64 | float64](m map[K]V) V &#123; var s V for _, v := range m &#123; s += v &#125; return s &#125; // SumNumbers sums the values of map m. Its supports both integers // and floats as map values. func SumNumbers[K comparable, V Number](m map[K]V) V &#123; var s V for _, v := range m &#123; s += v &#125; return s &#125;","tags":[{"name":"翻译","slug":"翻译","permalink":"https://vitsumoc.github.io/tags/%E7%BF%BB%E8%AF%91/"},{"name":"Go","slug":"Go","permalink":"https://vitsumoc.github.io/tags/Go/"}]},{"title":"在Ubuntu22.04LTS上使用 BBR","date":"2024-04-11T04:27:40.000Z","path":"在Ubuntu22.04LTS上使用 BBR.html","text":"什么是BBR 以下内容摘自Wiki Bottleneck Bandwidth and Round-trip propagation time (BBR) 是由 Google 在 2016年开发的一种拥塞控制算法 (CCA)。虽然其他的拥塞控制算法大多基于丢包机制，通过丢包来检测到拥塞并降低传输速率，但 BBR，和 TCP Vegas 相似，是基于模型的。算法利用网络传送最近一次发出的数据包达到的最大带宽和往返时间来构建网络模型。每次累积确认或选择性确认数据包的传送都会产生一个速率样本，该样本记录了数据包的发送时间和确认时间之间间隔内传送的数据量。 在 YouTube 的实际部署中，BBRv1 版本平均带来了 4% 的网络吞吐量提升，在某些国家甚至能达到 14%。BBR 算法从 Linux 4.9 版本开始就被集成到 Linux 内核的 TCP 协议栈中。它同样也适用于 QUIC 协议。 BBR 版本 1 (BBRv1) 对非 BBR 流的公平性存在争议。尽管谷歌的演示文稿显示 BBRv1 可以很好地与 CUBIC 协同工作，但一些研究人员 (例如 Geoff Huston 和 Hock、Bless 及 Zitterbart) 认为它对其他数据流并不公平，并且难以扩展。Hock等人还发现 Linux 4.9 版本的 BBR 实现存在一些严重的固有缺陷，例如增加的队列延迟、不公平性和大量丢包。Soheil Abbasloo 等人 (C2TCP 算法的作者) 指出，BBRv1 版本在动态环境（例如蜂窝网络）中表现不佳。他们还指出 BBR 存在公平性问题。例如，当网络中存在一个 CUBIC 流 (它是 Linux、Android 和 MacOS 操作系统默认的 TCP 实现) 和一个 BBR 流时，BBR 流可能会主导 CUBIC 流，并占用整个链路带宽。 第 2 版 (Version 2) 尝试解决与基于丢包的拥塞控制 (例如 CUBIC) 共同运行时出现的不公平问题。BBRv2 改进了 BBRv1 的模型，加入了丢包信息和来自显式拥塞通知 (ECN) 的信息。虽然 BBRv2 有时可能比 BBRv1 吞吐量更低，但它通常被认为具有更好的有效吞吐量 (goodput)。[需要来源] 第 3 版 (BBRv3) 修复了 BBRv2 中的两个漏洞（带宽探测过早结束、带宽收敛问题）并进行了一些性能调整。它还提供了一个变体版本，称为 BBR.Swift，专为数据中心内部链路进行优化：它使用 network_RTT（不包含接收方延迟）作为主要的拥塞控制信号。 使用既然 BBR 已经被集成到 Linux 内核中，那么我们稍作配置就可以使用，首先： echo net.core.default_qdisc=fq >> /etc/sysctl.conf echo net.ipv4.tcp_congestion_control=bbr >> /etc/sysctl.conf 向 sysctl.conf 写入两条配置： net.core.default_qdisc=fq 修改 Linux 系统中的的 qdisc 为 fq(fair queue)，避免 BBR 占用太多流量 net.ipv4.tcp_congestion_control=bbr &gt;&gt; 将 ipv4 的 TCP 拥塞控制算法设置为 BBR 接下来，保存生效： sysctl -p 查看是否已经应用： sysctl net.ipv4.tcp_congestion_control net.ipv4.tcp_congestion_control = bbr 这样就完成了所有配置。 （经过实际测试，不开启公平队列时 BBR 能提供更大的速率，也许对于一些纯粹跑流量的服务器（例如网络代理），不开启公平队列是更好的用法。）","tags":[{"name":"豆知识","slug":"豆知识","permalink":"https://vitsumoc.github.io/tags/%E8%B1%86%E7%9F%A5%E8%AF%86/"},{"name":"Linux","slug":"Linux","permalink":"https://vitsumoc.github.io/tags/Linux/"},{"name":"网络工具","slug":"网络工具","permalink":"https://vitsumoc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7/"},{"name":"VPS","slug":"VPS","permalink":"https://vitsumoc.github.io/tags/VPS/"}]},{"title":"[转]人月神话的困境：项目经理的挑战与转变","date":"2024-04-01T08:42:26.000Z","path":"人月神话的困境.html","text":"原文 人月神话的困境：项目经理的挑战与转变 线性思维的束缚与局限很多“聪明人”的思维都是线性思维，拿到任务，分解成小项，逐个完成，一步一步的像是在做证明题：期待着攒够一个又一个的事实和推理，最后拼图一般将它们串起来，达成某项任务。逻辑层面上看起来无懈可击，仿佛一切困难都可迎刃而解。 不可否认的是这套思维在应试方面屡试不爽，因为有一个天然的假设是存在的：“所有问题都有标准答案，问题在设计上就是逻辑可解的”。但是习惯这套“逻辑“的人，在处理现实世界的问题时，往往会不自觉地将自己带入死胡同。 逻辑、事实关联的对立与统一我将以上方法论称之为逻辑关联，与之相对的即是事实关联，生活中不乏遇到这种思维陷阱： 白菜3块钱一斤，15块钱可以买五斤白菜 你们工厂一个月可以生产3000个零件，那明天先给我10个吧 这个项目比较急，上次排期的工时是一周，我再给你一倍的人，三天给我做出来 有时候其实很难意识到这样的思考模式存在的问题，这也是《人月神话》里屡次提到的困境，可能上面的例子不太直观，代入下现实生活： 生一个孩子需要9个月，生一对双胞胎需要18个月 生一个孩子需要9个月，9个妈妈是不是只要1个月？！ 专注解决问题的思维方式久了，就会慢慢开始只在乎逻辑关联，而忽略事实关联，就会开始期待一种“银弹”，说是缘木求鱼也不过如此。 初级项目经理常见的误区与反思很多初级项目经理最常犯的错误就在这里，总是期待着任何事情都有一个进度条，这样就可以直观的反馈当前进展，自己要做的也就不过是按照排期表往下催进度。 这种人最喜欢问的问题就是“你这个要多久才能做出来？”，行使着身为“管理者”的特权，却不承担应有的角色义务。 项目经理这个角色，真正应该问的问题是“你还需要哪些其他的帮助可以提升你的速度？”。优秀的项目经理知道，项目进度不是靠完成了多少来判断，而是靠如何拥有足够的资源进行最大规模的试错。项目经理确保的应该是满足需求，成功交付。 然而现实中X-Y本末倒置的现象非常普遍，即为了完成某个目标，制定了一些KPI（关键绩效指标），最后完全忽视了原初的目标，而去追求后定的KPI。就像是前段时间北京环卫工人买新鲜白菜当厨余垃圾事件，政策目标是垃圾分类，管理者制定了每种垃圾必须的数量指标，然后只考察这个数量指标，下面执行的人就变了味，偏离初衷，最终酿成悲剧。 软件行业里人的特殊性再者，项目经理在向上汇报进度的同时，也在享受作为一个管理者的荣誉，以及成功后收割胜利果实。这使得执行层面的人本身就对这些只能汇报进度，却无法承担执行工作的人非常敌视。 况且在软件开发这个对人依赖非常大的领域，管理起来更需要一定的水平积累。项目经理每天跟人打交道，要知道人是有感情的，绝对不是你给他输入1+1，他就给你输出2。同一个功能点同一个人，由于其工作状态的差别，也会产生巨大的差异，如果主动积极做，可能只要1天，消极怠工的做，就无法预期了。这在传统行业是无法想象的，因为只要按规定的程序和规范来建房子，即使换一拨工人，也可以在同样的时间建造出来，建出来的房子的质量也不会相差太远。要知道，再烂的挖土机也能挖出一个大坑。 结果导向与过程管理的平衡：避免悲剧的关键执行时，对软件工程师来说，遇到问题，解决问题。但如果遇到的问题占用了比预期更多的时间，则是对自己能力和自信的打击。此时如果项目经理也不专业，硬推进度，工程师就会出现一些掩盖问题的行为。 我总觉得，负责技术攻坚的人也去追进度就很可惜。悲剧的根源是管理能力和技巧的不足，如果真的想做到结果导向，需要的是目标的制定和拆解，工作计划的精确评估和执行，真实有效的复盘，信息同步与应对突发状况的能力，这些都对领导者有很高的要求，如果能力不足以管理结果，那大家就只能来管理过程，最终陷入恶性循环。 参考工程师想要做管理？先改变你的思考方式 从程序员到项目经理：为什么要当项目经理","tags":[{"name":"软件项目","slug":"软件项目","permalink":"https://vitsumoc.github.io/tags/%E8%BD%AF%E4%BB%B6%E9%A1%B9%E7%9B%AE/"},{"name":"转载","slug":"转载","permalink":"https://vitsumoc.github.io/tags/%E8%BD%AC%E8%BD%BD/"}]},{"title":"[翻译]Effective Go","date":"2024-03-25T07:22:03.000Z","path":"effective_go.html","text":"原文 Effective Go 目录 简介 示例 格式 注释 命名 包命名 Getters 接口命名 驼峰命名 分号 控制结构 If 重声明与重赋值 For Switch Type switch 函数 多返回值 命名结果参数 Defer 数据 通过new分配 构造器与复合字面量 通过make分配 数组 切片 二维切片 Maps 打印 Append 初始化 常量 变量 init函数 方法 指针或是值 接口和其他类型 接口 转换 接口转换与类型断言 概论 接口与方法 空标识符 多重赋值中的空标识符 未使用的引入和变量 为了潜在作用而引入 接口检查 嵌入式 并发 通过通信共享 Goroutines Channels Channels of channels 并行处理 A leaky buffer 错误 Panic Recover 一个WEB服务器 .indentation { margin-left: 2rem; } 简介Go 是一门新语言。虽然他借鉴了现有编程语言的思想，但他也具有独特的特性，使得有效的 Go 程序与其他语言编写的程序有性质上的不同。直接将 C++ 或 Java 程序改编为 Go 程序可能无法得到一个让人满意的结果——Java 程序是使用 Java 编写的，而不是 Go。另一方面，从 Go 的角度思考问题可能会产生一个成功但完全不同的程序。换句话说，要写好Go，重要的是要理解它的特性和习惯用法。了解 Go 编程的既定约定也很重要，例如命名、格式、程序构造等，这样您编写的程序将易于其他 Go 程序员理解。 这份文档提供了编写清晰、地道的 Go 代码的建议。他补充了 language specification、the Tour of Go以及 How to Write Go Code 这几份资料，建议您在阅读本指南之前先阅读这些资料。 2022 年 1 月注：这份指南最初发布于 2009 年，自那以来更新并不频繁。虽然他仍然是理解如何使用 Go 语言本身的良好指南（因为语言本身很稳定），但他几乎没有涉及到 Go 生态系统自发布以来的重大变化，例如构建系统、测试、模块化和多态性。由于近年来变化太多，官方也不会再更新此文档。目前已经有很多文档、博客和书籍详细描述了现代 Go 的用法，足以满足学习需求。因此，虽然这份「Effective Go」指南仍然可用，但读者需要理解它并不是全面的指南。详情请参阅 issue 28782。 示例Go package sources不仅是核心库，还包含了如何使用该语言的示例。此外，许多标准库包都包含可直接在 go.dev 网站上运行的独立可执行示例（例如本例，如果需要，可以点击 Example 按钮打开它）。如果您对如何解决问题或如何实现某项功能有疑问，那么标准库中的文档、代码和示例可以提供答案、思路和背景信息。 格式格式问题是争议最大但影响最小的问题。人们可以适应不同的格式风格，但如果没有必要的话，最好保持统一，这样大家就可以少花时间在格式上争论。 难点在于如何在没有冗长强制性风格指南的情况下实现这种「乌托邦」式的统一格式。 对于 Go 代码格式，我们采用了一种不同寻常的方法，让机器来处理大多数格式化问题。gofmt 程序（也可以称为 go fmt，它在包级别而不是源文件级别工作）读取一个 Go 程序，并按照标准的缩进和垂直对齐样式输出源代码，同时保留并根据需要重新格式化注释。如果您想了解如何处理一些新的布局情况，请运行 gofmt； 如果答案看起来不对，请重新排列您的程序（或提交有关 gofmt 的 bug 报告），不要试图绕过它。 例如，不必浪费时间去对齐结构体中的注释，Gofmt 会协助你处理，对于如下声明： type T struct &#123; name string // name of the object value int // its value &#125; gofmt 会将列对其： type T struct &#123; name string // name of the object value int // its value &#125; 所有标准库中的 Go 代码都使用 gofmt 进行了格式化。 简要的介绍一下格式化的细节： 缩进 我们使用制表符 (tab) 进行缩进，gofmt 工具默认也会采用这种方式。只有在绝对必要的情况下才使用空格。 行长 Go 没有代码行长限制。不用担心代码会超出打孔卡的限制。如果一行代码看起来太长，可以将其换行并使用额外的制表符缩进。 括号 与 C 和 Java 语言相比，Go 需要更少的括号：控制结构 (if、for、switch) 的语法本身不需要括号。此外，Go 的运算符优先级层次更短更清晰。因此 x&lt;&lt;8 + y&lt;&lt;16 通过间隔暗示了执行顺序，这一点和其他编程语言不同。 注释Go 提供了 C 风格的 &#x2F;* *&#x2F; 块状注释和 C++ 风格的 &#x2F;&#x2F; 行注释。通常情况下会使用行注释，块状注释往往是在包注释中使用，但也可以用在表达式中或禁用大块的代码。 位于顶层声明之前的注释，如果没有额外的空行隔开，就会被视为该声明的文档。这些“文档注释”是 Go 程序包或命令的主要文档形式。有关文档注释的更多信息，请参阅“Go Doc Comments”。 命名在 Go 中，命名和其他语言一样重要。他们甚至具有语义上的影响：一个名称对于包外部的可见性取决于他的首字母是否大写。因此，值得花一点时间讨论 Go 程序中的命名约定。 包命名当一个包被引入时，包名称就成为了其内容的入口，当做了如下引入之后 import \"bytes\" 引入该包的程序可以使用 bytes.Buffer。所有人都使用相同的名称来引用包的内容有很多好处，这也意味着包的命名必须是优秀的：短，简洁，意义明确。按照约定，包使用小写单个单词命名，不应出现下划线或驼峰命名。宁可过于简洁，因为每个使用您的包的人都需要输入这个名称。也无需担心包名的重复，包名只是引入时的默认名称，他不必在所有的源码中保持唯一，在极少数的包名重复的情况下，引入包可以选择一个本地使用的别名。无论如何，包名重复都是很罕见的，因为引入中的文件名决定了在使用哪个包。 另一个约定是包名是他源文件夹的基础名称，src&#x2F;encoding&#x2F;base64 中的包被 “encoding&#x2F;base64” 引入，但使用名称为 base64，并非 encoding_base64 或 encodingBase64。 引入包的程序会使用包名来引用包中的内容，因此包导出的名称可以利用这一点来避免重复（不要使用 import . 来省略包名，他可以简单的运行一些必须在包外部运行的测试，但应该在其他场合下避免）。例如，在 bufio 包中的缓冲读取器被命名为 Reader，而不是 BufReader，因为使用者看到的将会是 bufio.Reader，这是一个清晰、简洁的名称。此外，由于引入的内容总是和引入的包名一起使用，因此 bufio.Reader 并不会和 io.Reader 冲突。相似的，创建 ring.Ring 新实例的函数——也就是 Go 中的构造函数——通常被命名为 NewRing，但是考虑到 Ring 是 ring 包中导出的唯一类型，而且又因为包名已经是 ring，所以这个函数只需被命名为 New，包的使用者看到的是 ring.New。利用包的结构可以帮助你选择合适的命名。 另一个简短的示例是 once.Do，once.Do(setup) 读起来非常友好，而且明显优于 once.DoOrWaitUntilDone(setup)。长的命名不一定能带来更丰富的含义。一个实用的文档注释常常比长的命名更有价值。 GettersGo 没有提供对 getters 和 setters 的自动支持。但您可以自己添加 getters 和 setters，而且这也常常是很适合的，但是在 getter 的名称前加上 Get 即不必须，也不符合 Go 的习惯。假设你有一个名为 owner 的字段（小写，非导出），那么他的 getter 方法应该被命名为 Owner（大写，导出），而不是 GetOwner。使用大写名称来作为导出标志可以方便的区分字段和方法。如果需要的话，他的 setter 函数应该被命名为 SetOwner。这些名称在实践中具有很好的阅读性： owner := obj.Owner() if owner != user &#123; obj.SetOwner(user) &#125; 接口命名按照约定，只有一个方法的接口会使用方法名加 -er 后缀或类似的修改，构成一个表示操作者的名词：Reader，Writer，Formatter，CloseNotifier 等等。 许多常用方法名已经约定俗成，遵循这些既有命名并保持其含义是高效的。Read，Write，Close，Flush，String 等都拥有标准的方法签名和含义。为了避免混淆，不要给你的方法起这些名称，除非它们的方法签名和含义完全相同。相反地，如果你的实现具有和现有类型完全相同的方法签名和含义，那么就应该使用相同的名称和方法签名。例如，将你的字符串转换方法命名为 String，而不是 ToString。 驼峰命名最后，Go 中处理多个单词的名称时使用大驼峰命名或小驼峰命名，而非下划线连接。 分号和 C 相同，Go 的语法使用分号来终止语句，但与 C 不同的是，这些分号不会出现在源码中。取而代之的是，词法分析器会使用一个简单的规则在扫描时自动插入分号，因此输入的文本基本上无需含有分号。 规则是这样的。如果在换行符之前的最后一个词是类型标志（比如 int 和 float64），基本字面量（比如一个数字或字符串），或是以下之一： break continue fallthrough return ++ -- ) &#125; 词法分析器会在这些词后插入一个分号。可以这样总结“如果一个换行符前的词可以使用分号结尾，则插入一个分号”。 右大括号前的分号也可以省略，因此这样的语句 go func() &#123; for &#123; dst &lt;- &lt;-src &#125; &#125;() 无需分号。地道的 Go 程序只会在类似于 for 循环处使用分号，用来区分初始化语句、约束条件和循环动作。如果您必须要将多条语句写入同一行中，那么他们之间也需要分号。 分号插入规则带来的后果之一是你不能将左大括号放置在控制语句（if，for，switch，select）的下一行。如果您这样做了，大括号前会被插入一个分号，这会带来一些不良影响。应该这样写 if i &lt; f() &#123; g() &#125; 而不是这样写 if i &lt; f() // wrong! &#123; // wrong! g() &#125; 控制结构Go 中的控制结构与 C 息息相关，但在一些重要的方面又有所不同。没有 do 或 while 循环，只有一个更通用的 for；switch 更加灵活；if 和 switch 像 for 一样可以设置初始化语句；break 和 continue 语句采用可选标签来标识需要中断或继续的内容；有一些新的控制结构例如type switch 和一个多路选择器 select。语法也略有不同：没有小括号，并且主体内容必须用大括号包裹。 IfGo 中简单的 If 看起来是这样： if x > 0 &#123; return y &#125; 强制要求的大括号鼓励使用多行书写简单的 if 语句。无论如何，这都是一种好的代码风格，特别是当主体内容包含 return 或 break 之类的控制语句的时候。 由于 if 和 switch 可以接收一个初始化语句，因此通常会看到他被用来设置局部变量。 if err := file.Chmod(0664); err != nil &#123; log.Print(err) return err &#125; 在 Go 库中，你会发现当 if 语句不流入下一个语句时——即内容主体使用 break，continue，goto 或 return 结尾——不必要的 else 会被省略。 f, err := os.Open(name) if err != nil &#123; return err &#125; codeUsing(f) 这是一个常见情况的示例，其中的代码必须考虑一系列的错误情况。代码的可读性很好，成功的步骤按序向下执行，错误总是在他出现的地方被处理。由于错误情况都使用 return 语句结束流程，因此不需要使用 else 语句。 f, err := os.Open(name) if err != nil &#123; return err &#125; d, err := f.Stat() if err != nil &#123; f.Close() return err &#125; codeUsing(f, d) 重声明与重赋值上一节的例子通过调用 os.Open 函数展示了如何使用 :&#x3D; 进行短声明 f, err := os.Open(name) 这行代码声明了两个变量，f 和 err。几行后，又调用了 f.Stat d, err := f.Stat() 这看起来是声明了 d 和 err。但请注意，这两行代码都出现了 err。这种重复是合法的：err 只被第一行代码声明，在第二行代码中只是被重赋值（re-assigned）。这意味着调用 f.Stat 使用的是之前声明的 err，此处仅仅是给他赋予新的值。 在一个 :&#x3D; 赋值中，已经被声明的变量 v 仍然可以被重赋值，只要： 本次声明和已经存在的对 v 的声明在同一个代码空间（如果 v 是在外部空间被声明的，那么本次声明会创造一个新的变量§）， 初始化中相应的值可以被赋值给 v，而且 本次声明中至少包括一个全新被声明的变量。 这样的非常规设计是纯粹的实用主义，使得使用单个 err 变得很容易，例如在一长串的 if-else 中。你会经常看到这样的用法。 § 这里值得注意的是，在 Go 中，函数的参数和返回值的空间与函数体相同，即使它们在词法上出现在函数体的大括号之外。 ForGo 中的 for 循环和 C 中的 for 循环相似但又不同。他统一了 for 循环和 while 循环，并且没有 do-while 循环。总共有三种形式，其中只有一种带有分号。 // Like a C for for init; condition; post &#123; &#125; // Like a C while for condition &#123; &#125; // Like a C for(;;) for &#123; &#125; 短声明方式让声明循环中使用的索引变得容易。 sum := 0 for i := 0; i &lt; 10; i++ &#123; sum += i &#125; 如果您在循环数组、切片、字符串或 map，又或是在读取 channel，range 关键字可以帮助你管理循环。 for key, value := range oldMap &#123; newMap[key] = value &#125; 如果您只需要 range 中的第一个参数（key 或者 index），那么丢掉第二个： for key := range m &#123; if key.expired() &#123; delete(m, key) &#125; &#125; 如果你只需要 range 中的第二个参数（值），使用空标识，也就是下划线，从而丢弃第一个参数： sum := 0 for _, value := range array &#123; sum += value &#125; 空标识有很多种用法，就像后续章节中描述的这样。 对于字符串，range 为您做了更多的事情，通过解析 UTF-8 来分解各个 Unicode 码。错误的编码消耗一个 byte 并使用 rune U+FFFD 代替（rune 是 Go 中称呼和使用单个 Unicode 码点的术语。参考language specification了解更多）。对于下面的循环 for pos, char := range \"日本\\x80語\" &#123; // \\x80 is an illegal UTF-8 encoding fmt.Printf(\"character %#U starts at byte position %d\\n\", char, pos) &#125; 输出为 character U+65E5 '日' starts at byte position 0 character U+672C '本' starts at byte position 3 character U+FFFD '�' starts at byte position 6 character U+8A9E '語' starts at byte position 7 最后，Go 没有逗号运算符， ++ 和 -- 是语句而不是表达式。因此如果你在 for 中运行多个变量，你应该使用多重赋值（不包括 ++ 和 --）。 // Reverse a for i, j := 0, len(a)-1; i &lt; j; i, j = i+1, j-1 &#123; a[i], a[j] = a[j], a[i] &#125; SwitchGo 中的 switch 比 C 中的更通用。表达式不需要是常量，甚至不需要是整数，cases 从上向下匹配，直到寻找到匹配项，如果 switch 没有表达式，则他匹配到 true。因此，习惯上可以将 if-else-if-else 链编写为 switch。 func unhex(c byte) byte &#123; switch &#123; case '0' &lt;= c &amp;&amp; c &lt;= '9': return c - '0' case 'a' &lt;= c &amp;&amp; c &lt;= 'f': return c - 'a' + 10 case 'A' &lt;= c &amp;&amp; c &lt;= 'F': return c - 'A' + 10 &#125; return 0 &#125; Go 语言的 switch 不会自动执行下一个分支，但是可以使用逗号分隔的列表来组合判断条件。 func shouldEscape(c byte) bool &#123; switch c &#123; case ' ', '?', '&amp;', '=', '#', '+', '%': return true &#125; return false &#125; 尽管他们在 Go 中不像在其他一些类似 C 的语言中那么常见，但 break 语句可以用来中止 switch。但有时，我们需要打破外围的循环，而非 switch，在 Go 中可以通过在循环上放置标签并 “breaking” 该标签来完成。下面的例子演示了这两种用途。 Loop: for n := 0; n &lt; len(src); n += size &#123; switch &#123; case src[n] &lt; sizeOne: if validateOnly &#123; break &#125; size = 1 update(src[n]) case src[n] &lt; sizeTwo: if n+1 >= len(src) &#123; err = errShortInput break Loop &#125; if validateOnly &#123; break &#125; size = 2 update(src[n] + src[n+1]&lt;&lt;shift) &#125; &#125; 当然， continue 语句也可以接受标签，但他仅适用于循环。 为了完成这个章节，这里有一个使用两个 switch 语句的字节切片比较函数。 // Compare returns an integer comparing the two byte slices, // lexicographically. // The result will be 0 if a == b, -1 if a &lt; b, and +1 if a > b func Compare(a, b []byte) int &#123; for i := 0; i &lt; len(a) &amp;&amp; i &lt; len(b); i++ &#123; switch &#123; case a[i] > b[i]: return 1 case a[i] &lt; b[i]: return -1 &#125; &#125; switch &#123; case len(a) > len(b): return 1 case len(a) &lt; len(b): return -1 &#125; return 0 &#125; Type switchswitch 也可以用来发现接口变量的动态类型。这种 type switch 使用类型断言的语法，并将关键字 type 放在括号内。如果 switch 在表达式中声明了变量，那么变量会在每个匹配项中获得相应的类型。在每个 case 项中使用相同的名称也是惯用的做法，实际上是在每个 case 中声明了名称相同但类型不同的变量。 var t interface&#123;&#125; t = functionOfSomeType() switch t := t.(type) &#123; default: fmt.Printf(\"unexpected type %T\\n\", t) // %T prints whatever type t has case bool: fmt.Printf(\"boolean %t\\n\", t) // t has type bool case int: fmt.Printf(\"integer %d\\n\", t) // t has type int case *bool: fmt.Printf(\"pointer to boolean %t\\n\", *t) // t has type *bool case *int: fmt.Printf(\"pointer to integer %d\\n\", *t) // t has type *int &#125; 函数多返回值Go 中的一个特殊特性是函数和方法可以返回多个值。这种形式可以用于改进 C 程序中的几个笨拙的惯用方法：例如通过返回 -1 来表示 EOF 或是修改一个使用指针传入的参数。 在 C 语言中，write 错误通过一个负数来表示，而错误代码隐藏在容易丢失的变量中。在 Go 中， Write 可以同时返回计数和错误：“你写入了一些字节，但没有完全写入，因为你的磁盘满了”。在 os 包中的 Write 方法的方法签名是： func (file *File) Write(b []byte) (n int, err error) 正如文档所说，当 n !&#x3D; len(b) 时，函数返回了已经写入的字节数和一个非 nil 的 error。这是一个通用的风格，查看关于错误处理的章节了解更多例子。 一个类似的可以用来替代传递指针作为参数的方法是，通过返回一个值来模拟引用参数。这里是一个简单的函数，用来从字节切片的某个定位开始抓取数字，并返回数字和数字后的定位。 func nextInt(b []byte, i int) (int, int) &#123; for ; i &lt; len(b) &amp;&amp; !isDigit(b[i]); i++ &#123; &#125; x := 0 for ; i &lt; len(b) &amp;&amp; isDigit(b[i]); i++ &#123; x = x*10 + int(b[i]) - '0' &#125; return x, i &#125; 您可以通过这样的方式使用，扫描切片 b 中的数字： for i := 0; i &lt; len(b); &#123; x, i = nextInt(b, i) fmt.Println(x) &#125; 命名结果参数在 Go 函数中返回的结果“参数”可以被命名并像其他常规变量一样使用，就像输入参数一样。当被命名时，他们会在函数开始时被初始化为其对应类型的0值；如果函数执行不带参数的返回，那么这些结果参数的当前值会被用作返回值。 命名不是强制性的，但是他们会让代码更加简短和清晰：他们是文档的一种。如果我们将 nextInt 函数的返回结果命名，那么返回的 int 的含义将变得显而易见。 func nextInt(b []byte, pos int) (value, nextPos int) &#123; 因为命名的返回值已经和不带参数的 return 绑定在了一起，他们可以用来简化和澄清代码。这里是使用命名结果参数的 io.ReadFull： func ReadFull(r Reader, buf []byte) (n int, err error) &#123; for len(buf) > 0 &amp;&amp; err == nil &#123; var nr int nr, err = r.Read(buf) n += nr buf = buf[nr:] &#125; return &#125; DeferGo 中的 defer 语句可以在当前执行的函数返回前执行一次函数调用（ deferred 函数）。这是一个不寻常但有效的方案，可以用来处理类似于在任何函数执行路径下的资源关闭问题。典型的例子是解锁一个 mutex 或关闭一个文件。 // Contents returns the file's contents as a string. func Contents(filename string) (string, error) &#123; f, err := os.Open(filename) if err != nil &#123; return \"\", err &#125; defer f.Close() // f.Close will run when we're finished. var result []byte buf := make([]byte, 100) for &#123; n, err := f.Read(buf[0:]) result = append(result, buf[0:n]...) // append is discussed later. if err != nil &#123; if err == io.EOF &#123; break &#125; return \"\", err // f will be closed if we return here. &#125; &#125; return string(result), nil // f will be closed if we return here. &#125; 通过 defer 调用 Close 函数有两个好处。其一， 他确保了你不会忘记关闭这个文件，尤其是你之后再为函数添加更多种返回路径时。其二，他意味着 close 的位置与 open 在一起，这比将他放在函数的末尾要清晰的多。 deferred 函数的参数（或是 deferred 方法的接收者）是在 defer 语句执行时计算的（意味着创建一个闭包），而非是在函数被调用时计算。除了无需担心在函数执行过程中的变量值改变外，这也意味着一个 defer 语句可以创建多个延迟执行的函数。这是一个不太聪明的示例。 for i := 0; i &lt; 5; i++ &#123; defer fmt.Printf(\"%d \", i) &#125; Deferred 函数按照后进先出的顺序执行，因此这段代码会在函数返回时打印 4 3 2 1 0。一个更合理的例子是简单的通过程序跟踪函数调用的方法。我们可以写一些类似这样的跟踪例程： func trace(s string) &#123; fmt.Println(\"entering:\", s) &#125; func untrace(s string) &#123; fmt.Println(\"leaving:\", s) &#125; // Use them like this: func a() &#123; trace(\"a\") defer untrace(\"a\") // do something.... &#125; 我们可以利用 deferred 函数是在 defer 执行时计算参数这一事实来做的更好。tracing 例程可以用来设置 untracing 例程的参数。下面是例子： func trace(s string) string &#123; fmt.Println(\"entering:\", s) return s &#125; func un(s string) &#123; fmt.Println(\"leaving:\", s) &#125; func a() &#123; defer un(trace(\"a\")) fmt.Println(\"in a\") &#125; func b() &#123; defer un(trace(\"b\")) fmt.Println(\"in b\") a() &#125; func main() &#123; b() &#125; 输出 entering: b in b entering: a in a leaving: a leaving: b 对于在其他编程语言中习惯了块级资源管理的程序员来说，defer 也许看起来有些特殊，但是他最有趣也是最强大的的应用恰恰来自于他是基于函数而非基于块的事实。在 panic 与 recover 章节我们会看到这种可能性的例子。 数据通过new分配Go 中有两个分配关键字，内置函数 new 和 make。他们做不同的事情而且用于不同的类型，这可能会令人困惑，但是规则实际上很简单。让我们先从 new 开始。这是一个内建的用于分配内存的函数，但与一些其他编程语言中的同名函数不同，他并不会初始化内存，而只是将内存值置零。也就是说，new(T) 分配了一块零值的内存用来放置类型 T 并返回他的指针，一个类型为 *T 的值。在 Go 术语中，他返回了一个指向新分配的零值 T 的指针。 由于 new 返回的内存值总是 0，因此在设计您的数据结构时，将 0 值作为一个合理的初始化值就非常有帮助。这意味着数据结构的使用者可以通过 new 来创建他并立刻使用。例如 bytes.Buffer 的文档表示“零值的 Buffer 是一个可以被使用的空 buffer”。类似的，sync.Mutex 也没有显式的构造函数或是初始化方法。取而代之的是，零值的 sync.Mutex 被定义为一个未锁定的 mutex。 零值有效的设计方式是可以传递的，考虑下述类型声明。 type SyncedBuffer struct &#123; lock sync.Mutex buffer bytes.Buffer &#125; 类型为 SyncedBuffer 的值也可以在被分配或声明后立即使用。在下面的片段里，p 和 v 都可以在无需更多参数的情况下正确使用。 p := new(SyncedBuffer) // type *SyncedBuffer var v SyncedBuffer // type SyncedBuffer 构造器与复合字面量(composite literals)有些情况下无法通过零值初始化，这时就需要构造器，例如这个 os 包中的例子。 func NewFile(fd int, name string) *File &#123; if fd &lt; 0 &#123; return nil &#125; f := new(File) f.fd = fd f.name = name f.dirinfo = nil f.nepipe = 0 return f &#125; 这里有很多的赋值操作。我们可以简单的使用复合字面量，这是一种在每次执行时创建一个新实例的表达式。 func NewFile(fd int, name string) *File &#123; if fd &lt; 0 &#123; return nil &#125; f := File&#123;fd, name, nil, 0&#125; return &amp;f &#125; 请注意，与 C 不同，返回局部变量的地址是完全可行的；在函数返回后与变量关联的存储依然存在。实际上，每次获取复合字面量地址时都会分配一个新的实例，因此我们可以合并最后两行。 return &amp;File&#123;fd, name, nil, 0&#125; 复合字面量中的字段必须按序且全部存在。然而，通过使用 field:value 对标记元素，初始值设定可以以任何顺序出现，缺失的字段保留位各自的零值。因此我们可以 return &amp;File&#123;fd: fd, name: name&#125; 作为一个特殊情况，如果复合字面量没有包括任何字段，他会创建当前类型的零值对象。表达式 new(File) 和 &amp;File{} 是等效的。 复合字面量也可以用来创建数组、切片和 maps，其中的字段标签被视为索引或 map 中的键。在这些示例中，只要 Enone、Eio、Einval 的值不同，无论他们的值如何，初始化都会生效。 a := [...]string &#123;Enone: \"no error\", Eio: \"Eio\", Einval: \"invalid argument\"&#125; s := []string &#123;Enone: \"no error\", Eio: \"Eio\", Einval: \"invalid argument\"&#125; m := map[int]string&#123;Enone: \"no error\", Eio: \"Eio\", Einval: \"invalid argument\"&#125; 通过make分配回到内存分配的话题。内置函数 make(T, args) 提供了一个与 new(T) 不同的用途。他只用来创建切片、maps 和 channels，而且他返回一个已经被初始化的（非零值）的 T 的值（而非 *T）。区别的原因是这三种类型在底层都是对必须被初始化的某种数据结构的引用。例如切片，由三个元素组成，指向数据的指针（数据是内置的数组）、长度和容量，在这些元素被初始化前，切片的值是 nil。对于切片、maps 和 channels，make 初始化了他们内部的数据结构而且提供了可用的值。对于， make([]int, 10, 100) 分配了一个长度为 100 int 的数组，随后创建切片结构，长度为 10，容量为 100，指向数组最初的 10 个元素。（在创建切片时，可以不手动指定容量；参考切片章节了解更多信息）。相反，new([]int) 返回一个新分配的，值为零的切片结构的指针，也就是一个指向 nil 切片值的指针。 这些例子阐明了 new 和 make 的区别。 var p *[]int = new([]int) // allocates slice structure; *p == nil; rarely useful var v []int = make([]int, 100) // the slice v now refers to a new array of 100 ints // Unnecessarily complex: var p *[]int = new([]int) *p = make([]int, 100, 100) // Idiomatic: v := make([]int, 100) 请记住，make 用于 maps，切片和 channels，并不返回指针。如果想要显式的获得指针，需要使用 new 或是显式的获取变量的地址。 数组数组在进行详细的内存规划时很有用，而且有时候可以用来避免分配动作，但是大部分时候他们还是用于作为切片的一部分使用，也就是下一个章节的主题。为了给下一个主题打下基础，这里简单介绍一下数组。 这里有一些 Go 中数组和 C 中数组的主要区别。在 Go 中， 数组是值，将一个数组赋值给另一个会复制所有的元素。 特别是，将数组传递给函数，他会收到数组的副本，而不是数组的指针。 数组的尺寸使其类型的一部分。[10]int 和 [20]int 是不同的类型。 使用值传递可能会有用，但是开销也很大；如果你想要和 C 相似的表现方式和效率，你可以传递一个数组的指针。 func Sum(a *[3]float64) (sum float64) &#123; for _, v := range *a &#123; sum += v &#125; return &#125; array := [...]float64&#123;7.0, 8.5, 9.1&#125; x := Sum(&amp;array) // Note the explicit address-of operator 但是这也不是 Go 中的惯用方式，Go 程序员使用切片。 切片切片封装了数组，提供了一个更加通用、强大、方便的处理序列数据的接口。除了例如变换矩阵这种有显式的维度的情况外，在 Go 中大部分关于序列数据的编程都是通过切片而非数组完成的。 切片持有了对其下层数组的引用，如果你将一个切片赋值给另一个，他们将会引用同一个数组。如果函数使用切片作为参数，则调用者可以看到函数对切片中元素的修改，类似于传递了下层数组的指针。因此，Read 函数可以接收切片作为参数，而非指针和计数；切片中的长度设置了要读取数据内容的上限。这里是 os 包中 File 类型的 Read 方法的方法签名： func (f *File) Read(buf []byte) (n int, err error) 该方法返回读取的字节数和可能的错误值。如果想要将前 32 个字节的内容读取到一个大容量的 buffer（名为 buf）中，可以对这个 buffer 进行切片（此处为动词）。 n, err := f.Read(buf[0:32]) 这种切片是常见且高效的。事实上，暂且不考虑执行效率，下面的代码片段也可以将前 32 个字节读取到 buffer 中。 var n int var err error for i := 0; i &lt; 32; i++ &#123; nbytes, e := f.Read(buf[i:i+1]) // Read one byte. n += nbytes if nbytes == 0 || e != nil &#123; err = e break &#125; &#125; 切片的长度可以在其底层数据限制的范围内任意修改；只要切取他自身的一部分并赋值即可。切片的容量可以通过内建函数 cap 访问，报告了切片可用的最大长度。这里是一个向切片添加数据的函数。如果数据超出了容量限制，切片会采用重新分配的内存。最终的结果是函数返回的切片。设计这个函数时巧妙利用了如下事实：对 nil 切片使用 len 和 cap 操作是合法的，且会返回 0。 func Append(slice, data []byte) []byte &#123; l := len(slice) if l + len(data) > cap(slice) &#123; // reallocate // Allocate double what's needed, for future growth. newSlice := make([]byte, (l+len(data))*2) // The copy function is predeclared and works for any slice type. copy(newSlice, slice) slice = newSlice &#125; slice = slice[0:l+len(data)] copy(slice[l:], data) return slice &#125; 最后我们必须返回切片，因为虽然 Append 可以改变切片中的元素，但切片本身（运行时的数据结构，包括指针，长度和容量）是按值传递的。 向切片添加元素是一个常用操作，因此内建函数 append 实现了这一功能。为了理解这个函数的设计，我们需要掌握更多的信息，因此我们会在稍后讨论他。 二维切片Go 中的数组和切片是一维的。为了等效的实现二维数组或二维切片，必须定义 数组的数组 或是 切片的切片，类似于： type Transform [3][3]float64 // A 3x3 array, really an array of arrays. type LinesOfText [][]byte // A slice of byte slices. 因为切片的长度是可变的，因此每个内部切片的长度不同是可能的。这是一个很常见的情况，如果我们的 文本行 的例子：每一行都有独立的长度。 text := LinesOfText&#123; []byte(\"Now is the time\"), []byte(\"for all good gophers\"), []byte(\"to bring some fun to the party.\"), &#125; 有时需要分配二维切片，例如在处理逐行像素扫描时。有两种方式可以实现这一目标。一种是为每个切片独立进行分配；另一种是分配一个独立的数组，然后将各个切片指向其中不同的区域。使用哪一种方式取决于您的应用程序。如果您的切片可能会增大或缩小，那应该独立分配切片，避免覆盖到下一行的内容；如果不是，单次分配一个数据来使用可能会更高效。作为参考，这里提供了两种方式的简单实现。第一种，每次一行的方式： // Allocate the top-level slice. picture := make([][]uint8, YSize) // One row per unit of y. // Loop over the rows, allocating the slice for each row. for i := range picture &#123; picture[i] = make([]uint8, XSize) &#125; 现在是单次分配，切为多行： // Allocate the top-level slice, the same as before. picture := make([][]uint8, YSize) // One row per unit of y. // Allocate one large slice to hold all the pixels. pixels := make([]uint8, XSize*YSize) // Has type []uint8 even though picture is [][]uint8. // Loop over the rows, slicing each row from the front of the remaining pixels slice. for i := range picture &#123; picture[i], pixels = pixels[:XSize], pixels[XSize:] &#125; MapsMaps 是一种方便且强大的内建数据结构，他将一种类型的值（键）关联到另一种类型的值（值）。键可以是支持相等操作的任意数据类型，例如整数、浮点数、复数、字符串、指针、接口（只要其中的动态类型支持相等）、结构体或数组。切片不能用作 map 的键，因为没有为其定义相等操作。与切片类似，maps 持有了对下层数据结构的引用。如果你将 map 传入一个函数并且在函数中改变了 map 的内容，调用者也会看到这个改变。 Maps 可以使用常规的复合字面量语法，加上冒号分隔键值对来构建，因此在初始化期间构建他们很容易。 var timeZone = map[string]int&#123; \"UTC\": 0*60*60, \"EST\": -5*60*60, \"CST\": -6*60*60, \"MST\": -7*60*60, \"PST\": -8*60*60, &#125; 对 map 分配值或获取值的语法看起来和对数组或切片的操作相同，只是索引不必须是整数。 offset := timeZone[\"EST\"] 尝试获取 map 中不存在键映射的值会返回该类型的零值。例如，如果 map 包含整数，查询一个不存在的键会返回 0。可以使用 bool 作为值的 map 来实现 set。将每个键的值都设置为 true，之后可以通过索引来简单的判断该键是否存在。 attended := map[string]bool&#123; \"Ann\": true, \"Joe\": true, ... &#125; if attended[person] &#123; // will be false if person is not in the map fmt.Println(person, \"was at the meeting\") &#125; 有时您需要去区分缺失条目或是零值。究竟是是否有 UTC 的值，或者说 0 只是因为他并没有在 map 中设置？你可以使用多重赋值的方式分辨。 var seconds int var ok bool seconds, ok = timeZone[tz] 出于一些显然的原因，这被称为 comma ok 用法。在下面的例子中，如果 tz 存在，seconds 将会被赋值而且 ok 的值为 true；如果 tz 不存在，seconds 的值将会是 0 而且 ok 的值会是 false。下面是一个将这些内容和一个错误日志组合到一起的函数： func offset(tz string) int &#123; if seconds, ok := timeZone[tz]; ok &#123; return seconds &#125; log.Println(\"unknown time zone:\", tz) return 0 &#125; 如果不关心值的内容，只想测试键是否存在，您可以使用空标识符 (_) 代替值的变量。 _, present := timeZone[tz] 要删除 map 中的条目，可以使用内建的 delete 函数，他需求的参数是 map 和要被删除的键。即使要删除键已经不在 map 中，这个操作也是安全的。 delete(timeZone, \"PDT\") // Now on Standard Time 打印Go 中的格式化输出采用了和 C 中的 printf 系列相似但更加丰富和通用的实现。这些函数位于 fmt 包中且拥有大写的名称：fmt.Printf，fmt.Fprintf，fmt.Sprintf 等等。字符串系列函数（Sprintf等）返回一个字符串，而非填充某个指定的 buffer。 您不需要提供格式化字符串。对于每个 Printf，Fprintf 和 Sprintf 都存在另外两个与之对应的函数，例如 Print 和 Println。这些函数不接收格式化字符串，但为他们的每个参数提供默认格式。Println 会在两个参数间加入空格，而且在输出内容末尾添加换行符，Print 则是只有当两个连续的参数不是字符串时才添加空格。在这个例子中每一行都会提供同样的输出。 fmt.Printf(\"Hello %d\\n\", 23) fmt.Fprint(os.Stdout, \"Hello \", 23, \"\\n\") fmt.Println(\"Hello\", 23) fmt.Println(fmt.Sprint(\"Hello \", 23)) fmt.Fprint 系列的格式化输出函数接收任何实现了 io.Writer 接口的对象作为其第一个参数；os.Stdout 和 os.Stderr 是最常见的用法。 从现在开始事情变得和 C 不同。首先，%d 这样的数字格式不采用符号或大小标志；相反，打印例程使用参数的类型来决定这些属性。 var x uint64 = 1&lt;&lt;64 - 1 fmt.Printf(\"%d %x; %d %x\\n\", x, x, int64(x), int64(x)) 输出 18446744073709551615 ffffffffffffffff; -1 -1 如果您只想要默认转换，例如输出十进制整数，您可以使用万能格式 %v （含义是 “value”）；输出将会是 Print 和 Println 默认产生的结果。此外，这个格式可以用来打印任何值，甚至数组、切片、结构体和 maps。这里是打印上一章节定义的时区 map 的语句。 fmt.Printf(\"%v\\n\", timeZone) // or just fmt.Println(timeZone) 输出是这样的： map[CST:-21600 EST:-18000 MST:-25200 PST:-28800 UTC:0] 对于 maps，Printf 系列函数按字典顺序对输出进行排序。 在打印结构体时，使用 %+v 可以将字段值和名称共同输出，使用 %#v 则可以输出 Go 格式中全量的信息。 type T struct &#123; a int b float64 c string &#125; t := &amp;T&#123; 7, -2.35, \"abc\\tdef\" &#125; fmt.Printf(\"%v\\n\", t) fmt.Printf(\"%+v\\n\", t) fmt.Printf(\"%#v\\n\", t) fmt.Printf(\"%#v\\n\", timeZone) 输出 &amp;&#123;7 -2.35 abc def&#125; &amp;&#123;a:7 b:-2.35 c:abc def&#125; &amp;main.T&#123;a:7, b:-2.35, c:\"abc\\tdef\"&#125; map[string]int&#123;\"CST\":-21600, \"EST\":-18000, \"MST\":-25200, \"PST\":-28800, \"UTC\":0&#125; （注意 &amp; 符号。）当输出 string 或 []byte 类型的值时，可以使用 %q 产生带引号的输出。如果可以的话，%#q 会使用反引号输出。（%q 也可以用于整数和 runes，输出一个单引号的 rune。）同样，%x 对 string、byte 数组、byte 切片和对整数有同样的效果，产生一个长十六进制字符串，如果在该格式中添加空格（% x），输出时会在字节间加入空格。 另一种方便的格式时 %T，他会输出值的类型。 fmt.Printf(\"%T\\n\", timeZone) 输出 map[string]int 如果您想要控制自定义类型的默认输出格式，只需为该类型定义方法签名为 String() 的方法。对于一个简单的例子 T，看起来可能是这样。 func (t *T) String() string &#123; return fmt.Sprintf(\"%d/%g/%q\", t.a, t.b, t.c) &#125; fmt.Printf(\"%v\\n\", t) 打印出的内容 7/-2.35/\"abc\\tdef\" (如果您需要打印 T 的类型和指向 T 的指针，String 函数的接收者必须是值类型；这个例子中使用指针是因为这样执行效率更高，也更复合结构体类型的习惯。查看后续章节指针或是值了解更多信息。) 在我们的 String 方法中可以调用 Sprintf，因为打印例程是完全可重入的，而且可以通过这种方式包裹。然而，关于这种方法有一个非常重要的细节需要了解：不要使用会调用您的 String 方法的 Spintf 来构建您的 String 方法，这会导致您的 String 方法被无限调用。这种情况可能在您的 Sprintf 尝试直接将方法接收者直接作为 string 输出时发生，从而再次调用该方法。这是一个常见的但容易解决的问题，比如这个例子。 type MyString string func (m MyString) String() string &#123; return fmt.Sprintf(\"MyString=%s\", m) // Error: will recur forever. &#125; 修复起来也很简单：将参数转换为基本的 string 类型，转换后的参数不会调用这个方法。 type MyString string func (m MyString) String() string &#123; return fmt.Sprintf(\"MyString=%s\", string(m)) // OK: note conversion. &#125; 在初始化部分，我们将看到另一种避免这种递归的技术。 另一种打印技术是将打印例程的参数直接传递给另一个例程。Printf 的方法签名使用 …interface() 作为最后一个参数，用来指定任意数量（以及任意类型）的参数都可以出现在 format 之后。 func Printf(format string, v ...interface&#123;&#125;) (n int, err error) &#123; 在函数 Printf 中，v 的作用类似于类型为 []interface{} 的变量，但是如果将其传递到另一个可变参数的函数中，他则可以当作常规的参数列表使用。这里是我们之前用过的 log.Println 函数的实现。他直接将参数传递到 fmt.Sprintln 中，从而进行实际的格式化工作。 // Println prints to the standard logger in the manner of fmt.Println. func Println(v ...interface&#123;&#125;) &#123; std.Output(2, fmt.Sprintln(v...)) // Output takes parameters (int, string) &#125; 我们在嵌套调用 Sprintln 时在参数 v 之后写上 …，用来告诉编辑器将 v 作为一个参数列表对待；否则他会将 v 作为一个切片类型的参数传递。 关于打印的内容比我们在这里介绍的还要多。有关详细信息，请参阅 fmt 包的 godoc 文档。 顺便提一句，…参数可以指定类型，例如使用 …int 实现的最小值函数，用来选取整数列表中的最小值： func Min(a ...int) int &#123; min := int(^uint(0) >> 1) // largest int for _, i := range a &#123; if i &lt; min &#123; min = i &#125; &#125; return min &#125; Append现在我们需要解释之前缺失的碎片，关于内建函数 append 的设计。append 的方法签名和之前我们自定义的 Append 函数不同。示意一下的话，他看起来类似这样： func append(slice []T, elements ...T) []T 此处的 T 表示任何给定的类型。你不能在 Go 中编写一个由调用者决定 T 类型的函数。这也就是为何 append 作为内建函数的原因：他需要编译器的支持。 append 做的事情是将元素加入到切片的末尾并返回结果。需要返回结果的原因和我们之前手写的 Append 一样，底层的数组可能已经被改变。这里有个而简单的例子 x := []int&#123;1,2,3&#125; x = append(x, 4, 5, 6) fmt.Println(x) 输出 [1 2 3 4 5 6]。因此 append 的工作方式有点像 Printf，因为他可以接收任意数量和任意类型的参数。 但如果我们只想做和我们自定义 Append 一样的事情，把一个切片添加到另一个切片之后呢？简单：在调用时使用 …，就像我们在之前的 Output 调用时做的那样。这个片段会产生和上一个完全相同的输出。 x := []int&#123;1,2,3&#125; y := []int&#123;4,5,6&#125; x = append(x, y...) fmt.Println(x) 如果缺少了 …，这段代码会因为类型错误而无法编译，因为 y 的类型并不是 int。 初始化尽管从表面上看它与 C 或 C++ 中的初始化没有太大区别，但 Go 中的初始化更强大。可以在初始化期间构建复杂的结构，并且可以正确处理初始化对象之间（甚至不同包之间）的排序问题。 常量在 Go 中，常量的意思是——常量。他们是在编译时创建的，即使是在函数中被定义为局部变量也是如此，并且只能是数字、字符（rune）、字符串或是布尔值。由于编译时的限制，定义常量的表达式必须是常量表达式，可由编译器计算。例如，1&lt;&lt;3 是一个常量表达式，而 math.Sin(math.Pi&#x2F;4) 则不是，因为对函数 math.Sin 的调用需要在运行时发生。 在 Go 中，枚举常量是使用 iota 枚举器创建的。由于 iota 可以是表达式的一部分，并且表达式可以隐式重复，因此很容易构建复杂的值集。 type ByteSize float64 const ( _ = iota // ignore first value by assigning to blank identifier KB ByteSize = 1 &lt;&lt; (10 * iota) MB GB TB PB EB ZB YB ) 将类似 String 这样的方法附加到任何用户自定义类型的能力使得任何值都可以在打印时格式化输出自己。虽然最常见的用法是对结构体的应用，这种技术对于标量类型（例如浮点数表示的字节大小）也很有用。 func (b ByteSize) String() string &#123; switch &#123; case b >= YB: return fmt.Sprintf(\"%.2fYB\", b/YB) case b >= ZB: return fmt.Sprintf(\"%.2fZB\", b/ZB) case b >= EB: return fmt.Sprintf(\"%.2fEB\", b/EB) case b >= PB: return fmt.Sprintf(\"%.2fPB\", b/PB) case b >= TB: return fmt.Sprintf(\"%.2fTB\", b/TB) case b >= GB: return fmt.Sprintf(\"%.2fGB\", b/GB) case b >= MB: return fmt.Sprintf(\"%.2fMB\", b/MB) case b >= KB: return fmt.Sprintf(\"%.2fKB\", b/KB) &#125; return fmt.Sprintf(\"%.2fB\", b) &#125; 表达式 YB 会输出为 1.00YB，而 ByteSize(1e13) 则会输出为 9.09TB。 这里使用 Sprintf 来实现 ByteSize 类型的 String 方法是安全的（不会产生无限调用），并不是因为数据转换，而是因为他使用 %f 作为 Sprintf 的参数，这不是字符串格式的：Sprintf 只会在需要字符串值时调用 String 方法，而 %f 表示需要的是浮点数的值。 变量变量可以像常量一样被初始化，但是其初始化表达式可以在运行时计算。 var ( home = os.Getenv(\"HOME\") user = os.Getenv(\"USER\") gopath = os.Getenv(\"GOPATH\") ) init函数最后，每个源文件都可以定义自己的 无参数（niladic） init 函数，用来设置任何他们所需的状态。（实际上每个文件可以有多个 init 函数。）最后的最后：init 会在包中声明的所有变量完成初始化计算后执行，而这些变量的初始化计算则会在所有引入的包已经完成初始化后执行。 除了执行不能用声明表示的初始化动作外，init 函数的一个常见用途是在程序开始前确认或修复程序状态的正确性。 func init() &#123; if user == \"\" &#123; log.Fatal(\"$USER not set\") &#125; if home == \"\" &#123; home = \"/home/\" + user &#125; if gopath == \"\" &#123; gopath = home + \"/go\" &#125; // gopath may be overridden by --gopath flag on command line. flag.StringVar(&amp;gopath, \"gopath\", gopath, \"override default GOPATH\") &#125; 方法指针或是值如同我们之前在 Bytesize 中看到的，方法可以为任何命名类型定义（除了指针或接口）；方法的接收者不必是一个结构体。 在之前我们对切片的讨论中，我们写了 Append 函数。我们可以将他替换为切片的方法。为了实现这个目标，首先我们声明一个命名的类型，这样我们可以将方法绑定在上面，之后我们将该类型的值作为方法的接收者。 type ByteSlice []byte func (slice ByteSlice) Append(data []byte) []byte &#123; // Body exactly the same as the Append function defined above. &#125; 这个方法仍然需要配返回更新后的切片。我们可以通过重新定义方法，采用 ByteSlice 的指针作为接收者，来消除这种不便，调用这个方法会覆盖调用者的切片。 func (p *ByteSlice) Append(data []byte) &#123; slice := *p // Body as above, without the return. *p = slice &#125; 实际上，我们甚至可以做的更好。如果我们修改我们的函数，让他看起来像标准的 Write 方法，比如 func (p *ByteSlice) Write(data []byte) (n int, err error) &#123; slice := *p // Again as above. *p = slice return len(data), nil &#125; 之后，*ByteSlice 类型满足了基础的 io.Writer 接口，这样就很方便。例如，我们可以使用 print 写入。 var b ByteSlice fmt.Fprintf(&amp;b, \"This hour has %d days\\n\", 7) 我们传递 ByteSlice 的地址是因为只有 *ByteSlice 类型满足了 io.Wirter 的接口条件。使用指针或是值作为接收者的规则是这样的，值的方法可以被指针或是值调用，而指针的方法只能被指针调用。 这条规则的出现是因为指针的方法可以修改其接收者，在值上调用这种方法会导致方法接收到值的复制，因此任何修改都会失效。因此，该语言不允许出现这种错误。不过，有一个方便的例外。当值本身可寻址时，Go 通过在值前自动插入 &amp; 照顾了使用值调用指针方法的情况。在我们的例子中，变量 b 是可寻址的，因此我们可以使用 b.Write 调用他的 Write 方法。编译器会帮助我们自动重写为 (&amp;b).Write。 顺带一提，通过 Write 像字节切片写入数据的想法是 bytes.Buffer 包实现的核心。 接口和其他类型接口Go 中的接口提供了一个指定对象行为的方法：如果他可以实现这个功能，那么他就可以在这里使用。我们之前已经看到了几个简单的例子；自定义打印可以通过 String 方法实现，而 Fprintf 可以向任何实现了 Write 方法的对象输出内容。Go 中的接口往往只定义了一到两个方法，而且通常会根据方法指定一个名称，例如 io.Writer 表示任何 Write 接口实现。 一个类型可以实现多个接口。例如，如果一个集合实现了 sort.Interface（其中包含了 Len，Less(i, j int) bool，Swap(i, j int)），那么他就可以被 sort 包中的例程排序，同时他也可以有一个自定义的格式化器。在下面这个定制的例子中，Sequence 同时满足了这两个条件。 type Sequence []int // Methods required by sort.Interface. func (s Sequence) Len() int &#123; return len(s) &#125; func (s Sequence) Less(i, j int) bool &#123; return s[i] &lt; s[j] &#125; func (s Sequence) Swap(i, j int) &#123; s[i], s[j] = s[j], s[i] &#125; // Copy returns a copy of the Sequence. func (s Sequence) Copy() Sequence &#123; copy := make(Sequence, 0, len(s)) return append(copy, s...) &#125; // Method for printing - sorts the elements before printing. func (s Sequence) String() string &#123; s = s.Copy() // Make a copy; don't overwrite argument. sort.Sort(s) str := \"[\" for i, elem := range s &#123; // Loop is O(N²); will fix that in next example. if i > 0 &#123; str += \" \" &#125; str += fmt.Sprint(elem) &#125; return str + \"]\" &#125; 转换Sequence 类型的 String 方法重复了 Sprint 输出切片的工作。（而且复杂度为 O(N²)，这很糟糕）。如果我们在调用 Sprint 之前将他转换为普通的 []int，那么我们的工作量会减少，运行速度也会提升。 func (s Sequence) String() string &#123; s = s.Copy() sort.Sort(s) return fmt.Sprint([]int(s)) &#125; 这个方法是另一个通过转换技术在 String 方法中安全调用 Sprintf 的例子。因为这两种类型（Sequence 和 []int）在忽略名称的情况下实际上是相同的，因此这种转换是合法的。这种转换不会创建新的值，他只是暂时的将值作为一个新的类型来使用。（还有一种合法的转换，例如将整数转换为浮点数，过程中会创建新的值。） 通过转换类型来使用不同的方法是一种 Go 程序中的常见用法。作为示例，我们可以使用 sort.IntSlice 将上文中的例子改变为： type Sequence []int // Method for printing - sorts the elements before printing func (s Sequence) String() string &#123; s = s.Copy() sort.IntSlice(s).Sort() return fmt.Sprint([]int(s)) &#125; 现在，不再是让 Sequence 实现多个接口（sorting 和 printing），我们通过使用将数据转换为多种类型的能力（Sequence，sort.IntSlice 和 []int），每种类型可以解决一部分工作。这种方式在实践中并不常用，但是可能会很有效。 接口转换与类型断言Type switch 是一种类型转换的形式：获取一个接口，对于 switch 中的每个 case，将接口“转换”为 case 对应的类型。这里是一个 fmt.Printf 如何通过类型转换将值转换为字符串的示例。如果值早已是 string，我们获取该接口持有的 string 本身的值，当值有 String 方法是，我们获取该方法的输出。 type Stringer interface &#123; String() string &#125; var value interface&#123;&#125; // Value provided by caller. switch str := value.(type) &#123; case string: return str case Stringer: return str.String() &#125; 第一个 case 匹配一个具体的类型；第二个 case 将接口转换成另一个接口。这样混合不同种类的使用是完全可行的。 当只有一种我们关心的类型时呢？如果我们提前知道值是 string 类型，而且我们只想将他提取出来呢？使用只有一个 case 的 type switch 是可以的，但 类型断言 也可以。类型断言使用一个接口值，从中提取出一个类型明确的值。该语法借鉴了 type switch，但是使用明确的类型而非 type 关键字： value.(typeName) 获得的结果就是一个符合指定的 typeName 类型的值。新的类型要么是接口持有的具体类型，要么是值可以转换的另一个接口类型。为了提炼我们已经知道的类型为 string 的值，我们可以： str := value.(string) 但是如果实际上值并非 string，程序会产生一个运行时错误并崩溃。为了防止这种情况，可以使用 “comma, ok” 方式来测试，判断值到底是否属于 string 类型： str, ok := value.(string) if ok &#123; fmt.Printf(\"string value is: %q\\n\", str) &#125; else &#123; fmt.Printf(\"value is not a string\\n\") &#125; 如果类型断言失败，str 依然会是 string 类型的变量，但是他的值为零值，也就是一个空字符串。 作为补充说明，这里是一个使用类型断言和 if-else 实现的语句，达到了和本章开始时 type switch 相同的效果。 if str, ok := value.(string); ok &#123; return str &#125; else if str, ok := value.(Stringer); ok &#123; return str.String() &#125; 概论如果一个类型的存在仅仅是为了实现某个接口，而且不会导出除了接口方法外的任何方法，那么这个类型本身也无需被导出。仅导出接口清晰的表明了该值没有超出接口范围的行为能力。这也避免了在常见方法的各个实例上重复编写文档的必要。 在这种情况下，构造器应该返回接口类型的值而非实际实现类型的值。例如：在 hash 库中，crc32.NewIEEE 和 adler32.New 都返回了 hash.Hash32 接口的值。在 Go 中用 CRC-32 算法替换 Adler-32 只需要改变构造器中的调用；代码的其他部分都不会受到算法改变的影响。 类似的方法允许将各种加密包中的流式密码算法与他们相关的块状加密分开。crypto&#x2F;cipher 包中的 Block 接口指定了块状加密的行为，它提供单个数据块的加密。然后，与 bufio 包类比，实现该接口的 cipher 包可用于构造由 Stream 接口表示的流式加密，而无需知道块状加密的细节。 crypto&#x2F;cipher 中的接口看起来是这样： type Block interface &#123; BlockSize() int Encrypt(dst, src []byte) Decrypt(dst, src []byte) &#125; type Stream interface &#123; XORKeyStream(dst, src []byte) &#125; 这是 counter mode (CTR) 流的定义，他将块状加密转换为流式加密；请注意，关于块状加密的细节已经全部被抽象处理： // NewCTR returns a Stream that encrypts/decrypts using the given Block in // counter mode. The length of iv must be the same as the Block's block size. func NewCTR(block Block, iv []byte) Stream NewCTR 不止是适用于某一种指定的加密算法或是数据源，而是可以适配任何 Block 接口的实现和任何数据流。因为他们返回的是接口类型的值，更换 CRT 加密模式是完全本地化的更改。构造器的调用必须修改，但是由于其他的代码仅仅将结果作为 Stream 看待，他们则不会受到影响。 接口与方法由于几乎所有类型都可以绑定方法，因此所有类型也都可以用来成为接口实现。http 包就是一个很好的例子，其中定义了 Handler 接口。所有实现了 Handler 接口的对象都可以用来处理 HTTP 请求。 type Handler interface &#123; ServeHTTP(ResponseWriter, *Request) &#125; ResponseWriter 自身就是一个接口，提供了需要向客户端返回响应的方法的入口。这些方法包括了基础的 Write 方法，因此 http.ResponseWriter 可以用在任何 io.Writer 可用的地方。Request 是一个包含了已经解析好的客户端请求的结构体。 简单起见，让我们忽略 POSTs，假装 HTTP 请求总是 GETs；这种简化不会影响到 handlers 的代码逻辑。这里有一个 handler 实现的小例子，可以用来统计页面被访问的次数。 // Simple counter server. type Counter struct &#123; n int &#125; func (ctr *Counter) ServeHTTP(w http.ResponseWriter, req *http.Request) &#123; ctr.n++ fmt.Fprintf(w, \"counter = %d\\n\", ctr.n) &#125; （继续我们的主题，请注意 Fprintf 是如何向 http.ResponseWriter 输出内容的。）在实际的服务器中，对 ctr.n 的访问需要进行并发保护。参考 sync 和 atomic 包来获取建议。 作为引用，这里是如何将这样一个服务添加到 URL 树上。 import \"net/http\" ... ctr := new(Counter) http.Handle(\"/counter\", ctr) 但是为什么我们需要将 Counter 定义为结构体呢？使用整数就足够满足所有的需求了。（方法的接收者需要设置为指针，这样数字的增长才对调用者可见。） // Simpler counter server. type Counter int func (ctr *Counter) ServeHTTP(w http.ResponseWriter, req *http.Request) &#123; *ctr++ fmt.Fprintf(w, \"counter = %d\\n\", *ctr) &#125; 如果您的程序有一些内部状态想要得知页面已经被访问的话？可以将 channel 绑定到服务中。 // A channel that sends a notification on each visit. // (Probably want the channel to be buffered.) type Chan chan *http.Request func (ch Chan) ServeHTTP(w http.ResponseWriter, req *http.Request) &#123; ch &lt;- req fmt.Fprint(w, \"notification sent\") &#125; 最后，假设我们想要在 &#x2F;arg 上显示服务器启动时使用的参数。编写一个打印参数的函数很简单。 func ArgServer() &#123; fmt.Println(os.Args) &#125; 如何将其变为 HTTP 服务呢？我们可以将将 ArgServer 设置成某些我们不关注的类型的方法，但是有一个更清晰的实现方式。由于我们可以为除了指针和接口外的所有类型定义方法，我们也可以为函数定义方法。http 包中包含了这样的定义： // The HandlerFunc type is an adapter to allow the use of // ordinary functions as HTTP handlers. If f is a function // with the appropriate signature, HandlerFunc(f) is a // Handler object that calls f. type HandlerFunc func(ResponseWriter, *Request) // ServeHTTP calls f(w, req). func (f HandlerFunc) ServeHTTP(w ResponseWriter, req *Request) &#123; f(w, req) &#125; HandlerFunc 是一个有 ServerHTTP 方法的类型，因此该类型的数据实现了 Handler 接口，可以处理 HTTP 请求。观察这个方法的实现：接收者是一个函数 f，而方法调用了 f。这可能看起来有点奇怪，但是本质上和用 channel 作为接收者然后在方法中向 channel 发送数据没什么区别。 为了将 ArgServer 变成 HTTP 服务，首先我们改变他的方法签名。 // Argument server. func ArgServer(w http.ResponseWriter, req *http.Request) &#123; fmt.Fprintln(w, os.Args) &#125; ArgServer 现在有了和 HanderFunc 相同的方法签名，所以他可以被类型转换为 HanderFunc 从而使用 HanderFunc 的方法，就像我们将 Sequence 转换为 IntSlice 从而使用 IntSlice.Sort 一样。设置的代码很简单： http.Handle(\"/args\", http.HandlerFunc(ArgServer)) 当有人访问页面 &#x2F;args 时，此处的处理器是 HandlerFunc 类型的 ArgServer。HTTP 服务器会调用处理器的 ServeHTTP 方法，而 ArgServer 作为接收者，实际上会调用 ArgServer（通过 HandlerFunc.ServeHTTP 中的 f(w,rea)）。相关的参数结果也会随之返回。 在这一章节中我们使用多种方式实现 HTTP 服务，包括结构体、整数、channel 和 函数，这一切都是因为接口只是方法的集合，几乎所有类型都可以成为接口的实现。 空标识符在之前的 for range 循环 和 maps 的内容中，我们已经几次提到了关于空标识符的内容。空标识符可以被声明为任何类型的任何数据，之后该数据则会被无害的丢弃。这有点像在 Unix 中向 &#x2F;dev&#x2F;null 文件写入内容：他提供了一个需要变量占位符但是实际值又无关紧要的场景下的只写的值。他的用途比我们之前见到的还要更加广泛。 多重赋值中的空标识符在 for range 循环中使用空标识符其实是某种通用解决方案的特例：在多重赋值中使用空标识符。 如果在赋值语句的左侧需要多个变量，但是其中的某个变量实际上又不会被系统使用，那么使用空标识符就可以避免我们去创建一个无效的变量，也可以清晰的表明此处变量的值会被丢弃。例如，当调用的函数可以同时提供返回值和错误值，但我们仅需要错误值时，可以使用空标识符丢弃无关紧要的返回值。 if _, err := os.Stat(path); os.IsNotExist(err) &#123; fmt.Printf(\"%s does not exist\\n\", path) &#125; 偶尔你会看到有代码通过丢弃错误的方式来忽略对他们的处理；这是一种很糟糕的实践。请确保总是检查错误的值，提供错误返回是有原因的。 // Bad! This code will crash if path does not exist. fi, _ := os.Stat(path) if fi.IsDir() &#123; fmt.Printf(\"%s is a directory\\n\", path) &#125; 未使用的引入和变量引入一个包或声明一个变量后不去使用是一种错误。未使用的引入会导致程序膨胀，编译速度变慢，当一个变量被初始化但没有使用时，至少他会造成计算性能的浪费，而且可能会表示某处存在更大的 bug。当一个程序处在活跃的开发阶段时，未使用的引入和变量会经常出现，如果只是为了继续编译而删除他们，而之后又需要重新引入或声明，这很让人懊恼。空标识符提供了对这个问题的解决方案。 这个半成品程序包括两个未使用的引入（fmt 和 io）和一个未使用的变量（fd），因此他无法被编译，但是假设我们想要查看至今为止的代码是否正确。 package main import ( \"fmt\" \"io\" \"log\" \"os\" ) func main() &#123; fd, err := os.Open(\"test.go\") if err != nil &#123; log.Fatal(err) &#125; // TODO: use fd. &#125; 为了消除未使用引入的报错，可以使用空标识符从引入的包中引用一个变量。类似的，将 fd 赋值给空标识符会消除未使用变量的错误。这个版本的程序就可以编译了。 package main import ( \"fmt\" \"io\" \"log\" \"os\" ) var _ = fmt.Printf // For debugging; delete when done. var _ io.Reader // For debugging; delete when done. func main() &#123; fd, err := os.Open(\"test.go\") if err != nil &#123; log.Fatal(err) &#125; // TODO: use fd. _ = fd &#125; 方便起见，为了消除引入错误而进行的全局声明应该集中在 imports 代码块后并且被注解，这样既可以方便的找到他们，又可以提醒我们之后将他们清理掉。 为了潜在作用而引入前文中提到的未使用的引入例如 fmt 或 io 最终会被使用或被移除：空赋值表示了代码仍在开发过程中。但有时，不去显式的使用一个包，而仅仅是为了他的潜在作用而引入他也是有效的。例如，net&#x2F;http&#x2F;pprof 包在他的 init 函数中注册了提供 debug 信息的 HTTP 接口。他有一个导出 API，但是大多数客户端只需要初始化 HTTP 处理然后通过 web 页面访问数据。为了只利用包的潜在作用而引入包，可以将包名重命名为空标识符： import _ \"net/http/pprof\" 这种引入形式清楚的表明了这个包是为了他的潜在作用而引入，因为我们已经没有别的使用这种包的可能性：在这个文件里，他甚至连名称都没有。（如果他有名称，而且我们未使用的话，编译器会拒绝这段源码。） 接口检查就像我们之前在讨论接口时看到的，一个类型无需显示的声明他实现了某种接口。反之，一个类型只需要实现了该接口需要的方法，则他就默认实现了这个接口。在实践中，大部分的接口转换是静态的，因此他们会在编译时被检查。例如，在一个需要 io.Reader 参数的函数中传入 *os.File 不会被编译，除非 *os.File 实现了 io.Reader 接口。 尽管如此，有些接口检查确实是在运行时发生的。一个例子是 encoding&#x2F;json 包，其中定义了 Marshaler 接口。当 JSON 编码器接收到实现了该接口的值时，编码器使用该值的编码方法将其转换为 JSON，否则使用基础方法转换。编码器在运行时使用类型断言检查此属性： m, ok := val.(json.Marshaler) 如果仅仅只需要了解类型是否实现了某个接口，但并不使用接口值自身，也许就是作为错误检查的一部分，可以使用空标识符来忽略类型断言的值： if _, ok := val.(json.Marshaler); ok &#123; fmt.Printf(\"value %v of type %T implements json.Marshaler\\n\", val, val) &#125; 这个情况出现的一个地方是在实现类型的包中需要保证它实际上满足了接口。如果一个类型——例如，json.RawMessage——需要一个定制化的 JSON 表示，那么他应该实现 json.Marshaler 接口，但是这里没有静态类型转换使得编译器去自动检查这一点。如果这个类型的不经意间的改动无法满足了接口要求，JSON 编码器仍然会工作，但是不再使用定制化的实现方式。为了确保可以采用正确的实现，可以在这个包中进行一个全局的使用空标识符的声明： var _ json.Marshaler = (*RawMessage)(nil) 在这个声明中，赋值语句调用了一个从 *RawMessage 到 Marshaler 的类型转换，这需要 *RawMassage 实现 Marshaler 接口，且这个属性会在编译时被检查。如果 json.Marshaler 接口发生变化，这个包将不再编译，我们会注意到这一点，意识到这个包需要被更新。 这里的空标识符表示这个声明的存在仅仅是为了做类型检查，而非创建一个变量。尽管如此，不要对每个实现接口的类型做这种检查。为了方便起见，这种声明只在代码中没有静态转换的使用使用，这其实是一种很罕见的情况。 嵌入式Go 没有提供传统的、类型驱动的子类概念，但他拥有通过 嵌入类型 来借用结构体或接口部分实现的能力。 接口嵌入十分简单，我们之前已经提过 io.Reader 和 io.Writer 接口；这里是他们的定义。 type Reader interface &#123; Read(p []byte) (n int, err error) &#125; type Writer interface &#123; Write(p []byte) (n int, err error) &#125; io 包还提供了其他几个接口，用来指定对象需要满足这些方法。例如，io.ReadWriter 是一个同时包括了读写的接口。我们可以通过显示的列举这两个方法的方式来指定 io.ReadWriter 接口，但是更简单且优雅的方式是直接将原先的两个接口嵌入其中，就像这样： // ReadWriter is the interface that combines the Reader and Writer interfaces. type ReadWriter interface &#123; Reader Writer &#125; 他的作用不言自明：ReadWriter 等同于 Reader 加上 Writer；他的能力由被嵌入接口组合而成。只有接口可以被接口嵌入。 这个想法同样适用于结构体，但是实现的更加深入。bufio 包有两个结构体类型，bufio.Reader 和 bufio.Writer，他们当然各自实现了 io 包中的接口。同时，bufio 包也实现了一个基于 buffer 的读写结构体，他通过嵌入的方式将 reader 和 writer 结合到一起：他包括了结构体内部的类型，但没有给他们字段名。 // ReadWriter stores pointers to a Reader and a Writer. // It implements io.ReadWriter. type ReadWriter struct &#123; *Reader // *bufio.Reader *Writer // *bufio.Writer &#125; 被嵌入的元素是已经正确初始化的结构体的指针。ReadWriter 结构体可以被写为 type ReadWriter struct &#123; reader *Reader writer *Writer &#125; 但随后为了暴露字段的方法，且需要满足接口的需求，我们还需要提供对方法的转发，就像这样： func (rw *ReadWriter) Read(p []byte) (n int, err error) &#123; return rw.reader.Read(p) &#125; 通过直接嵌入结构体，我们可以避免这样的抄书工作。被嵌入类型的方法可以直接调用，这意味着 bufio.ReadWriter 不仅有 bufio.Reader 和 bufio.Writer 的方法，他其实同时满足了三个接口：io.Reader，io.Writer，io.ReadWriter。 嵌入和子类有一个很重要的区别。当我们嵌入一个类型时，该类型的方法会变成外层的方法，但是当方法被调用时，方法的接收者是内部类型，而非外部类型。在我们的例子中，当 bufio.ReadWriter 中的 Read 方法被调用时，他实际上的效果和我们将这个方法转发到外层相同；方法的接收者是 ReadWriter 中的 reader 字段，而非 ReadWriter 自身。 嵌入式也带来一些简单的小技巧。这个例子里我们同时使用了一个嵌入式字段和一个常规的命名字段。 type Job struct &#123; Command string *log.Logger &#125; 现在 Job 类型就拥有了 Print， Printf， Println 和其他 *log.Logger 带来的方法。我们当然可以选择给 Logger 提供一个字段名，但这没有必要。现在，当初始化完成后，我们可以这样输出 Job： job.Println(\"starting now...\") Logger 也是 Job 结构体中的一个字段，因此我们可以采用普通的方式在 Job 的构造函数中初始化他，例如这样， func NewJob(command string, logger *log.Logger) *Job &#123; return &amp;Job&#123;command, logger&#125; &#125; 或者采用复合字面量， job := &amp;Job&#123;command, log.New(os.Stderr, \"Job: \", log.Ldate)&#125; 如果我们需要直接引用被嵌入的字段，可以将他的类型名称（忽略包名）直接视作字段名称，就像我们在 ReadWriter 结构体中的 Read 方法中做的那样。在这里，如果我们需要访问 Job 类变量 job 中的 *log.Logger，我们可以使用 job.Logger，这对于如果我们想要重写 Logger 中的方法时很有用。 func (job *Job) Printf(format string, args ...interface&#123;&#125;) &#123; job.Logger.Printf(\"%q: %s\", job.Command, fmt.Sprintf(format, args...)) &#125; 嵌入类型引入了名称冲突的问题，但解决他们的规则很简单。首先，一个名为 X 的字段或方法会将其他更深层的的名为 X 的部分隐藏。如果 log.Logger 包含一个名为 Command 的字段或方法，那么 Job 中的 Command 方法会屏蔽他。 其次，如果相同层级中出现了相同的名称，那通常会是一个错误；如果 Job 结构体包含另一个名为 Logger 的字段或方法，则嵌入 log.Logger 是错误的。然而，如果在类型定义外的任何地方，程序都没有使用这个重复的名称，那么是没有问题的。这种限定可以防止外部嵌入的类型发生更改时带来的一些问题；如果从未使用过某个字段，即使它与另一个子类型中的字段冲突也无关紧要。 并发通过通信共享并发编程是一个庞大的主题，这里仅仅介绍一些 Go 相关的重点内容。 由于实现对共享变量的访问有很多微妙的细节，这导致了在很多环境中并发编程十分困难。Go 鼓励采用另一种方法，即通过通信传递共享的值，而非使用多个分离的线程来访问他。在任何时候只会有一个 goroutine 在使用这个值。通过这种设计方式，根本不会产生数据竞态问题。为了鼓励这种思维方式我们把他提炼成了一句简单的口号： 不要通过共享内存来通信，而是通过通信来共享内存。 这种设计可能会矫枉过正。例如，对于一个引用计数器，最好的方法就是在整数上加一个 mutex。但是作为一种高级方法，使用管道来控制接入还是会让编写清晰、正确的程序更加简单。 一种理解这个模型的方法是，考虑一个在 CPU 上运行的典型的单线程程序。他不需要任何的同步关键字。现在运行该程序的另一个实例，他也不需要任何同步关键字。现在让他们之间进行通信，如果通信过程是同步的，那么就仍然不需要任何同步关键字。Unix 中的管道就是这个模型的完美实例。尽管 Go 的并发方法起源于 Hoare 的 通信顺序进程（CSP），但他也可以被看作一种类型安全的 Unix 管道。 Goroutinesgoroutines 被这样命名是因为所有现有的术语：线程、协程、进程等等，都无法准确表达他的内涵。goroutine 有一个简单的模型：他是一个与其他 goroutines 在同一地址空间并发执行的函数。他非常的轻量级，开销仅仅略多于堆栈空间分配。开始时仅使用一个小堆栈，因此开销很低，随后在使用时按序分配（或释放）堆存储。 Goroutines 在操作系统的多个线程上多路复用，如果其中一个发生堵塞，例如在等待 I&#x2F;O，其他的 goroutines 可以继续运行。这种设计隐藏了很多线程创建和管理上的复杂性。 在函数或方法调用前添加 go 关键字会让这次调用运行在一个新建的 goroutine 中。当调用完成后，goroutine 静默的退出。（效果类似于在 Unix shell 中使用 &amp; 在后台运行命令。） go list.Sort() // run list.Sort concurrently; don't wait for it. 匿名函数可以方便的通过 goroutine 调用。 func Announce(message string, delay time.Duration) &#123; go func() &#123; time.Sleep(delay) fmt.Println(message) &#125;() // Note the parentheses - must call the function. &#125; 在 Go 中，匿名函数是闭包：实现确保了函数引用的变量的生命周期至少和函数一致。 这些例子都不是很典型，因为函数无法发出完成信号。对此，我们需要 channels。 Channels类似于 maps，channels 同样使用 make 进行分配，获得的值同样引用了一个底层的数据结构。分配 channels 的 make 提供了一个可选的整数参数，用于设定 channel 的缓冲大小。默认值是 0，表示一个无缓冲的同步通道。 ci := make(chan int) // unbuffered channel of integers cj := make(chan int, 0) // unbuffered channel of integers cs := make(chan *os.File, 100) // buffered channel of pointers to Files 无缓冲的 channels 结合了通信（值的交换）与同步（保证两个计算(goroutines)）处在一个已知的状态。 关于通道的使用有很多好的惯例，我们从下面这个开始。在这段代码中我们在后台启动了数组排序。而 channel 允许启动者的 goroutine 等待排序完成。 c := make(chan int) // Allocate a channel. // Start the sort in a goroutine; when it completes, signal on the channel. go func() &#123; list.Sort() c &lt;- 1 // Send a signal; value does not matter. &#125;() doSomethingForAWhile() &lt;-c // Wait for sort to finish; discard sent value. 接收者会在收到数据之前一直阻塞。如果 channel 是无缓冲的，发送者也会在接收者接受数据前一直堵塞。如果通道是有缓冲的，发送者只会在向缓冲区满的通道再次发送数据的时候堵塞，这意味着需要等待一些接收者来领取数据。 有缓冲的 channel 可以像信号量一样使用，例如用来进行吞吐量的限制。在这个例子中，输入的请求被传递到 handle，而他将一个值放入 channel、处理请求、最后从 channel 中接收一个值，为下一个使用者准备好“信号量”。channel 缓冲器的容量限制了 process 函数的并发数量。 var sem = make(chan int, MaxOutstanding) func handle(r *Request) &#123; sem &lt;- 1 // Wait for active queue to drain. process(r) // May take a long time. &lt;-sem // Done; enable next request to run. &#125; func Serve(queue chan *Request) &#123; for &#123; req := &lt;-queue go handle(req) // Don't wait for handle to finish. &#125; &#125; 一旦有 MaxOutstanding 数量的 handlers 同时在处理，更多的请求会由于尝试向满载的缓冲 channel 写入数据而被堵塞，直到其中某个现存的 handlers 完成计算并且从缓冲 channel 中接收数据。 不过，这样的设计仍然存在一个问题：Serve 对每一个进入的请求创建新的 goroutine，即便在任何时候只有 MaxOutstanding 个请求可以运行。这样带来的结果是，当请求到来的过快时，该程序可能会消耗大量的资源。我们可以将 goroutines 的创建移入 Serve 来解决这个问题。这里有一个很明显的解决方案，但是小心，现在这里有一个 bug，我们随后会修复： func Serve(queue chan *Request) &#123; for req := range queue &#123; sem &lt;- 1 go func() &#123; process(req) // Buggy; see explanation below. &lt;-sem &#125;() &#125; &#125; 这里的 bug 是，在 Go 循环中，循环变量是在每次迭代时共享的，因此 req 变量是在所有 goroutines 中共享的，这并不符合我们的预期，我们希望每个 goroutine 中的 req 是独立的。这里有一个解决方式，将 req 的值作为参数传递给 goroutines 的闭包： func Serve(queue chan *Request) &#123; for req := range queue &#123; sem &lt;- 1 go func(req *Request) &#123; process(req) &lt;-sem &#125;(req) &#125; &#125; 对比这个版本和上一个版本的代码，可以观察闭包声明和运行中的区别。另一个解决方案是创建一个同名变量，比如在这个例子： func Serve(queue chan *Request) &#123; for req := range queue &#123; req := req // Create new instance of req for the goroutine. sem &lt;- 1 go func() &#123; process(req) &lt;-sem &#125;() &#125; &#125; 这个写法也许看起来很怪 req := req 但这是合法的，而且很符合 Go 中的习惯。这会产生一个同名的新变量，有意的在循环体中隐藏了循环变量，确保了每个 goroutine 中变量的唯一性。 回到编写这个服务器的问题，另一个可以良好管理资源的解决方案是启动固定数量的 goroutines 并使他们都去读取 request channel。goroutines 的数量限制了 process 并发调用的数量。Serve 函数同时也接受一个通知其退出的 channel，在启动 goroutines 之后他阻塞直到从该通道接收到内容。 func handle(queue chan *Request) &#123; for r := range queue &#123; process(r) &#125; &#125; func Serve(clientRequests chan *Request, quit chan bool) &#123; // Start handlers for i := 0; i &lt; MaxOutstanding; i++ &#123; go handle(clientRequests) &#125; &lt;-quit // Wait to be told to exit. &#125; Channels of channelsGo 中最重要的特性之一就是 channel 是 Go 中的一等公民，他可以像其他值一样被分配和传递。这个属性的常见用途之一是用来实现安全、并行的解复用。 在上一章节的例子中，handle 是一个想象中用来处理请求的模型，但是我们没有定义他所处理的具体类型。如果该类型包含接收回复的通道，那么每个客户端都可以独立定义他们接收计算结果的路径。这里是一个对 Request 类型定义的示意。 type Request struct &#123; args []int f func([]int) int resultChan chan int &#125; 客户端提供了计算函数，计算参数，以及在其内部的用来接收结果的 channel。 func sum(a []int) (s int) &#123; for _, v := range a &#123; s += v &#125; return &#125; request := &amp;Request&#123;[]int&#123;3, 4, 5&#125;, sum, make(chan int)&#125; // Send request clientRequests &lt;- request // Wait for response. fmt.Printf(\"answer: %d\\n\", &lt;-request.resultChan) 而在服务端一侧，唯一的改变就是 handler 函数的内容。 func handle(queue chan *Request) &#123; for req := range queue &#123; req.resultChan &lt;- req.f(req.args) &#125; &#125; 显然还需要很多代码工作才能让这个例子成为真正的实现，但是这些代码可以视作一个有限速的、并发的、非阻塞的 RPC 系统的框架，而且看不到任何一个 mutex。 并行处理关于这些想法的另一个应用是在多个 CPU 核心上并行处理计算任务。如果计算任务可以被分解成多个独立执行的小块，那么他就可以被并行处理，只需为每一块分配一个 channel 来标志其完成。 假设我们有一个开销很大的向量计算操作，而且对每个元素的计算是独立的，就像这个理想化的例子。 type Vector []float64 // Apply the operation to v[i], v[i+1] ... up to v[n-1]. func (v Vector) DoSome(i, n int, u Vector, c chan int) &#123; for ; i &lt; n; i++ &#123; v[i] += u.Op(v[i]) &#125; c &lt;- 1 // signal that this piece is done &#125; 我们在循环中按照 CPU 的数量独立启动每个计算任务。他们可能会按照任意顺序完成但是这不重要，我们只需要在启动所有 goroutines 后通过清空 channel 来对完成信号进行计数。 const numCPU = 4 // number of CPU cores func (v Vector) DoAll(u Vector) &#123; c := make(chan int, numCPU) // Buffering optional but sensible. for i := 0; i &lt; numCPU; i++ &#123; go v.DoSome(i*len(v)/numCPU, (i+1)*len(v)/numCPU, u, c) &#125; // Drain the channel. for i := 0; i &lt; numCPU; i++ &#123; &lt;-c // wait for one task to complete &#125; // All done. &#125; 相比于创建一个固定值的 numCPU，我们可以在运行时获得一个更合适的值。函数 runtime.NumCPU 返回运行机器的 CPU 硬件核心数量，因此我们可以 var numCPU = runtime.NumCPU() 还有一个函数是 runtime.GOMAXPROCS，他可以报告（或设置）由用户定义的 Go 程序运行时可以使用的核心数。他的默认值是 runtime.NumCPU，但是可以被一个名称相似的环境变量修改，或是被调用这个函数并传入一个正整数修改。调用此函数并传入 0 会查询这个值。因此，如果我们想尊重用户设置的资源限制，我们可以 var numCPU = runtime.GOMAXPROCS(0) 请注意不要混淆并发（将程序结构化为独立的执行组件）和并行（在多个 CPU 上并行计算以提高效率）的概念。虽然 Go 语言的并发特性可以让一些问题易于结构化为并行计算，但 Go 语言是一种并发语言，而不是并行语言，并不是所有并行化问题都适合 Go 语言的模型。关于这两种概念的区别，可以参考这篇博客中引用的演讲。 A leaky buffer并发编程的工具甚至可以让非并发的想法更容易表达。这里有一个对某个 RPC 包的抽象例子。客户端 goroutine 从某个数据源循环的接收数据，也许是通过网络。为了避免大量分配和释放 buffer 的开销，他持有了一个空闲 buffer 的列表，然后通过一个带缓冲区的 channel 来表示这个列表。如果 channel 是空的，那么就分配一个新的 buffer。一旦 buffer 的内容被填充完成，他使用 serverChan 将其发送至服务程序。 var freeList = make(chan *Buffer, 100) var serverChan = make(chan *Buffer) func client() &#123; for &#123; var b *Buffer // Grab a buffer if available; allocate if not. select &#123; case b = &lt;-freeList: // Got one; nothing more to do. default: // None free, so allocate a new one. b = new(Buffer) &#125; load(b) // Read next message from the net. serverChan &lt;- b // Send to server. &#125; &#125; server 循环接收来自客户端的消息，处理，并将 buffer 返回到空闲列表。 func server() &#123; for &#123; b := &lt;-serverChan // Wait for work. process(b) // Reuse buffer if there's room. select &#123; case freeList &lt;- b: // Buffer on free list; nothing more to do. default: // Free list full, just carry on. &#125; &#125; &#125; 客户端尝试从空闲列表中取出一个 buffer，如果没有空闲的 buffer ，那么他会分配一个新的 buffer。服务器将 b 发送到空闲列表除非 freeList 已满，这时 buffer 会被丢弃之后被垃圾回收器回收。（select 语句中的 default 条件会在其他 case 都不生效时被选中，这意味着这条 select 语句永远不会堵塞。）在带缓冲区的 channel 和垃圾回收机制的共同作用下，这个实现仅使用了几行代码就构建了一个泄露桶式的 buffer 池。 错误库例程必须经常向调用者返回一些错误信息。就像我们之前提过的，Go 中的多重返回让我们可以轻松的在正常的返回值旁边附带详细的错误描述。使用这个特性来提供详细的错误信息是很好的风格。例如，就像我们即将看到的，os.Open 不仅仅是在故障时返回一个空指针，他还提供了一个错误值来表述错误的内容。 为了方便起见，错误被定义为类型 error，一个简单的内建接口。 type error interface &#123; Error() string &#125; 库的作者可以在这个包装下自由的使用更丰富的模型实现该接口，让错误信息不仅包括错误本身，同时提供一些其他的内容。就像之前提过的，除了返回的 *os.File 类型的值之外，os.Open 还返回一个 error 类型的值。如果文件被成功的打开，那么这个 error 值将会是 nil，但是如果发生了错误，他将会持有一个 os.PathError： // PathError records an error and the operation and // file path that caused it. type PathError struct &#123; Op string // \"open\", \"unlink\", etc. Path string // The associated file. Err error // Returned by the system call. &#125; func (e *PathError) Error() string &#123; return e.Op + \" \" + e.Path + \": \" + e.Err.Error() &#125; PathError 的 Error 方法生成的字符串类似于这样： open /etc/passwx: no such file or directory 像这样一个 error，囊括了有问题的文件名称、操作内容和他触发了的系统错误，即使错误打印的地方和调用处相距甚远，这样的报错依然十分有用；他比直接的打印 “no such file or directory” 能提供更多有效的信息。 如果有条件的话，error 字符串应该标注他们的来源，例如添加前缀来标注是哪个操作或者包生成了这个 error。例如，在 image 包中，因为未知格式而导致的解码错误的错误字符串为 “image: unknown format”。 关心精确的错误细节的调用者可以使用 type switch 或者类型断言来获得 error 的具体类型从而获取更多的细节。对于 PathErrors 来说，这可能包括了检查内部的 Err 字段用来处理可恢复的故障。 for try := 0; try &lt; 2; try++ &#123; file, err = os.Create(filename) if err == nil &#123; return &#125; if e, ok := err.(*os.PathError); ok &amp;&amp; e.Err == syscall.ENOSPC &#123; deleteTempFiles() // Recover some space. continue &#125; return &#125; 这里的第二个 if 语句是一个类型断言。如果他失败了，ok 的值会是 false，e 的值会是 nil。如果他成功了，ok 的值会是 true，这表示 error 的类型确实是 *os.PathError，此时 e 会成为这个类型，这样我们可以检查其中的更多信息细节。 Panic常规的向调用者汇报错误的方式是添加一个 error 类型的返回值。Read 方法就是一个广为人知的典范，他返回了读取的字节数和一个 error。但是，当发生了不可恢复的故障的情况下怎么办呢？有些情况下就是需要中断程序运行。 为了实现这个目的，有一个内建函数 panic，他可以创建一个运行时错误从而中止程序（但也有例外，参考下一章）。此函数需要一个任意类型的信号参数——通常是字符串——用作程序终止时的打印输出。他也可以用来表明发生了某些不该发生的事，例如存在一个无限循环。 // A toy implementation of cube root using Newton's method. func CubeRoot(x float64) float64 &#123; z := x/3 // Arbitrary initial value for i := 0; i &lt; 1e6; i++ &#123; prevz := z z -= (z*z*z-x) / (3*z*z) if veryClose(z, prevz) &#123; return z &#125; &#125; // A million iterations has not converged; something is wrong. panic(fmt.Sprintf(\"CubeRoot(%g) did not converge\", x)) &#125; 这里只是一个例子，实际上的库函数应该避免 panic。如果问题可以被掩盖或者解决，让程序继续运行下去总比直接中断整个程序要好。一个可能的反例是初始化：可以认为，如果一个库确实无法完成自身设置，那么进行 panic 也是合理的。 var user = os.Getenv(\"USER\") func init() &#123; if user == \"\" &#123; panic(\"no value for $USER\") &#125; &#125; Recover当 panic 发生时，或者包括隐式的运行时错误例如切片越界、类型断言错误等等，他会立刻中断当前执行的函数并且开始释放当前 goroutine 的堆栈，运行沿途上的任何 defer 函数。如果这个释放过程到达了当前 goroutine 的顶部，程序则会终止。然而，可以使用内建函数 recover 来恢复对 goroutine 的控制并让其继续执行。 对 recover 的调用会中止释放过程，并返回传递给 panic 的参数。由于在释放过程中唯一能够被执行的代码是位于 defer 中的代码，因此 recover 只有在 defer 函数中才有作用。 recover 的一个应用是中断服务中失败的 goroutine，从而避免中断整个程序。 func server(workChan &lt;-chan *Work) &#123; for work := range workChan &#123; go safelyDo(work) &#125; &#125; func safelyDo(work *Work) &#123; defer func() &#123; if err := recover(); err != nil &#123; log.Println(\"work failed:\", err) &#125; &#125;() do(work) &#125; 在这个例子中，如果 do(work) 导致了 panic，错误结果将被日志记录，而且报错的 goroutine 只会干净的退出而不会影响其他协程。无需再 defer 闭包中再添加任何东西，调用 cover 就完全足够。 除非是直接被 defer 函数调用，否则 recover 都会返回 nil，因此 defer 中的代码可以调用那些本身也使用了 panic 和 recover 的库函数。例如，在 safelyDo 函数中的 defer 函数可以在 recover 之前调用 logging 函数，该函数的执行不会受到 panic 过程的影响。 理解了 recover 的工作模式后，我们可以通过调用 panic 让 do 函数（以及他调用的任何函数）在遇到错误情况时干净的退出。我们可以利用这个概念来简化复杂软件中的错误处理。让我们看看这个理性化的 regexp 包，他通过调用一个带有本地定义错误类型的 panic 来报告解析错误。这里是关于 Error、error 方法和 Compile 函数的定义。 // Error is the type of a parse error; it satisfies the error interface. type Error string func (e Error) Error() string &#123; return string(e) &#125; // error is a method of *Regexp that reports parsing errors by // panicking with an Error. func (regexp *Regexp) error(err string) &#123; panic(Error(err)) &#125; // Compile returns a parsed representation of the regular expression. func Compile(str string) (regexp *Regexp, err error) &#123; regexp = new(Regexp) // doParse will panic if there is a parse error. defer func() &#123; if e := recover(); e != nil &#123; regexp = nil // Clear return value. err = e.(Error) // Will re-panic if not a parse error. &#125; &#125;() return regexp.doParse(str), nil &#125; 如果 doParse 触发了 panic，recover 代码块会将返回值设置为nil——因为 defer 函数可以修改命名返回值的值。之后，他会在向 err 赋值的语句中通过将 e 类型断言为本地类型 Error，检查问题是否是解析错误。如果不是，那么类型断言会失败，引发一个运行时错误，从而导致堆栈继续释放，就像释放过程未曾中断这样。这种检查意味着当有一些类似于数组越界的运行时错误发生时，即使我们使用 panic 和 recover 处理了解析错误，代码仍然会失败。 在错误处理机制到位后，error 方法（虽然他和内建类型 error 同名，但是由于他是一个绑定在类型上的方法，因此这个命名没有问题，使用起来也很自然）使得我们可以更简单的上报解析错误，而无需操心于手动释放解析堆栈： if pos == 0 &#123; re.error(\"'*' illegal at start of expression\") &#125; 虽然这个模式非常实用，但是他应该仅限在包内部使用。通过解析将内部的 panic 转化为 error 类型的值，而不是将 panic 暴露给自己的客户端，这是一个良好的规则。 顺带一提，这种类型的用法改变了实际报错中的 panic 内容。然而，不管是原始的还是新的报错内容都会在崩溃日志中体现，因此报错的根源依然可以被找到。因此这种简单的 re-panic 机制往往就够用了——毕竟最终都是要崩溃的——但是如果你只想在崩溃日志中展示原始错误，你可以通过写一小段代码来过滤非预期的错误然后使用原始的错误来 re-panic。这是留给读者的小练习。 一个WEB服务器让我们用一个完整的 Go 程序来收尾，一个 WEB 服务器。这其实是一个基于其他服务的 web 服务器。Google 在 chart.apis.google.com 上提供了一个服务，可以自动将数据格式化为图表和图形。但是他的交互比较麻烦，因为你要把数据作为 URL 的一部分用来查询。这个程序提供了一个更好的数据格式接口：通过输入一段文本，他调用图表服务来生成一个二维码，他可以被您的手机扫描并且转换为一个 URL，这样您就无需在手机的小键盘上输入这个 URL。 这里是完整的程序，随后会有说明。 package main import ( \"flag\" \"html/template\" \"log\" \"net/http\" ) var addr = flag.String(\"addr\", \":1718\", \"http service address\") // Q=17, R=18 var templ = template.Must(template.New(\"qr\").Parse(templateStr)) func main() &#123; flag.Parse() http.Handle(\"/\", http.HandlerFunc(QR)) err := http.ListenAndServe(*addr, nil) if err != nil &#123; log.Fatal(\"ListenAndServe:\", err) &#125; &#125; func QR(w http.ResponseWriter, req *http.Request) &#123; templ.Execute(w, req.FormValue(\"s\")) &#125; const templateStr = ` &lt;html> &lt;head> &lt;title>QR Link Generator&lt;/title> &lt;/head> &lt;body> &#123;&#123;if .&#125;&#125; &lt;img src=\"http://chart.apis.google.com/chart?chs=300x300&amp;cht=qr&amp;choe=UTF-8&amp;chl=&#123;&#123;.&#125;&#125;\" /> &lt;br> &#123;&#123;.&#125;&#125; &lt;br> &lt;br> &#123;&#123;end&#125;&#125; &lt;form action=\"/\" name=f method=\"GET\"> &lt;input maxLength=1024 size=70 name=s value=\"\" title=\"Text to QR Encode\"> &lt;input type=submit value=\"Show QR\" name=qr> &lt;/form> &lt;/body> &lt;/html> ` main 之前的部分应该都很容易理解。flag 为我们的服务设置了一个默认的 HTTP 端口。模板变量 templ 是有趣的地方。他构建了一个服务器用来显示页面的 HTML 模板，稍后会详细介绍。 main 函数中解析了 flags，使用我们之前讨论过的机制将 QR 函数绑定在服务的根路径。之后 http.ListenAndServe 被调用，启动 HTTP 服务，并且在服务运行期间阻塞主程序。 QR 接受请求包含表单数据的请求，根据表单中名为 s 的数据的值来执行模板。 模板包 html&#x2F;template 非常强力，这个程序仅仅涉及他功能的一小部分。本质上，它通过替换从传递给 templ.Execute 的数据项派生的元素来动态重写一段 HTML 文本，在这里例子中就是表单的值。在模板文本 (template Str) 中，双括号分隔的部分表示模板操作。仅当数据项 .（点） 非空时，{{if .}} 到 {{end}} 之间的代码片才会执行。这意味着，当传入字符串为空时，这一部分的模板将不生效。 两个 {{.}} 表示了两个提供给模板的数据——一个位于查询字符串——另一个直接在 web 页面中。HTML 模板包自动提供适当的转移，以便文本可以安全的显示。 模板中剩余部分的字符串只是当页面加载时显示的 HTML。如果这部分的解释过于简短，您也可以参考这篇关于模板包的文档进行更全面的讨论。 此时你已经拥有了一个仅使用几行代码创建的数据驱动的 HTML 服务。Go 就是这样，他有能力仅仅使用几行代码来实现很多事情。","tags":[{"name":"翻译","slug":"翻译","permalink":"https://vitsumoc.github.io/tags/%E7%BF%BB%E8%AF%91/"},{"name":"Go","slug":"Go","permalink":"https://vitsumoc.github.io/tags/Go/"}]},{"title":"Go标准库：log","date":"2024-02-29T07:55:29.000Z","path":"Go标准库：log.html","text":"彪悍的人生不需要解释，那么彪悍的模块也不需要解释，例如今天所讨论的 log 模块，就绝对称得上是简明易懂、短小精干，只需稍微花个十来分钟阅读源码就可以理解并使用，非常具有 go 的味道。 示例最简单的应用：test.gofunc main() &#123; log.Println(\"Hello Log!\") &#125; 输出： 2024/03/01 09:46:29 Hello Log! 通过 Logger 对象指定写入位置和自定义前缀test.gofunc main() &#123; file, _ := os.OpenFile(\"./test.log\", os.O_RDWR|os.O_CREATE, 0666) defer file.Close() logger := log.New(file, \"[Custom prefix]\", log.LstdFlags) logger.Println(\"Hello Log!\") &#125; test.log[Custom prefix]2024/03/01 09:51:53 Hello Log! 一个结构体log 模块定义了名为 Logger 的结构体，用来打理一切和日志有关的操作： log.gotype Logger struct &#123; outMu sync.Mutex out io.Writer // destination for output prefix atomic.Pointer[string] // prefix on each line to identify the logger (but see Lmsgprefix) flag atomic.Int32 // properties isDiscard atomic.Bool &#125; Logger 中仅有5个成员变量，其含义如下： 成员 含义 outMu 输出锁，实现并发环境下有序的输出 out 输入对象，表示日志输出的目的地 prefix 用户设置的日志前缀 flag 配置项，一共有8个开关项 isDiscard 内部使用，记录输出对象是否为丢弃，当输出目标是丢弃时，输出函数不再处理，直接返回 flag 表示的配置项有这些： 配置项 含义 示例 Ldate 添加日期 2009&#x2F;01&#x2F;23 Ltime 添加时间 01:23:23 Lmicroseconds 添加微秒 01:23:23.123123 Llongfile 添加完整的日志产生的文件和行数 &#x2F;a&#x2F;b&#x2F;c&#x2F;d.go:23 Lshortfile 添加简短的日志产生的文件和行数 d.go:23 LUTC 使用UTC时间，不使用本地时区 Lmsgprefix 将前缀至于行首，而非消息前 2024&#x2F;03&#x2F;01 10:30:58 [Custom prefix]Hello Log! LstdFlags 等于 Ldate | Ltime 设置日期时间的快捷方法 两种入口使用者可以自己创建 Logger 对象，从而定制日志输出的目标、字符串前缀、配置项等，然而更简单的方式是直接使用 log 模块提供的公共函数。这些函数使用 log 模块内置的 Logger 对象、使用 os.stdOut 作为输出、没有前缀并使用 LstdFlags 作为默认配置。 log.Println(\"Hello Log!\") 或者自己创建 Logger 实现更多的定制化需求，或是创建多个 Logger 将日志发往不同地方等： logger := log.New(file, \"[Custom prefix]\", log.LstdFlags) 三类输出方式不管是如何创建的 Logger ，都提供了相同的输出方式，即三类、六种功能函数： Print[f|ln] Fatal[f|ln] Panic[f|ln] 函数 含义 Printf 输出日志 Println 输出日志并换行 Fatalf 输出日志，之后退出程序 Fatalln 输出日志并换行，之后退出程序 Panicf 输出日志，之后向上抛出panic，可能退出程序或被recover Panicln 输出日志并换行，之后向上抛出panic，可能退出程序或被recover 总结Go 提供的日志模块非常简单，清晰易懂，便于使用者将其封装为各种业务模块。使用方法简单到堪称优雅的程度，再次提醒我们在使用 Go 工作的过程中，要反复不断的去学习标准库，体会其少即是多的设计思想。","tags":[{"name":"Go","slug":"Go","permalink":"https://vitsumoc.github.io/tags/Go/"}]},{"title":"通过proxychains-windows在命令行中使用socks5代理","date":"2024-02-18T14:57:51.000Z","path":"通过proxychains-windows在命令行中使用socks5代理.html","text":"工作时有时会需要使用一些带有网络操作命令行工具，这些工具也可能需要通过socks5进行代理，proxychains-windows 为我们提供了直接的解决方案。 介绍在proxychains-windows的介绍文档中摘录如下内容： Proxychains.exe 是一个适用于 Win32(Windows) 和 Cygwin 平台的命令行强制代理工具（Proxifier）。它能够截获大多数 Win32 或 Cygwin 程序的 TCP 连接，强制它们通过一个或多个 SOCKS5 代理隧道。Proxychains.exe 通过给动态链接的程序注入一个 DLL，对 Ws2_32.dll 的 Winsock 函数挂钩子的方式来将应用程序的连接重定向到 SOCKS5 代理。 工作原理 主程序 Hook CreateProcessW Win32 API 函数调用。 主程序创建按照用户给定的命令行启动子进程。 创建进程后，挂钩后的 CreateProcessW 函数将 Hook DLL 注入到子进程。当子进程被注入后，它也会 Hook 如下的 Win32 API 函数调用： CreateProcessW，这样每一个后代进程都会被注入； connect 和 ConnectEx，这样就劫持了 TCP 连接； GetAddrInfoW 系列函数，这样可以使用 Fake IP 来追踪访问的域名，用于远程 DNS 解析； 等等。 主程序并不退出，而是作为一个命名管道服务端存在。子进程与主程序通过命名管道交换包括日志、域名等内容在内的数据。主程序实施大多数关于 Fake IP 和子进程是否还存在的簿记工作。 当所有后代进程退出后，主程序退出。 主程序收到一个 SIGINT（Ctrl-C）后，终止所有后代进程。 使用按照文档，最简单的使用方法为： proxychains_win32_x64.exe -f proxychains.conf cmd 格式为 可执行程序 -f 配置文件路径 被代理的命令行工具，使用 cmd 作为工具则可以在新开的命令行中手动使用其他命令行工具，均会被代理。 快捷方式通过创建下述快捷方式，可以更方便的使用 proxychains-windows。 C:\\Windows\\System32\\cmd.exe /k C:\"\\Program Files\\\"proxychains_0.6.8_win32_x64\\proxychains_win32_x64.exe -f proxychains.conf cmd","tags":[{"name":"网络工具","slug":"网络工具","permalink":"https://vitsumoc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7/"}]},{"title":"MQTT 5.0 中文文档","date":"2024-01-06T02:14:39.000Z","path":"mqtt-v5-0-chinese.html","text":"原文 MQTT Version 5.0[mqtt-v5.0]MQTT Version 5.0. Edited by Andrew Banks, Ed Briggs, Ken Borgendale, and Rahul Gupta. 07 March 2019. OASIS Standard. https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html. Latest version: https://docs.oasis-open.org/mqtt/mqtt/v5.0/mqtt-v5.0.html. :root { --vc-marked: #ffc107; --vc-referred: #EE0000; } [data-user-color-scheme=\"dark\"] { --vc-marked: #886c57; --vc-referred: #EE0000; } .bold { font-weight: bold; } .vcLinked { color: var(--post-link-color); } .vcMarked { background: var(--vc-marked); } .vcReferred { color: var(--vc-referred); } .vcTrans { font-size: 0.8rem; font-style: italic; } MQTT 5.0OASIS 标准 2019年3月7日 规范 URIs此版本https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.docx (权威性)https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.htmlhttps://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.pdf 前一版本http://docs.oasis-open.org/mqtt/mqtt/v5.0/cos01/mqtt-v5.0-cos01.docx (权威性)http://docs.oasis-open.org/mqtt/mqtt/v5.0/cos01/mqtt-v5.0-cos01.htmlhttp://docs.oasis-open.org/mqtt/mqtt/v5.0/cos01/mqtt-v5.0-cos01.pdf 最新版本https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.docx (权威性)https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.htmlhttps://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.pdf 技术委员会OASIS Message Queuing Telemetry Transport (MQTT) TC 主席Richard Coppen (&#x63;&#111;&#112;&#112;&#101;&#x6e;&#x40;&#x75;&#107;&#x2e;&#x69;&#x62;&#x6d;&#46;&#x63;&#111;&#x6d;), IBM 编辑Andrew Banks (&#97;&#x6e;&#x64;&#114;&#x65;&#x77;&#95;&#98;&#97;&#x6e;&#107;&#115;&#64;&#x75;&#x6b;&#x2e;&#x69;&#x62;&#109;&#46;&#99;&#111;&#109;), IBMEd Briggs (&#101;&#x64;&#x62;&#114;&#105;&#x67;&#103;&#115;&#64;&#x6d;&#105;&#x63;&#x72;&#x6f;&#115;&#x6f;&#102;&#116;&#46;&#x63;&#111;&#x6d;), MicrosoftKen Borgendale (&#107;&#x77;&#98;&#64;&#117;&#x73;&#x2e;&#105;&#98;&#109;&#x2e;&#x63;&#111;&#x6d;), IBMRahul Gupta (&#x72;&#97;&#104;&#117;&#108;&#46;&#103;&#117;&#112;&#116;&#x61;&#x40;&#x75;&#x73;&#x2e;&#105;&#x62;&#109;&#46;&#99;&#111;&#x6d;), IBM 相关工作本规范取代： MQTT 3.1.1 由 Andrew Banks 和 Rahul Gupta 编辑发布与 2014年10月29日。 OASIS 标准 http://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html 最新版本：http://docs.oasis-open.org/mqtt/mqtt/v3.1.1/mqtt-v3.1.1.html 本规范涉及： MQTT and the NIST Cybersecurity Framework Version 1.0 由 Geoff Brown 和 Louis-Philippe Lamoureux 编辑发布。最新版本： http://docs.oasis-open.org/mqtt/mqtt-nist-cybersecurity/v1.0/mqtt-nist-cybersecurity-v1.0.html 简介MQTT 是一个 客户端&#x2F;服务器 架构，采用 订阅&#x2F;发布 模式的消息传输协议。是一套轻量级的、开放的、简单且易于实现的标准。这些特性使得他适用于多种场景，包括一些资源受限的场景比如机器和机器之间的通信（M2M）或是物联网（IoT）场景，这些场景要求较小的代码空间占用，或是网络带宽非常珍贵。 MQTT 基于 TCP&#x2F;IP 或其他提供了顺序、无包丢失、双向链接的网络协议。MQTT 的特性包括： 通过 订阅&#x2F;发布 模式实现一对多的消息传输和应用程序解耦。 与负载内容无关的消息传输。 三种不同服务质量(QoS)的消息传输： 至多一次(At most once)，根据操作环境情况尽最大努力来传输消息，消息可能会丢失。例如这种模式可以用于传感器数据采集，单次的消息的丢失并不重要，因为下一个消息很快就会到来。 至少一次(At least once)，可以确保消息到达，但是可能会造成消息重复。 确保一次(Exactly once)，可以确保消息只到达一次，例如这种消息可以用于账单交易信息，在交易场景下消息的丢失或者重复处理都会带来糟糕的后果。 小型的协议头，用来降低网络负载。 当发生异常断开时通知相关方的机制。 状态本文档最后一次修订的日期和级别都已经在前文中描述。检查最新版本位置了解本文档后续可能的修订版。技术委员会(TC)制作的其他版本文档或其他技术项目均在此提供 https://www.oasis-open.org/committees/tc_home.php?wg_abbrev=mqtt#technical 技术委员会成员应将对此文档的评论发送至技术委员会邮件列表，其他人需在技术委员会的网站(https://www.oasis-open.org/committees/mqtt/)订阅公共评论列表后，通过点击[发送评论](https://www.oasis-open.org/committees/comments/index.php?wg_abbrev=mqtt)将评论发送至公共评论列表。 本规范是在 OASIS 知识产权政策的 Non-Assertion模式下提供的，该模式是技术委员会成立时选择的。关于是否有实施本规范依赖的已经披露的专利信息或是关于任何专利许可条款的信息，请参考技术委员会网站中的知识产权部分(https://www.oasis-open.org/committees/mqtt/ipr.php)。 请注意，本工作产品声明为规范的任何机器可读内容（计算机语言定义）均以单独的纯文本文件提供。 如果任何此类纯文本文件与工作产品的散文叙述性文档中的显示内容之间存在差异，则以单独的纯文本文件中的内容为准。 引用格式引用本规范时，需要使用如下引用格式： [mqtt-v5.0] MQTT Version 5.0. Edited by Andrew Banks, Ed Briggs, Ken Borgendale, and Rahul Gupta. 07 March 2019. OASIS Standard. https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html. Latest version: https://docs.oasis-open.org/mqtt/mqtt/v5.0/mqtt-v5.0.html. 提示Copyright © OASIS Open 2019. All Rights Reserved. 以下文本中所有 大写 术语均具有 OASIS 知识产权政策（the OASIS IPR Policy）中指定的含义。 完整的政策可以在 OASIS 网站上找到。 本文档及其译本可以被复制并提供给其他人，本文档的原文或对本文档的部分引用、评论、解释说明等衍生品的制作、复制、出版和分发均没有限制，但上述许可的前提条件是上述的版权说明和本节内容必须包括在此类副本和衍生品内。并且，对于本文档本身的内容不得做任何修改，包括删除版权申明或对 OASIS 的引用，除非是为了 OASIS 技术委员会为了制作某些文件或者交付成果的需要（在这种情况下，必须遵守 OASIS 知识产权政策中规定的适用于版权的规则）或是将本文档翻译为英语之外的其他语言。 上述授予的有限权限是永久性的，OASIS 或其继承者或受让人不会撤销。 本文档和此处包含的信息均按原样提供，OASIS 不承担任何明示或暗示的保证，包括但不限于使用此处信息不会侵犯任何所有权的任何保证或任何暗示的保证商用能力或特定用途的适用性。 OASIS 要求任何 OASIS 方或任何其他方认为其专利主张必然会因实施本 OASIS 委员会规范或 OASIS 标准而受到侵犯时，通知 OASIS 技术委员会管理员并表明其愿意向此类人员授予专利许可。 专利权利要求的方式与制定本规范的 OASIS 技术委员会的 IPR 模式一致。 OASIS 邀请任何一方联系 OASIS 技术委员会管理员，如果它知道任何专利权利要求的所有权主张，如果专利持有者不愿意使用与制定本规范的 OASIS 技术委员会的 IPR 模式一致的方式。 OASIS 可能会在其网站上包含此类声明，但不承担任何这样做的义务。 对于可能声称与本文档中描述的技术的实施或使用有关的任何知识产权或其他权利的有效性或范围，或者此类权利下的任何许可可能或可能不可用的范围，OASIS 不持任何立场 ; 他也不代表他已做出任何努力来确定任何此类权利。 有关 OASIS 与 OASIS 技术委员会制定的任何文件或交付物的权利有关的程序的信息，请参见 OASIS 网站。 可供发布的权利主张的副本以及可供使用的许可证的任何保证，或者本 OASIS 委员会规范的实施者或用户尝试获得使用此类专有权利的一般许可证或许可的结果，或 OASIS 标准，可从 OASIS 技术委员会管理员处获取。 OASIS 不声明任何信息或知识产权列表在任何时候都是完整的，也不声明该列表中的任何权利要求实际上是基本权利要求。 名称“OASIS”是 OASIS（本规范的所有者和开发者）的商标，仅用于指代该组织及其官方输出。 OASIS 欢迎参考、实施和使用规范，同时保留强制执行其标记以防止误导性使用的权利。 请参阅 https://www.oasis-open.org/policies-guidelines/trademark 了解上述指南。 目录 1 介绍 1.0 知识产权政策 1.1 MQTT规范结构 1.2 术语表 1.3 规范性引用 1.4 非规范性引用 1.5 数据表示 1.5.1 比特位 1.5.2 2字节整数 1.5.3 4字节整数 1.5.4 UTF-8字符串 1.5.5 变长整数 1.5.6 二进制数据 1.5.7 UTF-8字符串对 1.6 安全性 1.7 编辑约定 1.8 变更历史 1.8.1 MQTT v3.1.1 1.8.2 MQTT v5.0 2 MQTT包格式 2.1 MQTT包结构 2.1.1 固定头 2.1.2 MQTT包类型 2.1.3 控制标识 2.1.4 剩余长度 2.2 可变头 2.2.1 包ID 2.2.2 属性集 2.2.2.1 属性长度 2.2.2.2 属性 2.3 载荷 2.4 原因码 3 MQTT包 3.1 CONNECT - 连接请求 3.1.1 CONNECT固定头 3.1.2 CONNECT可变头 3.1.2.1 协议名 3.1.2.2 协议版本 3.1.2.3 连接标识 3.1.2.4 全新开始 3.1.2.5 遗嘱标识 3.1.2.6 遗嘱QoS 3.1.2.7 遗嘱保留消息 3.1.2.8 用户名标识 3.1.2.9 密码标识 3.1.2.10 保活时间 3.1.2.11 CONNECT属性集 3.1.2.11.1 属性长度 3.1.2.11.2 会话过期间隔 3.1.2.11.3 接收最大值 3.1.2.11.4 最大包尺寸 3.1.2.11.5 主题别名最大值 3.1.2.11.6 请求响应信息 3.1.2.11.7 请求问题信息 3.1.2.11.8 用户属性 3.1.2.11.9 认证方式 3.1.2.11.10 认证数据 3.1.2.12 可变头非规范性示例 3.1.3 CONNECT载荷 3.1.3.1 客户端ID 3.1.3.2 遗嘱属性集 3.1.3.2.1 属性长度 3.1.3.2.2 遗嘱延迟间隔 3.1.3.2.3 载荷格式标识 3.1.3.2.4 消息过期间隔 3.1.3.2.5 内容类型 3.1.3.2.6 响应主题 3.1.3.2.7 关联数据 3.1.3.2.8 用户属性 3.1.3.3 遗嘱主题 3.1.3.4 遗嘱载荷 3.1.3.5 用户名 3.1.3.6 密码 3.1.4 CONNECT动作 3.2 CONNACK - 连接确认 3.2.1 CONNACK固定头 3.2.2 CONNACK可变头 3.2.2.1 连接回复标识 3.2.2.1.1 会话展示 3.2.2.2 连接原因码 3.2.2.3 CONNACK属性集 3.2.2.3.1 属性长度 3.2.2.3.2 会话过期间隔 3.2.2.3.3 接收最大值 3.2.2.3.4 最大QoS 3.2.2.3.5 保留消息可用 3.2.2.3.6 最大包尺寸 3.2.2.3.7 分配的客户端ID 3.2.2.3.8 主题别名最大值 3.2.2.3.9 原因字符串 3.2.2.3.10 用户属性 3.2.2.3.11 通配符订阅可用 3.2.2.3.12 订阅ID可用 3.2.2.3.13 共享订阅可用 3.2.2.3.14 服务器保活时间 3.2.2.3.15 响应信息 3.2.2.3.16 服务引用 3.2.2.3.17 认证方式 3.2.2.3.18 认证数据 3.2.3 CONNACK载荷 3.3 PUBLISH - 发布消息 3.3.1 PUBLISH 固定头 3.3.1.1 重复标识 3.3.1.2 QoS 3.3.1.3 保留消息 3.3.1.4 剩余长度 3.3.2 PUBLISH可变头 3.3.2.1 主题名称 3.3.2.2 包ID 3.3.2.3 PUBLISH属性集 3.3.2.3.1 属性长度 3.3.2.3.2 载荷格式标识 3.3.2.3.3 消息过期间隔 3.3.2.3.4 主题别名 3.3.2.3.5 响应主题 3.3.2.3.6 关联数据 3.3.2.3.7 用户属性 3.3.2.3.8 订阅ID 3.3.2.3.9 内容类型 3.3.3 PUBLISH载荷 3.3.4 PUBLISH动作 3.4 PUBACK - 发布确认 3.4.1 PUBACK固定头 3.4.2 PUBACK可变头 3.4.2.1 PUBACK原因码 3.4.2.2 PUBACK属性集 3.4.2.2.1 属性集长度 3.4.2.2.2 原因字符串 3.4.2.2.3 用户属性 3.4.3 PUBACK载荷 3.4.4 PUBACK动作 3.5 PUBREC - 发布签收（QoS 2 交付第一部分） 3.5.1 PUBREC固定头 3.5.2 PUBREC可变头 3.5.2.1 PUBREC原因码 3.5.2.2 PUBREC属性集 3.5.2.2.1 属性长度 3.5.2.2.2 原因字符串 3.5.2.2.3 用户属性 3.5.3 PUBREC载荷 3.5.4 PUBREC动作 3.6 PUBREL - 发布释放（QoS-2-交付第二部分） 3.6.1 PUBREL固定头 3.6.2 PUBREL可变头 3.6.2.1 PUBREL原因码 3.6.2.2 PUBREL属性集 3.6.2.2.1 属性长度 3.6.2.2.2 原因字符串 3.6.2.2.3 用户属性 3.6.3 PUBREL载荷 3.6.4 PUBREL动作 3.7 PUBCOMP - 发布完成（QoS-2-交付第三部分） 3.7.1 PUBCOMP固定头 3.7.2 PUBCOMP可变头 3.7.2.1 PUBCOMP原因码 3.7.2.2 PUBCOMP属性集 3.7.2.2.1 属性长度 3.7.2.2.2 原因字符串 3.7.2.2.3 用户属性 3.7.3 PUBCOMP载荷 3.7.4 PUBCOMP动作 3.8 SUBSCRIBE - 订阅请求 3.8.1 SUBSCRIBE固定头 3.8.2 SUBSCRIBE可变头 3.8.2.1 SUBSCRIBE属性集 3.8.2.1.1 属性长度 3.8.2.1.2 订阅ID 3.8.2.1.3 用户属性 3.8.3 SUBSCRIBE载荷 3.8.3.1 订阅选项 3.8.4 SUBSCRIBE动作 3.9 SUBACK - 订阅确认 3.9.1 SUBACK固定头 3.9.2 SUBACK可变头 3.9.2.1 SUBACK属性集 3.9.2.1.1 属性长度 3.9.2.1.2 原因字符串 3.9.2.1.3 用户属性 3.9.3 SUBACK载荷 3.10 UNSUBSCRIBE - 取消订阅请求 3.10.1 UNSUBSCRIBE固定头 3.10.2 UNSUBSCRIBE可变头 3.10.2.1 UNSUBSCRIBE属性集 3.10.2.1.1 属性长度 3.10.2.1.2 用户属性 3.10.3 UNSUBSCRIBE载荷 3.10.4 UNSUBSCRIBE动作 3.11 UNSUBACK - 取消订阅确认 3.11.1 UNSUBACK固定头 3.11.2 UNSUBACK可变头 3.11.2.1 UNSUBACK属性集 3.11.2.1.1 属性长度 3.11.2.1.2 原因字符串 3.11.2.1.3 用户属性 3.11.3 UNSUBACK载荷 3.12 PINGREQ - PING请求 3.12.1 PINGREQ固定头 3.12.2 PINGREQ可变头 3.12.3 PINGREQ载荷 3.12.4 PINGREQ动作 3.13 PINGRESP - PING响应 3.13.1 PINGRESP固定头 3.13.2 PINGRESP可变头 3.13.3 PINGRESP载荷 3.13.4 PINGRESP动作 3.14 DISCONNECT - 断开通知 3.14.1 DISCONNECT固定头 3.14.2 DISCONNECT可变头 3.14.2.1 断开原因码 3.14.2.2 DISCONNECT属性集 3.14.2.2.1 属性长度 3.14.2.2.2 会话过期间隔 3.14.2.2.3 原因字符串 3.14.2.2.4 用户属性 3.14.2.2.5 服务引用 3.14.3 DISCONNECT载荷 3.14.4 DISCONNECT动作 3.15 AUTH - 认证交换 3.15.1 AUTH固定头 3.15.2 AUTH可变头 3.15.2.1 认证原因码 3.15.2.2 AUTH属性集 3.15.2.2.1 属性长度 3.15.2.2.2 认证方式 3.15.2.2.3 认证数据 3.15.2.2.4 原因字符串 3.15.2.2.5 用户属性 3.15.3 AUTH载荷 3.15.4 AUTH动作 4 操作行为 4.1 会话状态 4.1.1 存储会话状态 4.1.2 会话状态非规范性示例 4.2 网络连接 4.3 QoS和协议流程 4.3.1 QoS 0：至多一次 4.3.2 Qos-1：至少一次 4.3.3 QoS 2：确保一次 4.4 消息传递重试 4.5 消息接收 4.6 消息顺序 4.7 主题名和主题过滤器 4.7.1 主题通配符 4.7.1.1 主题级别分隔符 4.7.1.2 多级通配符 4.7.1.3 单级通配符 4.7.2 $开头的主题 4.7.3 主题语义和使用 4.8 订阅 4.8.1 非共享订阅 4.8.2 共享订阅 4.9 流量控制 4.10 请求 &#x2F; 响应 4.10.1 基础请求响应（非规范性） 4.10.2 确定响应主题的值（非规范性） 4.11 服务重定向 4.12 增强认证 4.12.1 重新认证 4.13 错误处理 4.13.1 格式错误的包和协议错误 4.13.2 其他错误 5 安全性（非规范性） 5.1 介绍 5.2 MQTT解决方案：安全和认证 5.3 轻量级密码学和受限设备 5.4 实施说明 5.4.1 服务器对客户端进行身份验证 5.4.2 服务器对客户端进行授权 5.4.3 客户端对服务器进行身份验证 5.4.4 应用消息和MQTT包的完整性 5.4.5 应用消息和MQTT包的隐私 5.4.6 消息传输的不可否认性 5.4.7 检测客户端和服务器是否被入侵 5.4.8 检测异常行为 5.4.9 处理禁止的Unicode码段 5.4.9.1 关于使用禁止的Unicode码段的考虑 5.4.9.2 发布者和订阅者之间的交互 5.4.9.3 补救措施 5.4.10 其他安全注意事项 5.4.11 使用SOCKS代理 5.4.12 安全配置 5.4.12.1 透明通信配置 5.4.12.2 安全网络通信配置 5.4.12.3 安全传输配置 5.4.12.4 行业特定的安全配置 6 使用WebSocket作为传输层 6.1 IANA注意事项 7 一致性 7.1 一致性条款 7.1.1 MQTT服务器一致性条款 7.1.2 MQTT客户端一致性条款 附录 A. 致谢 附录 B. 强制性规范性声明（非规范性） 附录 C. MQTT v5.0 新特性汇总（非规范性） 1 介绍1.0 知识产权政策本规范是在 OASIS 知识产权政策的 Non-Assertion模式下提供的，该模式是技术委员会成立时选择的。关于是否有实施本规范依赖的已经披露的专利信息或是关于任何专利许可条款的信息，请参考技术委员会网站中的知识产权部分(https://www.oasis-open.org/committees/mqtt/ipr.php)。 1.1 MQTT规范结构本规范分为七个章节： 第一章 - 介绍 第二章 - MQTT包格式 第三章 - MQTT包 第四章 - 操作行为 第五章 - 安全性 第六章 - 使用Websocket作为传输层 第七章 - 一致性目标 1.2 术语表本文档中的关键字 **必须(MUST)，必须不(MUST NOT)，需要(REQUIRED)，应该(SHALL)，不应该(SHALL NOT)，理应(SHOULD)，理应不(SHOULD NOT)，推荐(RECOMMENDED)，可以(MAY)，和可选(OPTIONAL)**按照IETF RFC 2119的定义阐释，除非在此类关键字出现的地方明确被标记为非规范性。 网络连接: 由 MQTT 使用的传输协议提供的构造。 他在客户端与服务器之间提供连接。 他提供了有序、无丢失、双向传输数据流的能力。 参考 4.2 网络连接 中提供的非规范性示例。 应用消息 提供应用程序使用的通过MQTT协议携带的消息。当应用消息通过MQTT传输时，他包含载荷，服务质量，属性集合和主题名称。 客户端 一个使用了 MQTT 的程序或设备。一个客户端往往： 打开通往服务器的网络连接 发布其他客户端可能会感兴趣的应用消息 通过订阅来接收自己感兴趣的应用消息 通过取消订阅，不再接收应用消息 关闭通过服务器的网络连接 服务器 一个在发布应用消息的客户端和订阅应用消息的客户端之间充当转发中介的程序或设备。一个服务器往往： 接收来自客户端的网络连接 接收客户端发布的应用消息 处理客户端的订阅和取消订阅请求 根据客户端的订阅情况匹配转发应用消息 关闭和客户端的网络连接 会话 服务器和客户端之间的有状态交互。有些会话仅和单次网络连接持续一样长的时间，有些会话则能够跨越多次连续的网络断开和连接持续保持。 订阅 订阅包括了主题过滤器和最大QoS。订阅只关联到一个会话。一个会话可以包括多个订阅。会话中的每个订阅都拥有一个不同的主题过滤器。 共享订阅 共享订阅包括了主题过滤器和最大QoS。共享订阅可以与多个会话关联，以便使用更加宽泛的信息交换模式。匹配到共享订阅的应用消息只会发送到被关联的会话其中之一对应的客户端。一个会话可以同时持有多个共享订阅，也可以同时持有共享订阅和普通订阅。 通配订阅 通配订阅指的是主题过滤器中包括了一个或多个通配符的订阅。通配订阅允许此订阅匹配多个主题名。参考 4.7 来了解通配符如何在主题过滤器中起作用。 主题名 附加到应用消息的文字标签，用于与服务器已知的订阅相匹配。 主题过滤器 订阅中包含的一种表达式，用于指示对一个或多个主题的兴趣。主题过滤器可以包含通配符。 MQTT包 通过网络连接发送的数据包。MQTT规范定义了十五中不同类型的MQTT包，例如 发布 包用来承载应用消息。 格式错误的包 一个不能通过本规范解析的数据包。参考 4.13 查看关于错误处理的信息。 协议错误 数据包被解析后发现的不符合协议规范的数据内容或客户端与服务器状态不一致的数据。参考 4.13 查看关于错误处理的信息。 遗嘱 当网络连接非正常关闭后，由服务器发布的应用消息。参考 3.1.2.5 查看关于遗嘱的消息。 禁止的 Unicode 码段 在 UTF-8 字符串中不应出现的 Unicode 控制代码和 Unicode 非字符集。参考 1.5.4 查看更多关于禁止的 Unicode 码段的信息。 1.3 规范性引用[RFC2119] Bradner, S., “Key words for use in RFCs to Indicate Requirement Levels”, BCP 14, RFC 2119, DOI 10.17487&#x2F;RFC2119, March 1997, http://www.rfc-editor.org/info/rfc2119 [RFC3629] Yergeau, F., “UTF-8, a transformation format of ISO 10646”, STD 63, RFC 3629, DOI 10.17487&#x2F;RFC3629, November 2003, http://www.rfc-editor.org/info/rfc3629 [RFC6455] Fette, I. and A. Melnikov, “The WebSocket Protocol”, RFC 6455, DOI 10.17487&#x2F;RFC6455, December 2011, http://www.rfc-editor.org/info/rfc6455 [Unicode] The Unicode Consortium. The Unicode Standard, http://www.unicode.org/versions/latest/ 1.4 非规范性引用[RFC0793] Postel, J., “Transmission Control Protocol”, STD 7, RFC 793, DOI 10.17487&#x2F;RFC0793, September 1981, http://www.rfc-editor.org/info/rfc793 [RFC5246] Dierks, T. and E. Rescorla, “The Transport Layer Security (TLS) Protocol Version 1.2”, RFC 5246, DOI 10.17487&#x2F;RFC5246, August 2008, http://www.rfc-editor.org/info/rfc5246 [AES] Advanced Encryption Standard (AES) (FIPS PUB 197). https://csrc.nist.gov/csrc/media/publications/fips/197/final/documents/fips-197.pdf [CHACHA20] ChaCha20 and Poly1305 for IETF Protocols https://tools.ietf.org/html/rfc7539 [FIPS1402] Security Requirements for Cryptographic Modules (FIPS PUB 140-2) https://csrc.nist.gov/csrc/media/publications/fips/140/2/final/documents/fips1402.pdf [IEEE 802.1AR] IEEE Standard for Local and metropolitan area networks - Secure Device Identity http://standards.ieee.org/findstds/standard/802.1AR-2009.html [ISO29192] ISO&#x2F;IEC 29192-1:2012 Information technology – Security techniques – Lightweight cryptography – Part 1: General https://www.iso.org/standard/56425.html [MQTT NIST] MQTT supplemental publication, MQTT and the NIST Framework for Improving Critical Infrastructure Cybersecurity http://docs.oasis-open.org/mqtt/mqtt-nist-cybersecurity/v1.0/mqtt-nist-cybersecurity-v1.0.html [MQTTV311] MQTT V3.1.1 Protocol Specification http://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html [ISO20922] MQTT V3.1.1 ISO Standard (ISO&#x2F;IEC 20922:2016) https://www.iso.org/standard/69466.html [NISTCSF] Improving Critical Infrastructure Cybersecurity Executive Order 13636 https://www.nist.gov/sites/default/files/documents/itl/preliminary-cybersecurity-framework.pdf [NIST7628] NISTIR 7628 Guidelines for Smart Grid Cyber Security Catalogue https://www.nist.gov/sites/default/files/documents/smartgrid/nistir-7628_total.pdf [NSAB] NSA Suite B Cryptography http://www.nsa.gov/ia/programs/suiteb_cryptography/ [PCIDSS] PCI-DSS Payment Card Industry Data Security Standard https://www.pcisecuritystandards.org/pci_security/ [RFC1928] Leech, M., Ganis, M., Lee, Y., Kuris, R., Koblas, D., and L. Jones, “SOCKS Protocol Version 5”, RFC 1928, DOI 10.17487&#x2F;RFC1928, March 1996, http://www.rfc-editor.org/info/rfc1928 [RFC4511] Sermersheim, J., Ed., “Lightweight Directory Access Protocol (LDAP): The Protocol”, RFC 4511, DOI 10.17487&#x2F;RFC4511, June 2006, http://www.rfc-editor.org/info/rfc4511 [RFC5280] Cooper, D., Santesson, S., Farrell, S., Boeyen, S., Housley, R., and W. Polk, “Internet X.509 Public Key Infrastructure Certificate and Certificate Revocation List (CRL) Profile”, RFC 5280, DOI 10.17487&#x2F;RFC5280, May 2008, http://www.rfc-editor.org/info/rfc5280 [RFC6066] Eastlake 3rd, D., “Transport Layer Security (TLS) Extensions: Extension Definitions”, RFC 6066, DOI 10.17487&#x2F;RFC6066, January 2011, http://www.rfc-editor.org/info/rfc6066 [RFC6749] Hardt, D., Ed., “The OAuth 2.0 Authorization Framework”, RFC 6749, DOI 10.17487&#x2F;RFC6749, October 2012, http://www.rfc-editor.org/info/rfc6749 [RFC6960] Santesson, S., Myers, M., Ankney, R., Malpani, A., Galperin, S., and C. Adams, “X.509 Internet Public Key Infrastructure Online Certificate Status Protocol - OCSP”, RFC 6960, DOI 10.17487&#x2F;RFC6960, June 2013, http://www.rfc-editor.org/info/rfc6960 [SARBANES] Sarbanes-Oxley Act of 2002. http://www.gpo.gov/fdsys/pkg/PLAW-107publ204/html/PLAW-107publ204.htm [USEUPRIVSH] U.S.-EU Privacy Shield Framework https://www.privacyshield.gov [RFC3986] Berners-Lee, T., Fielding, R., and L. Masinter, “Uniform Resource Identifier (URI): Generic Syntax”, STD 66, RFC 3986, DOI 10.17487&#x2F;RFC3986, January 2005, http://www.rfc-editor.org/info/rfc3986 [RFC1035] Mockapetris, P., “Domain names - implementation and specification”, STD 13, RFC 1035, DOI 10.17487&#x2F;RFC1035, November 1987, http://www.rfc-editor.org/info/rfc1035 [RFC2782] Gulbrandsen, A., Vixie, P., and L. Esibov, “A DNS RR for specifying the location of services (DNS SRV)”, RFC 2782, DOI 10.17487&#x2F;RFC2782, February 2000, http://www.rfc-editor.org/info/rfc2782 1.5 数据表示1.5.1 比特位字节中的比特位被标记为7-0，最高位为7，最低位为0。 1.5.2 2字节整数2字节整数指16位的大端表示的无符号整数：高位字节在低位字节之前。这意味着在网络中传输的2字节整数先传输高有效字节(MSB)，后传输低有效字节(LSB)。 1.5.3 4字节整数4字节整数指32位的大端表示的无符号整数：高位字节先于连续的低位字节。这意味着在网络中传输的4字节整数先传输最高有效字节(MSB)，再传输次高有效字节(MSB)，再传输次高有效字节(MSB)，最后传输低有效字节(LSB)。 1.5.4 UTF-8字符串MQTT包中使用的文本类型字段均采用 UTF-8 编码。UTF-8 RFC3629 是一种高效的 Unicode 编码，他优化了 ACSII 的编码以用来支持基于文本的通信。 每个 UTF-8 编码的字符串都使用开头的两个字节表示字符串的长度，就像下方的 图1-1 UTF-8 字符串结构 示意的那样。因此，UTF-8 字符串的最大长度为65535字节。 除非另有说明，否则所有 UTF-8 编码字符串可以具有 0 到 65,535 字节范围内的任意长度。 图1-1 UTF-8 字符串结构 Bit 7 6 5 4 3 2 1 0 byte 1 字符串长度高字节(MSB) byte 2 字符串长度低字节(LSB) byte 3 ... 当长度 > 0 时, UTF-8 编码的字符数据 在 UTF-8 编码字符串中的字符必须为 [Unicode] 和 [RFC3629] 中所定义的，格式正确的字符编码。必须不使用U+D800 至 U+DFFF之间的编码 [MQTT-1.5.4-1]。如果客户端或服务器接收到的 MQTT 包中包括了非法 UTF-8 编码，将其视为一个格式错误的包。参考 4.13 查看关于错误处理的信息。 UTF-8 编码字符串必须不包含空字符 U+0000 [MQTT-1.5.4-2]。如果一个接收者（服务器或客户端）接收的 MQTT 包其中有空字符 U+0000 ，将其视为一个格式错误的包。参考 4.13 查看关于错误处理的信息。 数据不应该包括下方列表中的 Unicode 码段，如果一个接收者（服务器或客户端）接受的 MQTT 包其中有此类字符，接收者可以将此包视为一个格式错误的包。这些是禁止使用的 Unicode 码段。参考 5.4.9 查看关于错误处理的信息。 U+0001..U+001F 控制字符 U+007F..U+009F 控制字符 Unicode 规范中定义的非文本字符（例如 U+0FFFF） 无论 UTF-8 编码序列 0xEF 0xBB 0xBF 出现在字符串的何处，他永远被解释为 U+FEFF (0宽无换行空格) 而且必须不能被数据包的接收者跳过或剥离 [MQTT-1.5.4-3]。 非规范性示例 例如，字符串 A𪛔 的第一个字符是拉丁文大写字母A，第二个字符是码点 U+2A6D4 （代表 CJK IDEOGRAPH EXTENSION B 字符），他是这样编码的： 图1‑2 UTF-8 编码字符串非规范性示例 Bit 7 6 5 4 3 2 1 0 byte 1 字符串长度高字节(MSB)(0x00) 0 0 0 0 0 0 0 0 byte 2 字符串长度低字节(LSB)(0x05) 0 0 0 0 0 0 0 0 byte 3 ‘A’ (0x41) 0 1 0 0 0 0 0 1 byte 4 (0xF0) 1 1 1 1 0 0 0 0 byte 5 (0xAA) 1 0 1 0 1 0 1 0 byte 6 (0x9B) 1 0 0 1 1 0 1 1 byte 7 (0x94) 1 0 0 1 0 1 0 0 1.5.5 变长整数变长整数中将一个字节的最大值视为 127，更大的值采用如下方式处理。每个字节中较低的七位用来存储数字的值，最高位用来表示是否有后续的字节。因此，每个字节都编码了128个可能的值和一个 “后续位”。变长整数的最大字节数是4。变长整数编码时必须使用能够表示数字值的最小长度来进行编码 [MQTT-1.5.5-1]。表1-1 中展示了变长整数可以表示的值。 表1-1 变长整数的值 位数 最小值 最大值 1 0 (0x00) 127 (0x7F) 2 128 (0x80, 0x01) 16,383 (0xFF, 0x7F) 3 16,384 (0x80, 0x80, 0x01) 2,097,151 (0xFF, 0xFF, 0x7F) 4 2,097,152 (0x80, 0x80, 0x80, 0x01) 268,435,455 (0xFF, 0xFF, 0xFF, 0x7F) 非规范性示例 将非负整数 X 编码为变长整数的伪代码： do encodedByte = X MOD 128 X = X DIV 128 // if there are more data to encode, set the top bit of this byte if (X > 0) encodedByte = encodedByte OR 128 endif 'output' encodedByte while (X > 0) 上例中的 MOD 表示取模（C语言中的 %），DIV表示整数除法（C语言中的 &#x2F;），OR表示位运算中的或（C语言中的 |）。 非规范性示例 解码变长整数的伪代码： multiplier = 1 value = 0 do encodedByte = 'next byte from stream' value += (encodedByte AND 127) * multiplier if (multiplier > 128*128*128) throw Error(Malformed Variable Byte Integer) multiplier *= 128 while ((encodedByte AND 128) != 0) 上例中的 AND 表示位运算中的且（C语言中的 &amp;）。 当该算法完成时，value的值即是变长整数表示的值。 1.5.6 二进制数据二进制数据由2字节整数表示的字节流长度加上实际的字节流内容组成。因此，二进制数据的长度范围是 0-65535 字节。 1.5.7 UTF-8字符串对UT-8 字符串对包括两个 UTF-8 编码的字符串。这种数据类型用来存储 键-值 对。第一个字符串表示键，第二个字符串表示值。 UTF-8字符串对中的两个字符串都必须遵守 UTF-8 字符串的需求 [MQTT-1.5.7-1]。如果一个接收者（客户端或服务器）接收到的键值对没有遵守这些需求，则被视为一个格式错误的数据包。参考 4.13 查看关于错误处理的信息。 1.6 安全性MQTT 的客户端和服务器实现应该提供认证、授权和加密传输选项，这一部分在第五章讨论。强烈建议与关键基础设施、个人身份信息或其他个人或敏感信息相关的应用程序使用这些安全功能。 1.7 编辑约定本规范中以黄色突出显示的文本标识了一致性声明。每个一致性声明都被分配了一个格式为 [MQTT-x.x.x-y] 的引用，其中 x.x.x 是章节序号，y 是章节内的序号。 1.8 变更历史1.8.1 MQTT v3.1.1MQTT v3.1.1 是 OASIS 提出的第一个 MQTT 标准 [MQTTV311] 。 MQTT v3.1.1 同时也是 ISO&#x2F;IEC 20922:2016 标准 ISO20922。 1.8.2 MQTT v5.0MQTT v5.0 为 MQTT 添加了大量新功能，同时保留了大部分核心功能。主要功能目标是： 可扩展性和大型系统的增强 改进错误报告能力 将常见用法规范化，包括功能发现和请求响应 包括用户属性在内的拓展机制 性能改进，增强对小型客户端的支持 参考 附录 C 查阅 MQTT v5.0 的变更汇总。 2 MQTT包格式2.1 MQTT包结构MQTT 协议操作通过一系列的 MQTT 包交互来实现。本章用来描述这些 MQTT 包的结构。 一个 MQTT 包由三部分构成，顺序固定，参考下图： 固定头，所有的 MQTT 包都必须持有 可变头，部分 MQTT 包持有 载荷，部分 MQTT 包持有 2.1.1 固定头每个 MQTT 包都包含着一个下图所示的固定头： 图2-2 固定头格式 Bit 7 6 5 4 3 2 1 0 byte 1 MQTT包类型 针对不同包类型的控制标识 byte 2... 剩余长度 2.1.2 MQTT包类型位置：第一个Byte，比特位7-4。 表示为 4bit 的无符号整数，数值的含义如下表所示： 表2-1 MQTT包类型 Name Value Direction of flow Description 保留 0 禁止 保留 CONNECT 1 客户端到服务器 连接请求 CONNACK 2 服务器到客户端 连接回复 PUBLISH 3 双向 消息发布 PUBACK 4 双向 消息回复（QoS1） PUBREC 5 双向 消息已接收（QoS2交付第 1 部分） PUBREL 6 双向 消息释放（QoS2交付第 2 部分） PUBCOMP 7 双向 消息完成（QoS2交付第 3 部分） SUBSCRIBE 8 客户端到服务器 订阅请求 SUBACK 9 服务器到客户端 订阅回复 UNSUBSCRIBE 10 客户端到服务器 取消订阅请求 UNSUBACK 11 服务器到客户端 取消订阅回复 PINGREQ 12 客户端到服务器 PING 请求 PINGRESP 13 服务器到客户端 PING 响应 DISCONNECT 14 双向 断开连接通知 AUTH 15 双向 认证交换 2.1.3 控制标识固定头第一个 byte 中剩下的四个bit [3-0]包括了基于不同 MQTT 包类型的控制标识。当一个比特位被标记为 “保留” 时，他的意义被保留到未来使用而他的值必须按照下表设置 [MQTT-2.1.3-1]。如果接收到的控制标志不符合规范，则被认为是一个格式错误的数据包。参考 4.13 查看关于错误处理的信息。 表2‑2 控制标志 MQTT包 控制标志 Bit 3 Bit 2 Bit 1 Bit 0 CONNECT Reserved 0 0 0 0 CONNACK Reserved 0 0 0 0 PUBLISH MQTT 5.0版本使用 DUP QoS RETAIN PUBACK Reserved 0 0 0 0 PUBREC Reserved 0 0 0 0 PUBREL Reserved 0 0 1 0 PUBCOMP Reserved 0 0 0 0 SUBSCRIBE Reserved 0 0 1 0 SUBACK Reserved 0 0 0 0 UNSUBSCRIBE Reserved 0 0 1 0 UNSUBACK Reserved 0 0 0 0 PINGREQ Reserved 0 0 0 0 PINGRESP Reserved 0 0 0 0 DISCONNECT Reserved 0 0 0 0 AUTH Reserved 0 0 0 0 DUP &#x3D; 重复发送的 PUBLISH 包QoS &#x3D; PUBLISH 包的服务质量标识RETAIN &#x3D; PUBLISH 保留消息标识 参考 3.3.1 了解更多关于 DUP，QoS 和 RETAIN 标识在 PUBLISH 中的使用方式。 2.1.4 剩余长度位置：从第二个Byte开始。 剩余长度是一个变长整数，用来表示当前包剩余的字节数，包括可变头和载荷。剩余长度的值不包括剩余长度自己本身占用的字节数。一个 MQTT 包完整的字节数等于固定头的长度加上剩余长度的值。 2.2 可变头某些类型的 MQTT 包包含可变头。他位于固定头和载荷之间。可变头的内容根据数据包的类型变化。可变头中的包ID字段多种类型的数据包中都存在。 2.2.1 包ID很多类型的 MQTT 包都在其可变头中包含了 2byte 的包ID字段。这些 MQTT 包是 PUBLISH （当 QoS &gt; 0时），PUBACK，PUBREC，PUBREL，PUBCOMP，SUBSCRIBE，SUBACK，UNSUBSCRIBE，UNSUBACK。 需要包ID的 MQTT 包类型如下表所示： 表2-3 包含包ID的 MQTT 包类型 MQTT 包 包ID字段 CONNECT 否 CONNACK 否 PUBLISH 是（仅当 QoS &gt; 0 时） PUBACK 是 PUBREC 是 PUBREL 是 PUBCOMP 是 SUBSCRIBE 是 SUBACK 是 UNSUBSCRIBE 是 UNSUBACK 是 PINGREQ 否 PINGRESP 否 DISCONNECT 否 AUTH 否 当 PUBLISH 包的 QoS 值为 0 时，必须不包含 包ID 字段 [MQTT-2.2.1-2]。 每当客户端发送新的 SUBSCRIBE 包，UNSUBSCRIBE 包 或 QoS &gt; 0 的 PUBLISH 包，必须携带一个非零且当前未被使用的包ID [MQTT-2.2.1-3]。 每当服务器发送新的 QoS &gt; 0 的 PUBLISH 包，必须携带一个非零且当前未被使用的包ID [MQTT-2.2.1-4]。 包ID仅在发送者处理了对应的回复后可重新使用，定义如下。对于 QoS &#x3D; 1 的 PUBLISH，对应的回复是 PUBACK；对于 QoS &#x3D; 2 的PUBLISH，对应的回复是 PUBCOMP 或当原因码为 128 或更大时为 PUBREC。对于 SUBSCRIBE 或 UNSUBSCRIBE，对应的回复是 SUBACK 或 UNSUBACK。 在一个会话中，客户端与服务器分别使用一个单独、统一的集合用作提供 PUBLISH、SUBSCRIBE 和 UNSUBSCRIBE 的包ID。包ID在任何时候都不能被多个命令使用。 PUBACK，PUBREC，PUBREL 或 PUBCOMP 包必须携带和 PUBLISH 相同的包ID [MQTT-2.2.1-5]。SUBACK 和 UNSUBACK 必须携带和其对应的 SUBSCRIBE 和 UNSUBSCRIBE 包相同的包ID [MQTT-2.2.1-6]。 客户端与服务器各自独立的维护包ID分配。因此，客户端与服务器可以同时使用同样的包ID发送信息。 非规范性示例 客户端发送一个包ID为 0x1234 的 PUBLISH 包，之后在其接收到对应的 PUBACK 之前，从服务器接收到一个 包ID 为 0x1234 的 PUBLISH 包。这样的情况是合理而且完全有可能的。 Client Server PUBLISH 包ID=0x1234 ‒→ ←‒ PUBLISH 包ID=0x1234 PUBACK 包ID=0x1234 ‒→ ←‒ PUBACK 包ID=0x1234 2.2.2 属性集在 CONNECT，CONNACK，PUBLISH，PUBACK，PUBREC，PUBREL，PUBCOMP，SUBSCRIBE，SUBACK，UNSUBSCRIBE，UNSUBACK，DISCONNECT 和 AUTH 包的可变头中的最后一个字段是属性集。在 CONNECT 的载荷中也存在着一组可选的遗嘱属性集。 属性集由属性长度和属性组成。 2.2.2.1 属性长度属性长度是一个变长整数。属性长度的值不包括自己所占用的字节数，但包括了后续所有属性占用的字节数。如果没有属性，必须通过一个 0 值的属性长度来明确表示 [MQTT-2.2.2-1]。 2.2.2.2 属性属性由一个标识了其用途和数据类型的ID和一个后续的值组成。属性ID是一个变长整数。当一个数据包使用的属性ID和其包类型不一致，或属性的值和ID指明的类型不一致时，视为一个格式错误的包。如果收到，需使用带有原因码为 0x81 的 CONNACK 或 DISCONNECT 数据包，采用 4.13 描述的方法处理此错误。不同ID的属性没有顺序要求。 表2-4 属性 ID 名称（用途） 数据类型 包类型 / 遗嘱属性 十进制十六进制 10x01载荷格式标识单字节PUBLISH，Will Properties 20x02消息过期间隔4字节整数PUBLISH，Will Properties 30x03内容类型UTF-8字符串PUBLISH，Will Properties 80x08响应主题UTF-8字符串PUBLISH，Will Properties 90x09关联数据二进制数据PUBLISH，Will Properties 110x0B订阅ID变长整数PUBLISH，SUBSCRIBE 170x11会话过期间隔4字节整数CONNECT，CONNACK，DISCONNECT 180x12分配的客户端IDUTF-8字符串CONNACK 190x13服务器保活时间2字节整数CONNACK 210x15认证方式UTF-8字符串CONNECT，CONNACK，AUTH 220x16认证数据二进制数据CONNECT，CONNACK，AUTH 230x17请求问题信息单字节CONNECT 240x18遗嘱延迟间隔4字节整数Will Properties 250x19请求响应信息单字节CONNECT 260x1A响应信息UTF-8字符串CONNACK 280x1C服务引用UTF-8字符串CONNACK，DISCONNECT 310x1F原因字符串UTF-8字符串CONNACK，PUBACK，PUBREC，PUBREL，PUBCOMP，SUBACK，UNSUBACK，DISCONNECT，AUTH 330x21接收最大值2字节整数CONNECT，CONNACK 340x22主题别名最大值2字节整数CONNECT，CONNACK 350x23主题别名2字节整数PUBLISH 360x24QoS最大值单字节CONNACK 370x25保留消息可用单字节CONNACK 380x26用户属性UTF-8字符串对CONNECT，CONNACK，PUBLISH，Will Properties，PUBACK，PUBREC，PUBREL，PUBCOMP，SUBSCRIBE，SUBACK，UNSUBSCRIBE，UNSUBACK，DISCONNECT，AUTH 390x27最大包尺寸4字节整数CONNECT，CONNACK 400x28通配符订阅可用单字节CONNACK 410x29订阅ID可用单字节CONNACK 420x2A共享订阅可用单字节CONNACK 非规范性评论 虽然属性ID被定义为一个变长整数，但在规范的此版本中所有的属性ID都只有一个字节的长度。 2.3 载荷有些 MQTT 包的尾部是载荷。在 PUBLISH 包中的载荷就是应用消息。 表2-5 包含载荷的 MQTT 包 MQTT 包 载荷 CONNECT 有 CONNACK 无 PUBLISH 可选 PUBACK 无 PUBREC 无 PUBREL 无 PUBCOMP 无 SUBSCRIBE 有 SUBACK 有 UNSUBSCRIBE 有 UNSUBACK 有 PINGREQ 无 PINGRESP 无 DISCONNECT 无 AUTH 无 2.4 原因码原因码是一个单字节的无符号整数值，用来表示一个操作的结果。小于 0x80 的原因码用来表示操作成功，最常见的表示成功的原因码是 0x00。0x80或更大的原因码表示失败。 在 CONNACK，PUBACK，PUBREC，PUBREL，PUBCOMP，DISCONNECT 和 AUTH 包的可变头中有一个原因码字段。在 SUBACK 和 UNSUBACK 的载荷中包一个列表，其中有一个或多个原因码字段。 原因码字段值的通用定义如下： 表2-6 原因码 原因码 名称 包类型 十进制十六进制 00x00成功CONNACK，PUBACK，PUBREC，PUBREL，PUBCOMP，UNSUBACK，AUTH 00x00普通断开DISCONNECT 00x00授予 QoS 0SUBACK 10x01授予 QoS 1SUBACK 20x02授予 QoS 2SUBACK 40x04携带遗嘱的断开链接DISCONNECT 160x16没有匹配的订阅者PUBACK，PUBREC 170x11没有存在的订阅UNSUBACK 240x18继续认证AUTH 250x19重新认证AUTH 1280x80未指定错误CONNACK，PUBACK，PUBREC，SUBACK，UNSUBACK，DISCONNECT 1290x81格式错误的包CONNACK，DISCONNECT 1300x82协议错误CONNACK，DISCONNECT 1310x83特定实现错误CONNACK，PUBACK，PUBREC，SUBACK，UNSUBACK，DISCONNECT 1320x84协议版本不支持CONNACK 1330x85客户端ID不可用CONNACK 1340x86用户名或密码错误CONNACK 1350x87未经授权CONNACK，PUBACK，PUBREC，SUBACK，UNSUBACK，DISCONNECT 1360x88服务器不可用CONNACK 1370x89服务器忙CONNACK 1380x8A被禁止CONNACK 1390x8B服务器关闭DISCONNECT 1400x8C认证方式错误CONNACK，DISCONNECT 1410x8D保活超时DISCONNECT 1420x8E会话被接管DISCONNECT 1430x8F主题过滤器不可用SUBACK，UNSUBACK，DISCONNECT 1440x90主题名不可用CONNACK，PUBACK，PUBREC，DISCONNECT 1450x91包ID已被使用PUBACK，PUBREC，SUBACK，UNSUBACK 1460x92包ID未找到PUBREL，PUBCOMP 1470x93超出接收最大值DISCONNECT 1480x94主题别名不可用DISCONNECT 1490x95包过大CONNACK，DISCONNECT 1500x96消息频率过高DISCONNECT 1510x97超限CONNACK，PUBACK，PUBREC，SUBACK，DISCONNECT 1520x98管理员行为DISCONNECT 1530x99载荷格式错误CONNACK，PUBACK，PUBREC，DISCONNECT 1540x9A不支持保留消息CONNACK，DISCONNECT 1550x9B不支持的 QoSCONNACK，DISCONNECT 1560x9C使用另一台服务器CONNACK，DISCONNECT 1570x9D服务器迁移CONNACK，DISCONNECT 1580x9E不支持共享订阅SUBACK，DISCONNECT 1590x9F连接频率超限CONNACK，DISCONNECT 1600xA0最大连接时间DISCONNECT 1610xA1不支持订阅IDSUBACK，DISCONNECT 1620xA2不支持通配符订阅SUBACK，DISCONNECT 非规范性评论 对于 0x91（包ID已被使用）的原因码，对此的处理应是处理重复状态，或是使用 Clean Start 为 1 的标识重新创建连接来重置会话，或是检查客户端或服务器的实现是否有缺陷。 3 MQTT包3.1 CONNECT - 连接请求当客户端和服务器的网络连接建立后，客户端向服务器发送的第一个数据包必须是 CONNECT 包 [MQTT-3.1.0-1]。 一个客户端在一次网络连接中只能发送一个 CONNECT 包。服务器必须将客户端发送的第二个 CONNECT 包视为协议错误并关闭网络连接 [MQTT-3.1.0-2]。参考 4.13 查看关于错误处理的信息。 CONNECT 的载荷包含一个或更多的字段，包括唯一的客户端ID，遗嘱主题，遗嘱载荷，用户名和密码。除了客户端ID以外的字段都可以省略，他们的存在与否根据可变头中的标识确定。 3.1.1 CONNECT固定头图3‑1 CONNECT 包固定头 Bit76543210 byte 1MQTT包类型（1）保留 00010000 byte 2...剩余长度 剩余长度 表示可变头长度和载荷长度的总和，使用变长整数表示。 3.1.2 CONNECT可变头CONNECT 包中的可变头按固定顺序提供下列字段：协议名、协议版本、连接标识、保活时间和属性集。属性集的编码方式请参考 2.2.2。 3.1.2.1 协议名图3-2 协议名字节 描述76543210 协议名 byte 1长度高位（MSB）00000000 byte 2长度低位（LSB）00000100 byte 3'M'01001101 byte 4'Q'01010001 byte 5'T'01010100 byte 6'T'01010100 协议名是 UTF-8字符串表示的大写 “MQTT”，就像上图所示。这个字符串、他的位置和他的长度在未来的 MQTT 规范版本中永远不会改变。 支持多种协议的服务器可以通过协议名称来判断收到的数据是否是 MQTT 数据。协议名称必须是 UTF-8字符串表示的 “MQTT”。如果服务器不想接收此连接，同时又想告知客户端服务器是一个 MQTT 服务器，可以发送一个带有 0x84（协议版本不支持）原因码的 CONNACK，随后服务器必须关闭网络连接 [MQTT-3.1.2-1]。 非规范性评论 数据包检查器（例如防火墙）可以使用协议名称来识别 MQTT 流量。 3.1.2.2 协议版本图3‑3 协议版本字节 描述76543210 协议版本 byte 7版本（5）00000101 此处的单字节无符号值表示了客户端使用的协议的版本。MQTT 5.0 版本的协议版本的值应为 5（0x05）。 支持多个协议版本的服务器可以通过协议版本字段来判断客户端使用何种版本的 MQTT 协议。如果客户端使用的协议版本不为 5 而且服务器不想接受此 CONNECT 包，服务器可以发送一个带有 0x84（协议版本不支持）原因码的 CONNACK，随后服务器必须关闭网络连接 [MQTT-3.1.2-2]。 3.1.2.3 连接标识连接标志字节包含了几个指定 MQTT 连接行为的参数。他还用来指示载荷中的某些字段是否存在。 图3‑4 连接标识位 Bit76543210 用户名标识密码标识遗嘱保留消息遗嘱QoS遗嘱标识全新开始保留 byte 8XXXXXXX0 服务器必须验证 CONNECT 包中的保留位的值是 0 [MQTT-3.1.2-3]。如果保留位的值非 0，则视为一个格式错误的包，参考 4.13 查看关于错误处理的信息。 3.1.2.4 全新开始位置：连接标识字节中的比特位 1。 这个比特位指定了此连接是一个全新的会话还是一个已经存在会话的延续。参考 4.1 了解关于会话状态的定义。 如果接收到全新开始值置为 1 的 CONNECT 包，客户端和服务器必须丢弃任何已经存在的会话并开始一个新的会话 [MQTT-3.1.2-4]。因此，当 CONNECT 包中的全新开始值置为 1 时，对应的 CONNACK 包中的会话存在总是会被至为0。 如果服务器接收到的 CONNECT 包中的全新开始被置为 0 并且服务器中已经存在和客户端ID关联的会话，服务器必须基于已经存在的会话状态恢复客户端的连接 [MQTT-3.1.2-5]。如果服务器接收到的 CONNECT 包中的全新开始被置为 0 并且服务器中没有和客户端ID关联的会话，服务器必须创建一个新的会话 [MQTT-3.1.2-6]。 3.1.2.5 遗嘱标识位置：连接标识字节中的比特位 2。 如果遗嘱标识被置为 1，则表示遗嘱消息必须被存储在服务器中，并且关联到此会话 [MQTT-3.1.2-7]。遗嘱消息由 CONNECT 载荷中的遗嘱属性集、遗嘱主题和遗嘱载荷组成。遗嘱消息必须在网络连接断开后的遗嘱延迟间隔时间过期后或会话结束时发布，除非由于服务器接收到一个带有 0x00（普通断开）原因码的 DISCONNECT 包从而删除了遗嘱消息，或是在遗嘱延迟间隔时间过期前接收了一个带有相同客户端ID的连接 [MQTT-3.1.2-8]。 遗嘱消息被发布的场景包括不限于： 服务器检测到了 I&#x2F;O 错误或网络故障 客户端没有成功在保活时间内通信 客户端在没有发送原因码为 0x00（普通断开）的 DISCONNECT 包的前提下断开网络连接 服务器在没有收到原因码为 0x00（普通断开）的 DISCONNECT 包的前提下断开网络连接 当遗嘱标识被置为 1 时，载荷中必须包括遗嘱属性集、遗嘱主题和遗嘱载荷字段 [MQTT-3.1.2-9]。当服务器发布遗嘱后或服务器从客户端收到了原因码为 0x00（普通断开）的 DISCONNECT 包后，服务器必须从会话状态中删除遗嘱消息 [MQTT-3.1.2-10]。 服务器应该在下列两种情况中的某一种先发生时发布遗嘱消息：网络连接断开后经过了遗嘱延迟间隔时间、会话结束。如果发生了服务器关闭或故障，服务器也许可以在随后的重启之后发布遗嘱消息。当此种情况发生时，服务器故障发生的时间和遗嘱消息发布的时间之间可能会有延迟。 参考 3.1.3.2 了解关于遗嘱延迟间隔的消息。 非规范性评论 客户端可以设置遗嘱延迟间隔大于会话过期间隔，再发送带有原因码 0x04（携带遗嘱的断开链接）的 DISCONNECT 断开连接。这样可以使用遗嘱消息来通知会话已过期。 3.1.2.6 遗嘱QoS位置：连接标识字节中的比特位 4 和 3。 这两个比特位指定了发布遗嘱消息时使用的 QoS 等级。 当遗嘱标识被置为 0 时，遗嘱 QoS 必须被置为 0（0x00） [MQTT-3.1.2-11]。 当遗嘱标识被置为 1 时，遗嘱QoS的值可以是 0（0x00），1（0x01）或 2（0x02） [MQTT-3.1.2-12]。当值为 3（0x03）时视为格式错误的包，参考 4.13 查看关于错误处理的信息。 3.1.2.7 遗嘱保留消息位置：连接标识字节中的比特位 5。 这个比特位指定了当遗嘱消息发布时是否会被保留。 当遗嘱标识被置为 0 时，遗嘱保留消息的值必须被置为 0 [MQTT-3.1.2-13]。当遗嘱标识被置为 1 且遗嘱保留消息被置为 0 时，服务器必须将遗嘱消息作为一个非保留消息发布 [MQTT-3.1.2-14]。当遗嘱标识被置为 1 且遗嘱保留消息被置为 1 时，服务器必须将遗嘱消息作为一个保留消息发布 [MQTT-3.1.2-15]。 3.1.2.8 用户名标识位置：连接标识字节中的比特位 7。 当用户名标识被置为 0 时，载荷中必须不存在用户名 [MQTT-3.1.2-16]。当用户名标识被置为 1 时，载荷中必须存在用户名 [MQTT-3.1.2-17]。 3.1.2.9 密码标识位置：连接标识字节中的比特位 6。 当密码标识被置为 0 时，载荷中必须不存在密码 [MQTT-3.1.2-18]。当密码标识被置为 1 时，载荷中必须存在密码 [MQTT-3.1.2-19]。 非规范性评论 本版协议允许在不使用用户名时使用密码，和 MQTT v3.1.1 不同。这反映了密码作为密码以外的凭证的常见用途。 3.1.2.10 保活时间图3-5 保活时间字节 Bit76543210 byte 9保活时间高位（MSB） byte 10保活时间地位（LSB） 保活时间是一个表示时间间隔秒数的 2字节整数。他是允许客户端在发送一个 MQTT 包后到发送下一个数据包之间的最大时间间隔。客户端有责任确保两个 MQTT 包之间的时间间隔不超过保活时间。如果保活时间不为 0 且没有任何其他需要发送的数据包，客户端必须发送 PINGREQ 包 [MQTT-3.1.2-20]。 如果服务器在 CONNACK 中提供了服务器保活时间，则客户端必须采用服务器保活时间的值来替代自己发送的保活时间的值 [MQTT-3.1.2-21]。 不论保活时间的值如何设置，客户端可以在任何时间发送 PINGREQ，并通过检查相应的 PINGRESP 来确认服务器与网络是否可用。 如果保活时间为非零值且服务器在 1.5 倍的保活时间内没有收到来自客户端的任何 MQTT 包，服务器必须断开到客户端的网络连接并视为网络连接故障 [MQTT-3.1.2-22]。 如果客户端在发送 PINGREQ 的合理时间后依然没有收到 PINGRESP，客户端应断开到服务器的网络连接。 保活时间的值为 0 表示关闭保活机制。当保活时间为 0 时客户端没有义务按任何特定时间发送 MQTT 包。 非规范性评论 服务器可能会因为其他原因关闭向客户端的连接，例如服务器关机。设置保活时间并非意味着客户端可以持续保持连接。 非规范性评论 保活时间的具体值是由应用程序设置的，通常来说，是几分钟。保活时间的最大值 65535 表示 18小时12分钟15秒。 3.1.2.11 CONNECT属性集3.1.2.11.1 属性长度CONNECT 包可变头中的属性集长度，使用变长整数编码。 3.1.2.11.2 会话过期间隔会话过期间隔的属性ID是17 (0x11) Byte。 随后跟随 4字节整数 用来表示会话过期间隔，单位为秒。在属性集中出现超过一次会话过期间隔视为协议错误。 当没有设置会话过期间隔是使用 0 作为默认值。如果会话过期间隔的值为 0 或者没有设置，当网络连接断开时会话立即结束。 如果会话过期间隔被设置为 0xFFFFFFFF (UINT_MAX)，表示会话不会过期。 当会话过期间隔的值大于 0 时，客户端和服务器都必须在网络连接断开后存储会话状态 [MQTT-3.1.2-23]。 非规范性评论 客户端或服务器的时钟可能在某些时间内没有运行，例如当客户端或服务器被关闭时。这可能会导致状态被延迟删除。 参考 4.1 了解更多关于会话的信息。参考 4.1.1 了解更多关于会话状态存储的细节和限制。 当会话过期时，客户端与服务器不需要自动删除会话状态。 非规范性评论 将全新开始标识设置为 1 并将会话过期间隔设置为 0，等同于在 MQTT v3.1.1 规范中将 CleanSession 设置为 1。将全新开始标识设置为 0 且不设置会话过期间隔，等同于在 MQTT v3.1.1 规范中将 CleanSession 设置为 0。 非规范性评论 一个只想处理其在线时消息的客户端可以将全新开始标识设置为 1 同时将会话过期间隔设置为 0。这样他将不会收到任何在他离线时产生的消息，并且他必须在每次连接后重新订阅所有他需要的主题。 非规范性评论 当客户端使用一个间歇性可用的网络连接服务器时，客户端可以设置一个较短的会话过期间隔这样每当网络连接可用时他都会重连并继续进行可靠的消息传递。而当客户端没有重连时，允许会话超时，这样应用消息就会丢失。 非规范性评论 当一个客户端使用较长的会话过期间隔连接服务器时，这意味着他希望服务器能够在他断开连接后的较长时间里维护会话状态。客户端只有在明确的意识到自己会在某个时间点重连时才使用这种较长的会话过期间隔。当一个客户端决定未来不再使用此会话，他应该在断开时将会话过期间隔设置为0。 非规范性评论 客户端总是应该基于 CONNACK 中的会话存在标识来判断服务器是否保存有该客户端的会话状态。 非规范性评论 客户端可以依赖服务器返回的会话存在标识来判断会话是否过期，而不必自己实现会话过期机制。如果客户端自己实现了会话过期机制，那么则必须在自己的会话状态中记录何时该会话状态需要被删除。 3.1.2.11.3 接收最大值接收最大值的属性ID是33 (0x21) Byte。 随后跟随 2字节整数 用来表示有状态数据接收的最大值。接收最大值在属性集中出现超过一次，或接收最大值的值为0，均为协议错误。 客户端使用此值限制他同时处理的 QoS1 和 QoS2 包发布动作数量。没有任何机制限制服务器可能尝试的对 QoS0 包的发布。 接收最大值的值仅对当前网络连接有效。如果没有设置接收最大值那么他的默认值是 65535。 参考 4.9 流量控制 了解关于接收最大值的使用细节。 3.1.2.11.4 最大包尺寸最大包尺寸的属性ID是33 (0x21) Byte。 随后跟随 4字节整数 用来表示客户端可以接受的最大包尺寸。如果没有设置最大包尺寸，则其受限于固定头中的剩余长度限制，除此外并没有其他限制。 在属性集中出现超过一次最大包尺寸或其值为 0 均视为协议错误。 非规范性评论 当包的尺寸需要被限制时，应用程序有责任选择一个合适的最大包尺寸的值。 最大包尺寸表示 MQTT 包完整的字节数，其定义参考 2.1.4。客户端使用最大包尺寸告知服务器，客户端不会处理超过此尺寸限制的信息。 服务器必须不向客户端发送超过最大包尺寸的数据包 [MQTT-3.1.2-24]。如果客户端收到了超过其最大包尺寸限制的包，这被视为一个协议错误，客户端需要使用带有原因码 0x95（包过大）的 DISCONNECT 包来中断连接，参考 4.13 的描述。 当一个包因超过最大包尺寸而无法发送，服务器必须将其丢弃，并视为发送成功 [MQTT-3.1.2-25]。 当某个包的尺寸大于共享订阅中的部分客户端的最大包尺寸，而又可以被另外的某些客户端接收时，服务器可以决定丢弃此包或者将其发送到可以接收此包的客户端。 非规范性评论 当一个包未被发送即被丢弃时，服务器可以将其放入“丢包队列”或者提供其他的诊断机制。此类行为实现不属于本规范的范畴。 3.1.2.11.5 主题别名最大值主题别名最大值的属性ID是34 (0x22) Byte。 随后跟随 2字节整数 表示主题别名的最大值。在属性集中出现超过一次主题别名最大值视为协议错误。如果主题别名最大值没有设置，则采用默认值 0。 主题别名最大值表示了客户端可以接受的来自服务器发送的主题别名的最大数量。客户端使用此值来约束他在本次连接中可以持有的主题别名数量。服务器必须不发送一个主题别名的值大于客户端设置的主题别名最大值的 PUBLISH 包 [MQTT-3.1.2-26]。主题别名最大值的值为 0 表示客户端在本次连接中不支持任何主题别名。如果主题别名最大值未设置或值为 0，服务器必须不向客户端发送主题别名 [MQTT-3.1.2-27]。 3.1.2.11.6 请求响应信息请求响应信息的属性ID是25 (0x19) Byte。 随后跟随一个值为 0 或 1 的字节。在属性集中出现超过一次请求响应信息，或其值不为 1 或 0，均视为协议错误。如果请求响应信息没有设置，则采用默认值 0。 客户端通过此值请求服务器，希望服务器在 CONNACK 中回复响应信息。此值为 0 表示服务器必须不在 CONNACK 中回复响应信息 [MQTT-3.1.2-28]。此值为 1 表示服务器可以在 CONNACK 中回复响应信息。 非规范性评论 即使客户端请求了，服务器也可以不在 CONNACK 中回复响应信息。 参考 4.10 了解关于 请求&#x2F;响应 的更多信息。 3.1.2.11.7 请求问题信息请求问题信息的属性ID是23 (0x17) Byte。 随后跟随一个值为 0 或 1 的字节。在属性集中出现超过一次请求问题信息，或其值不为 1 或 0，均视为协议错误。如果请求问题信息没有设置，则采用默认值 0。 客户端通过此值表示服务器是是否应该在故障时发送原因字符串或用户属性。 如果请求问题信息的值为 0，服务器可以在 CONNACK 或 DISCONNECT 包中携带原因字符串或用户属性，但必须不在除 PUBLISH，CONNACK，DISCONNECT 之外的包中携带原因字符串或用户属性 [MQTT-3.1.2-29]。如果请求问题信息的值为 0 且客户端接收到除 PUBLISH，CONNACK，DISCONNECT 之外的包中带有了原因字符串或用户属性，客户端使用带有原因码 0x82（协议错误）的 DISCONNECT 包断开连接，参考 4.13 了解更多信息。 如果请求问题信息的值为 1，服务器可以在任何允许的包中返回原因字符串或用户属性。 3.1.2.11.8 用户属性用户属性的属性ID是38 (0x26) Byte。 随后跟随 UTF-8字符串对。 用户属性可以出现多次，用来携带多个 键-值 对。同样的 键 允许出现超过一次。 非规范性评论 CONNECT 包中的用户属性可以用来从客户端向服务器发送连接过程中依赖的属性。这些属性的含义超出了本规范的范围。 3.1.2.11.9 认证方式认证方式的属性ID是21 (0x15) Byte。 随后跟随 UTF-8字符串，其中包括了使用的增强认证方式的名称。认证方式在属性集中出现超过一次视为协议错误。 如果没有设置认证方式，将不会执行增强认证。参考 4.12。 如果客户端再 CONNECK 包中设置了认证方式，那么在其收到 CONNACK 包之前，客户端必须不发送除了 AUTH 和 DISCONNECT 包之外的任何类型的包 [MQTT-3.1.2-30]。 3.1.2.11.10 认证数据认证数据的属性ID是22 (0x16) Byte。 随后跟随 二进制数据 其中包括认证数据。当认证方式不存在是提供认证数据，或是在任何情况下提供超过一次的认证数据，均视为协议错误。 认证数据的内容由认证方式决定。参考 4.12 了解更多关于增强认证的信息。 3.1.2.12 可变头非规范性示例图3-6 可变头示例 描述76543210 协议名称 byte 1长度高字节（MSB）（0） 00000000 byte 2长度低字节（LSB）（4） 00000100 byte 3‘M’ 01001101 byte 4‘Q’ 01010001 byte 5‘T’ 01010100 byte 6‘T’ 01010100 协议版本 byte 7版本（5） 00000101 连接标识 byte 8 用户名标识（1） 密码标识（1） 遗嘱保留消息（0） 遗嘱QoS（01） 遗嘱标识（1） 全新开始（1） 保留（0） 11001110 保活时间 byte 9保活时间高位（MSB）（0） 00000000 byte 10保活时间低位（LSB）（10） 00001010 属性集 byte 11长度（5） 00000101 byte 12属性ID：会话过期间隔（17） 00010001 byte 13会话过期间隔（10） 00000000 byte 14 00000000 byte 15 00000000 byte 16 00001010 3.1.3 CONNECT载荷CONNECT 中的载荷包含了一个或多个 长度 + 内容 格式的字段，这些字段的存在与否由可变头中的标志位决定。这些字段的顺序是固定的，如果存在的话，必须按照 客户端ID，遗嘱属性集，遗嘱主题，遗嘱载荷，用户名，密码 这样的顺序出现 [MQTT-3.1.3-1]。 3.1.3.1 客户端ID客户端ID用来在服务器端区分不同的客户端。每个连向服务器的客户端都拥有一个唯一的客户端ID。客户端ID必须被客户端和服务器用于关联客户端和服务器之间的会话状态 [MQTT-3.1.3-2]。参考 4.1 了解更多关于会话状态的信息。 客户端ID必须作为 CONNECT 包载荷中的第一个字段出现 [MQTT-3.1.3-3]。 客户端ID必须被编码为一个 UTF-8字符串，该数据类型的定义在 1.5.4 [MQTT-3.1.3-4]。 服务器必须允许客户端ID是长度为 1 到 23 个字节之间的 UTF-8字符串，且仅包含下列字符：“0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ” [MQTT-3.1.3-5]。 服务器可以允许客户端ID的长度超过23字节。服务器可以允许客户端ID的内容包含上述以外的内容。 服务器可以允许客户端传递长度为 0 的客户端ID，当此情况发生时，服务器必须将此情况作为一个特殊情况对待，并为客户端分配一个唯一的客户端ID [MQTT-3.1.3-6]。服务器之后必须正常处理此 CONNECT 包，就如同客户端本身携带了这个唯一的客户端ID一样，而且必须在 CONNACK 包中返回这个分配的客户端ID [MQTT-3.1.3-7]。 如果服务器拒绝了客户端ID，服务器可以使用一个带有原因码 0x85（客户端ID不可用）的 CONNACK 包作为对客户端 CONNECT 包的响应，如同 4.13 中描述的那样，之后服务器必须关闭网络连接 [MQTT-3.1.3-8]。 非规范性评论 客户端实现可以提供一个方便的生成随机客户端ID的方法。使用这种方法的客户端应该注意避免创建长期存在的孤立会话。 3.1.3.2 遗嘱属性集如果遗嘱标识被置为 1，载荷中的下一个字段会是遗嘱属性集。遗嘱属性集决定了当遗嘱消息被发布时所使用的应用消息属性集，还决定了何时发布遗嘱消息。遗嘱属性集包含了属性长度和属性集内容。 3.1.3.2.1 属性长度遗嘱属性集中的属性集长度是一个变长整数。 3.1.3.2.2 遗嘱延迟间隔遗嘱延迟间隔的属性ID是24 (0x18) Byte。 随后跟随 4字节整数，表示遗嘱延迟间隔时间，单位为秒。遗嘱延迟间隔在属性集中出现超过一次视为协议错误。如果遗嘱延迟间隔未设置，默认值为0，表示遗嘱发布前没有间隔时间。 服务器在遗嘱延迟间隔结束或是会话结束时发布遗嘱，这两种条件以先触发的为准。如果在遗嘱延迟间隔结束前，该会话被新的网络连接延续，服务器必须不发送遗嘱 [MQTT-3.1.3-9]。 非规范性评论 遗嘱延迟间隔的一个作用是，当使用周期性可用的网络进行通信时，客户端使用遗嘱延迟间隔可以在遗嘱发布前重新连接并使用会话，而非每次连接断开后都发布遗嘱。 非规范性评论 当客户端和服务器的网络连接存在时，如果客户端再次使用相同的客户端ID连接到服务器，现有网络连接的遗嘱消息会被发布，除非新连接将 全新开始 标识置为 0 且遗嘱延迟间隔的值大于 0。如果遗嘱延迟间隔的值为 0，遗嘱消息会因为原有网络连接的关闭而发布，如果 全新开始 标识为 1 ，遗嘱消息会因为原有会话的结束而发布。 3.1.3.2.3 载荷格式标识载荷格式标识的属性ID是1 (0x01) Byte。 随后的值表示遗嘱载荷的格式： 0（0x00）Byte 表示遗嘱消息是未指定的字节流，这等同于没有发送载荷格式标识。 1（0x01）Byte 表示遗嘱消息是 UTF-8字符串。载荷中的 UTF-8 数据必须符合 Unicode 和 RFC3629 规范。 载荷格式标识在属性集中出现超过一次视为协议错误。服务器可以验证遗嘱消息是否符合载荷格式标识指定的格式，如果不符合则发送一个带有原因码 0x99（载荷格式错误）的 CONNACK 报文，详情参考 4.13。 3.1.3.2.4 消息过期间隔消息过期间隔的属性ID是2 (0x02) Byte。 随后跟随 4字节整数 用来表示消息过期间隔。消息过期间隔在属性集中出现超过一次视为协议错误。 当消息过期间隔存在时，此四字节的整数表示遗嘱消息的存活时间（单位秒），同时也是服务器发送此遗嘱消息时使用的发布过期时间。 如果没有设置此值，服务器发布遗嘱消息时不设置消息过期时间。 3.1.3.2.5 内容类型内容类型的属性ID是3 (0x03) Byte。 随后跟随 UTF-8字符串，表示遗嘱消息的内容类型。内容类型在属性集中出现超过一次视为协议错误。内容类型的值由发送方和接收方的应用程序定义。 3.1.3.2.6 响应主题响应主题的属性ID是8 (0x08) Byte。 随后跟随 UTF-8字符串，作为响应消息的主题名称。响应主题在属性集中出现超过一次视为协议错误。响应主题的存在表示将遗嘱消息视为一个请求。 参考 4.10 了解关于 请求&#x2F;响应 的更多信息。 3.1.3.2.7 关联数据关联数据的属性ID是9 (0x09) Byte。 随后跟随 二进制数据。请求消息的发送者使用关联数据来识别接收到的响应消息针对哪个请求。关联数据在属性集中出现超过一次视为协议错误。如果关联数据未设置，请求方无需携带任何关联数据。 关联数据的值仅对请求消息的发送者和响应消息的接收者有意义。 参考 4.10 了解关于 请求&#x2F;响应 的更多信息。 3.1.3.2.8 用户属性用户属性的属性ID是38 (0x26) Byte。 随后跟随 UTF-8字符串对。用户属性允许出现多次来表示多个键值对。同样的键允许出现多次。 服务器必须在发布遗嘱消息时维持用户属性的顺序 [MQTT-3.1.3-10]。 非规范性评论 这个属性只是提供一种传输键值对的方式，键值对的含义和解释只有负责发送和接收该属性的应用程序了解。 3.1.3.3 遗嘱主题如果遗嘱标识被置为 1，载荷中的下一个字段会是遗嘱主题。遗嘱主题必须是一个 UTF-8字符串，参考 1.5.4 中的定义[MQTT-3.1.3-11]。 3.1.3.4 遗嘱载荷如果遗嘱标识被置为 1，载荷中的下一个字段会是遗嘱载荷。如同 3.1.2.5 的定义，遗嘱载荷是会被发布遗嘱主题中的应用消息。遗嘱载荷字段内含有二进制数据。 3.1.3.5 用户名如果用户名标识被置为 1，载荷中的下一个字段会是用户名。用户名必须是一个 UTF-8字符串，参考 1.5.4 中的定义[MQTT-3.1.3-12]。用户名可以被服务器用作认证和授权。 3.1.3.6 密码如果密码标识被置为 1，载荷中的下一个字段会是密码。密码字段内容是 二进制数据。虽然此字段被称为密码，但此字段实际上可以携带任何形式的凭据信息。 3.1.4 CONNECT动作请注意，服务器可以在同一 TCP 端口或其他网络端点上支持多个协议（包括其他版本的 MQTT 协议）。如果服务器确定协议是 MQTT v5.0，则它会按如下方式验证连接尝试。 如果服务器在客户端的网络连接建立后的一段合理时间内没有收到 CONNECT 包，服务器应该关闭网络连接。 服务器必须验证 CONNECT 包的格式符合 3.1 中的描述，如不符合则关闭网络连接 [MQTT-3.1.4-1]。服务器可以参考 4.13 在关闭网络连接前使用带有 0x80 或更高值的原因码的 CONNACK 通知客户端。 服务器可以检查 CONNECT 包中的内容是否满足更进一步的限制要求，并且应该进行认证和授权检查。如果其中任何检查失败，服务器必须关闭网络连接 [MQTT-3.1.4-2]。在关闭网络连接前，服务器可以参考 3.2 和 4.13 发送一个带有 0x80 或更高值的原因码的符合情况的 CONNACK 包。 如果验证成功，服务器施行下列动作。 如果客户端ID代表了一个已经连接到服务器的客户端，服务器参考 4.13 发送一个带有原因码 0x8E（会话被接管）的 DISCONNECT 包到当前已有连接的客户端，且必须关闭当前已有连接客户端的网络连接 [MQTT-3.1.4-3]。如果已有连接的客户端包含遗嘱，遗嘱的发布情况参考 3.1.2.5。 非规范性评论 如果已有连接的遗嘱延迟间隔值为0且存在遗嘱消息，遗嘱消息会因为网络连接断开的原因发布。当已有连接的会话过期间隔值为0，或是新连接的全新开始标识被置为 1时，如果已有连接存在遗嘱消息，那么遗嘱消息会被发布，因为原有会话已经在接管时结束。 服务器必须参考 3.1.2.4 中的描述处理全新开始标识 [MQTT-3.1.4-4]。 服务器必须使用带有原因码为 0x00（成功）的 CONNACK 回复 CONNECT 包 [MQTT-3.1.4-5]。 非规范性评论 如果服务器用于处理任何形式的业务关键数据，建议执行身份验证和授权检查。如果这些检查通过，服务器会使用带有原因码 0x00（成功）的 CONNACK 回复。如果检查失败，建议服务器根本不发送 CONNACK，因为这可能会提醒潜在攻击者 MQTT 服务器的存在，并鼓励此类攻击者发起拒绝服务或密码猜测攻击。 启动消息传递和保活监控。 客户端可以在发送 CONNECT 包之后立刻发送其他 MQTT 包；客户端无需等待接收到来自服务器的 CONNACK 包。如果服务器拒绝了 CONNECT，服务器必须不处理客户端在 CONNECT 包之后发送的任何除了 AUTH 以外的包 [MQTT-3.1.4-6]。 非规范性评论 客户端通常会等待 CONNACK 数据包，然而，客户端可以选择在接受 CONNACK 前发送其他 MQTT 数据包，这样做可能会简化客户端实现，因为客户端无需监管连接状态。客户端需要接受在其收到 CONNACK 前，如果服务器拒绝了连接，其发送的数据都不会被服务器处理。 非规范性评论 在接收 CONNACK 之前发送其他 MQTT 包的客户端将不知道服务器约束以及是否正在使用任何现有会话。 非规范性评论 如果客户端在认证完成前就发送了过多的数据，服务器可以限制从网络连接读取数据或关闭网络连接。建议将此作为避免拒绝服务攻击的一种方法。 3.2 CONNACK - 连接确认CONNACK 包是由服务器发送用来响应客户端发送的 CONNECT 包的MQTT包。服务器必须在发送除 AUTH 外的其他任何MQTT包之前使用带有响应码 0x00（成功）的 CONNACK 包回复客户端 [MQTT-3.2.0-1]。服务器必须不在一次网络连接中发送超过一个 CONNACK 包 [MQTT-3.2.0-2]。 如果客户端没有在合理的时间内收到来自服务器的 CONNACK 包，客户端应该断开网络连接。一个“合理”的时间取决于应用程序的类型和通信基础设施。 3.2.1 CONNACK固定头固定头格式参考 图3-7。 图3-7 CONNACK包固定头 Bit76543210 byte 1MQTT包类型（2）保留 00000010 byte 2剩余长度 剩余长度字段 这是使用可变整数编码的值，代表可变头的长度。 3.2.2 CONNACK可变头CONNACK 包中的可变头按序包括了下列字段：连接回复标识，连接原因码，属性集。属性集的编码方式参考 2.2.2。 3.2.2.1 连接回复标识Byte 1 是 “连接回复标识”。Bits 7-1 是保留字段，必须被置为 0 [MQTT-3.2.2-1]。 Bit 0 是会话展示标识。 3.2.2.1.1 会话展示会话展示标识位于连接回复标识的 bit 0。 会话展示标识向客户端通知服务器是否在使用一个与客户端有相同客户端ID的连接的会话状态。这允许客户端和服务器对会话状态是否存在有一致的观点。 如果服务器接收连接的全新开始标识被置为 1，服务器必须在带有 0x00（成功）的原因码的 CONNACK 包中将会话展示置为 0 [MQTT-3.2.2-2]。 如果服务器接收到的连接中全新开始位被置为 0，且服务器持有对此客户端ID的会话状态，服务器必须在 CONNACK 包中将会话展示标识置为 1，其他情况下，服务器都必须在 CONNACK 包中将会话展示标识置为 0。这两种情况下服务器都必须在 CONNACK 中使用原因码 0x00（成功） [MQTT-3.2.2-3]。 如果客户端从服务器接收到的会话展示的值不符合预期，客户端按照如下步骤继续： 如果客户端不持有会话状态，且接收到的会话展示值为 1，客户端必须关闭网络连接 [MQTT-3.2.2-4]。如果客户端想要使用新的会话重启，客户端可以将全新开始标识置为 1 然后重新连接。 如果客户端持有会话状态且收到的会话展示值为 0，如果客户端继续使用此网络连接，客户端必须丢弃会话状态 [MQTT-3.2.2-5]。 如果服务器使用非 0 原因码的 CONNACK 包，服务器必须将会话展示的值置为 0 [MQTT-3.2.2-6]。 3.2.2.2 连接原因码可变头中的 Byte 2 是连接原因码。 连接原因码的值如下表所示。当服务器收到一个格式正确的 CONNECT 包，但服务器无法完成连接时，服务器可以发送一个带有下表中合适原因码的 CONNACK 包。如果服务器发送的 CONNACK 包带有一个值为 128 或更高的原因码，服务器必须随后关闭网络连接 [MQTT-3.2.2-7]。 表 3-1 原因码值 值 Hex制值 原因码名称 描述 0 0x00 成功 连接被接受。 128 0x80 未指定错误 服务器不希望透露失败的原因，或者其他原因代码均不适用。 129 0x81 格式错误的包 无法正确解析 CONNECT 包中的数据。 130 0x82 协议错误 CONNECT 包中的数据不符合此规范。 131 0x83 特定实现错误 CONNECT 有效，但未被该服务器接受。 132 0x84 不支持的协议版本 服务器不支持客户端请求的 MQTT 协议版本。 133 0x85 客户端ID无效 客户端标识符是有效的字符串，但不被服务器允许。 134 0x86 用户名或密码错误 服务器不接受客户端指定的用户名或密码 135 0x87 未经授权 客户端无权连接。 136 0x88 服务器无法使用 MQTT 服务器不可用。 137 0x89 服务器忙 服务器忙。稍后再试。 138 0x8A 禁止 该客户端已被管理员禁止。请联系服务器管理员。 140 0x8C 错误的身份验证方法 该身份验证方法不受支持或与当前使用的身份验证方法不匹配。 144 0x90 主题名称无效 遗嘱主题名称格式正确，但不被该服务器接受。 149 0x95 数据包太大 CONNECT 数据包超出了最大允许大小。 151 0x97 超出配额 已超出实现或管理员设定的限制。 153 0x99 载荷格式错误 遗嘱载荷与指定的载荷格式标识不匹配。 154 0x9A 不支持保留消息 服务器不支持保留消息，且遗嘱保留消息被置为 1。 155 0x9B 不支持 QoS 服务器不支持 QoS，且遗嘱 QoS 被置为 1。 156 0x9C 使用另一台服务器 客户端应暂时使用另一台服务器。 157 0x9D 服务器已迁移 客户端应永久使用另一台服务器。 159 0x9F 连接频率超限 已超出连接速率限制。 服务器发送的 CONNACK 包必须使用上表中之一的原因码 [MQTT-3.2.2-7]。 非规范性评论 原因码 0x80（未指定错误）可以用在服务器了解故障原因，但不想透露给客户端的时候，或没有其他合适原因码可用的时候。 当在 CONNECT 中发现错误时，服务器可以选择不发送 CONNACK 而直接关闭连接，用以提升安全性。例如，当在一个公共网络中，且连接没有被授权，向客户端透露服务器是 MQTT 服务器可能是不明智的。 3.2.2.3 CONNACK属性集3.2.2.3.1 属性长度属性长度是变长整数编码的表示 CONNACK 中属性集长度的值。 3.2.2.3.2 会话过期间隔会话过期间隔的属性ID是17 (0x11) Byte。 随后跟随 4字节整数 用来表示会话过期间隔，单位为秒。在属性集中出现超过一次会话过期间隔视为协议错误。 如果会话过期间隔未设置，则使用 CONNECT 包中的值。服务器通过在 CONNACK 中的此属性告知客户端使用非客户端设置的值。参考 3.1.2.11.2 了解关于会话过期间隔的描述。 3.2.2.3.3 接收最大值接收最大值的属性ID是33 (0x21) Byte。 随后跟随 2字节整数 用来表示有状态数据接收的最大值。接收最大值在属性集中出现超过一次，或接收最大值的值为0，均为协议错误。 服务器使用此值限制他同时处理的 QoS1 和 QoS2 包发布动作数量。没有任何机制限制客户端可能尝试的对 QoS0 包的发布。 接收最大值的值仅对当前网络连接有效。如果没有设置接收最大值那么他的默认值是 65535。 参考 4.9 流量控制 了解关于接收最大值的使用细节。 3.2.2.3.4 最大QoS最大QoS的属性ID是36 (0x24) Byte。 随后跟随值为 0 或 1 的 Byte。最大QoS在属性集中出现超过一次，或最大QoS的值不为 0 或 1，均为协议错误。如果接收最大值未设置，客户端可以使用的最大QoS值为 2。 如果服务器不支持 QoS 1 或 QoS 2 的 PUBLISH，服务器必须发送一个带有其可以支持的最大QoS的 CONNACK 包 [MQTT-3.2.2-9]。一个不支持 QoS 1 或 QoS 2 PUBLISH 的服务器必须依然接收包含 QoS 0、1 或 2 的 SUBSCRIBE 包 [MQTT-3.2.2-10]。 如果客户端从服务器接收了最大QoS，客户端必须不发送 QoS 等级超过最大QoS的 PUBLISH 包 [MQTT-3.2.2-11]。服务器收到了超过已指定最大QoS等级的 PUBLISH 包视为协议错误。这种情况下需使用带有原因码 0x9B（不支持的 QoS）的 DISCONNECT 断开连接，参考 4.13 错误处理。 如果服务器收到包含超过其能力的遗嘱QoS的 CONNECT 数据包，服务器必须拒绝连接。服务器应该回复带有原因码 0x9B（不支持的 QoS）的 CONNACK 包，参考 4.13 错误处理，且随后必须关闭网络连接 [MQTT-3.2.2-12]。 非规范性评论 客户端不必须支持 QOS 1 或 QOS 2 的 PUBLISH 包。在这种情况下，客户端只需简单的在 SUBSCRIBE 中将最大QoS字段设置为其可支持的值。 3.2.2.3.5 保留消息可用保留消息可用的属性ID是37 (0x25) Byte。 随后跟随一个 Byte。当此字段存在时，此 Byte 表示服务器是否支持保留消息。值为 0 表示不支持保留消息。值为 1 表示支持保留消息。如果此字段不存在，默认表示支持保留消息。保留消息可用在属性集中出现超过一次，或保留消息可用的值不为 0 或 1，均为协议错误。 如果服务器接收到的 CONNECT 包中包含遗嘱消息，且遗嘱保留消息的值为 1，同时服务器不支持保留消息，服务器必须拒绝此连接请求。服务器应该发送带有原因码 0x9A（不支持保留消息）的 CONNACK 且随后必须关闭网络连接 [MQTT-3.2.2-13]。 一个收到了服务器发送的保留消息可用值为 0 的客户端，必须不发送带有保留消息标识为 1 的 PUBLISH 包 [MQTT-3.2.2-14]。如果服务器收到了此种包，视为协议错误。服务器应该发送带有原因码为 0x9A（不支持保留消息）的 DISCONNECT 包，参考 4.13。 3.2.2.3.6 最大包尺寸最大包尺寸的属性ID是33 (0x21) Byte。 随后跟随 4字节整数 用来表示服务器可以接受的最大包尺寸。如果没有设置最大包尺寸，则其受限于固定头中的剩余长度限制，除此外并没有其他限制。 在属性集中出现超过一次最大包尺寸或其值为 0 均视为协议错误。 最大包尺寸表示 MQTT 包完整的字节数，其定义参考 2.1.4。服务器使用最大包尺寸告知客户端，服务器不会处理超过此尺寸限制的信息。 客户端必须不向服务器发送超过最大包尺寸的数据包 [MQTT-3.2.2-15]。如果服务器收到了超过其最大包尺寸限制的包，这被视为一个协议错误，服务器需要使用带有原因码 0x95（包过大）的 DISCONNECT 包来中断连接，参考 4.13 的描述。 3.2.2.3.7 分配的客户端ID分配的客户端ID的属性ID是18 (0x12) Byte。 随后跟随 UTF-8字符串 表示被分配的客户端ID。分配的客户端ID在属性集中出现超过一次视为协议错误。 由于在客户端发送的 CONNECT 包中的客户端ID长度为0，因此由服务器来分配客户端ID。 如果客户端使用长度为 0 的客户端ID连接，服务器必须使用带有分配的客户端ID的 CONNACK 回复。分配的客户端ID必须是一个当前所有会话都没有使用的全新ID [MQTT-3.2.2-16]。 3.2.2.3.8 主题别名最大值主题别名最大值的属性ID是34 (0x22) Byte。 随后跟随 2字节整数 表示主题别名的最大值。在属性集中出现超过一次主题别名最大值视为协议错误。如果主题别名最大值没有设置，则采用默认值 0。 主题别名最大值表示了服务器可以接受的来自客户端发送的主题别名的最大数量。服务器使用此值来约束他在本次连接中可以持有的主题别名数量。客户端必须不能发送一个主题别名的值大于服务器设置的主题别名最大值的 PUBLISH 包 [MQTT-3.2.2-17]。主题别名最大值的值为 0 表示服务器在本次连接中不支持任何主题别名。如果主题别名最大值未设置或值为 0，客户端必须不向服务器发送主题别名 [MQTT-3.2.2-18]。 3.2.2.3.9 原因字符串原因字符串的属性ID是31 (0x1F) Byte。 随后跟随 UTF-8字符串 表示本次响应的原因。原因字符串是一个被设计用来诊断问题的人类可读的字符串，原因字符串不应该被客户端解析。 服务器使用本字段向客户端提供课外的信息。如果因为添加原因字符串会导致 CONNACK 的包尺寸超过了客户端限制的最大包尺寸，服务器必须不发送此属性 [MQTT-3.2.2-19]。原因字符串在属性出现超过一次视为协议错误。 非规范性评论 客户端使用原因字符串的正确用法包括将其在异常中抛出或将其写入日志。 3.2.2.3.10 用户属性用户属性的属性ID是38 (0x26) Byte。 随后跟随 UTF-8字符串对。这个属性可以用来向客户端提供包括诊断消息在内的扩展信息。如果添加该属性会导致 CONNACK 的包尺寸大于客户端设置的最大包尺寸，服务器必须不添加此属性 [MQTT-3.2.2-20]。用户属性可以出现多次，用来携带多个 键-值 对。同样的 键 允许出现超过一次。 本属性的内容和含义不由本规范定义。CONNACK 的接收者在接收到本属性后可以选择忽略。 3.2.2.3.11 通配符订阅可用通配符订阅可用的属性ID是40 (0x28) Byte。 随后跟随一个 Byte。当该字段存在时，该 byte 表示服务器是否支持通配符订阅。值为 0 表示不支持通配符订阅。值为 1 表示支持通配符订阅。当该字段不存在时，默认表示支持通配符订阅。通配符订阅可用在属性集中出现超过一次，或其值不为 0 或者 1，均视为协议错误。 如果服务器不支持通配符订阅，但接收到了一个包含通配符的 SUBSCRIBE 包，则视为一个协议错误。服务器需要使用带有原因码 0xA2（不支持通配符订阅）的 DISCONNECT 包断开连接，具体参考 4.13。 如果服务器支持通配符订阅，他仍然可以拒绝包含某种特别通配符的订阅请求。在这种情况下服务器可以发送一个带有原因码 0xA2（不支持通配符订阅）的 SUBACK包。 3.2.2.3.12 订阅ID可用订阅ID可用的属性ID是41 (0x29) Byte。 随后跟随一个 Byte。当该字段存在时，该 byte 表示服务器是否支持订阅ID。值为 0 表示不支持订阅ID。值为 1 表示支持订阅ID。当该字段不存在时，默认表示支持订阅ID。订阅ID可用在属性集中出现超过一次，或其值不为 0 或者 1，均视为协议错误。 如果服务器不支持订阅ID，但接收到了一个包含订阅ID的 SUBSCRIBE 包，则视为一个协议错误。服务器需要使用带有原因码 0xA1（不支持订阅ID）的 DISCONNECT 包断开连接，具体参考 4.13。 3.2.2.3.13 共享订阅可用共享订阅可用的属性ID是42 (0x2A) Byte。 随后跟随一个 Byte。当该字段存在时，该 byte 表示服务器是否支持共享订阅。值为 0 表示不支持共享订阅。值为 1 表示支持共享订阅。当该字段不存在时，默认表示支持共享订阅。共享订阅可用在属性集中出现超过一次，或其值不为 0 或者 1，均视为协议错误。 如果服务器不支持共享订阅，但接收到了一个包含共享订阅的 SUBSCRIBE 包，则视为一个协议错误。服务器要使用带有原因码 0x9E（不支持共享订阅）的 DISCONNECT 包断开连接，具体参考 4.13。 3.2.2.3.14 服务器保活时间服务器保活时间的属性ID是19 (0x13) Byte。 随后跟随一个 2字节整数 表示服务器指定的保活时间。如果服务器在 CONNACK 中发送了服务器保活时间，客户端必须使用此值代替其在 CONNECT 中发送的保活时间 [MQTT-3.2.2-21]。如果服务器没有设置服务器保活时间，服务器必须使用客户端在 CONNECT 包中设置的保活时间 [MQTT-3.2.2-22]。服务器保活时间在属性集中出现超过一次视为协议错误。 非规范性评论 服务器保活时间的主要用途是让服务器通知客户端，他将比客户端指定的保活时间更早地断开与客户端的不活动连接。 3.2.2.3.15 响应信息响应信息的属性ID是26 (0x1A) Byte。 随后跟随一个 UTF-8字符串 用来表示构建响应主题的基础。客户端如何通过响应信息构建响应主题不由本规范定义。响应信息在属性集中出现超过一次视为协议错误。 如果客户端发送的请求响应信息值为 1，服务器可选则是否在 CONNACK 中包括响应信息。 非规范性评论 响应信息的常见用法是将响应信息作为响应主题中的某一部分，该部分为此客户端在其会话周期内保留。这一部分往往不能是一个随机的名称，因为请求客户端和响应客户端都需要通过授权才能使用此主题。这部分通常特定客户端的主题树的跟。为了让服务器能够返回此信息，通常需要进行一些正确的配置。使用本机制可以在服务端一次性配置响应信息，而非是在请求客户端和响应客户端中各自完成。 参考 4.10 了解更多关于 请求&#x2F;响应 的信息。 3.2.2.3.16 服务引用服务引用的属性ID是28 (0x1C) Byte。 随后跟随 UTF-8字符串，可被客户端用于定位到另一台服务器。服务引用在属性集中出现超过一次视为协议错误。 服务器在原因码为 0x9C（使用另一台服务器）或 0x9D（服务器迁移）的 CONNACK 或 DISCONNECT 包中使用服务引用，具体用法参考 4.13。 参考 4.11 了解服务引用的用法。 3.2.2.3.17 认证方式认证方式的属性ID是21 (0x15) Byte。 随后跟随 UTF-8字符串，内含认真方式的名称。认证方式在属性集中出现超过一次视为协议错误。参考 4.12 了解跟多关于增强认证的信息。 3.2.2.3.18 认证数据认证数据的属性ID是22 (0x16) Byte。 随后跟随 二进制数据，内含认证数据。数据的内容由认证方式和当然交换状态定义。认证数据在属性集中出现超过一次视为协议错误。参考 4.12 了解跟多关于增强认证的信息。 3.2.3 CONNACK载荷CONNACK 没有载荷。 3.3 PUBLISH - 发布消息PUBLISH 包可以由客户端发往服务端，或由服务端发往客户端，用于传输应用消息。 3.3.1 PUBLISH 固定头图 3‑8 – PUBLISH 包固定头 Bit76543210 byte 1MQTT包类型（3）重复标识QoS等级保留消息 0011XXXX byte 2...剩余长度 3.3.1.1 重复标识位置： byte 1，bit 3。 如果重复标识的值为 0，这表示这是客户端或服务器第一次尝试发送此 PUBLISH 包。如果重复标识的值为 1，这表示本包可能是之前尝试发送包的重传。 当客户端或服务器尝试重传 PUBLISH 包时，他们必须把重复标志置为 1 [MQTT-3.3.1-1]。对于 QoS 0 的消息，重复标识必须被置为 0 [MQTT-3.3.1-2]。 当服务器将 PUBLISH 包转发给订阅者时，来自传入 PUBLISH 包的重复标识不会传播。转发的 PUBLISH 包的重复标识独立于接收的 PUBLISH 包，此值仅被本次转发包是否为重传独立决定 [MQTT-3.3.1-3]。 非规范性评论 MQTT包的接收方接收到重复标志为 1 的包并不能假设他已经接收到了此包的早期副本。 非规范性评论 需要注意的是，重复标识仅表示 MQTT 包的重复，并不能表示其中应用消息的重复。当使用 QoS 1 时，客户端有可能接收到重复标志为 0 的包，但其中包含的应用消息却是早已接收的，只是包ID不同。章节 2.2.1 提供了更多关于包ID的信息。 3.3.1.2 QoS位置： byte 1，bit 2-1。 该字段表示应用消息传送的保障级别。QoS 级别如下表所示。 表 3-2 QoS 定义 QoS 值 bit 2 bit 1 描述 0 0 0 至多一次 1 0 1 至少一次 2 1 0 确保一次 - 1 1 保留 - 不可使用 如果客户端在 CONNACK 中向服务器提示了最大QoS，之后收到了超过最大QoS值的 PUBLISH 包，服务器使用带有原因码 0x9B（不支持的QoS）的 DISCONNECT 包断开连接，如同 4.13 中的描述。 PUBLISH 包必须不能将 QoS 的两个 bit 都设置为 1 [MQTT-3.3.1-4]。如果服务器或者客户端接收到了两个 bit 都为 1 的 PUBLISH 包，视为格式错误的包，使用带有原因码 0x81（格式错误的包）的 DISCONNECT 断开连接，参考 4.13。 3.3.1.3 保留消息位置： byte 1，bit 0。 当客户端向服务器发送的 PUBLISH 包中的保留消息被置为 1 时，服务器必须在此主题下保存此应用消息，替换任何已经存在的消息 [MQTT-3.3.1-5]，之后该保留消息可以被发布给订阅该主题的订阅者。如果载荷为空，服务器照常处理，只不过该同名主题下现有的保留消息必须被移除，未来的订阅者也不会再收到保留消息 [MQTT-3.3.1-6]。带有空载荷的保留消息必须不被服务器作为保留消息存储 [MQTT-3.3.1-7]。 如果客户端发送到服务器的 PUBLISH 包中的保留消息值为 0，服务器必须不将该消息作为保留消息存储且必须不删除或替换已经存在的保留消息 [MQTT-3.3.1-8]。 如果服务器回复的 CONNACK 带有保留消息可用标识且其值为 0，此时服务器又收到了带有保留消息值为 1 的 PUBLISH 包，服务器需使用带有原因码 0x9A（不支持保留消息）的 DISCONNECT 包断开连接，参考 4.13。 当一个新的非共享订阅创建时，如果存在保留消息，每个匹配主题名上的保留消息都按照订阅选项中的保留消息处理标识的指示发往客户端。这些消息发送时的保留消息标识都置为 1。保留消息是否发送由订阅选项中的保留消息处理字段控制。当客户端进行订阅时： 如果保留消息处理值为 0，服务器必须将匹配订阅主题过滤器的保留消息发送给客户端 [MQTT-3.3.1-9]。 如果保留消息处理值为 1，当该订阅之前不存在时，服务器必须将匹配订阅主题过滤器的保留消息发送给客户端，反之当该订阅之前存在时，服务器必须不发送保留消息 [MQTT-3.3.1-10]。 如果保留消息处理值为 2，服务器必须不发送保留消息 [MQTT-3.3.1-11]。 参考 3.8.3.1 了解关于订阅选项的定义。 当服务器接收到保留消息值为 1，QoS 值为 0 的 PUBLISH 包，服务器应该存储这个新的 QoS 值为 0 的消息作为该主题新的保留消息，但是可以在任何时候丢弃他。如果服务器丢弃了该消息，该主题下将没有保留消息。 如果主题下的保留消息过期，他将会被丢弃且主题下将没有保留消息。 服务器向已经建立的连接转发的应用消息中保留消息的值是由订阅选项中的保留消息引用发布选项决定的。参考 3.8.3.1 了解关于订阅选项的定义。 如果保留消息引用发布的值为 0，服务器必须在转发应用消息时将保留消息值置为 0，无论其收到的 PUBLISH 包中的保留消息值如何设置 [MQTT-3.3.1-12]。 如果保留消息引用发布的值为 1，服务器必须使用和收到的 PUBLISH 包中保留消息值相同的保留消息值 [MQTT-3.3.1-13]。 非规范性评论 当发布者不规律的发布状态消息时，保留消息非常有用。新的非共享订阅者会受到最新的状态。 3.3.1.4 剩余长度剩余长度是 变长整数，表示可变头与载荷的总长度。 3.3.2 PUBLISH可变头PUBLISH 可变头按顺序包含下列字段：主题名称，包ID，属性集。属性集的编码规则参考 2.2.2。 3.3.2.1 主题名称主题名称决定了载荷发布的信息通道。 主题名称必须作为 PUBLISH 包可变头的第一个字段。他必须采用 UTF-8字符串 编码，定义参考 1.5.4 [MQTT-3.3.2-1]。 PUBLISH 包中的主题名称必须不包含通配符 [MQTT-3.3.2-2]。 服务器发往客户端的 PUBLISH 包中的主题名称必须匹配订阅者的主题过滤器，匹配流程参考 4.7 [MQTT-3.3.2-3]。然而，考虑到服务器允许进行主题名称映射，转发的 PUBLISH 包的主题名称可以与原始 PUBLISH 包的主题名称不同。 为了减少 PUBLISH 包的尺寸，发送者可以使用主题别名。主题别名的描述参考 3.3.2.3.4。主题名称长度为 0 且没有主题别名视为协议错误。 3.3.2.2 包ID仅当 QoS 等级为 1 或 2 的 PUBLISH 包中存在包ID字段，章节 2.2.1 提供了更多关于包ID的信息。 3.3.2.3 PUBLISH属性集3.3.2.3.1 属性长度属性长度是变长整数编码的表示 PUBLISH 中属性集长度的值。 3.3.2.3.2 载荷格式标识载荷格式标识的属性ID是1 (0x01) Byte。 随后跟随的值表示载荷格式，二选其一： 0（0x00）Byte 表示载荷格式未指定，等同于没有发送载荷格式字段。 1（0x01）Byte 表示载荷是UTF-8编码的字符数据。载荷中的UTF-8数据必须是编码良好的UTF-8格式，符合 Unicode 规范和 RFC3629。 服务器必须将载荷格式标识原封不动的发送给所有应用消息的接收者 [MQTT-3.3.2-4]。接收者可以验证载荷是否和更是标志匹配，当不匹配时，发送带有原因码 0x99（载荷格式错误）的 PUBACK、PUBREC 或 DISCONNECT，参考 4.13。参考 5.4.9 了解关于验证载荷格式的安全建议。 3.3.2.3.3 消息过期间隔载荷格式标识的属性ID是2 (0x02) Byte。 随后跟随 4字节整数，表示消息过期间隔。 当该字段存在时，此四字节的值表示以秒为单位的应用消息生命时间。如果消息过期间隔已经超时，且服务器尚未设法开始向前传递到匹配的订阅者，服务器必须删除面向该订阅者的该消息的副本 [MQTT-3.3.2-5]。 如果该字段不存在，应用消息不会过期。 客户端发送给服务器的 PUBLISH 包中的消息过期间隔必须被设置为服务器接收的消息过期间隔的值减去消息在服务器中等待的时间 [MQTT-3.3.2-6]。参考 4.1 了解关于存储状态的更多细节和限制。 3.3.2.3.4 主题别名主题别名的属性ID是35 (0x23) Byte。 随后跟随 2字节整数 表示主题别名的值。主题别名在属性集中出现超过一次视为协议错误。 主题别名是一个用于替代主题名来区分主题的整数值。使用主题别名可以减少 PUBLISH 包的尺寸，主题别名在主题名较长且同一个主题名被反复使用的网络连接中有很大作用。 发送者可以决定是否使用主题别名，以及主题别名的值。他在 PUBLISH 包中创建了一个非零长度主题名和主题别名值的映射。接收者正常处理 PUBLISH 包，但需要同样添加该主题别名到主题名的映射。 一旦接收者设置了主题别名的映射，发送者可以发送包含主图别名的 PUBLISH 包，其中主题名可以为零长度。接收者将按照其中包含正常主题名的方式对待此 PUBLISH 包。 发送者可以在同一网络连接中通过再次发送一个带有相同的主题别名和不同的主题名 PUBLISH 包的方式改变主题别名的映射。 主题别名映射仅在单次网络连接中存在，其生命周期等同于网络连接的生命周期。接收者必须不能将主题别名从一个网络连接转发到另一个网络连接 [MQTT-3.3.2-7]。 主题别名的值不可为 0。发送者必须不能发送一个包含主题别名值为 0 的 PUBLISH 包 [MQTT-3.3.2-8]。 客户端必须不发送包含主题别名值超过服务器 CONNACK 中设置的主题别名最大值的 PUBLISH 包 [MQTT-3.3.2-9]。客户端必须接收所有大于 0 且小于或等于其 CONNECT 包中设置的主题别名最大值的主题别名 [MQTT-3.3.2-10]。 服务器必须不发送包含主题别名值超过客户端 CONNECT 包中设置的主题别名最大值的 PUBLISH 包 [MQTT-3.3.2-11]。服务器必须接收所有大于 0 且小于等于其 CONNACK 包中设置的主题别名最大值的主题别名 [MQTT-3.3.2-12]。 客户端和服务器使用的主题别名映射是互相独立的。因此，当一个客户端发送的 PUBLISH 包中的主题别名为 1，同时服务器发送的 PUBLISH 包中的主题别名也为 1 一般来说引用了不同的主题。 3.3.2.3.5 响应主题响应主题的属性ID是8 (0x08) Byte。 随后跟随 UTF-8字符串 作为响应消息的主题名。响应主题必须使用 UTF-8字符串 格式，其定义参考 1.5.4 [MQTT-3.3.2-13]。响应主题必须不包含通配符 [MQTT-3.3.2-14]。响应主题在属性集中出现超过一次视为协议错误。响应主题的出现表示该消息是一个请求。 参考 4.10 了解更多关于 请求&#x2F;响应 的信息。 服务器必须向所有接收该应用消息的订阅者原封不动的转发响应主题 [MQTT-3.3.2-15]。 非规范性评论 带有响应主题的应用消息的接收者通过使用响应主题作为 PUBLISH 的主题名称来发送响应。如果请求消息包含关联数据，则响应方还应该将该关联数据作为响应消息的 PUBLISH 数据包中的属性。 3.3.2.3.6 关联数据关联数据的属性ID是9 (0x09) Byte。 随后跟随 二进制数据。关联数据是由发送方添加在请求消息里，用于在响应消息中确定响应消息和请求消息的关联关系。关联数据在属性集中出现超过一次视为协议错误。如果没有设置关联数据，表示请求者无需任何关联数据。 服务器必须将关联数据原封不动的转发给接收应用消息的订阅者 [MQTT-3.3.2-16]。关联数据的值仅对请求的发送者和响应的接收者有意义。 非规范性评论 接受了包含响应主题和关联数据的应用消息的接收者，通过响应主题发送 PUBLISH 包作为响应。同时也应该在响应的 PUBLISH 包中原封不动的设置关联数据。 非规范性评论 如果响应中的关联数据内容改变会导致应用程序故障，那么此数据应该通过加密、哈希等手段来确保其改变可以被监测。 参考 4.10 了解更多关于 请求&#x2F;响应 的信息。 3.3.2.3.7 用户属性用户属性的属性ID是38 (0x26) Byte。 随后跟随 UTF-8字符串对。用户属性可以出现多次，用来携带多个 键-值 对。同样的 键 允许出现超过一次。 服务器必须将 PUBLISH 包中的所有用户属性原封不动的转发给客户端 [MQTT-3.3.2-17]。服务器必须在转发应用消息时维护用户属性的顺序 [MQTT-3.3.2-18]。 非规范性评论 该属性旨在提供一种传输应用层键-值对的方法，其含义和解释只有负责发送和接收它们的应用程序了解。 3.3.2.3.8 订阅ID订阅ID的属性ID是11 (0x0B) Byte。 随后跟随 变长整数 表示订阅动作的ID。 订阅ID的取值范围是 1 到 268435455。订阅ID的值为0视为协议错误。如果本次发布是匹配了多次重复订阅的发布，属性集中出现多次订阅ID也是合理的，此种情况下他们的顺序不重要。 3.3.2.3.9 内容类型内容类型的属性ID是3 (0x03) Byte。 随后跟随 UTF-8字符串 描述了应用消息的内容类型。内容类型必须是 UTF-8字符串 格式，其定义参考 1.5.4 [MQTT-3.3.2-19]。 内容格式在属性集中出现超过一次视为协议错误。内容格式的值由发送方和接收方定义。 服务器必须将内容格式原封不动的转发给所有接收应用消息的订阅者 [MQTT-3.3.2-20]。 非规范性评论 这个UTF-8编码的字符串可以使用 MIME 类型字符串来描述应用消息的类型。当然，由于该字段由发送方和接收方负责定义和解释，MQTT不会检查该字段的内容或格式。 非规范性示例 图 3-9 展示了一个 PUBLISH 包的例子，其主题名为 “a&#x2F;b”，其包ID为10，且没有属性集。 图 3-9 PUBLISH 包可变头非规范性示例 描述76543210 主题名称 byte 1长度高位（MSB）（0）00000000 byte 2长度低位（LSB）（3）00000011 byte 3'a'（0x61）01100001 byte 4'/'（0x2F）00101111 byte 5'b'（0x62）01100010 包ID byte 6包ID高位（MSB）（0）00000000 byte 7包ID低位（LSB）（10）00001010 属性集长度 byte 8无属性00000000 3.3.3 PUBLISH载荷载荷包含着被发布的应用消息。其内容和格式是由应用程序选择的。载荷的长度可由可变头中的剩余长度字段减去可变头长度计算所得。PUBLISH 包携带 0 长度的载荷也是合法的。 3.3.4 PUBLISH动作PUBLISH 包的接收者必须使用 PUBLISH 包中 QoS 对应的方式响应此包 [MQTT-3.3.4-1]。 表 3-3 PUBLISH 包响应方式 Qos等级 响应方式 QoS 0 无 QoS 1 PUBACK 包 QoS 2 PUBREC 包 客户端使用 PUBLISH 包将应用消息发送给服务器，以便由服务器转发给相关订阅者。 服务器使用 PUBLISH 包将应用消息发给每个匹配的订阅者客户端。如果订阅时的 SUBSCRIBE 包携带有订阅ID，则 PUBLISH 包也携带此订阅ID。 当客户端使用带有通配符的主题过滤器订阅时，客户端的订阅可能会重叠，因此一次消息发布可能匹配多个过滤器。在这种情况下服务器必须使用这些重叠订阅中最高的 QoS 等级来发布此数据 [MQTT-3.3.4-2]。此外，服务器可以发送此信息的多个副本，每个额外的订阅发送一个副本，且采用每个订阅建立时的 QoS 设置。 如果客户端收到一个不请自来的应用消息（并非来自其订阅的频道），其中包括了超过客户端最大 QoS 的 QoS，客户端将使用带有原因码 0x9B（不支持的 QoS）的 DISCONNECT 包断开连接，参考 4.13 中的描述。 如果客户端在重叠订阅时设置了订阅ID，服务器必须在为该订阅发布消息时将订阅ID放入消息中 [MQTT-3.3.4-3]。如果服务器发送该消息的单一副本，服务器必须将所有包含订阅ID的订阅动作的订阅ID放入 PUBLISH 包中，他们的顺序不重要 [MQTT-3.3.4-4]。如果服务器发送该消息的多个副本，服务器必须在每个副本中放入对应订阅动作的订阅ID [MQTT-3.3.4-5]。 客户端可能对某个发布动作进行了多次订阅，且使用相同的订阅ID。在这种情况下，PUBLISH 包将携带多个相同的订阅ID。 PUBLISH 包因接收 SUBSCRIBE 包携带的订阅ID之外，通过其他方式携带订阅ID视为协议错误。从客户端发往服务器的 PUBLISH 包必须不携带订阅ID [MQTT-3.3.4-6]。 如果是共享订阅，则只有正在接收消息的客户端发送的 SUBSCRIBE 包中的订阅ID会在 PUBLISH 包中返回。 PUBLISH 包的接收者基于QoS等级的动作描述参考 4.3。 如果 PUBLISH 包包含主题别名，接收者按照如下流程处理： 主题别名值为 0 或大于主题别名最大值视为协议错误，接收者使用带有原因码 0x94（主题别名不可用）的 DISCONNECT 包断开连接，参考 4.13。 如果接收者已经建立了对该主题别名的映射，则 如果包中的主题名长度为 0，则接收者使用主题别名对应的主题名 如果包中的主题名长度不为 0，则接收者使用该主题名处理此包，随后更新主题别名映射，将主题别名与主题名关联 如果接收者尚未建立对该主题别名的映射，则 如果包中的主题名长度为 0，则视为一个协议错误，使用带有原因码 0x82（协议错误）的 DISCONNECT 包断开连接，参考 4.3 如果包中的主题名长度不为 0，则接收者使用该主题名处理此包，随后更新主题别名映射，将主题别名与主题名关联 非规范性评论 如果服务器向采用其他版本的客户端（例如 MQTT V3.1.1）发送应用消息，这些客户端可能不支持属性集或者本协议中的其他特性，有些应用消息中的信息可能会丢失，依赖于这些信息的应用程序可能无法正常工作。 当客户端没有接收到足够的 PUBACK、PUBCOMP 或带有大于等于 128 原因码的 PUBREC 时，客户端必须不发送QoS 1 或 QoS 2 的 PUBLISH 包导致其需接收的返回数量超过接收最大值 [MQTT-3.3.4-7]。如果服务器接收且未使用 PUBACK 或 PUBCOMP 返回的 QoS 1 或 QoS 2 的包超过其接收最大值时，服务器使用带有原因码 0x93（超出接收最大值）的 DISCONNECT 包断开连接，参考 4.13。参考 4.9 了解更多关于流量控制的信息。 客户端不能延迟任何包的发送，除了因未收到接受回复而达到接收最大值因此未能发送的 PUBLISH 包 [MQTT-3.3.4-8]。接受最大值的值仅对当前网络连接有效。 非规范性评论 客户端可以选择发送小于接受最大值的包让服务器处理，即使客户端实际上有更多的消息需要发送。 非规范性评论 客户端可以选择在其停发 QoS 1 和 QoS 2 的 PUBLISH 包时，同时停发 QoS 0 的 PUBLISH 包。 非规范性评论 如果客户端在接收到 CONNACK 前就发送 QoS 1 或 QoS 2 的 PUBLISH包，可能存在断开连接的风险，因为他的发送可能超过接受最大值。 当服务器没有接收到足够的 PUBACK、PUBCOMP 或带有大于等于 128 原因码的 PUBREC 时，服务器必须不发送QoS 1 或 QoS 2 的 PUBLISH 包导致其需接收的返回数量超过接收最大值 [MQTT-3.3.4-9]。如果客户端接收且未使用 PUBACK 或 PUBCOMP 返回的 QoS 1 或 QoS 2 的包超过其接收最大值时，客户端使用带有原因码 0x93（超出接收最大值）的 DISCONNECT 包断开连接，参考 4.13。参考 4.9 了解更多关于流量控制的信息。 服务器不能延迟任何包的发送，除了因未收到接受回复而达到接收最大值因此未能发送的 PUBLISH 包 [MQTT-3.3.4-10]。 非规范性评论 服务器可以选择发送小于接受最大值的包让客户端处理，即使服务器实际上有更多的消息需要发送。 非规范性评论 服务器可以选择在其停发 QoS 1 和 QoS 2 的 PUBLISH 包时，同时停发 QoS 0 的 PUBLISH 包。 3.4 PUBACK - 发布确认PUBACK 包是 QoS 1 的 PUBLISH 包的响应。 3.4.1 PUBACK固定头图 3‑10 PUBACK 包固定头 Bit76543210 byte 1MQTT包类型（4）保留 01000000 byte 2剩余长度 剩余长度字段 表示可变头的长度，采用 变长整数 编码。 3.4.2 PUBACK可变头PUBACK 包的可变头按序包含下列字段：对应 PUBLISH 包的包ID，PUBACK 原因码，属性集长度，属性集。属性集的编码规则和描述参考 2.2.2。 图 3-11 PUBACK 包可变头 Bit76543210 byte 1包ID高位（MSB） byte 2包ID低位（LSB） byte 3PUBACK 原因码 byte 4属性集长度 3.4.2.1 PUBACK原因码可变头中的 Byte 3 是 PUBACK 原因码。如果剩余长度的值为 2，表示没有设置原因码，采用默认值 0x00（成功）。 表 3‑4 PUBACK 原因码 值 Hex 原因码名称 描述 0 0x00 成功 消息已接收。继续处理 QoS 1 消息。 16 0x10 没有匹配的订阅者 消息已接收但没有订阅者。此内容只由服务器发送。如果服务器了解没有匹配的订阅者，服务器可以使用此原因码代替 0x00（成功）。 128 0x80 未指定错误 接收者没有接收消息，接收者不想透露原因或原因与其他原因码不匹配。 131 0x83 特定实现错误 PUBLISH 包合法但接收者不想接收。 135 0x87 未经授权 PUBLISH 包未经授权。 144 0x90 主题名不可用 主题名格式正确，但不被此客户端或服务器接受。 145 0x91 包ID已被使用 包ID已经被使用。这可能表示客户端与服务器之间的会话状态不匹配。 151 0x97 超限 超出了实现或管理员设置的限制。 153 0x99 载荷格式错误 载荷格式与载荷格式标识不匹配。 客户端或服务器发送的 PUBACK 包必须采用上述之一的 PUBACK 原因码 [MQTT-3.4.2-1]。当原因码为 0x00（成功）且没有属性集时，原因码与属性集长度可以省略。此时 PUBACK 的剩余长度值为 2。 3.4.2.2 PUBACK属性集3.4.2.2.1 属性集长度表示 PUBACK 可变头中属性集长度的值，采用 变长整数 编码。如果剩余长度的值小于 4，表示没有属性集长度，其值视为 0。 3.4.2.2.2 原因字符串原因字符串的属性ID是31 (0x1F) Byte。 随后跟随 UTF-8字符串 表示此响应关联的原因。原因字符串是人类可读的用于诊断故障的字符串，没有义务被接收端解析。 发送方使用此字段向接收方传递额外的信息。如果添加此字段会导致 PUBACK 的尺寸大于接收方的最大包尺寸，发送方必须不添加此字段 [MQTT-3.4.2-2]。原因字符串在属性集中出现超过一次视为协议错误。 3.4.2.2.3 用户属性用户属性的属性ID是38 (0x26) Byte。 随后跟随 UTF-8字符串对。这个属性可以用于提供额外的诊断信息或者其他信息。如果添加此字段会导致 PUBACK 的尺寸大于接收方的最大包尺寸，发送方必须不添加此字段 [MQTT-3.4.2-3]。用户属性可以出现多次用以发送多个键-值对。同样的键允许出现超过一次。 3.4.3 PUBACK载荷PUBACK 包没有载荷。 3.4.4 PUBACK动作这部分在 4.3.2 中描述。 3.5 PUBREC - 发布签收（QoS 2 交付第一部分）PUBREC 包是对 QoS 2 的 PUBLISH 包的响应。这是 QoS 2 协议交换的第二个包。 3.5.1 PUBREC固定头图 3‑12 PUBREC固定头 Bit76543210 byte 1MQTT包类型（5）保留 01010000 byte 2剩余长度 剩余长度 表示可变头的长度，采用 变长整数 编码。 3.5.2 PUBREC可变头PUBREC 可变头按序包括下列字段：对应 PUBLISH 包的包ID、PUBREC 原因码、属性集。属性集的编码规则和描述参考 2.2.2。 图 3-13 PUBREC 包可变头 Bit76543210 byte 1包ID高位（MSB） byte 2包ID低位（LSB） byte 3PUBREC 原因码 byte 4属性集长度 3.5.2.1 PUBREC原因码可变头中的 Byte 3 是 PUBREC 原因码。如果剩余长度的值为 2，表示没有设置原因码，采用默认值 0x00（成功）。 表 3‑5 PUBREC 原因码 值 Hex 原因码名称 描述 0 0x00 成功 消息已接收。继续处理 QoS 1 消息。 16 0x10 没有匹配的订阅者 消息已接收但没有订阅者。此内容只由服务器发送。如果服务器了解没有匹配的订阅者，服务器可以使用此原因码代替 0x00（成功）。 128 0x80 未指定错误 接收者没有接收消息，接收者不想透露原因或原因与其他原因码不匹配。 131 0x83 特定实现错误 PUBLISH 包合法但接收者不想接收。 135 0x87 未经授权 PUBLISH 包未经授权。 144 0x90 主题名不可用 主题名格式正确，但不被此客户端或服务器接受。 145 0x91 包ID已被使用 包ID已经被使用。这可能表示客户端与服务器之间的会话状态不匹配。 151 0x97 超限 超出了实现或管理员设置的限制。 153 0x99 载荷格式错误 载荷格式与载荷格式标识不匹配。 客户端或服务器发送的 PUBREC 包必须采用上述之一的 PUBREC 原因码 [MQTT-3.5.2-1]。当原因码为 0x00（成功）且没有属性集时，原因码与属性集长度可以省略。此时 PUBREC 的剩余长度值为 2。 3.5.2.2 PUBREC属性集3.5.2.2.1 属性长度属性长度是采用 变长整数 编码的 PUBREC 可变头中的属性集长度。如果剩余长度的值小于 4，表示没有属性长度字段，其值视为 0。 3.5.2.2.2 原因字符串原因字符串的属性ID是31 (0x1F) Byte。 随后跟随 UTF-8字符串 表示此响应关联的原因。原因字符串是人类可读的用于诊断故障的字符串，不应该被接收方解析。 发送方使用此字段向接收方传递额外的信息。如果添加此字段会导致 PUBREC 的尺寸大于接收方的最大包尺寸，发送方必须不添加此字段 [MQTT-3.5.2-2]。原因字符串在属性集中出现超过一次视为协议错误。 3.5.2.2.3 用户属性用户属性的属性ID是38 (0x26) Byte。 随后跟随 UTF-8字符串对。这个属性可以用于提供额外的诊断信息或者其他信息。如果添加此字段会导致 PUBREC 的尺寸大于接收方的最大包尺寸，发送方必须不添加此字段 [MQTT-3.5.2-3]。用户属性可以出现多次用以发送多个键-值对。同样的键允许出现超过一次。 3.5.3 PUBREC载荷PUBREC 包没有载荷。 3.5.4 PUBREC动作这部分在 4.3.3 中描述。 3.6 PUBREL - 发布释放（QoS 2 交付第二部分）PUBREL 包是对 PUBREC 包的响应。这是 QoS 2 协议交换的第三个包。 3.6.1 PUBREL固定头图 3‑14 PUBREL固定头 Bit76543210 byte 1MQTT包类型（6）保留 01100010 byte 2剩余长度 PUBREL 包固定头中的 Bit 3、2、1、0 为保留字段，其值必须被分别设置为 0、0、1、0。服务器必须将其他值视为格式错误的包并关闭网络连接 [MQTT-3.6.1-1]。 剩余长度 表示可变头的长度，采用 变长整数 编码。 3.6.2 PUBREL可变头PUBREL 可变头按序包括下列字段：对应 PUBLISH 包的包ID、PUBREL 原因码、属性集。属性集的编码规则和描述参考 2.2.2。 图 3-15 PUBREL 包可变头 Bit76543210 byte 1包ID高位（MSB） byte 2包ID低位（LSB） byte 3PUBREL 原因码 byte 4属性集长度 3.6.2.1 PUBREL原因码可变头中的 Byte 3 是 PUBREL 原因码。如果剩余长度的值为 2，表示没有设置原因码，采用默认值 0x00（成功）。 表 3‑6 PUBREL 原因码 值 Hex 原因码名称 描述 0 0x00 成功 消息已接收。继续处理 QoS 1 消息。 146 0x92 包ID未找到 未知的包ID。在恢复期间这不是错误，但在其他时间则表示客户端和服务器上的会话状态不匹配。 客户端或服务器发送的 PUBREL 包必须采用上述之一的 PUBREL 原因码 [MQTT-3.6.2-1]。当原因码为 0x00（成功）且没有属性集时，原因码与属性集长度可以省略。此时 PUBREL 的剩余长度值为 2。 3.6.2.2 PUBREL属性集3.6.2.2.1 属性长度属性长度是采用 变长整数 编码的 PUBREL 可变头中的属性集长度。如果剩余长度的值小于 4，表示没有属性长度字段，其值视为 0。 3.6.2.2.2 原因字符串原因字符串的属性ID是31 (0x1F) Byte。 随后跟随 UTF-8字符串 表示此响应关联的原因。原因字符串是人类可读的用于诊断故障的字符串，不应该被接收方解析。 发送方使用此字段向接收方传递额外的信息。如果添加此字段会导致 PUBREL 的尺寸大于接收方的最大包尺寸，发送方必须不添加此字段 [MQTT-3.6.2-2]。原因字符串在属性集中出现超过一次视为协议错误。 3.6.2.2.3 用户属性用户属性的属性ID是38 (0x26) Byte。 随后跟随 UTF-8字符串对。这个属性可以用于提供额外的诊断信息或者其他信息。如果添加此字段会导致 PUBREL 的尺寸大于接收方的最大包尺寸，发送方必须不添加此字段 [MQTT-3.6.2-3]。用户属性可以出现多次用以发送多个键-值对。同样的键允许出现超过一次。 3.6.3 PUBREL载荷PUBREL 包没有载荷。 3.6.4 PUBREL动作这部分在 4.3.3 中描述。 3.7 PUBCOMP - 发布完成（QoS 2 交付第三部分）PUBCOMP 包是对 PUBREL 包的响应。这是 QoS 2 协议交换的第四个包，也是最后一个包。 3.7.1 PUBCOMP固定头图 3‑16 PUBCOMP固定头 Bit76543210 byte 1MQTT包类型（7）保留 01110000 byte 2剩余长度 剩余长度 表示可变头的长度，采用 变长整数 编码。 3.7.2 PUBCOMP可变头PUBREL 可变头按序包括下列字段：对应 PUBLISH 包的包ID、PUBCOMP 原因码、属性集。属性集的编码规则和描述参考 2.2.2。 图 3-17 PUBCOMP 包可变头 Bit76543210 byte 1包ID高位（MSB） byte 2包ID低位（LSB） byte 3PUBCOMP 原因码 byte 4属性集长度 3.7.2.1 PUBCOMP原因码可变头中的 Byte 3 是 PUBCOMP 原因码。如果剩余长度的值为 2，表示没有设置原因码，采用默认值 0x00（成功）。 表 3‑3 PUBCOMP 原因码 值 Hex 原因码名称 描述 0 0x00 成功 消息已接收。继续处理 QoS 1 消息。 146 0x92 包ID未找到 未知的包ID。在恢复期间这不是错误，但在其他时间则表示客户端和服务器上的会话状态不匹配。 客户端或服务器发送的 PUBCOMP 包必须采用上述之一的 PUBCOMP 原因码 [MQTT-3.7.2-1]。当原因码为 0x00（成功）且没有属性集时，原因码与属性集长度可以省略。此时 PUBCOMP 的剩余长度值为 2。 3.7.2.2 PUBCOMP属性集3.7.2.2.1 属性长度属性长度是采用 变长整数 编码的 PUBCOMP 可变头中的属性集长度。如果剩余长度的值小于 4，表示没有属性长度字段，其值视为 0。 3.7.2.2.2 原因字符串原因字符串的属性ID是31 (0x1F) Byte。 随后跟随 UTF-8字符串 表示此响应关联的原因。原因字符串是人类可读的用于诊断故障的字符串，不应该被接收方解析。 发送方使用此字段向接收方传递额外的信息。如果添加此字段会导致 PUBCOMP 的尺寸大于接收方的最大包尺寸，发送方必须不添加此字段 [MQTT-3.7.2-2]。原因字符串在属性集中出现超过一次视为协议错误。 3.7.2.2.3 用户属性用户属性的属性ID是38 (0x26) Byte。 随后跟随 UTF-8字符串对。这个属性可以用于提供额外的诊断信息或者其他信息。如果添加此字段会导致 PUBCOMP 的尺寸大于接收方的最大包尺寸，发送方必须不添加此字段 [MQTT-3.7.2-3]。用户属性可以出现多次用以发送多个键-值对。同样的键允许出现超过一次。 3.7.3 PUBCOMP载荷PUBCOMP 包没有载荷。 3.7.4 PUBCOMP动作这部分在 4.3.3 中描述。 3.8 SUBSCRIBE - 订阅请求SUBSCRIBE 包由客户端发送到服务器，用来创建一个或多个订阅。每个订阅将客户端注册到一个或多个其感兴趣的主题。服务器将到达该客户端订阅匹配的主题的应用消息使用 PUBLISH 包转发给客户端。SUBSCRIBE 包也基于每个订阅指定了服务器向客户端发送应用消息的最大QoS。 3.8.1 SUBSCRIBE固定头图 3‑18 SUBSCRIBE固定头 Bit76543210 byte 1MQTT包类型（8）保留 10000010 byte 2剩余长度 SUBSCRIBE 包固定头中的 Bit 3、2、1、0 为保留字段，其值必须被分别设置为 0、0、1、0。服务器必须将其他值视为格式错误的包并关闭网络连接 [MQTT-3.8.1-1]。 剩余长度 表示可变头和载荷的长度，采用 变长整数 编码。 3.8.2 SUBSCRIBE可变头SUBSCRIBE 可变头按序包括下列字段：包ID、属性集。2.2.1 提供了更多关于包ID的信息。属性集的编码规则和描述参考 2.2.2。 非规范性示例 图 3-19 是一个 SUBSCRIBE 可变头的示例，其包ID为 10 且没有属性集。 图 3-19 SUBSCRIBE 可变头示例 描述76543210 包ID byte 1包ID高位（MSB）（0）00000000 byte 2包ID低位（LSB）（10）00001010 byte 3属性集长度（0）00000000 3.8.2.1 SUBSCRIBE属性集3.8.2.1.1 属性长度属性长度是采用 变长整数 编码的 SUBSCRIBE 可变头中的属性集长度。如果剩余长度的值小于 4，表示没有属性长度字段，其值视为 0。 3.8.2.1.2 订阅ID订阅ID属性ID是11 (0x0B) Byte。 随后跟随 变长整数 表示订阅ID。订阅ID的取值范围是 1 至 268435455。订阅ID的值为0视为协议错误。订阅ID在属性集中出现超过一次视为协议错误。 订阅ID将与此 SUBSCRIBE 包创建或修改的任何订阅关联。如果有订阅ID，他将存储在订阅中，如果没有订阅ID，将不会有订阅ID存储在订阅中。 参考 3.8.3.1 了解更多关于订阅ID处理的信息。 3.8.2.1.3 用户属性用户属性的属性ID是38 (0x26) Byte。 随后跟随 UTF-8字符串对。 用户属性可以出现多次用以发送多个键-值对。同样的键允许出现超过一次。 非规范性评论 SUBSCRIBE 中的用户属性可以被客户端用来向服务器发送一些订阅依赖的属性。这意味着这些属性并非本规范定义的。 3.8.3 SUBSCRIBE载荷SUBSCRIBE 包的载荷内含一个主题过滤器列表，指定了客户端想要订阅的主题。主题过滤器必须是一个 UTF-8字符串 [MQTT-3.8.3-1]。每个主题过滤器之后都跟随着一个 byte 的订阅选项 。 载荷必须至少包含一个主题过滤器和订阅选项对 [MQTT-3.8.3-2]。没有载荷的 SUBSCRIBE 视为协议错误。参考 4.13 了解关于错误处理的信息。 3.8.3.1 订阅选项订阅选项中的 Bit 0 和 Bit 1 表示最大QoS字段。这表示了服务器可以法相客户端的最大QoS等级。最大QoS的值为3视为协议错误。 订阅选项中的 Bit 2 表示非本地选项。如果其值为 1，服务器必须不将应用消息转发给与发布者客户端ID相同的订阅者 [MQTT-3.8.3-3]。在共享订阅中非本地选项值为 1 视为协议错误 [MQTT-3.8.3-4]。 订阅选项中的 Bit 3 表示保留消息引用发布选项。其值为 1 时，向该订阅转发的应用消息保留其原本发布时的保留消息标识。其值为 0 时，向该订阅转发的应用消息的保留标志置为 0。订阅建立时发布的保留消息的保留消息标识值为 1。 订阅选项中的 Bit 4 和 Bit 5 表示保留消息处理选项。这个选项决定了当订阅建立时保留消息是否发送。这个选项不会对连接建立后的保留消息发送有任何影响。如果该主题过滤器下没有匹配的保留消息，该选项的所有值的表现都一致。该选项的值包括： 0 &#x3D; 在订阅建立后发送保留消息 1 &#x3D; 只有建立全新的订阅而非重复订阅时发送保留消息 2 &#x3D; 订阅建立时不发送保留消息 保留消息处理的值为 3 视为协议错误。 订阅选项中的 Bit 6 和 Bit 7 被保留以后使用。服务器必须将载荷中保留字段值非 0 的 SUBSCRIBE 包视为格式错误的包 [MQTT-3.8.3-5]。 非规范性评论 非本地选项和保留消息引用发布选项可以用来将客户端的消息桥接到另一台服务器。 非规范性评论 当发生重连且客户端无法确定上次连接会话中订阅是否完成的时候，不对重复订阅发送保留消息的功能是很有用的。 非规范性评论 当客户端希望获得变化提醒且不关心初始状态时，不对新的订阅发送保留消息的功能是很有用的。 非规范性评论 对于不支持保留消息的服务器，所有的保留消息引用发布选项和保留消息处理选项的值结果都是相同的，订阅后服务器不会发送任何保留消息，且后续所有消息的保留消息标识的值都为 0。 图 3‑20 SUBSCRIBE 包载荷格式 描述76543210 主题过滤器 byte 1长度高位（MSB） byte 2长度低位（LSB） byte 3..N主题过滤器 订阅选项 保留保留消息处理RAPNLQoS byte N+100XXXXXX RAP 表示保留消息引用发布。NL 表示非本地。 非规范性示例 图 3.21 展示了 SUBSCRIBE 载荷中包含两个主题过滤器的示例。第一个是“a&#x2F;b”其 QoS 值为 1，第二个是 “c&#x2F;d”其 QoS 值为 2。 图 3‑21 - 载荷字节格式非规范性示例 描述76543210 主题过滤器 byte 1长度高字节（MSB）（0）00000000 byte 2长度低字节（LSB）（3）00000011 byte 3'a'（0x61）01100001 byte 4'/'（0x2F）00101111 byte 5'b'（0x62）01100010 订阅选项 byte 6订阅选项（1）00000001 主题过滤器 byte 7长度高字节（MSB）（0）00000000 byte 8长度低字节（LSB）（3）00000011 byte 9'c'（0x63）01100011 byte 10'/'（0x2F）00101111 byte 11'd'（0x64）01100100 订阅选项 byte 12订阅选项（2）00000010 3.8.4 SUBSCRIBE动作当服务器从客户端收到 SUBSCRIBE 包，服务器必须使用 SUBACK 响应 [MQTT-3.8.4-1]。SUBACK 中的包ID必须和其对应的 SUBSCRIBE 包中的包ID一致 [MQTT-3.8.4-2]。 服务器允许在发送 SUBACK 之前就转发订阅所匹配的 PUBLISH 包。 如果服务器接收到一个 SUBSCRIBE 包，其中包含的主题过滤器和现在会话中的一个订阅完全相同，服务器必须使用新订阅取代现有的订阅 [MQTT-3.8.4-3]。新订阅的主题过滤器和原有订阅的完全相同，虽然其订阅选项可能不同。如果他的保留消息处理选项值为 0，且主题过滤器中现在有匹配的保留消息，服务器必须重新发送，但是服务器必须不能因为订阅的替换导致应用消息的丢失 [MQTT-3.8.4-4]。 如果服务器接收到一个 SUBSCRIBE 包，其中包含的主题过滤器和现在会话中的订阅都不同，服务器创建一个新的非共享订阅。如果保留消息处理选项的值非 2，所有匹配的保留消息都要发往此客户端。 如果服务器接收到一个 SUBSCRIBE 包，其中包含的主题过滤器和服务器中已经存在的共享订阅相同，将该会话作为订阅者加入共享订阅。无需发送保留消息。 如果服务器接收到一个 SUBSCRIBE 包，其中包含共享订阅主题过滤器且和现有的共享订阅主题过滤器都不同，服务器创建一个新的共享订阅。该会话作为订阅者加入共享订阅。无需发送保留消息。 参考 4.8 了解更多关于共享订阅的细节。 如果一个服务器接受的 SUBSCRIBE 包包含有多个订阅主题，服务器必须像接收了多个独立的 SUBSCRIBE 包一个逐个处理，唯一的不同是服务器将所有订阅请求的响应放入一个 SUBACK 包中回复 [MQTT-3.8.4-5]。 服务器发往客户端的 SUBACK 必须为每一个 主题过滤器&#x2F;订阅选项 对提供一个原因码 [MQTT-3.8.4-6]。这个原因码必须提供服务器为此次订阅分配的最大QoS或是指明本次订阅失败 [MQTT-3.8.4-7]。服务器也许会提供一个比订阅者请求的更低的最大QoS。发送给订阅者的应用消息中的QoS必须是原始 PUBLISH 包中的QoS和服务器分配的最大QoS两者中的较小值 [MQTT-3.8.4-8]。当原始消息的QoS值为 1 且服务器分配的最大QoS值为 0 时，服务器被允许向订阅者发布消息的多个副本。 非规范性评论 如果订阅客户端对于某个特定主题被分配的最大QoS值为 1，QoS 值为 0 的应用消息通过该主题转发到客户端时QoS值为 0。这意味着客户端至多只能接收到此消息一次。另一方面，QoS 值为 2 的应用消息通过该主题转发，会被服务器降级为 QoS 1，因此客户端可能会多次收到该消息。 非规范性评论 如果订阅客户端被分配的最大QoS值为 0，随后原始 QoS 值为 2 的应用消息也可能在发往此客户端的路上丢失，但是服务器不应多次发送此消息。而同主题下 QoS 1 的消息则可能会丢失，也可能多次发给客户端。 非规范性评论 采用 QoS 2 订阅一个主题过滤器等同于宣布“我将使用该主题下所有发布消息的原始 QoS 值来接收消息”。这意味着发送者有责任决定被转发的应用消息的最大QoS等级，但是订阅者可以要求服务器将QoS降级到更适合其使用的级别。 订阅ID是服务器中会话状态的一部分，并在接收到匹配的 PUBLISH 包时在转发时返回给客户端。订阅ID在下面三种情况下被删除或修改：当服务器接收到 UNSUBSCRIBE 包时，当服务器再次收到相同主题过滤器的 SUBSCRIBE 包，其中订阅ID不同或未设置时，当服务器发送 CONNACK，其中的会话展示值为 0 时。 订阅ID并非是客户端会话状态的一部分。在一个有用的实现中，客户端会将订阅ID关联到其他的客户端侧状态，这个状态一般会在下面三种情况下被删除或修改：客户端取消订阅时，客户端再次订阅相同主题但使用不同的订阅ID或不使用订阅ID时，客户端接收到 CONNACK，且其中会话展示值为 0 时。 服务器不需要在重传的 PUBLISH 数据包中使用相同的订阅标识符集。 客户端可以通过发送包含主题过滤器的订阅数据包来重新创建订阅，该主题过滤器与当前会话中现有订阅的主题过滤器相同。 如果客户端在首次传输 PUBLISH 数据包后重新进行订阅并使用不同的订阅标识符，则允许服务器在任何重传中使用第一次传输中的标识符。 或者，允许服务器在重传期间使用新的标识符。 服务器在发送包含新标识符的 PUBLISH 数据包后，不允许恢复为旧标识符。 服务器无需在重传 PUBLISH 时保持相同的订阅ID。客户端可以通过发送和现有会话中订阅的主题过滤器完全相同的 SUBSCRIBE 包来重新订阅。如果客户端在服务器发送某个 PUBLISH 包后重新订阅了该主题并使用了不同的订阅ID，服务器可以使用第一次发送 PUBLISH 包时使用的订阅ID来进行重传。或者，服务器也可以使用新的订阅ID进行重传。但是服务器不允许在使用新的订阅ID发送 PUBLISH 包后再使用旧的订阅ID。 非规范性评论 用于说明订阅ID的使用场景 客户端实现可以通过其编程接口意识到收到的某一次发布可能与其多次订阅匹配。客户端实现在每次订阅时创建一个新的订阅ID。当返回的发布消息携带多个订阅ID时，表示该消息匹配了多次订阅。 客户端实现可以在订阅中让订阅者将消息指向某个回调。客户端实现创建唯一的订阅ID并将其映射到回调。当收到发布时使用其中携带的订阅ID来决定调用哪个回调。 客户端实现可以在收到发布消息时返回订阅该消息的主题字符串。为了实现这一点，客户端生成一个唯一订阅ID和主题过滤器匹配。当收到应用消息时，客户都安时间使用订阅ID查找到原始的主题字符串，并返回给客户端应用程序。 网关将从服务器接收到的发布转发到已订阅网关的客户端时。网关实现可以维护一个包含客户端ID到订阅ID的映射。网关为其转发到服务器的每个主题过滤器生成唯一ID。当收到发布消息时，网关查找其收到的订阅ID用以匹配客户端ID。并将客户端ID添加到发送给客户端的 PUBLISH 包中。如果上游服务器因为消息匹配多个订阅而发送多个 PUBLISH 数据包，则此行为将镜像到客户端。 3.9 SUBACK - 订阅确认SUBACK 包由服务器发往客户端，用以确认 SUBSCRIBE 包的接收和处理。 SUBACK 包包含一个原因码列表，其内容是对 SUBSCRIBE 中每个订阅请求的答复，要么是分配的最大QoS值，要么是错误返回。 3.9.1 SUBACK固定头图 3-22 SUBACK包固定头 Bit76543210 byte 1MQTT包类型（9）保留 10010000 byte 2剩余长度 剩余长度 表示可变头和载荷的长度，采用 变长整数 编码。 3.9.2 SUBACK可变头SUBACK 可变头按序包括下列字段：对应 SUBSCRIBE 包的包ID，属性集。 3.9.2.1 SUBACK属性集3.9.2.1.1 属性长度属性长度是采用 变长整数 编码的 SUBACK 可变头中的属性集长度。 3.9.2.1.2 原因字符串原因字符串的属性ID是31 (0x1F) Byte。 随后跟随 UTF-8字符串 表示此响应关联的原因。原因字符串是人类可读的用于诊断故障的字符串，不应该被接收方解析。 服务器使用此字段向客户端传递额外的信息。如果添加此字段会导致 SUBACK 的尺寸大于客户端的最大包尺寸，服务器必须不添加此字段 [MQTT-3.9.2-1]。原因字符串在属性集中出现超过一次视为协议错误。 3.9.2.1.3 用户属性用户属性的属性ID是38 (0x26) Byte。 随后跟随 UTF-8字符串对。这个属性可以用于提供额外的诊断信息或者其他信息。如果添加此字段会导致 SUBACK 的尺寸大于客户端的最大包尺寸，服务器必须不添加此字段 [MQTT-3.9.2-2]。用户属性可以出现多次用以发送多个键-值对。同样的键允许出现超过一次。 图 3‑23 SUBACK 包可变头 Bit76543210 byte 1包ID高位（MSB） byte 2包ID低位（LSB） 译者认为这里缺失了属性长度 3.9.3 SUBACK载荷载荷中包含一组原因码列表。每个原因码回复 SUBSCRIBE 包中一个对应的主题过滤器。SUBACK 中原因码的顺序必须与 SUBSCRIBE 中主题过滤器的顺序匹配 [MQTT-3.9.3-1]。 表 3‑8 - 订阅原因码 值 Hex 原因码名 描述 0 0x00 授予 QoS 0 订阅已被接收，向其发送的最大 QoS 值为 0。这个值可能会小于其请求时的值。 1 0x01 授予 QoS 1 订阅已被接收，向其发送的最大 QoS 值为 1。这个值可能会小于其请求时的值。 2 0x02 授予 QoS 2 订阅已被接收，服务器接收到的所有 QoS 值都会向其转发。 128 0x80 未指定错误 订阅未被接收，服务器不愿透露原因或其他原因码不匹配。 131 0x83 特定实现错误 SUBSCRIBE 合法，但服务器未接收。 135 0x87 未经授权 客户端未被授予创建此订阅的权力。 143 0x8F 主题过滤器不可用 主题过滤器格式正确，但不允许此客户端使用。 145 0x91 包ID已被使用 所选的包ID已经在使用中。 151 0x97 超限 超过了实现或管理员规定的限制。 158 0x9E 不支持共享订阅 服务器对此客户端不支持共享订阅。 161 0xA1 不支持订阅ID 服务器不支持订阅ID；订阅未被接收。 162 0xA2 不支持通配符订阅 服务器不支持通配符订阅；订阅未被接收。 服务器发送的 SUBACK 包必须对每个收到的主题过滤器使用上表列出的原因码进行回复 [MQTT-3.9.3-2]。 非规范性评论 SUBSCRIBE 包中的每个订阅主题总是会有一个对应的原因码。如果原因码的内容不是针对某个订阅主题的（例如 0x91（包ID已被使用）），此原因码需要被设置到对每一个订阅主题的回复上。 3.10 UNSUBSCRIBE - 取消订阅请求UBSUBSCRIBE 包由客户端发往服务器，用来取消对主题的订阅。 3.10.1 UNSUBSCRIBE固定头图 3‑28 UNSUBSCRIBE固定头 Bit76543210 byte 1MQTT包类型（10）保留 10100010 byte 2剩余长度 UNSUBSCRIBE 包固定头中的 Bit 3、2、1、0 为保留字段，其值必须被分别设置为 0、0、1、0。服务器必须将其他值视为格式错误的包并关闭网络连接 [MQTT-3.10.1-1]。 剩余长度 表示可变头（2 bytes）和载荷的长度，采用 变长整数 编码。 3.10.2 UNSUBSCRIBE可变头UNSUBSCRIBE 可变头按序包括下列字段：包ID，属性集。2.2.1 提供了更多关于包ID的信息。属性集的编码规则和描述参考 2.2.2。 3.10.2.1 UNSUBSCRIBE属性集3.10.2.1.1 属性长度属性长度是采用 变长整数 编码的 UNSUBSCRIBE 可变头中的属性集长度。 3.10.2.1.2 用户属性用户属性的属性ID是38 (0x26) Byte。 随后跟随 UTF-8字符串对。 用户属性可以出现多次用以发送多个键-值对。同样的键允许出现超过一次。 非规范性评论 UNSUBSCRIBE 中的用户属性可以被客户端用来向服务器发送一些订阅依赖的属性。这意味着这些属性并非本规范定义的。 3.10.3 UNSUBSCRIBE载荷UNSUBSCRIBE 的载荷中包含着一组客户端希望取消订阅的主题过滤器列表。UNSUBSCRIBE 中的主题过滤器必须是 UTF-8字符串 [MQTT-3.10.3-1]，其定义参考 1.5.4，这些字符串逐个排放。 UNSUBSCRIBE 包的载荷中必须至少包含一个主题过滤器 [MQTT-3.10.3-2]。不携带载荷的 UNSUBSCRIBE 包视为协议错误。参考 4.13 了解关于错误处理的信息。 非规范性示例 图 3.30 展示了 UNSUBSCRIBE 载荷中包含两个主题过滤器的示例。第一个是“a&#x2F;b”，第二个是 “c&#x2F;d”。 图 3‑30 - 载荷字节格式非规范性示例 描述76543210 主题过滤器 byte 1长度高字节（MSB）（0）00000000 byte 2长度低字节（LSB）（3）00000011 byte 3'a'（0x61）01100001 byte 4'/'（0x2F）00101111 byte 5'b'（0x62）01100010 主题过滤器 byte 7长度高字节（MSB）（0）00000000 byte 8长度低字节（LSB）（3）00000011 byte 9'c'（0x63）01100011 byte 10'/'（0x2F）00101111 byte 11'd'（0x64）01100100 3.10.4 UNSUBSCRIBE动作服务器必须逐字符的核对 UNSUBSCRIBE 包中提供的主题过滤器（无论其是否包含通配符）是否与其持有的当前客户端的订阅相同。如果任何过滤器被精确匹配，那么其拥有的订阅必须被删除 [MQTT-3.10.4-1]，除此之外没有额外处理。 当服务器接收到 UNSUBSCRIBE 时： 服务器必须停止向该主题过滤器添加新的发往客户端的消息 [MQTT-3.10.4-2]。 服务器必须完成匹配该主题过滤器的，且已经开始发往客户端的 QoS 1 和 QoS 2 消息的交付 [MQTT-3.10.4-3]。 服务器可以继续向客户端交付一些现有缓存中的消息。 服务器必须使用 UNSUBACK 包响应 UNSUBSCRIBE 请求 [MQTT-3.10.4-4]。UNSUBACK 包必须和 UNSUBSCRIBE 包有相同的包ID。即使没有主题订阅被删除，服务器也必须使用 UNSUBACK 回复 [MQTT-3.10.4-5]。 如果服务器收到的 UNSUBSCIRIBE 包包含有多个主题过滤器，服务器必须按序处理就如同他按序逐个收到了 UNSUBSCRIBE 包，唯一不同是服务器仅需要使用一个 UNSUBACK 回复 [MQTT-3.10.4-6]。 如果主题过滤器表示一个共享订阅，此会话需要被从共享订阅中移除。如果此会话是共享订阅关联的唯一一个会话，共享订阅需要被删除。参考 4.8.2 了解关于共享订阅处理的描述。 3.11 UNSUBACK - 取消订阅确认UNSUBACK 包由服务器发往客户端，用于确认 UNSUBSCRIBE 包的接收和处理。 3.11.1 UNSUBACK固定头图 3-31 UNSUBACK包固定头 Bit76543210 byte 1MQTT包类型（11）保留 10110000 byte 2剩余长度 剩余长度字段 表示可变头和载荷的长度，采用 变长整数 编码。 3.11.2 UNSUBACK可变头UNSUBACK 可变头按序包括下列字段：与其回复的 UNSUBSCRIBE 对应的包ID，属性集。属性集的编码规则和描述参考 2.2.2。 图 3-32 UNSUBACK 包可变头 Bit76543210 byte 1包ID高位（MSB） byte 2包ID低位（LSB） 译者认为这里缺失了属性长度 3.11.2.1 UNSUBACK属性集3.11.2.1.1 属性长度属性长度是采用 变长整数 编码的 UNSUBACK 可变头中的属性集长度。 3.11.2.1.2 原因字符串原因字符串的属性ID是31 (0x1F) Byte。 随后跟随 UTF-8字符串 表示此响应关联的原因。原因字符串是人类可读的用于诊断故障的字符串，不应该被接收方解析。 服务器使用此字段向客户端传递额外的信息。如果添加此字段会导致 UNSUBACK 的尺寸大于客户端的最大包尺寸，服务器必须不添加此字段 [MQTT-3.11.2-1]。原因字符串在属性集中出现超过一次视为协议错误。 3.11.2.1.3 用户属性用户属性的属性ID是38 (0x26) Byte。 随后跟随 UTF-8字符串对。这个属性可以用于提供额外的诊断信息或者其他信息。如果添加此字段会导致 UNSUBACK 的尺寸大于客户端的最大包尺寸，服务器必须不添加此字段 [MQTT-3.11.2-2]。用户属性可以出现多次用以发送多个键-值对。同样的键允许出现超过一次。 3.11.3 UNSUBACK载荷载荷带有一个原因码列表。每个原因码和 UNSUBSCRIBE 包中的一个主题过滤器对应。UNSUBACK 包中的原因码顺序必须和 UNSUBSCRIBE 包中的主题过滤器顺序一致 [MQTT-3.11.3-1]。 无符号一字节的取消订阅原因码参见下表。服务器发送的 UNSUBACK 包必须对每个收到的主题过滤器使用下表之一的原因码 [MQTT-3.11.3-2]。 表 3‑9 - 取消订阅原因码 值 Hex 原因码名 描述 0 0x00 Success 订阅已被删除。 17 0x11 没有存在的订阅 没有匹配到客户端使用的主题过滤器。 2 0x02 授予 QoS 2 订阅已被接收，服务器接收到的所有 QoS 值都会向其转发。 128 0x80 未指定错误 订阅未被接收，服务器不愿透露原因或其他原因码不匹配。 131 0x83 特定实现错误 UNSUBSCRIBE 合法，但服务器未接收。 135 0x87 未经授权 客户端未被授予取消此订阅的权力。 143 0x8F 主题过滤器不可用 主题过滤器格式正确，但不允许此客户端使用。 145 0x91 包ID已被使用 所选的包ID已经在使用中。 非规范性评论 UNSUBSCRIBE 包中的每个主题过滤器总是会有一个对应的原因码。如果原因码的内容不是针对某个主题过滤器的（例如 0x91（包ID已被使用）），此原因码需要被设置到对每一个主题过滤器的回复上。 3.12 PINGREQ - PING请求PINGREQ 包由客户端发往服务器。可以用于： 在没有其他 MQTT 包需要被发往服务器时，使用 PINGREQ 向服务器表明客户端依然在线。 请求服务器的响应，用来确认服务器是否在线。 测试网络连接，确保网络通讯正常。 PINGREQ 包用于保活处理。参考 3.1.2.10 了解更多细节。 3.12.1 PINGREQ固定头图 3.33 – PINGREQ 包固定头 Bit76543210 byte 1MQTT包类型（12）保留 11000000 byte 2剩余长度（0） 00000000 3.12.2 PINGREQ可变头PINGRESP 包没有可变头。 3.12.3 PINGREQ载荷PINGREQ 包没有载荷。 3.12.4 PINGREQ动作服务器必须发送 PINGRESP 包用来响应 PINGREQ 包 [MQTT-3.12.4-1]。 3.13 PINGRESP - PING响应PINGRESP 包由服务器发往客户端，用于响应 PINGREQ 包。他表示服务器处于可用状态。 PINGRESP 包用于保活处理。参考 3.1.2.10 了解更多细节。 3.13.1 PINGRESP固定头图 3.34 – PINGRESP 包固定头 Bit76543210 byte 1MQTT包类型（13）保留 11010000 byte 2剩余长度（0） 00000000 3.13.2 PINGRESP可变头PINGRESP 包没有可变头。 3.13.3 PINGRESP载荷PINGRESP 包没有载荷。 3.13.3 PINGRESP动作客户端收到此包后无动作。 3.14 DISCONNECT - 断开通知DISCONNECT 包是客户端或服务器发送的最后一个 MQTT 包。他表示了网络连接中断的原因。客户端或服务器可以在断开网络连接前发送 DISCONNECT 包。如果网络连接并非在客户端发送原因码 0x00（普通断开）的 DISCONNECT 后关闭，且连接持有遗嘱消息，遗嘱消息将被发布。参考 3.1.2.5 了解更多细节。 服务器必须不发送 DISCONNECT 包，除非在其发送了一个原因码小于 0x80 的 CONNACK 之后 [MQTT-3.14.0-1]。 3.14.1 DISCONNECT固定头图 3.35 – DISCONNECT 包固定头 Bit76543210 byte 1MQTT包类型（14）保留 11100000 byte 2剩余长度 客户端或服务器必须确认保留字段值为 0。如果非 0，客户端或服务器发送一个带有原因码 0x81（格式错误的包）的 DISCONNECT 包，参考 4.13 中的描述 [MQTT-3.14.1-1]。 剩余长度字段 表示可变头长度，采用 变长整数 编码。 3.14.2 DISCONNECT可变头DISCONNECT 包可变头按序包括下列字段：断开原因码、属性集。属性集的编码规则和描述参考 2.2.2。 3.14.2.1 断开原因码可变头中的 Byte 1 是断开原因码。如果剩余长度的值小于 1，表示没有设置原因码，采用默认值 0x00（普通断开）。 一个 byte 的无符号断开原因码字段参考下表。 表 3‑10 断开原因码 值 Hex 原因码名称 发送方 描述 0 0x00 普通断开 客户端或服务器 普通断开连接。无需发布遗嘱。 4 0x04 携带遗嘱的断开链接 客户端 客户端希望断开连接，但要求服务器发布遗嘱。 128 0x80 未指定错误 客户端或服务器 连接被断开，发送方不想透露原因，或没有匹配原因的原因码。 129 0x81 格式错误的包 客户端或服务器 收到的包不符合本规范。 130 0x82 协议错误 客户端或服务器 收到非预期的或顺序错误的包。 131 0x83 特定实现错误 客户端或服务器 收到的包正确，但不能被本实现处理。 135 0x87 未经授权 服务器 请求未经授权。 137 0x89 服务器忙 服务器 服务器繁忙，无法继续处理该客户端的请求。 139 0x8B 服务器关闭 服务器 服务器已经关闭。 141 0x8D 保活超时 服务器 因在保活时间 1.5 倍的时间内未收到包，连接已经关闭。 142 0x8E 会话被接管 服务器 其他使用同样客户端ID的连接已连接，导致此连接关闭。 143 0x8F 主题过滤器不可用 服务器 主题过滤器格式正确，但不被服务器接受。 144 0x90 主题名不可用 客户端或服务器 主题名格式正确，但不被客户端或服务器接受。 147 0x93 超出接收最大值 客户端或服务器 客户端或服务器接受而未发送 PUBACK 或 PUBCOMP 的包超过了其接收最大值。 148 0x94 主题别名不可用 客户端或服务器 客户端或服务器接收的 PUBLISH 包中设置的主题别名大于其在 CONNECT 或 CONNACK 中设置的主题别名最大值。 149 0x95 包过大 客户端或服务器 包尺寸大于客户端或服务器设置的最大包尺寸。 150 0x96 消息频率过高 客户端或服务器 接收的数据频率过高。 151 0x97 超限 客户端或服务器 超出了该实现或管理员设置的限制。 152 0x98 管理员行为 客户端或服务器 连接被管理员关闭。 153 0x99 载荷格式错误 客户端或服务器 载荷格式与载荷格式标志不匹配。 154 0x9A 不支持保留消息 服务器 服务器不支持保留消息。 155 0x9B 不支持的 QoS 服务器 客户端选择的 QoS 大于 CONNACK 中设置的最大QoS。 156 0x9C 使用另一台服务器 服务器 客户端需要临时使用其他服务器。 157 0x9D 服务器迁移 服务器 服务器已经迁移，客户端需要永久改变其服务器地址。 158 0x9E 不支持共享订阅 服务器 服务器不支持共享订阅。 159 0x9F 连接频率超限 服务器 因连接频率过高，连接被关闭。 160 0xA0 最大连接时间 服务器 此链接超过了其被授予的最大连接时间。 161 0xA1 不支持订阅ID 服务器 服务器不支持订阅ID，订阅未被接受。 162 0xA2 不支持通配符订阅 服务器 服务器不支持通配符订阅，订阅未被接受。 客户端或服务器发送的 DISCONNECT 包必须使用上表之一的断开原因码 [MQTT-3.14.2-1]。如果断开原因码的值是 0x00（普通断开）且没有属性集，原因码和属性长度可以被省略。此时 DISCONNECT 固定头中的剩余长度值为 0。 非规范性评论 DISCONNECT 包用来在没有响应包的情况下表示断开连接的原因（比如 QoS 0 的发布），或是当客户端或服务器无法继续处理连接时用以断开连接。 非规范性评论 DISCONNECT 提供的信息可以被客户端用来判断是否需要重连，或是等待多久以后尝试重连。 3.14.2.2 DISCONNECT属性集3.14.2.2.1 属性长度使用 变长整数 编码的 DISCONNECT 可变头中的属性集长度。如果剩余长度的值小于 2，表示属性集的长度为 0。 3.14.2.2.2 会话过期间隔会话过期间隔的属性ID是17 (0x11) Byte。 随后跟随 4字节整数 用来表示会话过期间隔，单位为秒。在属性集中出现超过一次会话过期间隔视为协议错误。 如果会话过期间隔未设置，则使用 CONNECT 包中的值。 服务器发送的 DISCONNECT 包中必须不包括会话过期间隔 [MQTT-3.14.2-2]。 如果 CONNECT 包中的会话过期间隔值为 0，客户端在 DISCONNECT 包中包括一个非 0 值的会话过期间隔视为协议错误。如果这样一个非 0 值的会话过期间隔的包被服务器接收，服务器无需将他作为一个合法的 DISCONNECT 包对待。服务器使用带有原因码 0x82（协议错误）的 DISCONNECT 包断开连接，参考 4.13。 3.14.2.2.3 原因字符串原因字符串的属性ID是31 (0x1F) Byte。 随后跟随 UTF-8字符串 表示断开连接的原因。原因字符串是人类可读的用于诊断故障的字符串，不应该被接收方解析。 如果添加此字段会导致 DISCONNECT 的尺寸大于接收者的最大包尺寸，发送者必须不添加此字段 [MQTT-3.14.2-3]。原因字符串在属性集中出现超过一次视为协议错误。 3.14.2.2.4 用户属性用户属性的属性ID是38 (0x26) Byte。 随后跟随 UTF-8字符串对。这个属性可以用于提供额外的诊断信息或者其他信息。如果添加此字段会导致 DISCONNECT 的尺寸大于接收方的最大包尺寸，发送方必须不添加此字段 [MQTT-3.14.2-4]。用户属性可以出现多次用以发送多个键-值对。同样的键允许出现超过一次。 3.14.2.2.5 服务引用服务引用的属性ID是28 (0x1C) Byte。 随后跟随 UTF-8字符串 表示客户都安可以使用的其他服务器。服务引用在属性集中出现超过一次视为协议错误。 服务器发送原因码为 0x9C（使用另一台服务器）或 0x9D（服务器迁移）的 DISCONNECT 包时包括服务引用字段，参考 4.13。 参考 4.11 服务重定向了解如何使用服务引用的信息。 图 3‑24 DISCONNECT 包可变头非规范性示例 描述76543210 断开原因码 byte 100000000 属性集 byte 2属性长度（5）00000101 byte 3会话过期间隔标志（17）00010001 byte 4会话过期间隔（0）00000000 byte 500000000 byte 600000000 byte 700000000 3.14.3 DISCONNECT载荷DISCONNECT 包没有载荷。 3.14.4 DISCONNECT动作发送 DISCONNECT 后，发送方将： 必须不在此网络连接中再发送任何 MQTT 包 [MQTT-3.14.4-1]。 必须关闭网络连接 [MQTT-3.14.4-2]。 当接收到带有原因码 0x00（成功） 的 DISCONNECT 包后，服务器将： 必须不发送改连接的遗嘱消息，并丢弃 [MQTT-3.14.4-3]，参考 3.1.2.5 中的描述。 当接收到 DISCONNECT 后，接收者将： 应该关闭网络连接。 3.15 AUTH - 认证交换AUTH 包由客户端发送到服务器，或有服务器发送到客户端，作为增强认证交换的一部分，类似 挑战&#x2F;响应 的认证方式。当服务器或客户端的 CONNECT 包中没有包含相同的认证方式时，发送 AUTH 包视为协议错误。 3.15.1 AUTH固定头图 3.35 – AUTH 包固定头 Bit76543210 byte 1MQTT包类型（15）保留 11110000 byte 2剩余长度 AUTH 包固定头中的 Bit 3、2、1、0 的内容保留且值必须为 0。客户端或服务器必须将任何其他值视为格式错误的包并断开网络连接 [MQTT-3.15.1-1]。 剩余长度字段 使用 变长整数 编码的可变头长度。 3.15.2 AUTH可变头AUTH 包的可变头按序包括下列字段：认证原因码、属性集。属性集的编码规则和描述参考 2.2.2。 3.15.2.1 认证原因码可变头中的 Byte 0 是认证原因码。一个 byte 的无符号断开原因码字段参考下表。AUTH 包的发送者必须使用下表之一的认证原因码 [MQTT-3.15.2-1]。 表 3‑11 认证原因码 值 Hex 原因码名称 发送方 描述 0 0x00 成功 服务器 认证成功。 24 0x18 继续认证 客户端或服务器 使用下个步骤继续认证。 25 0x19 重新认证 客户端 初始化重新认证。 如果认证原因码的值是 0x00（成功）且没有属性集，原因码和属性长度可以被省略。此时 AUTH 固定头中的剩余长度值为 0。 3.15.2.2 AUTH属性集3.15.2.2.1 属性长度使用 变长整数 编码的 AUTH 包中的属性集长度。 3.15.2.2.2 认证方式认证方式的属性ID是21 (0x15) Byte。 随后跟随 UTF-8字符串 包含认证方式字符串。认证方式的缺失或出现超过一次均视为协议错误。参考 4.12 了解更多关于增强认证的信息。 3.15.2.2.3 认证数据认证数据的属性ID是22 (0x16) Byte。 随后跟随 二进制数据，其中包括认证数据。认证数据在属性集中出现超过一次视为协议错误。认证数据的内容是由认证方式决定的。参考 4.12 了解更多关于增强认证的信息。 3.15.2.2.4 原因字符串原因字符串的属性ID是31 (0x1F) Byte。 随后跟随 UTF-8字符串 表示断开连接的原因。原因字符串是人类可读的用于诊断故障的字符串，不应该被接收方解析。 如果添加此字段会导致 AUTH 的尺寸大于接收者的最大包尺寸，发送者必须不添加此字段 [MQTT-3.15.2-2]。原因字符串在属性集中出现超过一次视为协议错误。 3.15.2.2.5 用户属性用户属性的属性ID是38 (0x26) Byte。 随后跟随 UTF-8字符串对。这个属性可以用于提供额外的诊断信息或者其他信息。如果添加此字段会导致 AUTH 的尺寸大于接收方的最大包尺寸，发送方必须不添加此字段 [MQTT-3.15.2-3]。用户属性可以出现多次用以发送多个键-值对。同样的键允许出现超过一次。 3.15.3 AUTH载荷AUTH 包没有载荷。 3.15.4 AUTH动作参考 4.12 了解更多关于增强认证的信息。 4 操作行为4.1 会话状态为了实现 QoS 1 和 QoS 2 的协议流程，客户端和服务器需要设置一些与客户端ID关联的状态，这被称为会话状态。服务器同时也将订阅信息作为会话状态的一部分存储。 会话状态可以跨连续的多个网络连接持续保持。会话状态的持续时间为最近的一次网络连接存在时间加上会话过期间隔。 客户端的会话状包括： 已经发送给服务器，但没有完成的 QoS 1 和 QoS 2 消息。 从服务器收到，但没有完成的 QoS 2 消息。 服务器的会话状态包括： 会话的存在，即便会话中其余所有内容均为空。 客户端订阅，包括所有订阅ID。 已经发送给服务器，但没有完成的 QoS 1 和 QoS 2 消息。 等待传输到客户端的 QoS 1 和 QoS 2 消息，可选的等待传输到客户端的 QoS 0 消息。 从客户端收到的，但没有完成的 QoS 2 消息。遗嘱消息和遗嘱延迟间隔。 如果会话当前未连接，存储会话结束和被丢弃的时间。 保留消息在服务器中不做为会话状态的一部分，保留消息不会在会话结束时被删除。 4.1.1 存储会话状态客户端和服务器必须不在网络连接打开时丢弃会话状态 [MQTT-4.1.0-1]。服务器必须在网络连接关闭且会话过期间隔到期后丢弃会话状态 [MQTT-4.1.0-2]。 非规范性评论 客户端与服务器实现的存储能力当然会受到容量限制，并且可能受到管理策略的限制。存储的会话状态可以被管理员行为丢弃，也可以被一些自动机制丢弃。这具有终止会话的效果。这些操作可能是由资源限制或其他操作原因引起的。硬件或软件故障可能会导致客户端或服务器存储的会话状态丢失或损坏。谨慎评估客户端和服务器的存储能力以确保他们足以承载业务。 4.1.2 会话状态非规范性示例例如，电表抄表解决方案可能使用 QoS 1 消息来保护读数免遭网络丢失。解决方案开发人员可能已经确定电源足够可靠，在这种情况下，客户端和服务器中的数据可以存储在易失性存储器中，而不会带来太大的丢失风险。 相反，停车计时器支付应用程序提供商可能会决定支付消息不应因网络或客户端故障而丢失。因此，它们要求所有数据在通过网络传输之前都写入非易失性存储器。 4.2 网络连接MQTT 协议依赖于一个有序、无损、基于数据流的双向底层传输协议。本规范并不指定特定的传输层协议。 MQTT 协议需要一个底层传输来提供从客户端到服务器以及从服务器到客户端的有序、无损的字节流。 该规范不需要任何特定传输协议的支持。 客户端或服务器可以支持此处列出的任何传输协议，或满足本节要求的任何其他传输协议。客户端或服务器可以选择下表中的任意传输协议，或选择符合本 章节 要求的任意传输协议。 非规范性评论 RFC0793 中定义的 TCP&#x2F;IP 可以被用于 MQTT 5.0。下列传输协议也可以： TLS RFC5246 WebSocket RFC6455 非规范性评论 TCP 端口 8883 和 1883 已经向 IANA 注册为 MQTT TLS 端口和 MQTT 非 TLS 端口。 非规范性评论 无连接的网络传输如 UDP，不适用于 MQTT，因为这些协议可能造成丢包或乱序。 4.3 QoS和协议流程MQTT 协议根据本章中定义的服务质量（QoS）交付应用消息。交付协议是对称的，在下面的描述中，客户端和服务器各自可以充当发送者或接收者的角色。传输协议仅涉及将应用消息从单个发送方传交付到接收方。当服务器向多个客户端交付应用消息时，每个客户端会被分别处理。用于发往客户端的出站消息的 QoS 等级可能和入站消息的 QoS 等级不同。 4.3.1 QoS 0：至多一次消息根据底层网络的能力进行交付。接收方不发送任何响应，发送方也不执行重试。消息要么到达接收者一次，要么不到达。 在 QoS 0 交付协议中，发送方 必须发送 QoS 0 且重复标志值为 0 的 PUBLISH 包。 [MQTT-4.3.1-1]. 在 QoS 0 交付协议中，接收方 在收到 PUBLISH 包时获得消息的所有权 图 4.1 – QoS 0 协议流图，非规范性示例 发送方动作 数据包 接收方动作 PUBLISH QoS 0，DUP&#x3D;0 ———-&gt; 将消息传递给适当的接收者 4.3.2 Qos 1：至少一次QoS 1 保证消息至少到达接收方一次。QoS 1 需要在 PUBLISH 可变头中携带一个包ID，并且这个包ID也会在回复的 PUBACK 中使用。2.2.1 提供了更多关于包ID的信息。 在 QoS 1 交付协议中，发送方 必须在每次发布新消息时选择一个未被使用的包ID [MQTT-4.3.2-1]。 必须发送包含此包ID，且重复标志值为 0 的 PUBLISH 包 [MQTT-4.3.2-2]。 必须将此 PUBLISH 包视为 “未回复的” 直到从接收方收到了正确的 PUBACK。参考 4.4 了解关于未回复消息的讨论 [MQTT-4.3.2-3]。 发送方接收到 PUBACK 包后，此包ID可被重用。 需要注意，发送者被允许在等待接收回复时发送更多带有不同包ID的 PUBLISH 包。 在 QoS 1 交付协议中，接收方 必须使用包含 PUBLISH 包中包ID的 PUBACK 包进行响应，拥有收到的消息的所有权 [MQTT-4.3.2-4]。 在发送 PUBACK 包后，接收方必须将到来的带有相同包ID的 PUBLISH 包视为新的应用消息，无论其重复标志如何设置 [MQTT-4.3.2-5]。 图 4.2 – QoS 1 协议流图，非规范性示例 发送方动作 数据包 接收方动作 存储消息 发送 PUBLISH QoS 1，DUP&#x3D;0，&lt;包ID&gt; ———-&gt; 开始转发应用消息1 &lt;———- 发送 PUBACK &lt;包ID&gt; 丢弃消息 1接收方无需在发送 PUBACK 前完成应用消息的转发。当原有的发送方收到 PUBACK 时，应用消息的所有权已经转移到了接收方。 4.3.3 Qos 2：确保一次QoS 2 是最高级的 QoS，用于消息既不能丢失又不能重复的场合。使用 QoS 2 会带来额外的开销。 QoS 2 消息的可变头中带有包ID。章节 2.2.1 提供了关于包ID的更多信息。QOS 2 PUBLISH 包的接收方使用两步确认过程来确认接收。 在 QoS 2 交付协议中，发送方： 必须在发布新消息时分配一个未使用的包ID [MQTT-4.3.3-1]。 必须发送 QoS 2，重复标志值为 0，携带此包ID的 PUBLISH 包 [MQTT-4.3.3-2]。 必须在收到接收方发来的对应的 PUBREC 之前将此 PUBLISH 包视为 “未回复的” [MQTT-4.3.3-3]。参考 4.4 了解关于未回复消息的讨论。 必须在收到接收方发来的原因码小于 0x80 的 PUBREC 后，发送 PUBREL 包。此 PUBREL 包必须包含和原始 PUBLISH 包相同的包ID [MQTT-4.3.3-4]。 必须在收到接收方发来的对应 PUBCOMP 之前将此 PUBREL 包视为 “未回复的” [MQTT-4.3.3-5]。 必须不在发送 PUBREL 之后重发 PUBLISH 包 [MQTT-4.3.3-6]。 必须不在发送 PUBLISH 包之后使此应用消息过期 [MQTT-4.3.3-7]。 当发送者收到 PUBCOMP 包或原因码大于等于 0x80 的 PUBREC 包后，此包ID可被重用。 需要注意，发送者被允许在等待接收回复时发送更多带有不同包ID的 PUBLISH 包，关于流量控制的主题在 4.9 中描述。 在 QoS 2 交付协议中，接收方： 必须使用和收到 PUBLISH 包相同的包ID的 PUBREC 包响应，拥有收到的消息的所有权 [MQTT-4.3.3-8]。 如果已经使用带有 0x80 或更大值的原因码的 PUBREC 包回复，接收方必须将后续带有相同包ID的 PUBLISH 包视为新应用消息 [MQTT-4.3.3-9]。 直到收到对应的 PUBREL 包为止，接收方必须使用 PUBREC 回复后续任何带有相同包ID的 PUBLISH 包。在此情形下必须不把重复的包转发给更进一步的消息使用者 [MQTT-4.3.3-10]。 必须使用和收到 PUBREL 包相同的包ID的 PUBCOMP 包响应 PUBREL 包 [MQTT-4.3.3-11]。 发送 PUBCOMP 包之后，接收方必须将后续带有相同包ID的 PUBLISH 包视为新应用消息 [MQTT-4.3.3-12]。 即使消息已经过期，也必须继续 QoS 2 的响应动作 [MQTT-4.3.3-13]。 4.4 消息传递重试当客户端使用全新开始值为 0 重连且存在会话时，客户端和服务器都必须使用原始的包ID重传所有未确认的 PUBLISH 包（其 QoS &gt; 0）和 PUBREL 包。这是客户端或服务器需要重传消息的唯一场景。客户端和服务器必须不在其他任何时间重传消息 [MQTT-4.4.0-1]。 如果接收到的 PUBACK 或 PUBREC 包含 0x80 或更大的原因代码，则相应的 PUBLISH 数据包将被视为已确认，且必须不被重传 [MQTT-4.4.0-2]。 图 4.3 – QoS 2 协议流图，非规范性示例 发送方动作 数据包 接收方动作 存储消息 发送 PUBLISH QoS 2，DUP&#x3D;0，&lt;包ID&gt; ———-&gt; 存储&lt;包ID&gt;，之后开始转发应用消息1 PUBREC &lt;包ID&gt; &lt;原因码&gt; &lt;———- 丢弃消息，存储收到的 PUBREC &lt;包ID&gt; PUBREL &lt;包ID&gt; ———-&gt; 丢弃 &lt;包ID&gt; 发送 PUBCOMP &lt;包ID&gt; &lt;———- 丢弃存储的状态 1接收方无需再发送 PUBREC 或 PUBCOMP 前完成消息交付。当原始的发送方收到 PUBREC 包时，应用消息的所有权转移给接收者。然而，接收者需要在接收所有权之前对所有可能导致转发失败的条件（例如限额、授权等）进行检查。接收者使用 PUBREC 中的原因码来表示接收成功或失败。 4.5 消息接收当服务器得到输入应用消息的所有权时，他必须把消息放入所有匹配订阅的客户端的会话状态 [MQTT-4.5.0-1]。匹配规则在 4.7 中定义。 在正常情况下，客户端会收到来自他已创建订阅中的消息。客户端还可能收到与他任何显式订阅不匹配的消息。这会在自动向客户端分配订阅时发生。客户端还可能在 UNSUBSCRIBE 包处理的过程中收到消息。无论何种情况，客户端必须按照匹配的 QoS 规则确认其收到包，无论客户端对包中的消息内容选择处理还是丢弃 [MQTT-4.5.0-2]。 4.6 消息顺序在实现第 4.3 中定义的协议流时，以下这些规则适用于客户端 当客户端重传 PUBLISH 包时，其必须按照原始 PUBLISH 包的顺序发送（包括 QoS 1 和 QoS 2 消息） [MQTT-4.6.0-1]。 客户端必须按照接收 PUBLSIH 包的顺序发送 PUBACK 包（QoS 1 消息） [MQTT-4.6.0-2]。 客户端必须按照接收 PUBLSIH 包的顺序发送 PUBREC 包（QoS 2 消息） [MQTT-4.6.0-3]。 客户端必须按照接收 PUBREC 包的顺序发送 PUBREL 包（QoS 2 消息） [MQTT-4.6.0-4]。 有序主题指的是客户端可以确定接收到该主题下的同一客户端发送的相同 QoS 的消息，其接收顺序和发送方的发送顺序是相同的。当服务器处理发布到有序主题的消息时，服务器必须保证其对消费者发送的 PUBLISH 包（对于相同主题和相同 QoS）的顺序和服务器从客户端接收这些包时相同 [MQTT-4.6.0-5]。这是对上面列出规则的补充。 默认情况下，服务器在转发非共享订阅上的消息时必须将每个主题视为有序主题。 [MQTT-4.6.0-6]。 服务器可以提供管理或其他机制，以允许一个或多个主题不被视为有序主题。 非规范性评论 上面列出的规则确保当消息流发布到 QoS 1 的有序主题，订阅者收到的每条消息的副本最终将按照它们发布的顺序排列。如果重传，则可能先收到早已收到的重复消息。例如，发布者可能会按照 1，2，3，4 的顺序发送消息，但如果发送消息 3 后出现网络断开，订阅者可能会按照 1，2，3，2，3，4 的顺序接收消息 。 如果客户端和服务器都将接收最大值设置为 1，则它们会确保在任何时间 “正在发送” 的消息不超过一条。在这种情况下，即使在重新连接时，也不会在收到后发出的消息后重复收到先前的消息。例如，订户可能会按 1，2，3，3，4 的顺序接收它们，但不会按 1，2，3，2，3，4 的顺序接收它们。有关如何使用接收最大值的详细信息，请参考 4.9 流量控制。 4.7 主题名和主题过滤器4.7.1 主题通配符主题级别分隔符用于结构化的主题名称。当使用主题级别分隔符时，他将主题名称分为多个 “主题级别”。 订阅用的主题过滤器可以包含特殊的通配符，这允许客户端一次订阅多个主题。 通配符可以在主题过滤器中使用，但必须不在主题名称中使用 [MQTT-4.7.0-1]。 4.7.1.1 主题级别分隔符正斜杠（’&#x2F;‘ U+002F）用于在主题树中区分各个层级，且提供一个具有层级结构的主题名称。当订阅客户端在主题过滤器中使用了通配符时，主题级别分隔符十分重要。主题级别分隔符可以出现在主题过滤器或主题名称中的任何位置。响铃到主题级别分隔符表示零长度主题级别。 4.7.1.2 多级通配符井号（’#’ U+0023）是在主题中匹配任意数量层级的通配符。多级通配符可以表示父级和任意数量的子级。多级通配符必须单独使用或在主题级别分隔符后使用。在任意情况下他都必须是主题过滤器中的最后一个字符 [MQTT-4.7.1-1]。 非规范性评论 例如，当客户端订阅了 “sport&#x2F;tennis&#x2F;player1&#x2F;#”，他将会收到下列主题中的消息： sport&#x2F;tennis&#x2F;player1 sport&#x2F;tennis&#x2F;player1&#x2F;ranking sport&#x2F;tennis&#x2F;player1&#x2F;score&#x2F;wimbledon 非规范性评论 “sport&#x2F;#” 可以匹配到 “sport”，因为 # 的匹配包括父级。 “#” 是合法的，将会接收到所有的消息。 “sport&#x2F;tennis&#x2F;#” 是合法的 “sport&#x2F;tennis#” 是非法的 “sport&#x2F;tennis&#x2F;#&#x2F;ranking” 是非法的 4.7.1.3 单级通配符加号（’+’ U+002B）实在主题中匹配单个层级的通配符。 单级通配符可以被用在主题过滤器中的任意层级，包括第一层和最后一层。当他被使用时，他必须占据过滤器中一个完整的级别 [MQTT-4.7.1-2]。他可以在主题过滤器中的多个层级使用，也可以结合多级通配符共同使用。 非规范性评论 例如，“sport&#x2F;tennis&#x2F;+” 可以匹配 “sport&#x2F;tennis&#x2F;player1” 和 “sport&#x2F;tennis&#x2F;player2”，但是不能匹配 “sport&#x2F;tennis&#x2F;player1&#x2F;ranking”。同样，由于单级通配符只能匹配一个层级，“sport&#x2F;+” 无法匹配 “sport”，但可以匹配 “sport&#x2F;”。 “+” 是合法的。 “+&#x2F;tennis&#x2F;#” 是合法的。 “sport+” 是非法的。 “sport&#x2F;+&#x2F;player1” 是合法的。 “&#x2F;finance” 可以被 “+&#x2F;+” 和 “&#x2F;+” 匹配，但不能被 “+” 匹配。 4.7.2 $开头的主题服务器必须不将以通配符（# 或 +）开始的主题过滤器与以 $ 开头的主题名匹配 [MQTT-4.7.2-1]。服务器应该防止客户端使用此类主题名称与其他客户端交换信息。服务器实现可以将 $ 开头的主题名称用于其他目的。 非规范性评论 $SYS&#x2F; 已被广泛采用作为包含服务器特定信息或控制 API 的主题的前缀 应用程序不得将 $ 开头的主题用于私有目的 非规范性评论 订阅 “#” 不会收到任何 $ 开头主题的消息。 订阅 “+&#x2F;monitor&#x2F;Clients” 不会收到任何 “$SYS&#x2F;monitor&#x2F;Clients” 主题的消息。 订阅 “$SYS&#x2F;#” 会收到所有以 “$SYS&#x2F;” 开头的消息。 订阅 “$SYS&#x2F;monitor&#x2F;+” 会收到 “$SYS&#x2F;monitor&#x2F;Clients” 主题的消息。 如果客户端想要接收所有 $SYS&#x2F; 开头的消息和所有其他非 $ 开头的消息，他需要同时订阅 “#” 和 “$SYS&#x2F;#”。 4.7.3 主题语义和使用下列规则适用于主题名称和主题过滤器： 所有的主题名称和主题过滤器必须至少包含一个字符 [MQTT-4.7.3-1] 主题名称和主题过滤器大小写敏感 主题名称和主题过滤器可以包含空格 添加前导的 ‘&#x2F;‘ 或结尾的 ‘&#x2F;‘ 会创建不同的主题名称或主题过滤器 只有 ‘&#x2F;‘ 字符的主题名称或主题过滤器是合法的 主题名称和主题过滤器中必须不能包括 null 字符（Unicode U+0000） Unicode [MQTT-4.7.3-2] 主题名称和主题过滤器是 UTF-8字符串；必须不超过 65535 字节 [MQTT-4.7.3-3]。参考 1.5.4 主题名称和主题过滤器的层级数没有限制，换句话说其受到 UTF-8字符串 的限制。 当进行订阅匹配时，服务器必须不对主题名称或主题过滤器执行任何标准化处理，或对无法识别的字符进行任何修改或替换 [MQTT-4.7.3-4]。主题过滤器中的每个非通配符级别必须与主题名称中的相应级别逐个匹配，匹配才能成功。 非规范性评论 UTF-8 编码规则意味着主题过滤器和主题名称的比较可以通过比较编码的 UTF-8 字节来执行，或是通过比较解码的 Unicode 字符来执行。 非规范性评论 “ACCOUNTS” 和 “Accounts” 是两个不同的主题名称 “Accounts payable” 是合法的主题名称 “&#x2F;finance” 和 “finance” 是不同的主题名称 应用消息会发送到客户端订阅的主题过滤器与该消息发送的主题名称匹配的所有客户端。主题资源可以有管理员在服务器中预定义，也可以被服务器自动创建，当服务器第一次收到关于该主题的订阅或收到发往该主题的应用消息时。服务器也可以使用安全组件来授权某客户端对主题资源进行特定操作。 4.8 订阅MQTT 提供了两种订阅，共享订阅和非共享订阅。 非规范性评论 在较早版本的 MQTT 中，所有的订阅都是非共享订阅。 4.8.1 非共享订阅非共享订阅仅与创建他的 MQTT 会话关联。每个订阅包含一个主题过滤器，决定了拿些主题的消息会被转发到此会话，还包括订阅选项。服务器负责收集匹配过滤器的消息，并在 MQTT 连接可用时将这些消息转发到此会话的 MQTT 连接。 一个会话不能对同主题名持有超过一个的非共享订阅，所以在会话中可以将主题过滤器用作区分订阅的键。 如果有多个客户端，都对相同的主题各自进行非共享订阅，每个客户端都会从主题中获得自己的应用消息副本。这意味着非共享订阅不能用于跨客户端之间的应用消息负载均衡，因为每个消息都会被发到所有的订阅客户端。 4.8.2 共享订阅共享订阅可以与多个订阅 MQTT 会话关联。与非共享订阅一样，持有主题过滤器和订阅选项；然而，发布到其主题过滤器的消息仅被转发到其中之一的订阅会话。当多个消费者客户端并发进行消息处理时，共享订阅非常有用。 共享订阅是用一种特殊格式的主题过滤器实现的。该过滤器的格式是： $share&#x2F;{ShareName}&#x2F;{filter} $share 是小写字符串，表示此主题过滤器是一个共享订阅主题过滤器。 {ShareName} 是不包括 ‘&#x2F;‘ ‘+’ ‘#’ 的字符串 {filter} 字符串的剩余部分的格式和语义与非共享订阅中的主题过滤器相同。参考 4.7。 共享订阅的主题过滤器必须以 $share&#x2F; 开始且必须包括至少一字符的共享名称 [MQTT-4.8.2-1]。共享名称必须不包含字符 ‘&#x2F;‘、’+’、’#’，但必须在其后跟随 ‘&#x2F;‘ 字符。此 ‘&#x2F;‘ 字符后必须跟随主题过滤器 [MQTT-4.8.2-2]，主题过滤器的描述参考 4.7。 非规范性评论 共享订阅在 MQTT 服务器范围内定义，而非在会话内定义。共享名称包含在共享订阅的主题过滤器中，因此一台服务器上可以有多个具有相同 {filter} 的不同共享订阅。通常来说，应用程序使用共享名称表示共享订阅的会话组。 例子： 共享订阅 “$share&#x2F;consumer1&#x2F;sport&#x2F;tennis&#x2F;+” 和 “$share&#x2F;consumer2&#x2F;sport&#x2F;tennis&#x2F;+” 是不同的共享订阅，他们可以被关联到不同的会话组。这两个订阅都可以匹配到与非共享订阅 “sport&#x2F;tennis&#x2F;+” 相同的内容。 如果有消息被发布到 “sport&#x2F;tennis&#x2F;+”，那么会有一个消息副本被发送至 “$share&#x2F;consumer1&#x2F;sport&#x2F;tennis&#x2F;+”，还会有一个消息副本被发送至 “$share&#x2F;consumer2&#x2F;sport&#x2F;tennis&#x2F;+”，另外还会有更多的消息副本被发往使用非共享订阅 “sport&#x2F;tennis&#x2F;+” 的客户端。 共享订阅 “$share&#x2F;consumer1&#x2F;&#x2F;finance” 和非共享订阅 “&#x2F;finance” 匹配相同的主题。 需要注意 “$share&#x2F;consumer1&#x2F;&#x2F;finance” 和 “$share&#x2F;consumer1&#x2F;sport&#x2F;tennis&#x2F;+” 是不同的共享订阅，虽然他们有相同的共享名称。虽然它们可能以某种方式相关，但它们具有相同的共享名并不意味着它们之间存在特定关系。 共享订阅通过在 SUBSCRIBE 中使用共享订阅主题过滤器创建。当只有一个会话使用某个共享订阅时，共享订阅的行为就像非共享订阅一样，不同之处在于： 当与发布消息进行匹配时，不会考虑 $share 和 {ShareName} 部分的内容。 当订阅初次建立时不会有保留消息被发送至会话。保留消息会在其发布时像其他匹配消息一样被发送到会话。 一旦共享订阅存在，其他会话都可以使用同样的共享订阅主题过滤器加入订阅。新的会话将成为此共享订阅新关联的订阅者。保留消息不会发送给新的订阅者。之后每个匹配共享订阅的应用消息都会发给共享订阅的订阅者中的有且仅有一个的某个会话。 会话可以通过发送包含完整共享订阅主题过滤器的 UNSUBSCRIBE 包来显式的退出共享订阅。当会话终止时也会退出共享订阅。 共享订阅只要与至少一个会话关联（即已向其主题过滤器发出成功的订阅请求但尚未完成相应的取消订阅的会话），就会持续存在。当最初创建共享订阅的会话取消订阅时，共享订阅将继续存在，除非其取消时共享订阅中已经没有其他的会话。当不再有任何会话订阅共享订阅时，共享订阅就会结束，并且与其关联的任何未传递的消息都将被删除。 共享订阅注意事项 如果有超过一个会话加入了共享订阅，服务器实现在每一条消息上都有自由选择使用哪个会话，并有自由制定选择会话的标准。 不同的订阅客户端可以在其 SUBSCRIBE 中请求不同的 QoS 等级。服务器可以决定向每个客户端授权的最大 QoS 等级，而且服务器被允许向不同的订阅者授予不同的 QoS 等级。当向客户端发送应用消息时，服务器必须遵守客户端订阅时授予的 QoS 等级 [MQTT-4.8.2-3]，就像服务器向订阅者发布消息一样。 如果服务器正在向其选择的客户端发送 QoS 2 消息，而客户端的连接在消息完成前断开了，服务器必须在客户端重新连接时完成该消息的交付 [MQTT-4.8.2-4]，如同 4.3.3 中的描述。如果该客户端的会话在其重连成功前终止了，服务器必须不将此应用消息发送给其他的订阅客户端 [MQTT-4.8.2-5]。 如果服务器正在向其选择的客户端发送 QoS 1 消息，而在收到回复前客户端的连接中止了，服务器可以等待客户端重连之后重传消息给客户端。如果该客户端的会话在其重连成功前终止了，服务器应该将此应用消息发给此共享订阅中的其他客户端。一旦失去与第一个客户端的连接，服务器就可以尝试将消息发送到另一个客户端。 如果客户端使用带有 0x80 或更大原因码的 PUBACK 或 PUBREC 响应来自服务器的 PUBLISH 包，服务器必须丢弃应用消息，并且不再尝试将消息发给其他订阅者 [MQTT-4.8.2-6]。 客户端被允许在同一个会话上已经存在共享订阅的情况下向此共享订阅发送第二个 SUBSCRIBE 请求。例如，客户端这样做也许是为了修改订阅请求的 QoS 或是由于客户端不确定上一次连接断开前是否已经完成了订阅。这个操作不会增加会话与共享订阅的关联次数，因此只需发送一个 UNSUBSCRIBE 包会话即可离开共享订阅。 每个共享订阅都独立于其他共享订阅。可以有两个过滤器一致的共享订阅。在这种情况下，消息会同时匹配到两个共享订阅并且由他们各自处理。如果客户端同时使用了共享订阅和非共享订阅，且消息和两个订阅都匹配，客户端会因为非共享订阅收到消息的副本。消息的第二个副本会被交付到共享订阅中的其中一个订阅者，这可能会导致此客户端收到两份消息的副本。 4.9 流量控制客户端和服务器通过使用 3.1.2.11.3 和 3.2.2.3.3 中描述的接受最大值来控制其接收并未处理的 PUBLISH 包的数量。接受最大值创建了一个限制消息的发送配额，用来限制 QOS &gt; 0 的 PUBLISH 包，可以是未收到 PUBACK （针对 QoS 1）或未收到 PUBCOMP（针对 QoS 2）的 PUBLISH 包。PUBACK 和 PUBCOMP 会按照下述方式补充配额。 客户端或服务器必须将其发送配额初始化为不超过接收最大值的非零值 [MQTT-4.9.0-1]。 每当客户端或服务器发送 QoS &gt; 0 的 PUBLISH 包，降低配额。如果发送配额值达到 0，客户端或服务器必须不再发送任何 QoS &gt; 0 的 PUBLISH 包 [MQTT-4.9.0-2]。他可以继续发送 QoS 值为 0 的 PUBLISH 包，或是可以选择同样暂停发送这些包。即使配额值为 0，客户端和服务器必须继续处理和响应其他类型的 MQTT 包 [MQTT-4.9.0-3]。 发送配额加 1： 每当收到 PUBACK 包或 PUBCOMP 包，无论 PUBACK 包或 PUBCOMP 包是否携带错误码。 每当收到带有原因码大于等于 0x80 的 PUBREC 包。 如果发送配额已等于初始发送配额，则不会增加。尝试增加超过初始发送配额可能是由于建立新的网络连接后重新传输 PUBREL 数据包造成的。 参考 3.3.4 的描述了解当客户端或服务器发送的 PUBLISH 包超过被允许的接受最大值后会如果反应。 发送配额和接受最大值不会跨网络连接保留，而是如上文所述在每个新的网络连接中重新初始化。他们不是会话状态的一部分。 4.10 请求 &#x2F; 响应有些应用程序或是标准可能希望通过 MQTT 实现请求&#x2F;响应式的交互。此版本的 MQTT 包括了四个可以用于实现此目的的属性： 响应主题，参考 3.3.2.3.5 关联数据，参考 3.3.2.3.6 请求响应信息，参考 3.1.2.11.6 响应信息，参考 3.2.2.3.15 随后的非规范性章节描述了如何使用这些属性。 客户端通过发送带有 3.3.2.3.5 中描述的响应主题的应用消息来发送请求。请求中可以包括在 3.3.2.3.6 中描述的关联数据。 4.10.1 基础请求响应（非规范性）请求&#x2F;响应交互过程如下： 一个 MQTT 客户端（请求方）向主题发送请求信息。请求信息指带有响应主题的应用消息。 另一个 MQTT 客户端（响应方）已经订阅了请求方发布时所用的主题，因此收到了请求消息。可能会有多个响应方订阅了此主题，也可能没有。 响应方根据请求消息采取适当的操作，然后向请求消息中携带的响应主题中的主题名称发布响应消息。 在通常用法中，请求者已经订阅了响应主题，从而接收响应消息。然而，其他客户端可能也订阅了响应主题，因此响应消息也会由这些客户端接收和处理。与请求消息一样，响应消息的主题可以被多个客户端订阅，也可能没有客户端订阅。 如果请求消息包含关联数据，响应方会在响应信息中复制此数据，这些数据被响应消息的接收方用来将响应消息和原始请求进行关联。响应消息不包括响应主题属性。 如果请求消息包含关联数据属性，则响应方将此属性复制到响应消息中，并且响应消息的接收方使用该属性将响应消息与原始请求关联起来。 响应消息不包括响应主题属性。 MQTT 服务器转发请求消息中的响应主题和关联数据，以及响应消息中的关联数据。服务器将请求消息和响应消息当作其他应用消息一样对待。 请求方往往在发布请求消息之前就订阅响应主题。如果当响应消息发布时响应主题没有订阅者，响应消息将不会被交付到任何客户端。 请求消息和响应消息可以使用任意等级的 QoS，且响应方可以使用一个会话过期间隔非 0 的会话。通常来说会先确认响应方在线，然后使用 QoS 0 等级发送请求消息。当然，这不是必须的。 响应方可以使用共享订阅来创建响应客户端池。但请主题，使用共享订阅时，消息在多个客户端之间的交付顺序是无法保证的。 请求者有责任确保其具有发布请求主题以及订阅其设置的响应主题的必要权限。响应者有责任确保其有订阅请求主题和发布到响应主题的权限。虽然主题授权不在本规范范围内，但建议服务器实现此类授权。 4.10.2 确定响应主题的值（非规范性）请求方可以使用任何方式（包括本地配置）确定响应主题的主题名称。为了避免不同请求方之间的冲突，最好能确保请求方使用的响应主题对于该客户端来说是唯一的。由于请求方和响应方通常需要获得这些主题的授权，使用随机主题名称对于授权来说可能是个挑战。 为了帮助解决这个问题，本规范在 CONNACK 数据包中定义了一个称为响应信息的属性。服务器可以使用此属性来指导客户端选择要使用的响应主题。该机制对于客户端和服务器都是可选的。在连接时，客户端通过设置 CONNECT 数据包中的请求响应信息属性来请求服务器发送响应信息。之后服务器会在 CONNACK 数据包中发送响应信息属性（格式为 UTF-8字符串）。 本规范没有定义响应信息的内容，但它可用于传递主题树的全局唯一部分，该部分至少在其会话的生命周期内为该客户端保留。使用此机制允许此配置在服务器中完成一次，而不是在每个客户端中完成。 参考 3.1.2.11.6 了解关于响应信息的定义。 4.11 服务重定向服务器可以通过发送带有原因码 0x9C（使用另一台服务器）或 0x9D（服务器迁移）的 CONNACK 包或 DISCONNECT 包通知客户端使用另一台服务器，参考 4.13 中的描述。当发送这类的原因码时，服务器可以包括服务引用属性，用来携带客户端应该使用的服务器地址。 原因码 0x9C（使用另一台服务器）表示客户端应该临时性的切换到另一台服务器。另一台服务器要么是客户端已知的，要么是写在服务引用中。 原因码 0x9D（服务器迁移）表示客户端应该永久性的切换到另一台服务器。另一台服务器要么是客户端已知的，要么是写在服务引用中。 服务引用是 UTF-8字符串。其值是空格分隔引用列表。引用的格式不在此处规范。 非规范性评论 建议每个引用都包含一个名称，其后可选的包含冒号和端口号。如果名称包含冒号，则名称字符串可以括在方括号内（’[‘和’]‘）。方括号括起来的名称不能包含右方括号 (‘]‘) 字符。这用于表示使用冒号分隔符的 IPv6 文字地址。 这是 RFC3986 中描述的 URI 授权的简化版本。 非规范性评论 服务引用中的名称通常表示主机名、DNS 名称 RFC1035、SRV 名称 RFC2782 或文字 IP 地址。冒号分隔符后面的值通常是十进制的端口号。如果端口信息来自名称解析（例如使用 SRV）或者是默认的，无需携带端口号。 非规范性评论 如果提供多个服务引用，则期望客户选择其中之一。 非规范性评论 服务引用的例子： myserver.xyz.org myserver.xyz.org:8883 10.10.151.22:8883 [fe80::9610:3eff:fe1c]:1883 4.12 增强认证MQTT CONNECT 包支持使用用户名和密码字段对网络连接进行基本身份验证。虽然这些字段是为简单的密码身份验证而命名的，但它们可用于携带其他形式的身份验证，例如传递 token。 增强认证扩展了这种基础的认证方式，添加了挑战&#x2F;响应式的认证。他可能涉及在 CONNECT 后， CONNACK 前，在客户端和服务器之间交换 AUTH 数据包。 为了开始增强认证，客户端需要在 CONNECT 包属性集中携带认证方式属性。他选择了需要使用的认证方式。如果服务器不支持客户端提供的认证方式，服务器可以发送带有原因码 0x8C（认证方式错误）或原因码 0x87（未经授权）的 CONNACK 包，并必须关闭网络连接，参考 4.13 中的描述 [MQTT-4.12.0-1]。 认证方法是客户端和服务器之间就 CONNECT 数据包中的认证数据和其他字段的含义、以及完成认证所需的客户端和服务器交换和处理达成的协议。 非规范性评论 通常情况下，认证方法采用 SASL 机制，使用注册名称有助于相互交流。但是，认证方法并不局限于使用注册的 SASL 机制。 如果客户端选择的认证方法规定客户端先发送数据，则客户端应在 CONNECT 数据包中包含认证数据属性。该属性可用于根据认证方法提供数据。认证数据的内容由认证方法定义。 如果服务器需要额外信息来完成认证，他可以向客户端发送一个 AUTH 数据包。此数据包必须包含原因码 0x18（继续认证） [MQTT-4.12.0-2]。如果认证方法要求服务器向客户端发送认证数据，则会在认证数据属性中发送。 客户端通过发送另一个 AUTH 包来响应来自服务器的 AUTH 包。此包必须包含原因码 0x18（继续认证） [MQTT-4.12.0-3]。如果认证方法要求客户端向服务器发送认证数据，则会在认证数据属性中发送。 客户端和服务器会根据需要交换 AUTH 数据包，直到服务器通过发送原因码为 0 的 CONNACK 包接受认证。如果接受认证需要向客户端发送数据，则会在认证数据属性中发送。 客户端可以在认证过程中的任何时候关闭连接。他可以在此之前发送一个 DISCONNECT 数据包。服务器可以在认证过程的任何点拒绝认证。他可以根据 4.13 的描述发送一个原因码为 0x80 或以上的 CONNACK 数据包，并必须关闭网络连接 [MQTT-4.12.0-4]。 如果初始 CONNECT 包包含认证方法，则所有 AUTH 包和任何成功的 CONNACK 包都必须包含和 CONNECT 包中相同值的 认证方法 [MQTT-4.12.0-5]。 增强认证的实现对于客户端和服务器都是可选的。如果客户端没有在 CONNECT 包中包含认证方法，则服务器必须不发送 AUTH 包，也必须不在 CONNACK 包中包含认证方法 [MQTT-4.12.0-6]。如果客户端没有在 CONNECT 包中包含认证方法，则客户端必须不向服务器发送 AUTH 包 [MQTT-4.12.0-7]。 如果客户端没有在 CONNECT 包中包含认证方法属性，服务器应该使用 CONNECT 数据包、TLS 会话和网络连接中的一些或所有信息进行认证。 SCRAM挑战的非规范性示例 客户端到服务器：CONNECT Authentication Method&#x3D;”SCRAM-SHA-1” Authentication Data&#x3D;client-first-data 服务器到客户端：AUTH rc&#x3D;0x18 Authentication Method&#x3D;”SCRAM-SHA-1” Authentication Data&#x3D;server-first-data 客户端到服务器：AUTH rc&#x3D;0x18 Authentication Method&#x3D;”SCRAM-SHA-1” Authentication Data&#x3D;client-final-data 服务器到客户端：CONNACK rc&#x3D;0 Authentication Method&#x3D;”SCRAM-SHA-1” Authentication Data&#x3D;server-final-dataNon-normative example showing a SCRAM challenge Kerberos挑战的非规范性示例 客户端到服务器：CONNECT Authentication Method&#x3D;”GS2-KRB5 服务器到客户端：AUTH rc&#x3D;0x18 Authentication Method&#x3D;”GS2-KRB5 客户端到服务器：AUTH rc&#x3D;0x18 Authentication Method&#x3D;”GS2-KRB5” Authentication Data&#x3D;initial context token 服务器到客户端：AUTH rc&#x3D;0x18 Authentication Method&#x3D;”GS2-KRB5” Authentication Data&#x3D;reply context token 客户端到服务器：AUTH rc&#x3D;0x18 Authentication Method&#x3D;”GS2-KRB5 服务器到客户端：CONNACK rc&#x3D;0 Authentication Method&#x3D;”GS2-KRB5” Authentication Data&#x3D;outcome of authentication 4.12.1 重新认证如果客户端在 CONNECT 包中提供了认证方法，则可以在收到 CONNACK 后随时启动重新认证。通过发送原因码为 0x19（重新认证）的 AUTH 包来实现。客户端必须将认证方法设置为与最初用于认证网络连接的认证方法相同的值 [MQTT-4.12.1-1]。如果认证方法要求客户端先发送数据，则此 AUTH 数据包通过认证数据属性携带第一份数据。 服务器通过发送原因码为 0x00（成功）的 AUTH 包来响应此重新认证请求，表示重新认证已完成，或原因码为 0x18（继续认证）来表示需要更多认证数据。客户端可以通过发送原因码为 0x18（继续认证）的 AUTH 数据包来响应并提供额外的认证数据。此流程像初始认证一样继续进行，直到重新认证完成或重新认证失败。 如果重新认证失败，客户端或服务器应该带有合适原因码的 DISCONNECT 包，且必须断开网络连接，参考 4.13 中的描述 [MQTT-4.12.1-2]。 在重新认证过程中，客户端和服务器之间的其他数据包流可以继续使用之前的认证方式。 非规范性评论 服务器可能会通过拒绝重新认证来限制客户端在重新认证中可以尝试的更改范围。例如，如果服务器不允许更改用户名，它可以拒绝任何更改用户名的重新认证尝试。 4.13 错误处理4.13.1 格式错误的包和协议错误格式错误的包和协议错误的定义包含在 1.2 术语表中，一些，但不是全部的此类错误在整个规范中都有著名。客户端或服务器检查收到 MQTT 包的严格程度是下列各项的折中： 客户端或服务器的实现规模。 实现所支持的功能。 接收方信任发送方发送正确 MQTT 包的程度。 接收方信任网络正确传递 MQTT 包的程度。 继续处理错误包带来的后果。 如果发送方符合此规范，他将不会发送格式错误的包或造成协议错误。然而，如果客户端在收到 CONNACK 前发送 MQTT 包，可能会导致协议错误因为他可能对服务器的能力做了错误的假设。参考 3.1.4 CONNECT动作。 用于格式错误的包和协议错误的原因码包括： 0x81 格式错误的包 0x82 协议错误 0x93 超出接收最大值 0x95 包过大 0x9A 不支持保留消息 0x9B 不支持的 QoS 0x9E 不支持共享订阅 0xA1 不支持订阅ID 0xA2 不支持通配符订阅 当客户端检测到格式错误的包或协议错误，且给出了规范中的原因码后，他应该关闭网络连接。当错误发生在 AUTH 包中时，他可以发先发送包含原因码的DISCONNECT包，再关闭网络连接。当错误发生在任何其他种类的包时，他应该发送带有原因码的 DISCONNECT 包，再关闭网络连接。可以使用原因码 0x81（格式错误的包）或 0x82（协议错误）或是 3.14.2.1 中定义的更详细的断开原因。 当服务器检测到格式错误的包或协议错误，且给出了规范中的原因码后，他必须断开网络连接 [MQTT-4.13.1-1]。如果错误发生在 CONNECT 包中，服务器可以发送带有原因码的 CONNACK 包，再关闭网络连接。当错误发生在任何其他种类的包时，他应该发送带有原因码的 DISCONNECT 包再关闭网络连接。可以使用原因码 0x81（格式错误的包）或 0x82（协议错误）或是 3.2.2.2 中定义的连接原因码或是 3.14.2.1 中定义的更详细的断开原因码。对其他会话没有影响。 如果服务器和客户端都没有对 MQTT 包进行检查，可能导致错误无法被测出，从而可能造成对数据的伤害。 4.13.2 其他错误除了格式错误的包和协议错误外，发送方无法提前预见其他错误，因为接收方可能存在一些限制条件，而这些限制条件未通知给发送方。录入，接收方的客户端或服务器可能会遇到瞬态错误，如内存不足，从到导致某个 MQTT 包处理失败。 带有 0x80 或更高原因码的确认包 PUBACK、PUBREC、PUBREL、PUBCOMP、SUBACK、UNSUBACK 表示由包ID标识的已接收包存在错误。此错误不会影响其他会话或同一会话中的其他包。 CONNACK 和 DISCONNECT 包允许使用原因码为 0x80 或更高来指示网络连接将被关闭。如果指定了 0x80 或更高的原因码，则无论是否发送了 CONNACK 或 DISCONNECT 包，都必须关闭网络连接 [MQTT-4.13.2-1]。发送这些原因码中的任何一个不会对任何其他会话产生影响。 如果 MQTT 包包含多个错误，接收方可以按任意顺序验证包，并对发现的任何错误采取适当的措施。 参考 5.4.9 了解关于处理禁止的 Unicode 码段的信息。 5 安全性（非规范性）5.1 介绍MQTT 是一种消息传输的传输协议规范，允许其实现选择网络、隐私、身份验证和授权技术。由于所选的具体安全技术将根据具体情况而定，因此实现者有责任在其设计中包含适当的功能。 MQTT 实现很可能需要紧跟不断变化的安全形势。 本章提供了一些通用的实现指导，为了不限制可做的选择，本章是非规范性的。但这不影响本章的重要性。 强烈建议提供了 TLS RFC5246 实现的服务器应使用 TCP 端口 8883（IANA 服务名：secure-mqtt）。 存在多种解决方案提供商需要考虑的威胁。例如： 设备可能被入侵 静态数据可能被访问 协议行为可能存在副作用（例如 “定时攻击”） 拒绝服务（DoS）攻击 通信可能会被拦截、篡改、重定向或泄露 注入伪造的 MQTT 包 MQTT 解决方案通常部署在具有潜在威胁的通信环境中。在这种情况下，实施方案通常需要提供以下机制： 用户和设备的身份验证 访问服务器资源的授权 MQTT包和应用程序数据的完整性 MQTT包和应用程序数据的隐私 除了技术安全问题之外，还可能存在地理（例如，美国-欧盟隐私盾框架 USEUPRIVSH）、行业特定（例如，支付卡行业数据安全标准 PCIDSS）和监管方面的考虑（例如，萨班斯-奥克斯利法案 SARBANES）。 5.2 MQTT解决方案：安全和认证实现 MQTT 解决方案时，可能需要符合特定的行业安全标准，例如美国国家标准与技术研究院网络安全框架 (NIST Cyber Security Framework) NISTCSF、支付卡行业数据安全标准 (PCI-DSS) PCIDSS、联邦信息处理标准 140-2 (FIPS-140-2) FIPS1402 和美国国家安全局套件 B (NSA Suite B) NSAB。 关于在 NISTCSF 中使用 MQTT 的指南，可以在 MQTT 补充出版物《MQTT 和 NIST 关键基础设施网络安全改进框架》MQTTNIST 中找到。使用经过行业验证、独立验证和认证的技术将有助于满足合规性要求。 5.3 轻量级密码学和受限设备高级加密标准 AES 是目前最广泛采用的加密算法。许多处理器都支持硬件加速 AES，但嵌入式处理器通常不支持。CHACHA20 加密算法在软件中加密和解密的速度要快得多，但没有 AES 那么广泛使用。 ISO29192 针对性能受限的 “低端” 设备，推荐了一些专门调整过的密码原语。 5.4 实施说明MQTT 实施和使用时需要考虑多个安全方面。以下部分并不应该被视为 “检查清单”。 实现可能希望实现以下部分或全部内容： 5.4.1 服务器对客户端进行身份验证CONNECT 包包含用户名和密码字段。实现可以选择如何利用这些字段的内容。实现可以提供自己的认证机制，使用类似 LDAP RFC4511 或 OAuth RFC6749 token 之类的外部认证系统，或借用操作系统的认证机制。 MQTT v5.0 提供了增强认证机制，参考 4.12 中的描述。使用此机制需要客户端和服务器同时支持。 以明文传递认证数据，混淆此类数据元素或是不需要身份验证数据的实现应该意识到这可能会引起中间人攻击和数据重放攻击。5.4.5 介绍了确保数据隐私的方法。 客户端和服务器之间的虚拟专用网络 (VPN) 可以确保数据仅从授权客户端接收。 当使用 TLS RFC5246 时，服务器可以使用客户端发送的 TLS 证书对客户端进行认证。 实现可能允许使用客户端发送到服务器的应用消息进行身份认证。 5.4.2 服务器对客户端进行授权如果客户端已成功通过身份验证，服务器实现应在接受其连接之前检查其是否已获得授权。 授权可能基于客户端提供的信息，例如用户名、客户端的主机名&#x2F;IP 地址或身份验证机制的结果。 特别是，实现应检查客户端是否有权使用客户端ID，因为这可以访问 MQTT 会话状态（4.1 中描述）。此授权检查是为了防止一个客户端意外或恶意地使用已被其他客户端使用的客户端ID的情况。 实现应该提供在 CONNECT 之后发生的访问控制，以限制客户端发布到特定主题或使用特定主题过滤器订阅的能力。实现应考虑限制对具有广泛范围的主题过滤器的访问，例如 # 主题过滤器。 5.4.3 客户端对服务器进行身份验证MQTT 协议不是信任对称的。在使用基本身份验证的情况下，没有客户端对服务器进行身份验证的机制。某些增强认证确实允许进行相互身份验证。 在使用 TLS RFC5246 的情况下，客户端可以使用服务器发送的 TLS 证书来对服务器进行身份验证。 从单个 IP 地址为多个主机名提供 MQTT 服务的实现应注意 RFC6066 第 3 节中定义的 TLS 服务器名称指示扩展 (Server Name Indication，SNI)。 这允许客户端告诉服务器它试图连接的服务器的主机名。 一些 MQTT 实现允许通过服务器发送给客户端的应用消息进行身份验证。MQTT v5.0 引入了增强身份验证机制（详细见 4.12），该机制可以用于服务器对客户端进行身份验证。但前提是客户端和服务器都支持此机制。 客户端与服务器之间使用 VPN 可以增強客户端连接到预期的服务器的可信度。 5.4.4 应用消息和MQTT包的完整性应用程序可以独立地在其应用消息中包含哈希值。这可以在网络传输过程中和静止状态下提供发布数据包内容的完整性。 TLS RFC5246 提供了哈希算法来验证通过网络发送的数据的完整性。 使用 VPN 连接客户端和服务器可以提供 VPN 覆盖的网络部分的数据完整性。 5.4.5 应用消息和MQTT包的隐私TLS RFC5246 可以对通过网络发送的数据进行加密。一些有效的 TLS 密码套件包含不加密数据的 NULL 加密算法。为确保隐私，客户端和服务器应避免使用这些密码套件。 应用程序可以独立加密其应用消息的内容。这可以为应用消息在网络传输过程中和静止状态下提供隐私保护。但这并不能为应用消息的其他属性（例如主题名称）提供隐私保护。 客户端和服务器实现可以为静止数据（例如作为会话的一部分存储的应用程序消息）提供加密存储。 使用 VPN 连接客户端和服务器可以提供 VPN 覆盖的网络部分的数据隐私。 5.4.6 消息传输的不可否认性应用程序设计者可能需要考虑适当的策略来实现端到端的不可否认性。 5.4.7 检测客户端和服务器是否被入侵使用 TLS RFC5246 的客户端和服务器实现应提供功能，以确保在建立 TLS 连接时提供的任何 TLS 证书与连接的客户端或被连接的服务器的主机名相关联。 使用 TLS 的客户端和服务器实现可以选择提供检查证书吊销列表 (CRL RFC5280) 和在线证书状态协议 (OSCP RFC6960) 的功能，以防止使用已吊销的证书。 物理部署可能将防篡改硬件与应用消息中特定数据的传输相结合。例如，仪表可能嵌入 GPS 以确保它不会在未经授权的位置使用。[IEEE8021AR](#1.4-IEEE 802.1AR) 是使用加密绑定标识符实现设备身份验证机制的标准。 5.4.8 检测异常行为服务器实现可以监控客户端行为以检测潜在的安全事件。例如： 重复连接尝试 重复身份验证尝试 异常终止连接 主题扫描（尝试发送或订阅许多主题） 发送无法投递的消息（没有订阅者订阅该主题） 连接但不发送数据的客户端 服务器实现可能会关闭违反其安全规则的客户端的网络连接。 服务器实现检测到可疑行为可能会基于诸如 IP 地址或客户端标识符之类的标识符实施动态阻止列表。 部署可以使用网络级控制（如果可用）基于 IP 地址或其他信息实施速率限制或阻止。 5.4.9 处理禁止的Unicode码段1.5.4 描述了禁止的 Unicode 码段，这些码段不应包含在 UTF-8 编码的字符串中。客户端或服务器实现可以选择是否验证这些码段未在 UTF-8字符串（例如主题名称或属性）中使用。 如果服务器不验证 UTF-8字符串 中的码段，但订阅的客户端会验证，则第二个客户端可能能够通过发布包含禁止的 Unicode 码段的主题名称或使用属性来导致订阅客户端关闭网络连接。本节建议采取一些步骤来防止此问题。 当客户端验证载荷是否与载荷格式标志匹配而服务器不验证时，可能会发生类似的问题。对此的考虑和补救措施类似于处理禁止的 Unicode 码段的措施。 5.4.9.1 关于使用禁止的Unicode码段的考虑通常，实现会选择验证 UTF-8字符串，检查是否未使用禁止的Unicode码段。这样可以避免实现面对以下难题，例如需要使用对这些码段铭感的库，或是避免了应用程序需要处理这些码段。 验证是否未使用这些码段可以消除一些安全风险。一些可能的安全漏洞是利用日志文件中的控制字符来掩盖日志中的条目或混淆处理日志文件的工具。Unicode Noncharacters 通常用作特殊标记，允许它们进入 UTF-8字符串可能会导致此类漏洞利用。 5.4.9.2 发布者和订阅者之间的交互发布应用程序消息的发布者通常期望服务器将消息转发给订阅者，并且这些订阅者能够处理消息。 以下是一些发布客户端可能导致订阅客户端关闭网络连接的条件： 发布客户端使用包含禁止的Unicode码段的主题名称发布应用程序消息。 发布客户端库允许在主题名称中使用禁止的Unicode码段，而不是拒绝他。 发布客户端被授权发送发布。 订阅客户端被授权使用匹配主题名称的主题过滤器。请注意，禁止的Unicode码段可能出现在主题名称的一部分，该部分与主题过滤器中的通配符字符匹配。 服务器将消息转发给匹配的订阅者，而不是断开发布者的连接。 在这种情况下，订阅客户端可能： 关闭网络连接，因为它不允许使用禁止的Unicode码段，可能在这样做之前发送 DISCONNECT 消息。对于 QoS 1 和 QoS 2 消息，这可能导致服务器再次发送消息，导致客户端再次关闭网络连接。 通过在 PUBACK (QoS 1) 或 PUBREC (QoS 2) 中发送大于或等于 0x80 的原因码来拒绝应用程序消息。 接受应用程序消息，但无法处理它，因为它包含禁止的Unicode码段。 成功处理应用程序消息。 客户端关闭网络连接的可能性可能直到发布者使用一个禁止的Unicode码段点才会被注意到。 5.4.9.3 补救措施如果存在将禁止的Unicode码段包含在主题名称或传递给客户端的其他属性中的可能性，解决方案所有者可以采用以下建议之一： 将服务器实现更改为拒绝禁止的Unicode码段的 UTF-8字符串 的实现，服务器可以通过发送大于或等于 0x80 的原因代码或关闭网络连接来拒绝这些消息。 将订阅者使用的客户端库更改为可以容忍禁止的Unicode码段的库。客户端可以处理或丢弃包含禁止的Unicode码段的 UTF-8字符串 的消息，只要它继续遵循协议即可。 5.4.10 其他安全注意事项证书安全: 如果客户端或服务器 TLS 证书丢失或被认为可能泄露，则应将其吊销（使用 CRL RFC5280 和&#x2F;或 OSCP RFC6960）。 丢失或被认为泄露的客户端或服务器身份验证凭证（例如用户名和密码）应予以撤销和&#x2F;或重新颁发。 长连接安全: 使用 TLS RFC5246 的客户端和服务器实现应允许会话重新协商以建立新的加密参数（替换会话密钥、更改密码套件、更改身份验证凭证）。 服务器可能会关闭客户端的网络连接，并要求他们使用新凭证重新验证身份。 服务器可能要求其客户端使用 4.12.1 节中描述的机制定期重新验证身份。 受限设备和受限网络上的客户端可以使用 TLS RFC5246 会话恢复，以降低重新连接 TLS RFC5246 会话的成本。 连接到服务器的客户端与连接到同一服务器并具有在相同主题上发布数据的权限的其他客户端具有传递信任关系。 5.4.11 使用SOCKS代理客户端实现应该注意，某些环境需要使用 SOCKSv5 RFC1928 代理进行外部网络连接。一些 MQTT 实现可以通过使用 SOCKS，利用替代的安全隧道（例如 SSH）进行连接。如果实现选择使用 SOCKS，他们应该支持匿名和用户名&#x2F;密码认证的 SOCKS 代理。后一种情况下，实现应该注意 SOCKS 认证可能以明文进行，因此应避免使用与连接 MQTT 服务器相同的凭证。 5.4.12 安全配置实现者和解决方案设计人员可以将安全性视为一组可应用于 MQTT 协议的配置。下面展示了分层安全体系结构的一个示例。 5.4.12.1 透明通信配置这种配置没有额外的安全机制，MQTT 协议直接运行在开放网络上。 5.4.12.2 安全网络通信配置这种配置使用具有安全控制措施的物理或虚拟网络，例如 VPN 或物理安全网络。 5.4.12.3 安全传输配置当使用安全传输配置时，MQTT 协议运行在一个物理网络或是虚拟网络中，使用 TLS RFC5246 加密 MQTT 协议传输，提供身份验证、完整性保护和隐私保护。 TLS RFC5246 客户端身份验证可以作为用户名和密码字段提供的 MQTT 客户端身份验证的补充或替代使用。 5.4.12.4 行业特定的安全配置预计 MQTT 协议将被设计到行业特定的应用配置中，每个配置都定义了一个威胁模型和用于解决这些威胁的具体安全机制。特定安全机制的建议通常会参考现有工作，包括： NISTCSF NIST 网络安全框架NIST7628 NISTIR 7628 智能电网网络安全指南FIPS1402 安全模块的安全要求 (FIPS PUB 140-2)PCIDSS PCI-DSS 支付卡行业数据安全标准NSAB 美国国家安全局 Suite B 加密 6 使用WebSocket作为传输层如果 MQTT 通过 WebSocket RFC6455 连接进行传输，则适用以下条件： MQTT 包必须在 WebSocket 二进制数据帧中发送。 如果收到任何其他类型的数据帧，接收方必须关闭网络连接 [MQTT-6.0.0-1]。 单个 WebSocket 数据帧可以包含多个或部分 MQTT 包。 接收方不得假定 MQTT 包与 WebSocket 帧边界对齐 [MQTT-6.0.0-2]。 客户端必须在其提供的 WebSocket 子协议列表中包含“mqtt” [MQTT-6.0.0-3]。 服务器选择并返回的 WebSocket 子协议名称必须为“mqtt” [MQTT-6.0.0-4]。 用于连接客户端和服务器的 WebSocket URI 对 MQTT 协议没有影响。 6.1 IANA注意事项本规范要求 IANA 修改 “WebSocket 子协议名称” 注册表下 WebSocket MQTT 子协议的注册，并使用以下数据： 图 6.6‑1 - IANA WebSocket Identifier Subprotocol Identifiermqtt Subprotocol Common Namemqtt Subprotocol Definitionhttp://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html 7 一致性MQTT 规范定义了 MQTT 客户端实现和 MQTT 服务器实现的一致性。 MQTT 实现既可以作为 MQTT 客户端，也可以作为 MQTT 服务器。 7.1 一致性条款7.1.1 MQTT服务器一致性条款服务器的定义请参考术语表中的 服务器。 一个 MQTT 服务器仅在满足以下所有陈述时才符合本规范： 服务器发送的所有 MQTT 包的格式必须与 第 2 章 和 第 3 章 描述的格式相匹配。 它遵循第 4.7 节 描述的主题匹配规则和第 4.8 节 描述的订阅规则。 它满足以下章节中已标识的必须级别要求，但仅适用于客户端的除外： 第一章 - 简介 第二章 - MQTT包格式 第三章 - MQTT包 第四章 - 操作行为 第六章 - 使用WebSocket作为传输层 不需要使用规范之外定义的任何扩展即可与任何其他符合标准的实现进行互操作。 7.1.2 MQTT客户端一致性条款客户端的定义请参考术语表中的 客户端。 MQTT 客户端仅在满足以下所有陈述时才符合本规范： 客户端发送的所有 MQTT 包的格式必须与第 2 章 和 第 3 章描述的格式相匹配。 客户端必须满足以下章节中已标识的必须级别要求，但仅适用于服务器的除外： 第一章 - 简介 第二章 - MQTT包格式 第三章 - MQTT包 第四章 - 操作行为 第六章 - 使用WebSocket作为传输层 不需要使用规范之外定义的任何扩展即可与任何其他符合标准的实现进行互操作。 附录 A. 致谢MQTT 技术委员会 (TC) 特别感谢 MQTT 协议的最初发明者 Andy Stanford-Clark 博士和 Arlen Nipper，以及他们对标准化过程的持续支持。 技术委员会感谢 Brian Raymor (前微软员工)，他在 5.0 版本标准的大部分开发过程中担任 MQTT 技术委员会的联合主席。 以下个人是 OASIS 技术委员会在创建本标准期间的成员，他们的贡献得到了热烈的认可： 参与者： Senthil Nathan Balasubramaniam (Infiswift) Dr. Andrew Banks, 编辑 (IBM) Ken Borgendale, 编辑 (IBM) Ed Briggs, 编辑 (微软) Raphael Cohn (个人) Richard Coppen, 主席 (IBM) William Cox (个人) Ian Craggs , 秘书 (IBM) Konstantin Dotchkoff (微软) Derek Fu (IBM) Rahul Gupta, 编辑 (IBM) Stefan Hagen (个人) David Horton (Solace Systems) Alex Kritikos (Software AG, Inc.) Jonathan Levell (IBM) Shawn McAllister (Solace Systems) William McLane (TIBCO Software Inc.) Peter Niblett (IBM) Dominik Obermaier (dc-square GmbH) Nicholas O’Leary (IBM) Brian Raymor (微软) Andrew Schofield (IBM) Tobias Sommer (Cumulocity) Joe Speed (IBM) Dr Andy Stanford-Clark (IBM) Allan Stockdill-Mander (IBM) Stehan Vaillant (Cumulocity) 有关对 MQTT 早期版本做出贡献的人员列表，请参考 MQTT v3.1.1 规范 MQTTV311 的附录 A。 附录 B. 强制性规范性声明（非规范性）本附录是非规范性的，是作为本文档主体中编号的一致性声明的方便摘要而提供的。有关一致性要求的明确列表，请参阅第 7 章。 规范性声明编号 规范性声明 [MQTT-1.5.4-1] 在 UTF-8 编码字符串中的字符必须为 [Unicode] 和 [RFC3629] 中所定义的，格式正确的字符编码。必须不使用U+D800 至 U+DFFF之间的编码 [MQTT-1.5.4-2] UTF-8 编码字符串必须不包含空字符 U+0000 [MQTT-1.5.4-3] 无论 UTF-8 编码序列 0xEF 0xBB 0xBF 出现在字符串的何处，他永远被解释为 U+FEFF (0宽无换行空格) 而且必须不能被数据包的接收者跳过或剥离 [MQTT-1.5.5-1] 变长整数编码时必须使用能够表示数字值的最小长度来进行编码 [MQTT-1.5.7-1] UTF-8字符串对中的两个字符串都必须遵守 UTF-8 字符串的需求 [MQTT-2.1.3-1] 当一个比特位被标记为 “保留” 时，他的意义被保留到未来使用而他的值必须按照下表设置 [MQTT-2.2.1-2] 当 PUBLISH 包的 QoS 值为 0 时，必须不包含 包ID 字段 [MQTT-2.2.1-3] 每当客户端发送新的 SUBSCRIBE 包，UNSUBSCRIBE 包 或 QoS &gt; 0 的 PUBLISH 包，必须携带一个非零且当前未被使用的包ID [MQTT-2.2.1-4] 每当服务器发送新的 QoS &gt; 0 的 PUBLISH 包，必须携带一个非零且当前未被使用的包ID [MQTT-2.2.1-5] PUBACK，PUBREC，PUBREL 或 PUBCOMP 包必须携带和 PUBLISH 相同的包ID [MQTT-2.2.1-6] SUBACK 和 UNSUBACK 必须携带和其对应的 SUBSCRIBE 和 UNSUBSCRIBE 包相同的包ID [MQTT-2.2.2-1] 如果没有属性，必须通过一个 0 值的属性长度来明确表示 [MQTT-3.1.0-1] 当客户端和服务器的网络连接建立后，客户端向服务器发送的第一个数据包必须是 CONNECT 包 [MQTT-3.1.0-2] 服务器必须将客户端发送的第二个 CONNECT 包视为协议错误并关闭网络连接 [MQTT-3.1.2-1] 协议名称必须是 UTF-8字符串表示的 “MQTT”。如果服务器不想接收此连接，同时又想告知客户端服务器是一个 MQTT 服务器，可以发送一个带有 0x84（协议版本不支持）原因码的 CONNACK，随后服务器必须关闭网络连接 [MQTT-3.1.2-2] 如果客户端使用的协议版本不为 5 而且服务器不想接受此 CONNECT 包，服务器可以发送一个带有 0x84（协议版本不支持）原因码的 CONNACK，随后服务器必须关闭网络连接 [MQTT-3.1.2-3] 服务器必须验证 CONNECT 包中的保留位的值是 0 [MQTT-3.1.2-4] 如果接收到全新开始值置为 1 的 CONNECT 包，客户端和服务器必须丢弃任何已经存在的会话并开始一个新的会话 [MQTT-3.1.2-5] 如果服务器接收到的 CONNECT 包中的全新开始被置为 0 并且服务器中已经存在和客户端ID关联的会话，服务器必须基于已经存在的会话状态恢复客户端的连接 [MQTT-3.1.2-6] 如果服务器接收到的 CONNECT 包中的全新开始被置为 0 并且服务器中没有和客户端ID关联的会话，服务器必须创建一个新的会话 [MQTT-3.1.2-7] 如果遗嘱标识被置为 1，则表示遗嘱消息必须被存储在服务器中，并且关联到此会话 [MQTT-3.1.2-8] 遗嘱消息必须在网络连接断开后的遗嘱延迟间隔时间过期后或会话结束时发布，除非由于服务器接收到一个带有 0x00（普通断开）原因码的 DISCONNECT 包从而删除了遗嘱消息，或是在遗嘱延迟间隔时间过期前接收了一个带有相同客户端ID的连接 [MQTT-3.1.2-9] 当遗嘱标识被置为 1 时，服务器需采用连接标志中的遗嘱 QoS 和遗嘱保留消息字段，载荷中必须包括遗嘱属性集、遗嘱主题和遗嘱载荷字段 [MQTT-3.1.2-10] 当服务器发布遗嘱后或服务器从客户端收到了原因码为 0x00（普通断开）的 DISCONNECT 包后，服务器必须从会话状态中删除遗嘱消息 [MQTT-3.1.2-11] 当遗嘱标识被置为 0 时，遗嘱 QoS 必须被置为 0（0x00） [MQTT-3.1.2-12] 当遗嘱标识被置为 1 时，遗嘱QoS的值可以是 0（0x00），1（0x01）或 2（0x02） [MQTT-3.1.2-13] 当遗嘱标识被置为 0 时，遗嘱保留消息的值必须被置为 0 [MQTT-3.1.2-14] 当遗嘱标识被置为 1 且遗嘱保留消息被置为 0 时，服务器必须将遗嘱消息作为一个非保留消息发布 [MQTT-3.1.2-15] 当遗嘱标识被置为 1 且遗嘱保留消息被置为 1 时，服务器必须将遗嘱消息作为一个保留消息发布 [MQTT-3.1.2-16] 当用户名标识被置为 0 时，载荷中必须不存在用户名 [MQTT-3.1.2-17] 当用户名标识被置为 1 时，载荷中必须存在用户名 [MQTT-3.1.2-18] 当密码标识被置为 0 时，载荷中必须不存在密码 [MQTT-3.1.2-19] 当密码标识被置为 1 时，载荷中必须存在密码 [MQTT-3.1.2-20] 如果保活时间不为 0 且没有任何其他需要发送的数据包，客户端必须发送 PINGREQ 包 [MQTT-3.1.2-21] 如果服务器在 CONNACK 中提供了服务器保活时间，则客户端必须采用服务器保活时间的值来替代自己发送的保活时间的值 [MQTT-3.1.2-22] 如果保活时间为非零值且服务器在 1.5 倍的保活时间内没有收到来自客户端的任何 MQTT 包，服务器必须断开到客户端的网络连接并视为网络连接故障 [MQTT-3.1.2-23] 当会话过期间隔的值大于 0 时，客户端和服务器都必须在网络连接断开后存储会话状态 [MQTT-3.1.2-24] 服务器必须不向客户端发送超过最大包尺寸的数据包 [MQTT-3.1.2-25] 当一个包因超过最大包尺寸而无法发送，服务器必须将其丢弃，并视为发送成功 [MQTT-3.1.2-26] 服务器必须不发送一个主题别名的值大于客户端设置的主题别名最大值的 PUBLISH 包 [MQTT-3.1.2-27] 如果主题别名最大值未设置或值为 0，服务器必须不向客户端发送主题别名 [MQTT-3.1.2-28] 此值为 0 表示服务器必须不在 CONNACK 中回复响应信息 [MQTT-3.1.2-29] 如果请求问题信息的值为 0，服务器可以在 CONNACK 或 DISCONNECT 包中携带原因字符串或用户属性，但必须不在除 PUBLISH，CONNACK，DISCONNECT 之外的包中携带原因字符串或用户属性 [MQTT-3.1.2-30] 如果客户端再 CONNECK 包中设置了认证方式，那么在其收到 CONNACK 包之前，客户端必须不发送除了 AUTH 和 DISCONNECT 包之外的任何类型的包 [MQTT-3.1.3-1] CONNECT 中的载荷包含了一个或多个 长度 + 内容 格式的字段，这些字段的存在与否由可变头中的标志位决定。这些字段的顺序是固定的，如果存在的话，必须按照 客户端ID，遗嘱属性集，遗嘱主题，遗嘱载荷，用户名，密码 这样的顺序出现 [MQTT-3.1.3-2] 客户端ID必须被客户端和服务器用于关联客户端和服务器之间的会话状态 [MQTT-3.1.3-3] 客户端ID必须作为 CONNECT 包载荷中的第一个字段出现 [MQTT-3.1.3-4] 客户端ID必须被编码为一个 UTF-8字符串 [MQTT-3.1.3-5] 服务器必须允许客户端ID是长度为 1 到 23 个字节之间的 UTF-8字符串，且仅包含下列字符：“0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ” [MQTT-3.1.3-6] 服务器可以允许客户端传递长度为 0 的客户端ID，当此情况发生时，服务器必须将此情况作为一个特殊情况对待，并为客户端分配一个唯一的客户端ID [MQTT-3.1.3-7] 服务器之后必须正常处理此 CONNECT 包，就如同客户端本身携带了这个唯一的客户端ID一样，而且必须在 CONNACK 包中返回这个分配的客户端ID [MQTT-3.1.3-8] 如果服务器拒绝了客户端ID，服务器可以使用一个带有原因码 0x85（客户端ID不可用）的 CONNACK 包作为对客户端 CONNECT 包的响应，如同 [4.13] 中描述的那样，之后服务器必须关闭网络连接 [MQTT-3.1.3-9] 如果在遗嘱延迟间隔结束前，该会话被新的网络连接延续，服务器必须不发送遗嘱 [MQTT-3.1.3-10] 服务器必须在发布遗嘱消息时维持用户属性的顺序 [MQTT-3.1.3-11] 遗嘱主题必须是一个 UTF-8字符串 [MQTT-3.1.3-12] 用户名必须是一个 UTF-8字符串 [MQTT-3.1.4-1] 服务器必须验证 CONNECT 包的格式符合 [3.1] 中的描述，如不符合则关闭网络连接 [MQTT-3.1.4-2] 服务器可以检查 CONNECT 包中的内容是否满足更进一步的限制要求，并且应该进行认证和授权检查。如果其中任何检查失败，服务器必须关闭网络连接 [MQTT-3.1.4-3] 如果客户端ID代表了一个已经连接到服务器的客户端，服务器参考 [4.13] 发送一个带有原因码 0x8E（会话被接管）的 DISCONNECT 包到当前已有连接的客户端，且必须关闭当前已有连接客户端的网络连接 [MQTT-3.1.4-4] 服务器必须参考 [3.1.2.4] 中的描述处理全新开始标识 [MQTT-3.1.4-5] 服务器必须使用带有原因码为 0x00（成功）的 CONNACK 回复 CONNECT 包 [MQTT-3.1.4-6] 如果服务器拒绝了 CONNECT，服务器必须不处理客户端在 CONNECT 包之后发送的任何除了 AUTH 以外的包 [MQTT-3.2.0-1] 服务器必须在发送除 AUTH 外的其他任何MQTT包之前使用带有响应码 0x00（成功）的 CONNACK 包回复客户端 [MQTT-3.2.0-2] 服务器必须不在一次网络连接中发送超过一个 CONNACK 包 [MQTT-3.2.2-1] Byte 1 是 “连接回复标识”。Bits 7-1 是保留字段，必须被置为 0 [MQTT-3.2.2-2] 如果服务器接收连接的全新开始标识被置为 1，服务器必须在带有 0x00（成功）的原因码的 CONNACK 包中将会话展示置为 0 [MQTT-3.2.2-3] 如果服务器接收到的连接中全新开始位被置为 0，且服务器持有对此客户端ID的会话状态，服务器必须在 CONNACK 包中将会话展示标识置为 1，其他情况下，服务器都必须在 CONNACK 包中将会话展示标识置为 0。这两种情况下服务器都必须在 CONNACK 中使用原因码 0x00（成功） [MQTT-3.2.2-4] 如果客户端不持有会话状态，且接收到的会话展示值为 1，客户端必须关闭网络连接 [MQTT-3.2.2-5] 如果客户端持有会话状态且收到的会话展示值为 0，如果客户端继续使用此网络连接，客户端必须丢弃会话状态 [MQTT-3.2.2-6] 如果服务器使用非 0 原因码的 CONNACK 包，服务器必须将会话展示的值置为 0 [MQTT-3.2.2-7] 如果服务器发送的 CONNACK 包带有一个值为 128 或更高的原因码，服务器必须随后关闭网络连接 [MQTT-3.2.2-8] 服务器发送的 CONNACK 必须使用下述之一的原因码 [MQTT-3.2.2-9] 如果服务器不支持 QoS 1 或 QoS 2 的 PUBLISH，服务器必须发送一个带有其可以支持的最大QoS的 CONNACK 包 [MQTT-3.2.2-10] 一个不支持 QoS 1 或 QoS 2 PUBLISH 的服务器必须依然接收包含 QoS 0、1 或 2 的 SUBSCRIBE 包 [MQTT-3.2.2-11] 如果客户端从服务器接收了最大QoS，客户端必须不发送QoS等级超过最大QoS的 PUBLISH 包 [MQTT-3.2.2-12] 如果服务器收到包含超过其能力的遗嘱QoS的 CONNECT 数据包，服务器必须拒绝连接。服务器应该回复带有原因码 0x9B（不支持的 QoS）的 CONNACK 包，参考 [4.13] 错误处理，且随后必须关闭网络连接 [MQTT-3.2.2-13] 如果服务器接收到的 CONNECT 包中包含遗嘱消息，且遗嘱保留消息的值为 1，同时服务器不支持保留消息，服务器必须拒绝此连接请求。服务器应该发送带有原因码 0x9A（不支持保留消息）的 CONNACK 且随后必须关闭网络连接 [MQTT-3.2.2-14] 一个收到了服务器发送的保留消息可用值为 0 的客户端，必须不发送带有保留消息标识为 1 的 PUBLISH 包 [MQTT-3.2.2-15] 客户端必须不向服务器发送超过最大包尺寸的数据包 [MQTT-3.2.2-16] 如果客户端使用长度为 0 的客户端ID连接，服务器必须使用带有分配的客户端ID的 CONNACK 回复。分配的客户端ID必须是一个当前所有会话都没有使用的全新ID [MQTT-3.2.2-17] 客户端必须不能发送一个主题别名的值大于服务器设置的主题别名最大值的 PUBLISH 包 [MQTT-3.2.2-18] 如果主题别名最大值未设置或值为 0，客户端必须不向服务器发送主题别名 [MQTT-3.2.2-19] 如果因为添加原因字符串会导致 CONNACK 的包尺寸超过了客户端限制的最大包尺寸，服务器必须不发送此属性 [MQTT-3.2.2-20] 如果添加该属性会导致 CONNACK 的包尺寸大于客户端设置的最大包尺寸，服务器必须不添加此属性 [MQTT-3.2.2-21] 如果服务器在 CONNACK 中发送了服务器保活时间，客户端必须使用此值代替其在 CONNECT 中发送的保活时间 [MQTT-3.2.2-22] 如果服务器没有设置服务器保活时间，服务器必须使用客户端在 CONNECT 包中设置的保活时间 [MQTT-3.3.1-1] 当客户端或服务器尝试重传 PUBLISH 包时，他们必须把重复标志置为 1 [MQTT-3.3.1-2] 对于 QoS 0 的消息，重复标识必须被置为 0 [MQTT-3.3.1-3] 转发的 PUBLISH 包的重复标识独立于接收的 PUBLISH 包，此值仅被本次转发包是否为重传独立决定 [MQTT-3.3.1-4] PUBLISH 包必须不能将 QoS 的两个 bit 都设置为 1 [MQTT-3.3.1-5] 当客户端向服务器发送的 PUBLISH 包中的保留消息被置为 1 时，服务器必须在此主题下保存此应用消息，替换任何已经存在的消息 [MQTT-3.3.1-6] 如果载荷为空，服务器照常处理，只不过该同名主题下现有的保留消息必须被移除，未来的订阅者也不会再收到保留消息 [MQTT-3.3.1-7] 带有空载荷的保留消息必须不被服务器作为保留消息存储 [MQTT-3.3.1-8] 如果客户端发送到服务器的 PUBLISH 包中的保留消息值为 0，服务器必须不将该消息作为保留消息存储且必须不删除或替换已经存在的保留消息 [MQTT-3.3.1-9] 如果保留消息处理值为 0，服务器必须将匹配订阅主题过滤器的保留消息发送给客户端 [MQTT-3.3.1-10] 如果保留消息处理值为 1，当该订阅之前不存在时，服务器必须将匹配订阅主题过滤器的保留消息发送给客户端，反之当该订阅之前存在时，服务器必须不发送保留消息 [MQTT-3.3.1-11] 如果保留消息处理值为 2，服务器必须不发送保留消息 [MQTT-3.3.1-12] 如果保留消息引用发布的值为 0，服务器必须在转发应用消息时将保留消息值置为 0，无论其收到的 PUBLISH 包中的保留消息值如何设置 [MQTT-3.3.1-13] 如果保留消息引用发布的值为 1，服务器必须使用和收到的 PUBLISH 包中保留消息值相同的保留消息值 [MQTT-3.3.2-1] 主题名称必须作为 PUBLISH 包可变头的第一个字段。他必须采用 UTF-8字符串 编码 [MQTT-3.3.2-2] PUBLISH 包中的主题名称必须不包含通配符 [MQTT-3.3.2-3] 服务器发往客户端的 PUBLISH 包中的主题名称必须匹配订阅者的主题过滤器 [MQTT-3.3.2-4] 服务器必须将载荷格式标识原封不动的发送给所有应用消息的接收者 [MQTT-3.3.2-5] 当该字段存在时，此四字节的值表示以秒为单位的应用消息生命时间。如果消息过期间隔已经超时，且服务器尚未设法开始向前传递到匹配的订阅者，服务器必须删除面向该订阅者的该消息的副本 [MQTT-3.3.2-6] 客户端发送给服务器的 PUBLISH 包中的消息过期间隔必须被设置为服务器接收的消息过期间隔的值减去消息在服务器中等待的时间 [MQTT-3.3.2-7] 接收者必须不能将主题别名从一个网络连接转发到另一个网络连接 [MQTT-3.3.2-8] 发送者必须不能发送一个包含主题别名值为 0 的 PUBLISH 包 [MQTT-3.3.2-9] 客户端必须不发送包含主题别名值超过服务器 CONNACK 中设置的主题别名最大值的 PUBLISH 包 [MQTT-3.3.2-10] 客户端必须接收所有大于 0 且小于或等于其 CONNECT 包中设置的主题别名最大值的主题别名 [MQTT-3.3.2-11] 服务器必须不发送包含主题别名值超过客户端 CONNECT 包中设置的主题别名最大值的 PUBLISH 包 [MQTT-3.3.2-12] 服务器必须接收所有大于 0 且小于等于其 CONNACK 包中设置的主题别名最大值的主题别名 [MQTT-3.3.2-13] 响应主题必须使用 UTF-8字符串 格式 [MQTT-3.3.2-14] 响应主题必须不包含通配符 [MQTT-3.3.2-15] 服务器必须向所有接收该应用消息的订阅者原封不动的转发响应主题 [MQTT-3.3.2-16] 服务器必须将关联数据原封不动的转发给接收应用消息的订阅者 [MQTT-3.3.2-17] 服务器必须将 PUBLISH 包中的所有用户属性原封不动的转发给客户端 [MQTT-3.3.2-18] 服务器必须在转发应用消息时维护用户属性的顺序 [MQTT-3.3.2-19] 内容类型必须是 UTF-8字符串 格式 [MQTT-3.3.2-20] 服务器必须将内容格式原封不动的转发给所有接收应用消息的订阅者 [MQTT-3.3.4-1] PUBLISH 包的接收者必须使用 PUBLISH 包中 QoS 对应的方式响应此包 [MQTT-3.3.4-2] 在这种情况下服务器必须使用这些重叠订阅中最高的 QoS 等级来发布此数据 [MQTT-3.3.4-3] 如果客户端在重叠订阅时设置了订阅ID，服务器必须在为该订阅发布消息时将订阅ID放入消息中 [MQTT-3.3.4-4] 如果服务器发送该消息的单一副本，服务器必须将所有包含订阅ID的订阅动作的订阅ID放入 PUBLISH 包中，他们的顺序不重要 [MQTT-3.3.4-5] 如果服务器发送该消息的多个副本，服务器必须在每个副本中放入对应订阅动作的订阅ID [MQTT-3.3.4-6] 从客户端发往服务器的 PUBLISH 包必须不携带订阅ID [MQTT-3.3.4-7] 当客户端没有接收到足够的 PUBACK、PUBCOMP 或带有大于等于 128 原因码的 PUBREC 时，客户端必须不发送QoS 1 或 QoS 2 的 PUBLISH 包导致其需接收的返回数量超过接收最大值 [MQTT-3.3.4-8] 客户端不能延迟任何包的发送，除了因未收到接受回复而达到接收最大值因此未能发送的 PUBLISH 包 [MQTT-3.3.4-9] 当服务器没有接收到足够的 PUBACK、PUBCOMP 或带有大于等于 128 原因码的 PUBREC 时，服务器必须不发送QoS 1 或 QoS 2 的 PUBLISH 包导致其需接收的返回数量超过接收最大值 [MQTT-3.3.4-10] 服务器不能延迟任何包的发送，除了因未收到接受回复而达到接收最大值因此未能发送的 PUBLISH 包 [MQTT-3.4.2-1] 客户端或服务器发送的 PUBACK 包必须采用上述之一的 PUBACK 原因码 [MQTT-3.4.2-2] 如果添加此字段会导致 PUBACK 的尺寸大于接收方的最大包尺寸，发送方必须不添加此字段 [MQTT-3.4.2-3] 如果添加此字段会导致 PUBACK 的尺寸大于接收方的最大包尺寸，发送方必须不添加此字段 [MQTT-3.5.2-1] 客户端或服务器发送的 PUBREC 包必须采用上述之一的 PUBREC 原因码 [MQTT-3.5.2-2] 如果添加此字段会导致 PUBREC 的尺寸大于接收方的最大包尺寸，发送方必须不添加此字段 [MQTT-3.5.2-3] 如果添加此字段会导致 PUBREC 的尺寸大于接收方的最大包尺寸，发送方必须不添加此字段 [MQTT-3.6.1-1] PUBREL 包固定头中的 Bit 3、2、1、0 为保留字段，其值必须被分别设置为 0、0、1、0。服务器必须将其他值视为格式错误的包并关闭网络连接 [MQTT-3.6.2-1] 客户端或服务器发送的 PUBREL 包必须采用上述之一的 PUBREL 原因码 [MQTT-3.6.2-2] 如果添加此字段会导致 PUBREL 的尺寸大于接收方的最大包尺寸，发送方必须不添加此字段 [MQTT-3.6.2-3] 如果添加此字段会导致 PUBREL 的尺寸大于接收方的最大包尺寸，发送方必须不添加此字段 [MQTT-3.7.2-1] 客户端或服务器发送的 PUBCOMP 包必须采用上述之一的 PUBCOMP 原因码 [MQTT-3.7.2-2] 如果添加此字段会导致 PUBCOMP 的尺寸大于接收方的最大包尺寸，发送方必须不添加此字段 [MQTT-3.7.2-3] 如果添加此字段会导致 PUBCOMP 的尺寸大于接收方的最大包尺寸，发送方必须不添加此字段 [MQTT-3.8.1-1] SUBSCRIBE 包固定头中的 Bit 3、2、1、0 为保留字段，其值必须被分别设置为 0、0、1、0。服务器必须将其他值视为格式错误的包并关闭网络连接 [MQTT-3.8.3-1] 主题过滤器必须是一个 UTF-8字符串 [MQTT-3.8.3-2] 载荷必须至少包含一个主题过滤器和订阅选项对 [MQTT-3.8.3-3] 订阅选项中的 Bit 2 表示非本地选项。如果其值为 1，服务器必须不将应用消息转发给与发布者客户端ID相同的订阅者 [MQTT-3.8.3-4] 在共享订阅中非本地选项值为 1 视为协议错误 [MQTT-3.8.3-5] 服务器必须将载荷中保留字段值非 0 的 SUBSCRIBE 包视为格式错误的包 [MQTT-3.8.4-1] 当服务器从客户端收到 SUBSCRIBE 包，服务器必须使用 SUBACK 响应 [MQTT-3.8.4-2] SUBACK 中的包ID必须和其对应的 SUBSCRIBE 包中的包ID一致 [MQTT-3.8.4-3] 如果服务器接收到一个 SUBSCRIBE 包，其中包含的主题过滤器和现在会话中的一个订阅完全相同，服务器必须使用新订阅取代现有的订阅 [MQTT-3.8.4-4] 如果他的保留消息处理选项值为 0，且主题过滤器中现在有匹配的保留消息，服务器必须重新发送，但是服务器必须不能因为订阅的替换导致应用消息的丢失 [MQTT-3.8.4-5] 如果一个服务器接受的 SUBSCRIBE 包包含有多个订阅主题，服务器必须像接收了多个独立的 SUBSCRIBE 包一个逐个处理，唯一的不同是服务器将所有订阅请求的响应放入一个 SUBACK 包中回复 [MQTT-3.8.4-6] 服务器发往客户端的 SUBACK 必须为每一个 主题过滤器&#x2F;订阅选项 对提供一个原因码 [MQTT-3.8.4-7] 这个原因码必须提供服务器为此次订阅分配的最大QoS或是指明本次订阅失败 [MQTT-3.8.4-8] 发送给订阅者的应用消息中的QoS必须是原始 PUBLISH 包中的QoS和服务器分配的最大QoS两者中的较小值 [MQTT-3.9.2-1] 如果添加此字段会导致 SUBACK 的尺寸大于客户端的最大包尺寸，服务器必须不添加此字段 [MQTT-3.9.2-2] 如果添加此字段会导致 SUBACK 的尺寸大于客户端的最大包尺寸，服务器必须不添加此字段 [MQTT-3.9.3-1] SUBACK 中原因码的顺序必须与 SUBSCRIBE 中主题过滤器的顺序匹配 [MQTT-3.9.3-2] 服务器发送的 SUBACK 包必须对每个收到的主题过滤器使用上表列出的原因码进行回复 [MQTT-3.10.1-1] UNSUBSCRIBE 包固定头中的 Bit 3、2、1、0 为保留字段，其值必须被分别设置为 0、0、1、0。服务器必须将其他值视为格式错误的包并关闭网络连接 [MQTT-3.10.3-1] UNSUBSCRIBE 中的主题过滤器必须是 UTF-8字符串 [MQTT-3.10.3-2] UNSUBSCRIBE 包的载荷中必须至少包含一个主题过滤器 [MQTT-3.10.4-1] 服务器必须逐字符的核对 UNSUBSCRIBE 包中提供的主题过滤器（无论其是否包含通配符）是否与其持有的当前客户端的订阅相同。如果任何过滤器被精确匹配，那么其拥有的订阅必须被删除 [MQTT-3.10.4-2] 服务器必须停止向该主题过滤器添加新的发往客户端的消息 [MQTT-3.10.4-3] 服务器必须完成匹配该主题过滤器的，且已经开始发往客户端的 QoS 1 和 QoS 2 消息的交付 [MQTT-3.10.4-4] 服务器必须使用 UNSUBACK 包响应 UNSUBSCRIBE 请求 [MQTT-3.10.4-5] UNSUBACK 包必须和 UNSUBSCRIBE 包有相同的包ID。即使没有主题订阅被删除，服务器也必须使用 UNSUBACK 回复 [MQTT-3.10.4-6] 如果服务器收到的 UNSUBSCIRIBE 包包含有多个主题过滤器，服务器必须按序处理就如同他按序逐个收到了 UNSUBSCRIBE 包，唯一不同是服务器仅需要使用一个 UNSUBACK 回复 [MQTT-3.11.2-1] 如果添加此字段会导致 UNSUBACK 的尺寸大于客户端的最大包尺寸，服务器必须不添加此字段 [MQTT-3.11.2-2] 如果添加此字段会导致 UNSUBACK 的尺寸大于客户端的最大包尺寸，服务器必须不添加此字段 [MQTT-3.11.3-1] UNSUBACK 包中的原因码顺序必须和 UNSUBSCRIBE 包中的主题过滤器顺序一致 [MQTT-3.11.3-2] 服务器发送的 UNSUBACK 包必须对每个收到的主题过滤器使用下表之一的原因码 [MQTT-3.12.4-1] 服务器必须发送 PINGRESP 包用来响应 PINGREQ 包 [MQTT-3.14.0-1] 服务器必须不发送 DISCONNECT 包，除非在其发送了一个原因码小于 0x80 的 CONNACK 之后 [MQTT-3.14.1-1] 客户端或服务器必须确认保留字段值为 0。如果非 0，客户端或服务器发送一个带有原因码 0x81（格式错误的包）的 DISCONNECT 包，参考 [4.13] 中的描述 [MQTT-3.14.2-1] 客户端或服务器发送的 DISCONNECT 包必须使用上表之一的断开原因码 [MQTT-3.14.2-2] 服务器发送的 DISCONNECT 包中必须不包括会话过期间隔 [MQTT-3.14.2-3] 如果添加此字段会导致 DISCONNECT 的尺寸大于接收者的最大包尺寸，发送者必须不添加此字段 [MQTT-3.14.2-4] 如果添加此字段会导致 DISCONNECT 的尺寸大于接收方的最大包尺寸，发送方必须不添加此字段 [MQTT-3.14.4-1] 发送 DISCONNECT 后，发送方必须不在此网络连接中再发送任何 MQTT 包 [MQTT-3.14.4-2] 发送 DISCONNECT 后，发送方必须关闭网络连接 [MQTT-3.14.4-3] 当接收到带有原因码 0x00（成功） 的 DISCONNECT 包后，服务器必须不发送改连接的遗嘱消息，并丢弃 [MQTT-3.15.1-1] AUTH 包固定头中的 Bit 3、2、1、0 的内容保留且值必须为 0。客户端或服务器必须将任何其他值视为格式错误的包并断开网络连接 [MQTT-3.15.2-1] AUTH 包的发送者必须使用下表之一的认证原因码 [MQTT-3.15.2-2] 如果添加此字段会导致 AUTH 的尺寸大于接收者的最大包尺寸，发送者必须不添加此字段 [MQTT-3.15.2-3] 如果添加此字段会导致 AUTH 的尺寸大于接收方的最大包尺寸，发送方必须不添加此字段 [MQTT-4.1.0-1] 客户端和服务器必须不在网络连接打开时丢弃会话状态 [MQTT-4.2.0-1] 客户端或服务器必须支持使用一种或多种底层传输协议，这些协议提供从客户端到服务器以及服务器到客户端的有序、无损的字节流。 [MQTT-4.1.0-2] 服务器必须在网络连接关闭且会话过期间隔到期后丢弃会话状态 [MQTT-4.3.1-1] 在 QoS 0 交付协议中，发送方必须发送 QoS 0 且重复标志值为 0 的 PUBLISH 包 [MQTT-4.3.2-1] 在 QoS 1 交付协议中，发送方必须在每次发布新消息时选择一个未被使用的包ID [MQTT-4.3.2-2] 在 QoS 1 交付协议中，发送方必须发送包含此包ID，且重复标志值为 0 的 PUBLISH 包 [MQTT-4.3.2-3] 在 QoS 1 交付协议中，发送方必须将此 PUBLISH 包视为 “未回复的” 直到从接收方收到了正确的 PUBACK [MQTT-4.3.2-4] 在 QoS 1 交付协议中，接收方必须使用包含 PUBLISH 包中包ID的 PUBACK 包进行响应，拥有收到的消息的所有权 [MQTT-4.3.2-5] 在 QoS 1 交付协议中，接收方在发送 PUBACK 包后，接收方必须将到来的带有相同包ID的 PUBLISH 包视为新的应用消息，无论其重复标志如何设置 [MQTT-4.3.3-1] 在 QoS 2 交付协议中，发送方必须在发布新消息时分配一个未使用的包ID [MQTT-4.3.3-2] 在 QoS 2 交付协议中，发送方必须发送 QoS 2，重复标志值为 0，携带此包ID的 PUBLISH 包 [MQTT-4.3.3-3] 在 QoS 2 交付协议中，发送方必须在收到接收方发来的对应的 PUBREC 之前将此 PUBLISH 包视为 “未回复的” [MQTT-4.3.3-4] 在 QoS 2 交付协议中，发送方必须在收到接收方发来的原因码小于 0x80 的 PUBREC 后，发送 PUBREL 包。此 PUBREL 包必须包含和原始 PUBLISH 包相同的包ID [MQTT-4.3.3-5] 在 QoS 2 交付协议中，发送方必须在收到接收方发来的对应 PUBCOMP 之前将此 PUBREL 包视为 “未回复的” [MQTT-4.3.3-6] 在 QoS 2 交付协议中，发送方必须不在发送 PUBREL 之后重发 PUBLISH 包 [MQTT-4.3.3-7] 在 QoS 2 交付协议中，发送方必须不在发送 PUBLISH 包之后使此应用消息过期 [MQTT-4.3.3-8] 在 QoS 2 交付协议中，接收方必须使用和收到 PUBLISH 包相同的包ID的 PUBREC 包响应，拥有收到的消息的所有权 [MQTT-4.3.3-9] 在 QoS 2 交付协议中，接收方如果已经使用带有 0x80 或更大值的原因码的 PUBREC 包回复，接收方必须将后续带有相同包ID的 PUBLISH 包视为新应用消息 [MQTT-4.3.3-10] 在 QoS 2 交付协议中，接收方直到收到对应的 PUBREL 包为止，接收方必须使用 PUBREC 回复后续任何带有相同包ID的 PUBLISH 包。在此情形下必须不把重复的包转发给更进一步的消息使用者 [MQTT-4.3.3-11] 在 QoS 2 交付协议中，接收方必须使用和收到 PUBREL 包相同的包ID的 PUBCOMP 包响应 PUBREL 包 [MQTT-4.3.3-12] 在 QoS 2 交付协议中，接收方发送 PUBCOMP 包之后，接收方必须将后续带有相同包ID的 PUBLISH 包视为新应用消息发送 PUBCOMP 包之后，接收方必须将后续带有相同包ID的 PUBLISH 包视为新应用消息 [MQTT-4.3.3-13] 在 QoS 2 交付协议中，接收方即使消息已经过期，也必须继续 QoS 2 的响应动作 [MQTT-4.4.0-1] 当客户端使用全新开始值为 0 重连且存在会话时，客户端和服务器都必须使用原始的包ID重传所有未确认的 PUBLISH 包（其 QoS &gt; 0）和 PUBREL 包。这是客户端或服务器需要重传消息的唯一场景。客户端和服务器必须不在其他任何时间重传消息 [MQTT-4.4.0-2] 如果接收到的 PUBACK 或 PUBREC 包含 0x80 或更大的原因代码，则相应的 PUBLISH 数据包将被视为已确认，且必须不被重传 [MQTT-4.5.0-1] 当服务器得到输入应用消息的所有权时，他必须把消息放入所有匹配订阅的客户端的会话状态 [MQTT-4.5.0-2] 无论何种情况，客户端必须按照匹配的 QoS 规则确认其收到包，无论客户端对包中的消息内容选择处理还是丢弃 [MQTT-4.6.0-1] 当客户端重传 PUBLISH 包时，其必须按照原始 PUBLISH 包的顺序发送（包括 QoS 1 和 QoS 2 消息） [MQTT-4.6.0-2] 客户端必须按照接收 PUBLSIH 包的顺序发送 PUBACK 包（QoS 1 消息） [MQTT-4.6.0-3] 客户端必须按照接收 PUBLSIH 包的顺序发送 PUBREC 包（QoS 2 消息） [MQTT-4.6.0-4] 客户端必须按照接收 PUBREC 包的顺序发送 PUBREL 包（QoS 2 消息） [MQTT-4.6.0-5] 当服务器处理发布到有序主题的消息时，服务器必须保证其对消费者发送的 PUBLISH 包（对于相同主题和相同 QoS）的顺序和服务器从客户端接收这些包时相同 [MQTT-4.6.0-6] 默认情况下，服务器在转发非共享订阅上的消息时必须将每个主题视为有序主题。 [MQTT-4.7.0-1] 通配符可以在主题过滤器中使用，但必须不在主题名称中使用 [MQTT-4.7.1-1] 多级通配符必须单独使用或在主题级别分隔符后使用。在任意情况下他都必须是主题过滤器中的最后一个字符 [MQTT-4.7.1-2] 当他被使用时，他必须占据过滤器中一个完整的级别 [MQTT-4.7.2-1] 服务器必须不将以通配符（# 或 +）开始的主题过滤器与以 $ 开头的主题名匹配 [MQTT-4.7.3-1] 所有的主题名称和主题过滤器必须至少包含一个字符 [MQTT-4.7.3-2] 主题名称和主题过滤器中必须不能包括 null 字符（Unicode U+0000） [MQTT-4.7.3-3] 主题名称和主题过滤器是 UTF-8字符串；必须不超过 65535 字节 [MQTT-4.7.3-4] 当进行订阅匹配时，服务器必须不对主题名称或主题过滤器执行任何标准化处理，或对无法识别的字符进行任何修改或替换 [MQTT-4.8.2-1] 共享订阅的主题过滤器必须以 $share&#x2F; 开始且必须包括至少一字符的共享名称 [MQTT-4.8.2-2] 共享名称必须不包含字符 ‘&#x2F;‘、’+’、’#’，但必须在其后跟随 ‘&#x2F;‘ 字符。此 ‘&#x2F;‘ 字符后必须跟随主题过滤器 [MQTT-4.8.2-3] 服务器必须遵守客户端订阅时授予的 QoS 等级 [MQTT-4.8.2-4] 服务器必须在客户端重新连接时完成该消息的交付 [MQTT-4.8.2-5] 如果该客户端的会话在其重连成功前终止了，服务器必须不将此应用消息发送给其他的订阅客户端 [MQTT-4.8.2-6] 如果客户端使用带有 0x80 或更大原因码的 PUBACK 或 PUBREC 响应来自服务器的 PUBLISH 包，服务器必须丢弃应用消息，并且不再尝试将消息发给其他订阅者 [MQTT-4.9.0-1] 客户端或服务器必须将其发送配额初始化为不超过接收最大值的非零值 [MQTT-4.9.0-2] 每当客户端或服务器发送 QoS &gt; 0 的 PUBLISH 包，降低配额。如果发送配额值达到 0，客户端或服务器必须不再发送任何 QoS &gt; 0 的 PUBLISH 包 [MQTT-4.9.0-3] 即使配额值为 0，客户端和服务器必须继续处理和响应其他类型的 MQTT 包 [MQTT-4.12.0-1] 如果服务器不支持客户端提供的认证方式，服务器可以发送带有原因码 0x8C（认证方式错误）或原因码 0x87（未经授权）的 CONNACK 包，并必须关闭网络连接，参考 [4.13] 中的描述 [MQTT-4.12.0-2] 如果服务器需要额外信息来完成认证，他可以向客户端发送一个 AUTH 数据包。此数据包必须包含原因码 0x18（继续认证） [MQTT-4.12.0-3] 客户端通过发送另一个 AUTH 包来响应来自服务器的 AUTH 包。此包必须包含原因码 0x18（继续认证） [MQTT-4.12.0-4] 服务器可以在认证过程的任何点拒绝认证。他可以根据 [4.13] 的描述发送一个原因码为 0x80 或以上的 CONNACK 数据包，并必须关闭网络连接 [MQTT-4.12.0-5] 如果初始 CONNECT 包包含认证方法，则所有 AUTH 包和任何成功的 CONNACK 包都必须包含和 CONNECT 包中相同值的 认证方法 [MQTT-4.12.0-6] 如果客户端没有在 CONNECT 包中包含认证方法，则服务器必须不发送 AUTH 包，也必须不在 CONNACK 包中包含认证方法 [MQTT-4.12.0-7] 如果客户端没有在 CONNECT 包中包含认证方法，则客户端必须不向服务器发送 AUTH 包 [MQTT-4.12.1-1] 如果客户端在 CONNECT 包中提供了认证方法，则可以在收到 CONNACK 后随时启动重新认证。通过发送原因码为 0x19（重新认证）的 AUTH 包来实现。客户端必须将认证方法设置为与最初用于认证网络连接的认证方法相同的值 [MQTT-4.12.1-2] 如果重新认证失败，客户端或服务器应该带有合适原因码的 DISCONNECT 包，且必须断开网络连接，参考 [4.13] 中的描述 [MQTT-4.13.1-1] 当服务器检测到格式错误的包或协议错误，且给出了规范中的原因码后，他必须断开网络连接 [MQTT-4.13.2-1] CONNACK 和 DISCONNECT 包允许使用原因码为 0x80 或更高来指示网络连接将被关闭。如果指定了 0x80 或更高的原因码，则无论是否发送了 CONNACK 或 DISCONNECT 包，都必须关闭网络连接 [MQTT-6.0.0-1] MQTT 包必须在 WebSocket 二进制数据帧中发送。 如果收到任何其他类型的数据帧，接收方必须关闭网络连接 [MQTT-6.0.0-2] 单个 WebSocket 数据帧可以包含多个或部分 MQTT 包。 接收方不得假定 MQTT 包与 WebSocket 帧边界对齐 [MQTT-6.0.0-3] 客户端必须在其提供的 WebSocket 子协议列表中包含“mqtt” [MQTT-6.0.0-4] 服务器选择并返回的 WebSocket 子协议名称必须为“mqtt” 附录 C. MQTT v5.0 新特性汇总（非规范性）下列新特性被引入了 MQTT v5.0 会话过期机制将 Clean Session 拆分为全新开始会话和会话过期间隔，全新开始会话指示是否应在不使用现有会话的情况下启动会话，会话过期间隔指示断开连接后保留会话的时间长短。会话过期间隔可以在断开连接时修改。将全新开始会话设置为 1 且将会话过期间隔设置为 0 等同于在 MQTT v3.1.1 中将 Clean Session 设置为 1。 消息过期允许发布消息时设置过期时间。 所有 ACK 的原因码将所有响应包都改为带有原因码的包。包括 CONNACK，PUBACK，PUBREL，PUBCOMP，SUBACK，UNSUBACK，DISCONNECT 和 AUTH。这使得调用者可以判断请求的函数是否成功。 所有 ACK 的原因字符串将所有响应包都改为带有原因码的包，同时也允许带原因字符串。这被设计用于问题定位，且不应被接收者解析。 服务器断开允许服务器发送 DISCONNECT 包以指示断开的原因。 载荷格式和内容类型允许在发布消息时指定有效负载格式（二进制、文本）和 MIME 样式内容类型，这些被转发到消息的接收者。 请求&#x2F;响应在 MQTT 中形式化请求&#x2F;响应模式，并提供响应主题和关联数据属性，以允许将响应消息路由回请求的发布者。另外，添加客户端从服务器获取有关如何构建响应主题的配置信息的功能。 共享订阅添加共享订阅支持，实现消费者对订阅的负载均衡。 订阅ID允许在 SUBSCRIBE 上指定数字订阅标识符，并在传递消息时在消息上返回该标识符。 这允许客户端确定哪个或哪些订阅导致消息被传递。 主题别名通过允许主题名称映射为整数来减少 MQTT 数据包开销的大小。客户端和服务器独立指定它们允许的主题别名数量。 流量控制允许客户端和服务器独立指定它们允许的未完成可靠消息的数量（QoS&gt;0）。发送方通过暂停发送使未处理消息总量低于此配额。这用于限制可靠消息的速率，并限制“正在处理”的消息数量。 用户属性将用户属性添加到大多数包中。PUBLISH 上的用户属性包含在消息中，并由客户端应用程序定义。PUBLISH 和遗嘱属性集上的用户属性由服务器转发给消息的接收者。 CONNECT、SUBSCRIBE 和 UNSUBSCRIBE 数据包上的用户属性由服务器实现定义。 CONNACK、PUBACK、PUBREC、PUBREL、PUBCOMP、SUBACK、UNSUBACK 和 AUTH 数据包上的用户属性由发送方定义，并且对于发送方实现而言是唯一的。MQTT 未定义用户属性的含义。 最大包尺寸允许客户端和服务器各自独立选择能支持的最大包尺寸。会话的对端发送超过尺寸的包是一种错误。 可选的服务器特性定义一组服务器不允许的功能，且提供了一种机制让服务器向客户端指定这些功能。可以使用这种方式选择的功能包括：最大QoS，保留消息可用，通配符订阅可用，订阅ID可用，共享订阅。当服务器宣称这些特性不可用后服务器使用这些功能是一种错误。 在早期版本的 MQTT 中，服务器通过声明客户端无权限来避免这些未实现的功能。此功能允许这种可选行为被声明，并在客户端仍使用这些功能时添加对应的原因码。 增强认证提供了一种启用挑战&#x2F;响应式身份验证（包括双向认证）的机制。如果客户端和服务器都支持，则允许使用 SASL 风格的身份验证，并且客户端可以在连接中重新进行身份验证。 订阅选项提供订阅选项，主要用于消息桥接应用程序。包括不发送源于自身的消息（非本地）（noLocal），如何处理保留消息（保留消息处理）。 遗嘱延迟添加了指定连接结束和发送遗嘱消息之间延迟的功能。此功能旨在当会话的连接重新建立时不发送遗嘱消息。这允许短暂中断连接而无需通知其他人。 服务端保活允许服务器指定希望客户端用作保活的值。这使服务器可以设置允许的最大保活时间，并确保客户端遵守该时间。 分配客户端ID如果客户端ID是服务器分配的，返回分配的ID，这也解除了服务器分配的 ClientID 只能与 Clean Session&#x3D;1 连接一起使用的限制。 服务器引用允许服务器在 CONNACK 或 DISCONNECT 上指定要使用的备用服务器，可以用作重定向或进行服务配置。","tags":[{"name":"MQTT","slug":"MQTT","permalink":"https://vitsumoc.github.io/tags/MQTT/"},{"name":"网络协议","slug":"网络协议","permalink":"https://vitsumoc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"}]},{"title":"go轻量级事件库：gookit-event","date":"2024-01-04T09:08:00.000Z","path":"go轻量级事件库：gookit-event.html","text":"项目链接 gookit&#x2F;event 项目介绍： Go实现的轻量级的事件管理、调度程序库, 支持设置监听器的优先级, 支持使用通配符来进行一组事件的监听 支持自定义创建预定义的事件对象 支持对一个事件添加多个监听器 支持设置事件监听器的优先级，优先级越高越先触发 支持通过通配符 * 来进行一组事件的匹配监听. ModeSimple - 注册 app.* 事件的监听，触发 app.run app.end 时，都将同时会触发 app.* 监听器 ModePath - NEW * 只匹配一段非 . 的字符,可以进行更精细的监听; ** 匹配任意多个字符,只能用于开头或结尾 支持直接使用通配符 * 来监听全部事件的触发 支持触发事件时投递到 chan, 异步进行消费处理. 触发: Async(), FireAsync() 完善的单元测试，单元覆盖率 &gt; 95% 我非常喜欢这种类型的项目，小巧、专注、恰到好处的feature。 当前这个项目可能没有经过足够的检验，可能存在一些bug，但是没有关系，他的代码足够简单，即便他产生了问题也可以轻松修复。","tags":[{"name":"库","slug":"库","permalink":"https://vitsumoc.github.io/tags/%E5%BA%93/"},{"name":"Go","slug":"Go","permalink":"https://vitsumoc.github.io/tags/Go/"}]},{"title":"[翻译]Sol - 从零开始的MQTT broker - 特别篇：重构与事件循环","date":"2024-01-03T01:14:03.000Z","path":"translate-sol-bonus.html","text":"原文 Sol - An MQTT broker from scratch. Refactoring &amp; eventloop 更新日期: 2020-02-07 前言在前面的六个部分中，我们探索了一些常见的 CS 主题，例如网络编程、数据结构，这段短暂的旅程的终点是得到了一个充满了BUG但是勉强可用的MQTT broker。 由于好奇心，我想测试一下我们的项目离真正的生产项目有多么接近，而且我想对项目进行一些重构，减少一些临时的代码，让项目的结构更加合理，同时关注项目的可移植性。 我不会把所有的重构过程都写到博客中，因为那会非常无聊，我只会突出一些最重要的部分，剩下的部分你可以直接把 master 分支合并到 tutorial 来查看，或者直接克隆 master 分支。 首先我按照有限度列出了需要优化的要点： 低层的 I&#x2F;O 处理器，用以正确处理数据流读写 对 EPOLL 进行抽象，因为他是 Linux 独有功能，提供一些备选方案 管理加密消息，实现可用明文消息或加密消息的透明接口 正确处理客户端会话，实现类似 &#39;+&#39; 通配符之类的其他 MQTT 功能 备注：虽然我们自己做的哈希表运行的不错，但我还是决定选择使用久经沙场的 UTHASH 库。由于他只有一个头文件，集成进我们的项目也非常容易。他的项目文档在这里。 TCP分片问题第一个也是最需要被检查的问题是网络通信，在本地进行负载测试时，我发现当负载量较大时程序开始丢包，或者说，内核缓冲区被淹没并开始对数据流进行分片。TCP 作为一个流协议，在处理数据中进行分片是无可厚非的，没有在一开始时就考虑这个问题显然是我比较幼稚，或者说因为我着急写一个可以运行的程序，忽略了底层细节。无论如何，这让程序产生了一些问题，例如解析错误的数据包，或者分片部分被当作数据包的第一个字节，识别成了各种不同的指令等等。 因此，最重要的修复之一是 server.c 模块中的 recv_packet 函数，特别是为每个客户端添加了类似状态机的行为，使其可以正确执行非阻塞读写，而不会阻塞线程。 我还将应用程序的核心部分，特别是 MQTT 抽象（例如客户端会话和主题）移到了 sol_internal.h 中。 sol_internal.h// 客户端行为可以被视为拥有四个状态的状态机： // - WAITING_HEADER 基础状态, 等待到来的第一字节数据头 // - WAITING_LENGTH 第二个状态, 收到了头部但还没有收取全部的 remaing data // - WAITING_DATA 第三个状态, 基于 remaing data 判断还有多少剩余数据 // - SENDING_DATA 最后一个状态, 已经收取了全部的数据包, 接下来判断是否需要返回数据包 enum client_status &#123; WAITING_HEADER, WAITING_LENGTH, WAITING_DATA, SENDING_DATA &#125;; // 客户端链接的包装类, 客户端可以是订阅者或发布者, 可以拥有会话 // 现在不再需要为每个客户端申请内存, 我在程序启动时初始化了一个客户端池, 当然, 读写 buffer 是使用时再申请的 // 这是一个可以被哈希的结构, 参考 https://troydhanson.github.io/uthash/userguide.html struct client &#123; struct ev_ctx *ctx; // 事件循环上下文指针 int rc; // 持有处理的上一个消息的返回码 int status; // 当前状态 int rpos; // 表示去除 Fixed Header, 数据包实际开始的位置 // 因为收包时需要解析 Fixed Header 中变长的 Remaing Length, 不想在解包时再次解析 // 就通过此字段记录 size_t read; // 已经读取的字节数 size_t toread;// 完成此数据包总共需要读取的字节数 unsigned char *rbuf; // 读取 buffer size_t wrote; // 已经写入的字节数 size_t towrite; // 还需写入的字节数 unsigned char *wbuf; // 写入 buffer char client_id[MQTT_CLIENT_ID_LEN]; // MQTT 规范中的客户端 ID struct connection conn; // 网络连接封装, 通过抽象接口支持普通连接或TLS连接 struct client_session *session; // 客户端会话 unsigned long last_seen; // 客户端上次活动的时间戳 bool online; // 在线标识 bool connected; // 是否已经处理 CONNECT 包的标识 bool has_lwt; // 表示 CONNECT 包是否包含遗嘱 LWT（Last Will and Testament） bool clean_session; // 表示是否设置了 clean_session 标识 UT_hash_handle hh; // UTHASH handle 处理器, 使用 UTHASH 的条件 &#125;; // 每个客户端都持有一个会话, 用来缓存该客户端订阅的主题、失联时错过的消息(只有当 clean_session 为 false)、还有服务器已经发往客户端但没收到回复的消息(inflight messages)(这些消息都带有 message ID) // 基于MQTT协议, 最大的 mid (message ID) 数量为 65535, 所以 i_acks, i_msgs 和 in_i_acks 被初始化为这个尺寸 // 这是一个可被哈希的结构体, APP可以追踪他完整的生命周期 struct client_session &#123; int next_free_mid; // 下一个可用的 mid (message ID) List *subscriptions; // 客户端订阅的所有主题, 使用主题结构体存储 List *outgoing_msgs; // 断开链接期间发往客户端的消息, 使用 mqtt_packet 指针存储 bool has_inflight; // 表示是否有 inflight 消息的标识 bool clean_session; // clean_session 标识 char session_id[MQTT_CLIENT_ID_LEN]; // session 中引用的 client_id struct mqtt_packet lwt_msg; // 遗嘱消息, 由 CONNECT 设置, 可为空 struct inflight_msg *i_acks; // 需要被清理的离线ACK struct inflight_msg *i_msgs; // 由于发送超时, 需要被重传的离线消息 struct inflight_msg *in_i_acks; // 需要被客户端清理的离线输入ACK UT_hash_handle hh; // UTHASH handle 处理器, 使用 UTHASH 的条件 struct ref refcount; // 被引用计数, 用来共享此结构体 &#125;; 因此，客户端结构现在更加健壮，它存储每个数据包读写的状态，以便在内核空间出现 EAGAIN 错误时恢复。 server.c// 客户端接收数据包 static ssize_t recv_packet(struct client *c) &#123; ssize_t nread = 0; unsigned opcode = 0, pos = 0; unsigned long long pktlen = 0LL; // 基础状态, 读头部 if (c->status == WAITING_HEADER) &#123; // 读取最初的2byte, 第一个byte应包含消息类型码 nread = recv_data(&amp;c->conn, c->rbuf + c->read, 2 - c->read); // 异常视为断链 if (errno != EAGAIN &amp;&amp; errno != EWOULDBLOCK &amp;&amp; nread &lt;= 0) return -ERRCLIENTDC; // 不管是否全部读取完成, 记录已经读取的数量 c->read += nread; // 没有完全读取, 返回 EAGAIN if (errno == EAGAIN &amp;&amp; c->read &lt; 2) return -ERREAGAIN; // 完成进入下一阶段 c->status = WAITING_LENGTH; &#125; // 头部已经读完, 已经了解消息类型, 接下来我们读取第2-4byte, 从第一个字节之后的三个字节可能会用来存储包长度 // 当然, 除了 PINGRESP/PINGREQ 或 DISCONNECT, 他们没有 remaining length if (c->status == WAITING_LENGTH) &#123; if (c->read == 2) &#123; opcode = *c->rbuf >> 4; // 数据包类型错误 if (DISCONNECT &lt; opcode || CONNECT > opcode) return -ERRPACKETERR; // 数据包类型是 PINGRESP/PINGREQ 或 DISCONNECT, 无需后续处理(没有 remaining length) if (opcode > UNSUBSCRIBE) &#123; c->rpos = 2; c->toread = c->read; goto exit; &#125; &#125; // 总共读取至 4 byte // 译者觉得这里应该到 5 nread = recv_data(&amp;c->conn, c->rbuf + c->read, 4 - c->read); if (errno != EAGAIN &amp;&amp; errno != EWOULDBLOCK &amp;&amp; nread &lt;= 0) return -ERRCLIENTDC; c->read += nread; if (errno == EAGAIN &amp;&amp; c->read &lt; 4) return -ERREAGAIN; // 通过 remaining length 获得剩余部分的长度 pktlen = mqtt_decode_length(c->rbuf + 1, &amp;pos); // 超长异常 if (pktlen > conf->max_request_size) return -ERRMAXREQSIZE; // rpos 定位到头部和变长长度之后 c->rpos = pos + 1; // 数据包总大小 c->toread = pktlen + pos + 1; // pos = bytes used to store length // ACK 包无需继续读取 if (pktlen &lt;= 4) goto exit; c->status = WAITING_DATA; &#125; // 读取完整的数据包字节 nread = recv_data(&amp;c->conn, c->rbuf + c->read, c->toread - c->read); if (errno != EAGAIN &amp;&amp; errno != EWOULDBLOCK &amp;&amp; nread &lt;= 0) return -ERRCLIENTDC; c->read += nread; if (errno == EAGAIN &amp;&amp; c->read &lt; c->toread) return -ERREAGAIN; exit: return 0; &#125; // 在接收链接或回复消息后使用此函数获取后续客户端输入的数据 static inline int read_data(struct client *c) &#123; // 我们必须接收一个完整的数据包 int err = recv_packet(c); // 链接断开或收到了错误的数据包 // TODO：设置一个处理 ERRMAXREQSIZE 的函数, 显示的提醒客户端故障 if (err &lt; 0) goto err; // 表示阻塞, 需要继续读取 if (c->read &lt; c->toread) return -ERREAGAIN; // 记录 info.bytes_recv += c->read; return 0; // 断开链接或故障 err: return err; &#125; // 通过网络连接向客户端发送数据流, 持续发送直到所有数据发送完成, 通过 towrite 字段跟踪 // 当阻塞时返回 EAGAIN static inline int write_data(struct client *c) &#123; ssize_t wrote = send_data(&amp;c->conn, c->wbuf+c->wrote, c->towrite-c->wrote); if (errno != EAGAIN &amp;&amp; errno != EWOULDBLOCK &amp;&amp; wrote &lt; 0) return -ERRCLIENTDC; c->wrote += wrote > 0 ? wrote : 0; if (c->wrote &lt; c->towrite &amp;&amp; errno == EAGAIN) return -ERREAGAIN; // 发送成功 更新状态 info.bytes_sent += c->towrite; // 重置记录数据 c->towrite = c->wrote = 0; return 0; &#125; 加密通讯需要注意的是，recv_packet 和 write_data 是两个在 network.h 模块中定义的函数： ssize_t send_data(struct connection *, const unsigned char *, size_t) ssize_t recv_data(struct connection *, unsigned char *, size_t) 他们都需要使用 struct connection 作为第一个参数，后面两个参数就是常规的读&#x2F;写 buffer 和读&#x2F;写字节数。 这个连接结构直接针对了前言中需改进列表内的第三条（明文消息和加密消息的抽象），他是客户端链接的抽象实现，并且提供了管理通信所需的4个基本回调函数： accept send recv close 这个改进允许我们基于选择的类型创建每条链接，不论是普通链接还是TLS链接都使用相同的函数收发数据。 结构定义如下： network.h// 链接抽象结构，向外提供统一接口，根据传输层加密与否设置正确的回调函数 // 四个主要的回调函数表示了可以在链接上进行的四种操作： // - accept // - read // - write // - close // 同时维护了 ip:port 信息 struct connection &#123; int fd; SSL *ssl; SSL_CTX *ctx; char ip[INET_ADDRSTRLEN + 6]; int (*accept) (struct connection *, int); ssize_t (*send) (struct connection *, const unsigned char *, size_t); ssize_t (*recv) (struct connection *, unsigned char *, size_t); void (*close) (struct connection *); &#125;; 结构体中存储了 SSL * 和 SSL_CTX *，当我们使用普通链接时他们会为 NULL。 编解码与辅助函数另一个有益的提升是修正了之前错误的编码和解码函数（感谢beej networking guide，这个教程真的很优秀）并且添加了一些工具函数用来处理整形和bytes的解码。 pack.c// 整数解码 long long unpack_integer(unsigned char **buf, char size) &#123; long long val = 0LL; switch (size) &#123; case 'b': val = **buf; *buf += 1; break; case 'B': val = **buf; *buf += 1; break; case 'h': val = unpacki16(*buf); *buf += 2; break; case 'H': val = unpacku16(*buf); *buf += 2; break; case 'i': val = unpacki32(*buf); *buf += 4; break; case 'I': val = unpacku32(*buf); *buf += 4; break; case 'q': val = unpacki64(*buf); *buf += 8; break; case 'Q': val = unpacku64(*buf); *buf += 8; break; &#125; return val; &#125; unsigned char *unpack_bytes(unsigned char **buf, size_t len) &#123; unsigned char *dest = malloc(len + 1); memcpy(dest, *buf, len); dest[len] = '\\0'; *buf += len; return dest; &#125; 微型的事件循环：ev在单线程环境中抽象主机提供的多路复用API并不是一件困难的事，本质上就是提供一个数据结构，用来持有一组自定义事件。头文件里描述的很清楚，最重要的部分是我们对事件类型的枚举（enum ev_type），自定义事件（struct ev）和持有自定义事件的数组（events_monitored）。这些构成了我们的事件封装（ev_ctx）。 ev_ctx 中使用不透明的 void * 指针可以让我们引用系统提供的任何底层 API，无论是 EPOLL、SELECT 还是 KQUEUE。 ev.h#include &lt;sys/time.h> #define EV_OK 0 #define EV_ERR 1 // 事件类型, 支持或运算 enum ev_type &#123; EV_NONE = 0x00, EV_READ = 0x01, EV_WRITE = 0x02, EV_DISCONNECT = 0x04, EV_EVENTFD = 0x08, EV_TIMERFD = 0x10, EV_CLOSEFD = 0x20 // 停止循环, 关闭服务 &#125;; struct ev_ctx; // 自定义事件, 存储与事件上下文的数组中 // 携带有客户端信息, 被触发时执行对应的回调函数 struct ev &#123; int fd; int mask; void *rdata; // 读取回调函数参数的不透明指针 void *wdata; // 写入回调函数参数的不透明指针 void (*rcallback)(struct ev_ctx *, void *); // 读取回调函数 void (*wcallback)(struct ev_ctx *, void *); // 写入回调函数 &#125;; // 事件循环上下文结构, 持有被监视的事件对象和指向后端事件引擎的指针 // 当前我们仍然使用 epoll, 因为现在的线程模型与 select 默认的电平触发机制不是很适配 // 对于单线程场景, 抽象select很容易 // 现在由于 epoll 边缘触发 + 单次触发 机制，我们可以轻松的在多线程场景使用我们的事件循环 struct ev_ctx &#123; int events_nr; int maxfd; // 最大监听fd数, events_monitored 的长度不得小于此数 int stop; int maxevents; unsigned long long fired_events; // 被触发事件数 struct ev *events_monitored; // 监控事件列表 void *api; // 指向基于平台的事件引擎的指针 &#125;; void ev_init(struct ev_ctx *, int); void ev_destroy(struct ev_ctx *); // 轮询 ev_ctx 中的事件, 无限阻塞或超时, 当有事件需要处理时返回 int ev_poll(struct ev_ctx *, time_t); // 调用 ev_poll 再阻塞中轮询事件, 每轮中执行事件中对应的回调函数 int ev_run(struct ev_ctx *); // 触发停止事件 void ev_stop(struct ev_ctx *); // 向循环队列尾部添加 fd, 和 ev_fire_event 相同只是没有回调函数 // 可以用来添加 socket 监听之类的简单描述符 int ev_watch_fd(struct ev_ctx *, int, int); // 在循环中删除 fd, 虽然 close 调用足以从事件引擎中删除 fd, 但是还是用此调用封装来确保所有相关事件都被清理并设置为 EV_NONE int ev_del_fd(struct ev_ctx *, int); // 注册一个新事件, 在功能上他和 ev_fire_event 相同但是此函数用于注册一个还未加入事件监听的fd // 此函数可以被集成到 ev_fire_event 中, 但是我还是倾向于保持语义分离 int ev_register_event(struct ev_ctx *, int, int, void (*callback)(struct ev_ctx *, void *), void *); // 注册一个周期性事件 int ev_register_cron(struct ev_ctx *, void (*callback)(struct ev_ctx *, void *), void *, long long, long long); // 为下一个循环周期的 FD 注册一个新事件 // 和 ev_watch_fd相同, 但可以携带回调函数和参数 int ev_fire_event(struct ev_ctx *, int, int, void (*callback)(struct ev_ctx *, void *), void *); 在服务器初始化时，ev_ctx 会被注册一些基本的周期性事件和服务端口的 on_accpet 事件。之后我们的程序就由事件循环不停驱动，比如当客户端链接建立后，我们会对输入的数据进行监听，触发 read_callback，收到完整的数据包并处理后，决定是否要发送回复。 MAIN THREAD [EV_CTX] ACCEPT_CALLBACK READ_CALLBACK WRITE_CALLBACK ------------------- ------------------ -------------------- | | | ACCEPT | | | ------------------> | | | READ AND DECODE | | | | | | | | PROCESS | | | | | | | | | --------------------> | | | WRITE ACCEPT | | | ------------------> | &lt;-------------------- | | | | 这是一个连接客户端的生命周期，我们有一个 accept 回调函数，他将接入的链接放入事件循环中，并且开启读取监听： server.c// 处理输入的链接, 创建一个客户端对象并关联到fd // 设置为 EV_READ 事件并绑定 read_callback 用以处理输入的数据流 static void accept_callback(struct ev_ctx *ctx, void *data) &#123; int serverfd = *((int *) data); while (1) &#123; // 接收一个新的连接, 将ip地址和fd配置给作为参数传入的conn结构 struct connection conn; connection_init(&amp;conn, conf->tls ? server.ssl_ctx : NULL); int fd = accept_connection(&amp;conn, serverfd); if (fd == 0) continue; if (fd &lt; 0) &#123; close_connection(&amp;conn); break; &#125; // 创建一个客户端结构, 用来持有conn和ev_ctx struct client *c = memorypool_alloc(server.pool); c->conn = conn; client_init(c); c->ctx = ctx; // 客户端添加到读取循环中 ev_register_event(ctx, fd, EV_READ, read_callback, c); // 记录 info.nclients++; info.nconnections++; log_info(\"[%p] Connection from %s\", (void *) pthread_self(), conn.ip); &#125; &#125; // 读取数据包的回调, 每当客户端发来数据时由事件循环触发此函数 static void read_callback(struct ev_ctx *ctx, void *data) &#123; // 客户端传入自身作为回调参数 struct client *c = data; // 状态机校验, 也意味着只要是 WAITING_* 状态都需要继续读取数据 if (c->status == SENDING_DATA) return; // 从客户端获取数据, 按照协议可了解数据是否已经读取完全 int rc = read_data(c); switch (rc) &#123; case 0: // 记录活跃时间 c->last_seen = time(NULL); // 置为 SENDING 状态, 后续根据处理器的处理决定是否要发送数据 c->status = SENDING_DATA; // 后续解码 + 处理器处理 process_message(ctx, c); break; case -ERRCLIENTDC: case -ERRPACKETERR: case -ERRMAXREQSIZE: // 客户端断开或数据错误 // 断开连接、清理资源 log_error(\"Closing connection with %s (%s): %s\", c->client_id, c->conn.ip, solerr(rc)); // 如果有遗嘱则发布遗嘱 if (c->has_lwt == true) &#123; char *tname = (char *) c->session->lwt_msg.publish.topic; struct topic *t = topic_get(&amp;server, tname); publish_message(&amp;c->session->lwt_msg, t); &#125; // 清理资源 ev_del_fd(ctx, c->conn.fd); // 从主题中删除订阅 if (c->session &amp;&amp; list_size(c->session->subscriptions) > 0) &#123; struct list *subs = c->session->subscriptions; list_foreach(item, subs) &#123; log_debug(\"Deleting %s from topic %s\", c->client_id, ((struct topic *) item->data)->name); topic_del_subscriber(item->data, c); &#125; &#125; client_deactivate(c); info.nclients--; info.nconnections--; break; case -ERREAGAIN: ev_fire_event(ctx, c->conn.fd, EV_READ, read_callback, c); break; &#125; &#125; // 此函数仅当客户端已经发送符合MQTT协议长度的完整字节流后才被调用 // 此函数使用事件循环基于收到的数据包类型做出反应, 在传入处理器前进行校验。 // 此函数根据处理器的输出结果, 在事件队列中加入回复事件, 或重置客户端继续监听输入事件 static void process_message(struct ev_ctx *ctx, struct client *c) &#123; // io.data 是 mqtt_packet 类型 struct io_event io = &#123; .client = c &#125;; // 将收到的数据解码为mqtt包 mqtt_unpack(c->rbuf + c->rpos, &amp;io.data, *c->rbuf, c->read - c->rpos); // 重置读取标识 c->toread = c->read = c->rpos = 0; // 使用对应的处理器处理 c->rc = handle_command(io.data.header.bits.type, &amp;io); switch (c->rc) &#123; // 回复处理 case REPLY: case MQTT_NOT_AUTHORIZED: case MQTT_BAD_USERNAME_OR_PASSWORD: // 向客户端发送数据 enqueue_event_write(c); // 释放资源 if (io.data.header.bits.type != PUBLISH) mqtt_packet_destroy(&amp;io.data); break; // 断链处理 case -ERRCLIENTDC: ev_del_fd(ctx, c->conn.fd); client_deactivate(io.client); info.nclients--; info.nconnections--; break; case -ERRNOMEM: log_error(solerr(c->rc)); break; default: c->status = WAITING_HEADER; if (io.data.header.bits.type != PUBLISH) mqtt_packet_destroy(&amp;io.data); break; &#125; &#125; // 写入事件触发的回调函数, 阻塞可重发, 发完后重置状态机, 并加入读取事件监听 static void write_callback(struct ev_ctx *ctx, void *arg) &#123; struct client *client = arg; // 发送数据 int err = write_data(client); switch (err) &#123; case 0: // OK // 开启读取监听 client->status = WAITING_HEADER; ev_fire_event(ctx, client->conn.fd, EV_READ, read_callback, client); break; // 阻塞重发 case -ERREAGAIN: enqueue_event_write(client); break; default: log_info(\"Closing connection with %s (%s): %s %i\", client->client_id, client->conn.ip, solerr(client->rc), err); ev_del_fd(ctx, client->conn.fd); client_deactivate(client); // Update stats info.nclients--; info.nconnections--; break; &#125; &#125; 当然，启动的服务器必须进行阻塞调用以启动事件循环，我们也需要一个停止机制。得益于 ev_stop API，添加一个额外的事件例程来在我们想要停止运行的循环时调用变得非常简单。 现在我们的服务器会使用一个阻塞的循环来提供服务，但是我们也需要一个停止机制。感谢 ev_stop 接口，他这让我们可以简单的停止循环。 server.c// 循环停止事件的回调函数, 由 EV_CLOSEFD 触发 static void stop_handler(struct ev_ctx *ctx, void *arg) &#123; (void) arg; ev_stop(ctx); &#125; // 事件循环启动函数, 是对 epoll 或者其他多路复用机制的抽象 static void eventloop_start(void *args) &#123; int sfd = *((int *) args); struct ev_ctx ctx; ev_init(&amp;ctx, EVENTLOOP_MAX_EVENTS); // 注册停止事件 ev_register_event(&amp;ctx, conf->run, EV_CLOSEFD|EV_READ, stop_handler, NULL); // 使用网络服务端口注册 accept_callback ev_register_event(&amp;ctx, sfd, EV_READ, accept_callback, &amp;sfd); // 注册周期性事件 ev_register_cron(&amp;ctx, publish_stats, NULL, conf->stats_pub_interval, 0); ev_register_cron(&amp;ctx, inflight_msg_check, NULL, 0, 9e8); // 开始循环, 阻塞线程 ev_run(&amp;ctx); ev_destroy(&amp;ctx); &#125; // 添加一个写入事件监听, 用来向客户端发送数据 void enqueue_event_write(const struct client *c) &#123; ev_fire_event(c->ctx, c->conn.fd, EV_WRITE, write_callback, (void *) c); &#125; 最终，我们的 start_server 函数，作为程序的入口，他会监听一个端口，并打开事件循环来提供服务。 server.c// 服务入口, 传入地址和端口开始工作 int start_server(const char *addr, const char *port) &#123; // Sol 全局对象初始化 trie_init(&amp;server.topics, NULL); server.authentications = NULL; server.pool = memorypool_new(BASE_CLIENTS_NUM, sizeof(struct client)); server.clients_map = NULL; server.sessions = NULL; server.wildcards = list_new(wildcard_destructor); if (conf->allow_anonymous == false) config_read_passwd_file(conf->password_file, &amp;server.authentications); // 服务器状态主题 for (int i = 0; i &lt; SYS_TOPICS; i++) topic_put(&amp;server, topic_new(xstrdup(sys_topics[i].name))); // 监听网络端口 int sfd = make_listen(addr, port, conf->socket_family); // 初始化SSL if (conf->tls == true) &#123; openssl_init(); server.ssl_ctx = create_ssl_context(); load_certificates(server.ssl_ctx, conf->cafile, conf->certfile, conf->keyfile); &#125; log_info(\"Server start\"); info.start_time = time(NULL); // 开启事件循环 eventloop_start(&amp;sfd); close(sfd); AUTH_DESTROY(server.authentications); list_destroy(server.wildcards, 1); // 释放SSL资源 if (conf->tls == true) &#123; SSL_CTX_free(server.ssl_ctx); openssl_cleanup(); &#125; log_info(\"Sol v%s exiting\", VERSION); return 0; &#125; 正如你看到的，这里有一个用于创建客户端池的 memorypool_new，我们预先分配了一定数量的客户端，并且在断开链接时回收他们。只要我们的客户端内容是懒加载的，特别是他们的读写buffer（可能是 MB 级别）是懒加载的，那么我们这个客户端池就相当划算。 当然，这只是整个过程的一小部分，但最终我做出了一个相当不错的原型。下一步将是进行一些压力测试，看看它与 Mosquitto 或 Mosca 这些久经考验且无可争议的优秀软件相比如何。我们仍然缺少许多功能，例如用于存储会话的持久层，但先贼发布&#x2F;订阅部分应该是可测试的。希望这个教程可以作为更整洁和精心设计的项目的起点。再见！","tags":[{"name":"网络编程","slug":"网络编程","permalink":"https://vitsumoc.github.io/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"name":"翻译","slug":"翻译","permalink":"https://vitsumoc.github.io/tags/%E7%BF%BB%E8%AF%91/"},{"name":"C","slug":"C","permalink":"https://vitsumoc.github.io/tags/C/"},{"name":"MQTT","slug":"MQTT","permalink":"https://vitsumoc.github.io/tags/MQTT/"},{"name":"物联网","slug":"物联网","permalink":"https://vitsumoc.github.io/tags/%E7%89%A9%E8%81%94%E7%BD%91/"}]},{"title":"[翻译]Sol - 从零开始的MQTT broker - 第六部分：处理器","date":"2023-12-29T00:56:57.000Z","path":"translate-sol-6.html","text":"原文 Sol - An MQTT broker from scratch. Part 6 - Handlers 这一部分我们会重点关注 处理器（handler） 的实现，每种处理器用来处理一种对应的MQTT包。就像我们在第四部分中已经描述的，我们把处理器放在一个固定长度的数组里，每个处理器的索引恰好是包的MQTT类型。 业务封装在我们开始主要工作之前，我们先补充一些前几章缺失的业务代码： src/core.h#include \"trie.h\" #include \"list.h\" #include \"hashtable.h\" struct topic &#123; const char *name; List *subscribers; &#125;; // sol的主体结构, 服务器运行时会产生一个全局实例 // 包括了所有连接的客户端、闭包和主题树 struct sol &#123; HashTable *clients; HashTable *closures; Trie topics; &#125;; // 在客户端中使用的session, 保存该客户端订阅的所有主题 struct session &#123; List *subscriptions; // TODO add pending confirmed messages &#125;; // 客户端包装 struct sol_client &#123; char *client_id; int fd; struct session session; &#125;; // 将客户端包装成订阅者, 之后由主题保存订阅者列表 struct subscriber &#123; unsigned qos; struct sol_client *client; &#125;; // 主题创建、订阅发布的一系列方法 struct topic *topic_create(const char *); void topic_init(struct topic *, const char *); void topic_add_subscriber(struct topic *, struct sol_client *, unsigned, bool); void topic_del_subscriber(struct topic *, struct sol_client *, bool); void sol_topic_put(struct sol *, struct topic *); void sol_topic_del(struct sol *, const char *); // 通过主题名称获得主题 struct topic *sol_topic_get(struct sol *, const char *); 这部分主要实现了客户端和服务端交互的各种抽象： 客户端（client）结构体，用来表示已经建立连接的客户端 主题（topic）结构体 订阅者（subscriber）结构体 会话结（session）构体，表示客户端持有的会话，仅当 clean session 选项为 false 时生效 sol结构体，全局运行实例，用来持有上述的所有内容 一些方便的辅助函数 这里是上述定义的实现： src/core.c#include &lt;string.h> #include &lt;stdlib.h> #include \"core.h\" // 传入两个订阅者, 比较其客户端id static int compare_cid(void *c1, void *c2) &#123; return strcmp(((struct subscriber *) c1)->client->client_id, ((struct subscriber *) c2)->client->client_id); &#125; // 创建一个topic对象 struct topic *topic_create(const char *name) &#123; struct topic *t = malloc(sizeof(*t)); topic_init(t, name); return t; &#125; void topic_init(struct topic *t, const char *name) &#123; t->name = name; t->subscribers = list_create(NULL); &#125; // 向主题对象内添加一个订阅者 void topic_add_subscriber(struct topic *t, struct sol_client *client, unsigned qos, bool cleansession) &#123; struct subscriber *sub = malloc(sizeof(*sub)); sub->client = client; sub->qos = qos; t->subscribers = list_push(t->subscribers, sub); // 如果cleansession置为false，必须将此订阅加入会话 if (!cleansession) client->session.subscriptions = list_push(client->session.subscriptions, t); &#125; // 主题取消客户端订阅 void topic_del_subscriber(struct topic *t, struct sol_client *client, bool cleansession) &#123; list_remove_node(t->subscribers, client, compare_cid); // TODO remomve in case of cleansession == false &#125; // 向sol设置主题 void sol_topic_put(struct sol *sol, struct topic *t) &#123; trie_insert(&amp;sol->topics, t->name, t); &#125; // 向sol删除主题 void sol_topic_del(struct sol *sol, const char *name) &#123; trie_delete(&amp;sol->topics, name); &#125; // 查询获得一个主题 struct topic *sol_topic_get(struct sol *sol, const char *name) &#123; struct topic *ret_topic; trie_find(&amp;sol->topics, name, (void *) &amp;ret_topic); return ret_topic; &#125; 处理器实现处理器（Handlers） 是一系列会在 on_read 中被执行的回调函数，就像他们的名称暗示的一样，他们负责处理客户端输入的数据，之后他们选择性的创建或不创建一个回复数据，并且返回一个指示下一步应该如何处理的返回值。返回值可以是： REARM_W，表示将下一个触发函数设置为 on_write，并提供需要发送到客户端的数据 REARM_R，表示没有需要回复客户端的数据，可以继续将触发函数重置为 on_read，继续等待客户端数据 -REARM_W，这个状态码没有被协议定义，我们在这里用来表示客户端断开链接或者故障发生 CONNECT 处理器按照顺序，我们先来实现 connect_handler，顾名思义，他用来处理客户端完成TCP链接之后发来的第一个数据包，也就是 CONNECT 包。 src/server.cstatic int connect_handler(struct closure *cb, union mqtt_packet *pkt) &#123; // 当一个已存在的客户端又发送了 CONNECT 包, 被视为违背协议 // 因此断开链接 if (hashtable_exists(sol.clients, (const char *) pkt->connect.payload.client_id)) &#123; sol_info(\"Received double CONNECT from %s, disconnecting client\", pkt->connect.payload.client_id); // 关闭链接, 释放资源 close(cb->fd); // 哈希表删除时的回调会负责销毁 client 或者 cb hashtable_del(sol.clients, (const char *) pkt->connect.payload.client_id); hashtable_del(sol.closures, cb->closure_id); // 更新状态 info.nclients--; info.nconnections--; return -REARM_W; &#125; sol_info(\"New client connected as %s (c%i, k%u)\", pkt->connect.payload.client_id, pkt->connect.bits.clean_session, pkt->connect.payload.keepalive); // 添加新链接 struct sol_client *new_client = malloc(sizeof(*new_client)); new_client->fd = cb->fd; // 由客户端保证cid的唯一性, 比如可以用mac地址 const char *cid = (const char *) pkt->connect.payload.client_id; new_client->client_id = strdup(cid); hashtable_put(sol.clients, cid, new_client); // 将 clinet 绑定到闭包 cb->obj = new_client; // 使用 CONNACK回复 union mqtt_packet *response = malloc(sizeof(*response)); // 高位赋值 unsigned char byte = CONNACK_BYTE; // clean_session == false 表示此链接支持保存 session if (pkt->connect.bits.clean_session == false) // 所以需要在会话中初始化订阅列表 new_client->session.subscriptions = list_create(NULL); // TODO 处理确实存在session的情况 // 这里暂时是简单的返回 session 不存在 unsigned char session_present = 0; unsigned char connect_flags = 0 | (session_present &amp; 0x1) &lt;&lt; 0; unsigned char rc = 0; // 返回 0 表示接收链接 // 完成组包 response->connack = *mqtt_packet_connack(byte, connect_flags, rc); // 包编码成数据流 cb->payload = bytestring_create(MQTT_ACK_LEN); unsigned char *p = pack_mqtt_packet(response, CONNACK); memcpy(cb->payload->data, p, MQTT_ACK_LEN); free(p); sol_debug(\"Sending CONNACK to %s (%u, %u)\", pkt->connect.payload.client_id, session_present, rc); free(response); // 标记之后发送 return REARM_W; &#125; 我们严格按照协议规范实现了处理器行为，除了 clean session 标识的处理，对于有会话的客户端该如何重连这件事我们暂时忽略了。如果一个客户端传入了两次 CONNECT，按照协议规范我们会断开他的链接。正常情况下我们会记录客户端，制作一个 CONNACK 数据流，并且返回 REARM_W，让 on_write 可以把我们的数据流发送回客户端。 DISCONNECT 处理器下一个包，DISCONNECT： src/server.cstatic int disconnect_handler(struct closure *cb, union mqtt_packet *pkt) &#123; // 获得客户端 struct sol_client *c = cb->obj; // 执行删除动作 sol_debug(\"Received DISCONNECT from %s\", c->client_id); close(c->fd); hashtable_del(sol.clients, c->client_id); hashtable_del(sol.closures, cb->closure_id); // 跟新状态 info.nclients--; info.nconnections--; // TODO 在该客户端订阅的所有主题中删除对其的引用 return -REARM_W; &#125; 我们做了最简单的处理：日志记录、关闭 fd、从哈希表中删除、更新信息，然后返回一个负值。 SUBSCRIBE UNSUBSCRIBE 处理器SUBSCRIBE 的处理器则是一个更加有意思的操作，在这里我们需要用到我们的 特里树，大概流程如下： 迭代传入的主题元组（包括 tpoic，QoS），对每一个主题进行如下操作： 如果主题不存在，我们创建该主题 将客户端加入该主题的订阅者列表 如果主题以 # 结尾，我们需要让客户端订阅该主题以及该主题所有的下级节点，由于特里树的数据结构设计，这个操作可以轻松的递归处理 如果 clean_session 标识的值为 false，我们需要给客户端添加一个会话，这里我们还没有完全实现 使用 SUBACK 回应 在 UNSUBSCRIBE 中也没有什么意外，只要在主题中删除客户端，然后使用 UNSUBACK 回应即可。 src/server.c// 用递归方式来订阅一个节点所有子节点的辅助函数 static void recursive_subscription(struct trie_node *node, void *arg) &#123; if (!node || !node->data) return; struct list_node *child = node->children->head; for (; child; child = child->next) recursive_subscription(child->data, arg); struct topic *t = node->data; struct subscriber *s = arg; t->subscribers = list_push(t->subscribers, s); &#125; // SUBSCRIBE 处理器 static int subscribe_handler(struct closure *cb, union mqtt_packet *pkt) &#123; struct sol_client *c = cb->obj; bool wildcard = false; // 标记是否通配 bool alloced = false; // 表示有新 malloc 的string, 用完需要释放 // 在 SUBACK 中使用和 SUB 同样的主题顺序回复的 QoS List unsigned char rcs[pkt->subscribe.tuples_len]; // SUBSCRIBE 包含了主题和QoS的列表, 此处循环处理 for (unsigned i = 0; i &lt; pkt->subscribe.tuples_len; i++) &#123; sol_debug(\"Received SUBSCRIBE from %s\", c->client_id); // 获得单个元组的主题字符串和QoS char *topic = (char *) pkt->subscribe.tuples[i].topic; sol_debug(\"\\t%s (QoS %i)\", topic, pkt->subscribe.tuples[i].qos); // 当使用 /# 结尾时, 标记通配 if (topic[pkt->subscribe.tuples[i].topic_len - 1] == '#' &amp;&amp; topic[pkt->subscribe.tuples[i].topic_len - 2] == '/') &#123; topic = remove_occur(topic, '#'); wildcard = true; &#125; else if (topic[pkt->subscribe.tuples[i].topic_len - 1] != '/') &#123; // 如果不以 / 结尾, 添加 / topic = append_string((char *) pkt->subscribe.tuples[i].topic, \"/\", 1); alloced = true; &#125; // 通过 topic 字符串找到对象 struct topic *t = sol_topic_get(&amp;sol, topic); // 当没有找到对象时, 创建并添加到特里树 if (!t) &#123; t = topic_create(strdup(topic)); sol_topic_put(&amp;sol, t); &#125; else if (wildcard == true) &#123; struct subscriber *sub = malloc(sizeof(*sub)); sub->client = cb->obj; sub->qos = pkt->subscribe.tuples[i].qos; // 让该节点和所有子节点都拥有表示此客户端的 subscriber trie_prefix_map_tuple(&amp;sol.topics, topic, recursive_subscription, sub); &#125; // 暂时都使用 cleansession = true // 译者觉得在通配符的情况下这里会到这 topic 对应的节点产生两个 subscriber topic_add_subscriber(t, cb->obj, pkt->subscribe.tuples[i].qos, true); if (alloced) free(topic); rcs[i] = pkt->subscribe.tuples[i].qos; &#125; // 制作 suback struct mqtt_suback *suback = mqtt_packet_suback(SUBACK_BYTE, pkt->subscribe.pkt_id, rcs, pkt->subscribe.tuples_len); // 复用pkt mqtt_packet_release(pkt, SUBSCRIBE); pkt->suback = *suback; // 制作数据流并发出 unsigned char *packed = pack_mqtt_packet(pkt, SUBACK); size_t len = MQTT_HEADER_LEN + sizeof(uint16_t) + pkt->subscribe.tuples_len; cb->payload = bytestring_create(len); memcpy(cb->payload->data, packed, len); free(packed); mqtt_packet_release(pkt, SUBACK); free(suback); sol_debug(\"Sending SUBACK to %s\", c->client_id); return REARM_W; &#125; // UNSUBSCRIBE 处理器 这里没做实际处理, 只是正确回复ACK static int unsubscribe_handler(struct closure *cb, union mqtt_packet *pkt) &#123; struct sol_client *c = cb->obj; sol_debug(\"Received UNSUBSCRIBE from %s\", c->client_id); pkt->ack = *mqtt_packet_ack(UNSUBACK_BYTE, pkt->unsubscribe.pkt_id); unsigned char *packed = pack_mqtt_packet(pkt, UNSUBACK); cb->payload = bytestring_create(MQTT_ACK_LEN); memcpy(cb->payload->data, packed, MQTT_ACK_LEN); free(packed); sol_debug(\"Sending UNSUBACK to %s\", c->client_id); return REARM_W; &#125; PUBLISH 处理器PUBLISH 处理器会比我们前面写的几个内容多一些，但是十分好理解： 如果发布的主题不存在, 则创建 基于消息的 QoS 设置，使用正确的 ACK 回复： QoS0：至多一次，不回复 QoS1：至少一次，使用 PUBACK 回复 QoS2：确保一次，使用 PUBREC 回复 向该主题的订阅者转发该消息，转发的 QoS 值应该是由消息的 QoS 决定，但不能大于接收方设置的最大 QoS 值 src/server.c// PUBLISH 处理器 static int publish_handler(struct closure *cb, union mqtt_packet *pkt) &#123; struct sol_client *c = cb->obj; sol_debug(\"Received PUBLISH from %s (d%i, q%u, r%i, m%u, %s, ... (%i bytes))\", c->client_id, pkt->publish.header.bits.dup, pkt->publish.header.bits.qos, pkt->publish.header.bits.retain, pkt->publish.pkt_id, pkt->publish.topic, pkt->publish.payloadlen); // 数据记录 info.messages_recv++; char *topic = (char *) pkt->publish.topic; bool alloced = false; // 标记字符串空间是分配的 unsigned char qos = pkt->publish.header.bits.qos; // 保证所有的主题都是用 / 结尾 if (topic[pkt->publish.topiclen - 1] != '/') &#123; topic = append_string((char *) pkt->publish.topic, \"/\", 1); alloced = true; &#125; // 获得或创建基于该 kye 的 topic 对象 struct topic *t = sol_topic_get(&amp;sol, topic); if (!t) &#123; t = topic_create(strdup(topic)); sol_topic_put(&amp;sol, t); &#125; if (alloced == true) free(topic); size_t publen; unsigned char *pub; struct list_node *cur = t->subscribers->head; for (; cur; cur = cur->next) &#123; publen = MQTT_HEADER_LEN + sizeof(uint16_t) + pkt->publish.topiclen + pkt->publish.payloadlen; struct subscriber *sub = cur->data; struct sol_client *sc = sub->client; // 将 QoS 设置为订阅者的 QoS （此处为方便设计，并未完全遵循协议） pkt->publish.header.bits.qos = sub->qos; if (pkt->publish.header.bits.qos > AT_MOST_ONCE) publen += sizeof(uint16_t); int remaininglen_offset = 0; if ((publen - 1) > 0x200000) remaininglen_offset = 3; else if ((publen - 1) > 0x4000) remaininglen_offset = 2; else if ((publen - 1) > 0x80) remaininglen_offset = 1; publen += remaininglen_offset; // 发送给该订阅者的 PUB 包 pub = pack_mqtt_packet(pkt, PUBLISH); ssize_t sent; if ((sent = send_bytes(sc->fd, pub, publen)) &lt; 0) sol_error(\"Error publishing to %s: %s\", sc->client_id, strerror(errno)); // 记录信息 info.bytes_sent += sent; sol_debug(\"Sending PUBLISH to %s (d%i, q%u, r%i, m%u, %s, ... (%i bytes))\", sc->client_id, pkt->publish.header.bits.dup, pkt->publish.header.bits.qos, pkt->publish.header.bits.retain, pkt->publish.pkt_id, pkt->publish.topic, pkt->publish.payloadlen); info.messages_sent++; free(pub); &#125; // 至少一次 使用ACK回复 if (qos == AT_LEAST_ONCE) &#123; mqtt_puback *puback = mqtt_packet_ack(PUBACK_BYTE, pkt->publish.pkt_id); mqtt_packet_release(pkt, PUBLISH); pkt->ack = *puback; unsigned char *packed = pack_mqtt_packet(pkt, PUBACK); cb->payload = bytestring_create(MQTT_ACK_LEN); memcpy(cb->payload->data, packed, MQTT_ACK_LEN); free(packed); sol_debug(\"Sending PUBACK to %s\", c->client_id); return REARM_W; &#125; else if (qos == EXACTLY_ONCE) &#123; // 确保一次 使用 PUBREC 回复 // TODO 需要通过一个哈希表记录已经处于 PUBREC 状态的客户端+包id mqtt_pubrec *pubrec = mqtt_packet_ack(PUBREC_BYTE, pkt->publish.pkt_id); mqtt_packet_release(pkt, PUBLISH); pkt->ack = *pubrec; unsigned char *packed = pack_mqtt_packet(pkt, PUBREC); cb->payload = bytestring_create(MQTT_ACK_LEN); memcpy(cb->payload->data, packed, MQTT_ACK_LEN); free(packed); sol_debug(\"Sending PUBREC to %s\", c->client_id); return REARM_W; &#125; // 至多一次 无需回复 mqtt_packet_release(pkt, PUBLISH); return REARM_R; &#125; ACK PINGREQ 处理器只剩下 ACK 处理器了，他们基本上都是一样的。现在我们只做基本的日志和回复，以后我们再来实现基于 QoS 的业务机制。 还有 PINGREQ 处理器，这是客户端用来确认链接状态的心跳报文，我们只需要用 PINGRESP 回复即可。 src/server.c// PUBACK 处理器 static int puback_handler(struct closure *cb, union mqtt_packet *pkt) &#123; sol_debug(\"Received PUBACK from %s\", ((struct sol_client *) cb->obj)->client_id); // TODO 基于QoS机制, 将该数据移出需重传列表 return REARM_R; &#125; // PUBREC 处理器 static int pubrec_handler(struct closure *cb, union mqtt_packet *pkt) &#123; struct sol_client *c = cb->obj; sol_debug(\"Received PUBREC from %s\", c->client_id); // 按照协议使用 RELEASE 回复 RECIVE mqtt_pubrel *pubrel = mqtt_packet_ack(PUBREL_BYTE, pkt->publish.pkt_id); pkt->ack = *pubrel; unsigned char *packed = pack_mqtt_packet(pkt, PUBREC); cb->payload = bytestring_create(MQTT_ACK_LEN); memcpy(cb->payload->data, packed, MQTT_ACK_LEN); free(packed); sol_debug(\"Sending PUBREL to %s\", c->client_id); return REARM_W; &#125; // PUBREL 处理器 static int pubrel_handler(struct closure *cb, union mqtt_packet *pkt) &#123; sol_debug(\"Received PUBREL from %s\", ((struct sol_client *) cb->obj)->client_id); // 按照协议使用 COMPLETE 回复 RELEASE mqtt_pubcomp *pubcomp = mqtt_packet_ack(PUBCOMP_BYTE, pkt->publish.pkt_id); pkt->ack = *pubcomp; unsigned char *packed = pack_mqtt_packet(pkt, PUBCOMP); cb->payload = bytestring_create(MQTT_ACK_LEN); memcpy(cb->payload->data, packed, MQTT_ACK_LEN); free(packed); sol_debug(\"Sending PUBCOMP to %s\", ((struct sol_client *) cb->obj)->client_id); return REARM_W; &#125; // PUBCOMP 处理器 static int pubcomp_handler(struct closure *cb, union mqtt_packet *pkt) &#123; sol_debug(\"Received PUBCOMP from %s\", ((struct sol_client *) cb->obj)->client_id); // TODO 基于 QoS 机制将其从待确认列表移出 return REARM_R; &#125; // PINGREQ 处理器 static int pingreq_handler(struct closure *cb, union mqtt_packet *pkt) &#123; sol_debug(\"Received PINGREQ from %s\", ((struct sol_client *) cb->obj)->client_id); // 按照协议使用 PINGRESP 回复 pkt->header = *mqtt_packet_header(PINGRESP_BYTE); unsigned char *packed = pack_mqtt_packet(pkt, PINGRESP); cb->payload = bytestring_create(MQTT_HEADER_LEN); memcpy(cb->payload->data, packed, MQTT_HEADER_LEN); free(packed); sol_debug(\"Sending PINGRESP to %s\", ((struct sol_client *) cb->obj)->client_id); return REARM_W; &#125; 现在我们的 broker 已经具有基本的功能，很快就可以和其他的 MQTT 工具联调测试，例如使用 mosquitto_sub 和 mosquitto_pub 或 Python 中的 paho-mqtt。 配置模块配置文件我们需要一个配置模块来设置各种参数，使用最经典的键值对的方式： conf/sol.conf# Sol configuration file, uncomment and edit desired configuration # Network configuration # Uncomment ip_address and ip_port to set socket family to TCP, if unix_socket # is set, UNIX family socket will be used # ip_address 127.0.0.1 # ip_port 9090 unix_socket &#x2F;tmp&#x2F;sol.sock # Logging configuration # Could be either DEBUG, INFO&#x2F;INFORMATION, WARNING, ERROR log_level DEBUG log_path &#x2F;tmp&#x2F;sol.log # Max memory to be used, after which the system starts to reclaim memory by # freeing older items stored max_memory 2GB # Max memory that will be allocated for each request max_request_size 50MB # TCP backlog, size of the complete connection queue tcp_backlog 128 # Interval of time between one stats publish on $SOL topics and the subsequent stats_publish_interval 10s 配置模块定义src/config.h#include &lt;stdio.h> // 默认参数 #define VERSION \"0.0.1\" #define DEFAULT_SOCKET_FAMILY INET #define DEFAULT_LOG_LEVEL DEBUG #define DEFAULT_LOG_PATH \"/tmp/sol.log\" #define DEFAULT_CONF_PATH \"/etc/sol/sol.conf\" #define DEFAULT_HOSTNAME \"127.0.0.1\" #define DEFAULT_PORT \"1883\" #define DEFAULT_MAX_MEMORY \"2GB\" #define DEFAULT_MAX_REQUEST_SIZE \"2MB\" #define DEFAULT_STATS_INTERVAL \"10s\" struct config &#123; /* Sol version &lt;MAJOR.MINOR.PATCH> */ const char *version; /* Eventfd to break the epoll_wait loop in case of signals */ int run; /* Logging level, to be set by reading configuration */ int loglevel; /* Epoll wait timeout, define even the number of times per second that the system will check for expired keys */ int epoll_timeout; /* Socket family (Unix domain or TCP) */ int socket_family; /* Log file path */ char logpath[0xFF]; /* Hostname to listen on */ char hostname[0xFF]; /* Port to open while listening, only if socket_family is INET, * otherwise it's ignored */ char port[0xFF]; /* Max memory to be used, after which the system starts to reclaim back by * freeing older items stored */ size_t max_memory; /* Max memory request can allocate */ size_t max_request_size; /* TCP backlog size */ int tcp_backlog; /* Delay between every automatic publish of broker stats on topic */ size_t stats_pub_interval; &#125;; // 全局配置对象 extern struct config *conf; void config_set_default(void); void config_print(void); int config_load(const char *); char *time_to_string(size_t); char *memory_to_string(size_t); 配置项目无需过多解释，都可以通过名称了解其作用。 配置模块实现配置项主要是使用工具将配置文件的字符串信息解析成配置对象的值： src/config.c#include &lt;ctype.h> #include &lt;string.h> #include &lt;stdlib.h> #include &lt;assert.h> #include &lt;sys/socket.h> #include &lt;sys/eventfd.h> #include \"util.h\" #include \"config.h\" #include \"network.h\" // 全局对象 static struct config config; struct config *conf; struct llevel &#123; const char *lname; int loglevel; &#125;; static const struct llevel lmap[5] = &#123; &#123;\"DEBUG\", DEBUG&#125;, &#123;\"WARNING\", WARNING&#125;, &#123;\"ERROR\", ERROR&#125;, &#123;\"INFO\", INFORMATION&#125;, &#123;\"INFORMATION\", INFORMATION&#125; &#125;; // 解析带单位的内存配置 static size_t read_memory_with_mul(const char *memory_string) &#123; // 解析数字部分 size_t num = parse_int(memory_string); int mul = 1; // 指针指向单位 while (isdigit(*memory_string)) memory_string++; // 通过单位获得乘系数 if (STREQ(memory_string, \"kb\", 2)) mul = 1024; else if (STREQ(memory_string, \"mb\", 2)) mul = 1024 * 1024; else if (STREQ(memory_string, \"gb\", 2)) mul = 1024 * 1024 * 1024; return num * mul; &#125; // 解析带单位的时间配置(默认秒) static size_t read_time_with_mul(const char *time_string) &#123; size_t num = parse_int(time_string); int mul = 1; while (isdigit(*time_string)) time_string++; switch (*time_string) &#123; case 'm': mul = 60; break; case 'd': mul = 60 * 60 * 24; break; default: mul = 1; break; &#125; return num * mul; &#125; // 将内存数字转为人类易读的字符串 例如 1024 => 1Kb char *memory_to_string(size_t memory) &#123; int numlen = 0; int translated_memory = 0; char *mstring = NULL; if (memory &lt; 1024) &#123; translated_memory = memory; numlen = number_len(translated_memory); // 数字 + 'b' mstring = malloc(numlen + 1); snprintf(mstring, numlen + 1, \"%db\", translated_memory); &#125; else if (memory &lt; 1048576) &#123; translated_memory = memory / 1024; numlen = number_len(translated_memory); // + \"Kb\" mstring = malloc(numlen + 2); snprintf(mstring, numlen + 2, \"%dKb\", translated_memory); &#125; else if (memory &lt; 1073741824) &#123; translated_memory = memory / (1024 * 1024); numlen = number_len(translated_memory); // + \"Mb\" mstring = malloc(numlen + 2); snprintf(mstring, numlen + 2, \"%dMb\", translated_memory); &#125; else &#123; translated_memory = memory / (1024 * 1024 * 1024); numlen = number_len(translated_memory); // + \"Gb\" mstring = malloc(numlen + 2); snprintf(mstring, numlen + 2, \"%dGb\", translated_memory); &#125; return mstring; &#125; // 将时间数字转为人类易读的字符串 char *time_to_string(size_t time) &#123; int numlen = 0; int translated_time = 0; char *tstring = NULL; if (time &lt; 60) &#123; translated_time = time; numlen = number_len(translated_time); tstring = malloc(numlen + 1); snprintf(tstring, numlen + 1, \"%ds\", translated_time); &#125; else if (time &lt; 60 * 60) &#123; translated_time = time / 60; numlen = number_len(translated_time); tstring = malloc(numlen + 1); snprintf(tstring, numlen + 1, \"%dm\", translated_time); &#125; else if (time &lt; 60 * 60 * 24) &#123; translated_time = time / (60 * 60); numlen = number_len(translated_time); tstring = malloc(numlen + 1); snprintf(tstring, numlen + 1, \"%dh\", translated_time); &#125; else &#123; translated_time = time / (60 * 60 * 24); numlen = number_len(translated_time); tstring = malloc(numlen + 1); snprintf(tstring, numlen + 1, \"%dd\", translated_time); &#125; return tstring; &#125; // 基于读取的 kv, 向配置对象赋值 static void add_config_value(const char *key, const char *value) &#123; size_t klen = strlen(key); size_t vlen = strlen(value); if (STREQ(\"log_level\", key, klen) == true) &#123; for (int i = 0; i &lt; 3; i++) &#123; if (STREQ(lmap[i].lname, value, vlen) == true) config.loglevel = lmap[i].loglevel; &#125; &#125; else if (STREQ(\"log_path\", key, klen) == true) &#123; strcpy(config.logpath, value); &#125; else if (STREQ(\"unix_socket\", key, klen) == true) &#123; config.socket_family = UNIX; strcpy(config.hostname, value); &#125; else if (STREQ(\"ip_address\", key, klen) == true) &#123; config.socket_family = INET; strcpy(config.hostname, value); &#125; else if (STREQ(\"ip_port\", key, klen) == true) &#123; strcpy(config.port, value); &#125; else if (STREQ(\"max_memory\", key, klen) == true) &#123; config.max_memory = read_memory_with_mul(value); &#125; else if (STREQ(\"max_request_size\", key, klen) == true) &#123; config.max_request_size = read_memory_with_mul(value); &#125; else if (STREQ(\"tcp_backlog\", key, klen) == true) &#123; int tcp_backlog = parse_int(value); config.tcp_backlog = tcp_backlog &lt;= SOMAXCONN ? tcp_backlog : SOMAXCONN; &#125; else if (STREQ(\"stats_publish_interval\", key, klen) == true) &#123; config.stats_pub_interval = read_time_with_mul(value); &#125; &#125; // 去空格 static inline void strip_spaces(char **str) &#123; if (!*str) return; while (isspace(**str) &amp;&amp; **str) ++(*str); &#125; static inline void unpack_bytes(char **str, char *dest) &#123; if (!str || !dest) return; while (!isspace(**str) &amp;&amp; **str) *dest++ = *(*str)++; &#125; // 读取配置 int config_load(const char *configpath) &#123; assert(configpath); FILE *fh = fopen(configpath, \"r\"); if (!fh) &#123; sol_warning(\"WARNING: Unable to open conf file %s\", configpath); sol_warning(\"To specify a config file run sol -c /path/to/conf\"); return false; &#125; char line[0xff], key[0xff], value[0xff]; int linenr = 0; char *pline, *pkey, *pval; while (fgets(line, 0xff, fh) != NULL) &#123; memset(key, 0x00, 0xff); memset(value, 0x00, 0xff); linenr++; // 跳过注解 if (line[0] == '#') continue; // 删除key前的空格 pline = line; strip_spaces(&amp;pline); if (*pline == '\\0') continue; // key pkey = key; unpack_bytes(&amp;pline, pkey); // 删除 key 后空格 strip_spaces(&amp;pline); // 忽略错误的配置格式并提示 if (line[0] == '\\0') &#123; sol_warning(\"WARNING: Incomplete configuration '%s' at line %d. \" \"Fallback to default.\", key, linenr); continue; &#125; // 获得值 pval = value; unpack_bytes(&amp;pline, pval); // 赋值 add_config_value(key, value); &#125; return true; &#125; // 设置默认参数 void config_set_default(void) &#123; // 全局配置对象指针 conf = &amp;config; // 默认赋值 config.version = VERSION; config.socket_family = DEFAULT_SOCKET_FAMILY; config.loglevel = DEFAULT_LOG_LEVEL; strcpy(config.logpath, DEFAULT_LOG_PATH); strcpy(config.hostname, DEFAULT_HOSTNAME); strcpy(config.port, DEFAULT_PORT); config.epoll_timeout = -1; config.run = eventfd(0, EFD_NONBLOCK); config.max_memory = read_memory_with_mul(DEFAULT_MAX_MEMORY); config.max_request_size = read_memory_with_mul(DEFAULT_MAX_REQUEST_SIZE); config.tcp_backlog = SOMAXCONN; config.stats_pub_interval = read_time_with_mul(DEFAULT_STATS_INTERVAL); &#125; // 配置输出 void config_print(void) &#123; if (config.loglevel &lt; WARNING) &#123; const char *sfamily = config.socket_family == UNIX ? \"Unix\" : \"Tcp\"; const char *llevel = NULL; for (int i = 0; i &lt; 4; i++) &#123; if (lmap[i].loglevel == config.loglevel) llevel = lmap[i].lname; &#125; sol_info(\"Sol v%s is starting\", VERSION); sol_info(\"Network settings:\"); sol_info(\"\\tSocket family: %s\", sfamily); if (config.socket_family == UNIX) &#123; sol_info(\"\\tUnix socket: %s\", config.hostname); &#125; else &#123; sol_info(\"\\tAddress: %s\", config.hostname); sol_info(\"\\tPort: %s\", config.port); sol_info(\"\\tTcp backlog: %d\", config.tcp_backlog); &#125; const char *human_rsize = memory_to_string(config.max_request_size); sol_info(\"\\tMax request size: %s\", human_rsize); sol_info(\"Logging:\"); sol_info(\"\\tlevel: %s\", llevel); sol_info(\"\\tlogpath: %s\", config.logpath); const char *human_memory = memory_to_string(config.max_memory); sol_info(\"Max memory: %s\", human_memory); free((char *) human_memory); free((char *) human_rsize); &#125; &#125; 主函数最后的最后，main 函数： src/sol.c#define _POSIX_C_SOURCE 2 #include &lt;stdio.h> #include &lt;stdlib.h> #include &lt;string.h> #include &lt;unistd.h> #include \"util.h\" #include \"config.h\" #include \"server.h\" int main (int argc, char **argv) &#123; char *addr = DEFAULT_HOSTNAME; char *port = DEFAULT_PORT; char *confpath = DEFAULT_CONF_PATH; int debug = 0; int opt; // 使用默认值赋值 config_set_default(); // 处理运行参数 while ((opt = getopt(argc, argv, \"a:c:p:m:vn:\")) != -1) &#123; switch (opt) &#123; case 'a': addr = optarg; strcpy(conf->hostname, addr); break; case 'c': confpath = optarg; break; case 'p': port = optarg; strcpy(conf->port, port); break; case 'v': debug = 1; break; default: fprintf(stderr, \"Usage: %s [-a addr] [-p port] [-c conf] [-v]\\n\", argv[0]); exit(EXIT_FAILURE); &#125; &#125; // 通过参数设置 debug 等级 conf->loglevel = debug == 1 ? DEBUG : WARNING; // 读配置 config_load(confpath); sol_log_init(conf->logpath); // 打印配置 config_print(); // 运行服务 start_server(conf->hostname, conf->port); sol_log_close(); return 0; &#125; 构建与运行我们的 sol 项目运行的所有所需内容都完成了： sol/ ├── src/ │ ├── mqtt.h │ ├── mqtt.c │ ├── network.h │ ├── network.c │ ├── list.h │ ├── list.c │ ├── hashtable.h │ ├── hashtable.c │ ├── server.h │ ├── server.c │ ├── trie.h │ ├── trie.c │ ├── util.h │ ├── util.c │ ├── core.h │ ├── core.c │ ├── config.h │ ├── config.c │ ├── pack.h │ ├── pack.c │ └── sol.c ├── conf │ └── sol.conf ├── CHANGELOG ├── CMakeLists.txt ├── COPYING └── README.md sol 项目的代码量并不算大，一般这种情况下我会编写 Makefile 用来控制编译。但是这一次，就像上方文件结构中描述的那样，我打算使用 CMakeLists.txt 来控制项目的构建： cmake_minimum_required(VERSION 2.8) project(sol) OPTION(DEBUG \"add debug flags\" OFF) if (DEBUG) message(STATUS \"Configuring build for debug\") set(CMAKE_C_FLAGS \"$&#123;CMAKE_C_FLAGS&#125; -Wall -Wunused -Werror -std=c11 -O3 -pedantic -luuid -ggdb -fsanitize=address -fsanitize=undefined -fno-omit-frame-pointer -pg\") else (DEBUG) message(STATUS \"Configuring build for production\") set(CMAKE_C_FLAGS \"$&#123;CMAKE_C_FLAGS&#125; -Wall -Wunused -Werror -Wextra -std=c11 -O3 -pedantic -luuid\") endif (DEBUG) set(EXECUTABLE_OUTPUT_PATH $&#123;CMAKE_SOURCE_DIR&#125;) file(GLOB SOURCES src/*.c) set(AUTHOR \"Andrea Giacomo Baldan\") set(LICENSE \"BSD2 license\") # Executable add_executable(sol $&#123;SOURCES&#125;) 唯一值得注意的就是我添加了 DEBUG 参数，这会产生一个带有监测内存泄漏参数版本的 Makefile。 所以接下来只需要生成 Makefile $ cmake -DDEBUG=1 . 然后编译我们的代码 $ make 编译后得到名为 sol 的可执行程序，我们可以运行他来启动我们的 broker，程序支持我们上面编写的那些参数。 我们通过 -v (verbose) 参数启动程序，这样可以看到 debug 级别的日志信息。 $ sol -v 结尾好了，到此为止就是这么多内容，现在我们的代码也许有很多bug，有内存泄露问题，有很多需要修复或者重构的代码，但是软件的框架就是这样子了。第七部分很快就会编写完成，我打算用 paho-mqtt 进行一些测试。接下来你可以看看特别篇，在那里我们会为 sol 添加多线程支持。","tags":[{"name":"网络编程","slug":"网络编程","permalink":"https://vitsumoc.github.io/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"name":"翻译","slug":"翻译","permalink":"https://vitsumoc.github.io/tags/%E7%BF%BB%E8%AF%91/"},{"name":"C","slug":"C","permalink":"https://vitsumoc.github.io/tags/C/"},{"name":"MQTT","slug":"MQTT","permalink":"https://vitsumoc.github.io/tags/MQTT/"},{"name":"物联网","slug":"物联网","permalink":"https://vitsumoc.github.io/tags/%E7%89%A9%E8%81%94%E7%BD%91/"}]},{"title":"[翻译]Sol - 从零开始的MQTT broker - 第五部分：主题树","date":"2023-12-28T02:43:27.000Z","path":"translate-sol-5.html","text":"原文 Sol - An MQTT broker from scratch. Part 5 - Topic abstraction 主题在第四部分中，我们已经实现了两个数据结构，哈希表和列表。 在MQTT协议中，有一种名为 主题(topic) 的路由方式，主题本质上是一个字符串，用来将消息匹配到符合规则的客户端中。主题使用分层模型，遵守以下规则： 主题是一个UTF-8编码的字符串，最大长度为65535个字节 / 用来区分不同的层级，就像文件系统一样 * 是多层匹配通配符，例如使用 foo&#x2F;bar&#x2F;* 可以匹配下列主题： foo&#x2F;bar foo&#x2F;bar&#x2F;baz foo&#x2F;bar&#x2F;bat&#x2F;yop + 是单层匹配通配符，例如使用 foo&#x2F;+&#x2F;baz 可以匹配下列主题： foo&#x2F;bar&#x2F;baz foo&#x2F;zod&#x2F;baz foo&#x2F;nop&#x2F;baz 主题和消息队列有一些类似的特性，但是主题更简单，更加轻量级，同时功能也更弱。 特里树定义现在，我们开始定义我们的 特里树(trie) ，这将是我们用来存储主题的数据结构。特里树是这样一种结构，他的每一个节点都带有一个字符，从根到节点的所有字符就组成一个key，数据则是关联在key对应的位置上，在最糟糕的情况下，插入和查找的复杂度为 O(m)，其中 m 是键的长度。特里树的主要优点是可以方便的进行前缀匹配。 src/trie.h#include &lt;stdio.h> #include &lt;stdbool.h> #include \"list.h\" // 向用户提供类型 Trie typedef struct trie Trie; // 树节点, 包括一个子节点列表 children // 如果是终端节点, 会在data中存储数据 struct trie_node &#123; char chr; List *children; void *data; &#125;; // 特里树类型, 包括根节点和数据数量 struct trie &#123; struct trie_node *root; size_t size; &#125;; // 创建一个新的字符节点 struct trie_node *trie_create_node(char); // 创建一个新的特里树 struct trie *trie_create(void); // 特里树初始化 void trie_init(Trie *); // 当前大小 size_t trie_size(const Trie *); /* * 叶子代表有关联数据的节点 * . * / \\ * h s: s -> value * / \\ * e k: hk -> value * / * l: hel -> value * * 上例中有三个键值对： * - s -> value * - hk -> value * - hel -> value */ void *trie_insert(Trie *, const char *, const void *); bool trie_delete(Trie *, const char *); // 查找节点, 查找成功时返回 true, 否则 false // 第三个参数作为返回值, 提供指向查找结果的指针, 未找到时值为NULL bool trie_find(const Trie *, const char *, void **); // 释放一个节点, 同时更新size void trie_node_free(struct trie_node *, size_t *); void trie_release(Trie *); // 通过一个前缀删除所有能匹配的节点 void trie_prefix_delete(Trie *, const char *); // 使用 mapfunc 处理树中的所有节点, 第四个参数是 mapfunc 可使用的参数 void trie_prefix_map_tuple(Trie *, const char *, void (*mapfunc)(struct trie_node *, void *), void *); 特里树性能关于树节点的实现，其实有很多种不同的方法，最简单的一种就是在每一个节点上使用固定长度的数组，数组的大小就是完整的字母表大小，例如这样： #define ALPHABET_SIZE 94 // 使用固定数组大小的树节点 struct trie_node &#123; struct trie_node *children[ALPHABET_SIZE]; void *data; &#125;; 除了可以对key进行范围查询（用以实现通配符功能）这个最大的优点外，特里树的另一个巨大优点是他基于哈希表或者说 B-Tree 的性能优势，能够在进行插入、删除和搜索时保持最坏为 O(L) 的时间复杂度（L是查询键的长度）。但这是有代价的，最明显的缺陷就是结构体自身的内存消耗。 在上面的例子中，我们的字母表长度是96，意味着从空格 开始一直到 ~ 结束的96个代表不同字符的 NULL 指针都会被存在 children 中。在一个64位的机器上，每个指针需要使用8个byte，也就是说一个节点至少需要 96 * 8 &#x3D; 768 个字节的空间。我们举个简单的例子： 插入一个key foo 插入一个key foot 此时我们的根节点 f 有一个非空指针 o，o 也有一个非空指针 o，这里储存着键 foo 对应的值。第二个 o 还有一个非空指针 t， 他将存储键 foot 对应的值。所以我们总共会有4个节点，这意味着我们会有 4 * 96 &#x3D; 384 个指针，然后只使用了其中的4个，显然造成了很大的空间浪费。 当然，业界早有解决这个问题的方法，即减少空间浪费又保持着良好的时间复杂度性能，比如压缩特里树（compressed trie）和自适应特里树（adaptive trie）。 我们不去深入挖掘这些概念，就我们目前情况来看，可以想到三个解决方案： 在特里树结构体本身（非节点）添加一个动态列表，每个节点都必须拥有一个指向该列表的指针，和一个char children_idx[ALPHABET_SIZE]数组，数组中保存了自己的子节点在列表中的索引（这句话译者没有理解，原文：Use a single dynamic array (vector) in the Trie structure, each node must have a pointer to that vector and an array char children_idx[ALPHABET_SIZE] which store the index in the main vector for each children，如果你能理解，请告诉我，感谢） 使用基于子节点数量增长存储空间的节点，例如当子节点数量 &lt;&#x3D; 4 时，可以使用固定长度为4的数组，当子节点数量增长时将数组更换为更大的数组并且重新关联子节点。 将每个节点上的定长数组更换为 链表， 在每次插入操作后保持排序，这样每次搜索的平均性能为 O(n&#x2F;2)，等同于 O(n)。 恰好我们在上个部分中实现了基于链表的列表，接下来就让我们使用第三种方案来实现我们的特里树。 特里树实现src/trie.c#include &lt;assert.h> #include &lt;stdlib.h> #include &lt;string.h> #include \"list.h\" #include \"trie.h\" // 合并两个输入的链表为一个链表, 并从小到大排序 // 要求输入的两个链表都是已经被从小到大排序 static struct list_node *merge_tnode_list(struct list_node *list1, struct list_node *list2) &#123; struct list_node dummy_head = &#123; NULL, NULL &#125;, *tail = &amp;dummy_head; // 每次都取 l1 或 l2 中较小的那个, 循环操作 while (list1 &amp;&amp; list2) &#123; // 使用char比较大小 char chr1 = ((struct trie_node *) list1->data)->chr; char chr2 = ((struct trie_node *) list2->data)->chr; struct list_node **min = chr1 &lt;= chr2 ? &amp;list1 : &amp;list2; struct list_node *next = (*min)->next; tail = tail->next = *min; *min = next; &#125; tail->next = list1 ? list1 : list2; return dummy_head.next; &#125; // 被递归调用, 将链表按照从小到大顺序排序 struct list_node *merge_sort_tnode(struct list_node *head) &#123; struct list_node *list1 = head; if (!list1 || !list1->next) return list1; // 从中分开 struct list_node *list2 = bisect_list(list1); return merge_tnode_list(merge_sort_tnode(list1), merge_sort_tnode(list2)); &#125; // 通过给定的 val 搜索链表中的 trie_node, 最糟糕情况下的时间复杂度是 O(n) static struct list_node *linear_search(const List *list, int value) &#123; if (!list || list->len == 0) return NULL; for (struct list_node *cur = list->head; cur != NULL; cur = cur->next) &#123; if (((struct trie_node *) cur->data)->chr == value) return cur; // 链表内部的节点是按照 chr 排序的，因此当大于 value 时无需继续搜索 else if (((struct trie_node *) cur->data)->chr > value) break; &#125; return NULL; &#125; // 辅助比较函数, 传入两个 list_node, 当其中的 trie_node->chr 相等时返回0, 否则返回1 static int with_char(void *arg1, void *arg2) &#123; struct trie_node *tn1 = ((struct list_node *) arg1)->data; struct trie_node *tn2 = ((struct list_node *) arg2)->data; if (tn1->chr == tn2->chr) return 0; return -1; &#125; // 判断 trie_node 是否有子节点, 没有则认为 free static bool trie_is_free_node(const struct trie_node *node) &#123; return node->children->len == 0 ? true : false; &#125; // 从 node 开始, 通过传入的 prefix, 找到对应的节点 static struct trie_node *trie_node_find(const struct trie_node *node, const char *prefix) &#123; // 结果, 最初指向 node struct trie_node *retnode = (struct trie_node *) node; // 遍历 prefix 向下查找 for (; *prefix; prefix++) &#123; // O(n) struct list_node *child = linear_search(retnode->children, *prefix); // 没找到 if (!child) return NULL; retnode = child->data; &#125; return retnode; &#125; // 创建一个新节点 struct trie_node *trie_create_node(char c) &#123; struct trie_node *new_node = malloc(sizeof(*new_node)); if (new_node) &#123; new_node->chr = c; new_node->data = NULL; new_node->children = list_create(NULL); &#125; return new_node; &#125; // 创建并初始化特里树, 当前 size 0 Trie *trie_create(void) &#123; Trie *trie = malloc(sizeof(*trie)); trie_init(trie); return trie; &#125; void trie_init(Trie *trie) &#123; trie->root = trie_create_node(' '); trie->size = 0; &#125; size_t trie_size(const Trie *trie) &#123; return trie->size; &#125; // 插入数据, 插入沿途的所有所需节点, 如果目标节点已经有数据则替换 // return 被插入的数据 // root 一般是根节点 // key 插入位置目标键 // data 要插入的数据内容 // size 带入 size, 如新增数据则+1 static void *trie_node_insert(struct trie_node *root, const char *key, const void *data, size_t *size) &#123; struct trie_node *cursor = root; // 上级节点 struct trie_node *cur_node = NULL; // 当前节点 struct list_node *tmp = NULL; // 包裹当前节点的 list_node // 逐字符遍历 key for (; *key; key++) &#123; // 我们使用一个 O(n) 复杂度的线性搜索器来搜索匹配的节点 tmp = linear_search(cursor->children, *key); // 如果没有匹配, 我们会添加一个节点, 然后对所有的节点进行排序 if (!tmp) &#123; cur_node = trie_create_node(*key); cursor->children = list_push(cursor->children, cur_node); cursor->children->head = merge_sort_tnode(cursor->children->head); &#125; else &#123; // 匹配成功, 进入下一层匹配 // 如果此时 key 已经被阅读完, 后续直接使用此节点 cur_node = tmp->data; &#125; cursor = cur_node; &#125; // 如果新节点或此节点没有数据, 则记录size if (!cursor->data) (*size)++; cursor->data = (void *) data; return cursor->data; &#125; // 删除 key 节点对应的数据, 同时递归的向上删除每一层不需要的节点（指既没有数据也没有子节点） // return 节点本身是否可被删除(如果没有子节点就可以删除) // node 寻找的起始节点, 一般用root // key 匹配键 // size 当前树的大小 // found 返回是否删除成功 static bool trie_node_recursive_delete(struct trie_node *node, const char *key, size_t *size, bool *found) &#123; if (!node) return false; // 字符串已经递归到达尾部的情况 if (*key == '\\0') &#123; if (node->data) &#123; // 标记成功找到数据 *found = true; // 释放资源（以下为作者原代码，译者觉得这里重复操作了） if (node->data) &#123; free(node->data); node->data = NULL; &#125; free(node->data); node->data = NULL; // 记录size if (*size > 0) (*size)--; // 如果没有子节点, 标记需要被删除 return trie_is_free_node(node); &#125; &#125; else &#123; // 通过 key 逐字符匹配节点 struct list_node *cur = linear_search(node->children, *key); if (!cur) return false; struct trie_node *child = cur->data; if (trie_node_recursive_delete(child, key + 1, size, found)) &#123; // 从list中删除和当前剩余key后缀相同的节点 struct trie_node t = &#123;*key, NULL, NULL&#125;; struct list_node tmp = &#123;&amp;t, NULL&#125;; list_remove(node->children, &amp;tmp, with_char); // 把被删除的节点释放掉 trie_node_free(child, size); // 递归, 逐级向上删除可以被删除的节点 return (!node->data &amp;&amp; trie_is_free_node(node)); &#125; &#125; return false; &#125; // 从根节点开始寻找目标节点, 提供目标节点的数据 // return 是否查询成功 // root 一般传入根节点 // key 查询的键 // ret 返回值 (使用双指针因此当无数据时 *ret 可以为NULL) static bool trie_node_search(const struct trie_node *root, const char *key, void **ret) &#123; struct trie_node *cursor = trie_node_find(root, key); *ret = (cursor &amp;&amp; cursor->data) ? cursor->data : NULL; return !*ret ? false : true; &#125; // 插入数据 void *trie_insert(Trie *trie, const char *key, const void *data) &#123; assert(trie &amp;&amp; key); return trie_node_insert(trie->root, key, data, &amp;trie->size); &#125; // 删除某个节点的数据 (会递归的删除上层不需要的节点) bool trie_delete(Trie *trie, const char *key) &#123; assert(trie &amp;&amp; key); bool found = false; if (strlen(key) > 0) trie_node_recursive_delete(trie->root, key, &amp;(trie->size), &amp;found); return found; &#125; // 获得数据 bool trie_find(const Trie *trie, const char *key, void **ret) &#123; assert(trie &amp;&amp; key); return trie_node_search(trie->root, key, ret); &#125; // 使用前缀删除所有匹配的内容 // 例如 prefix = \"hello\" // 会删除这些内容： hello hellot helloworld void trie_prefix_delete(Trie *trie, const char *prefix) &#123; assert(trie &amp;&amp; prefix); // 找到前缀对应的节点 struct trie_node *cursor = trie_node_find(trie->root, prefix); if (!cursor) return; // 如果没有子节点, 就直接删除这个节点即可 if (cursor->children->len == 0) &#123; trie_delete(trie, prefix); return; &#125; // 如果有子节点 struct list_node *cur = cursor->children->head; // 遍历 for (; cur; cur = cur->next) &#123; // 递归的释放所有内容 trie_node_free(cur->data, &amp;(trie->size)); // 并将子节点指针置空 cur->data = NULL; &#125; trie_delete(trie, prefix); list_clear(cursor->children, 1); &#125; // 使用传入的函数处理每个节点, 将 node 作为首个节点逐层向下遍历, arg 允许作为函数的参数 static void trie_prefix_map_func2(struct trie_node *node, void (*mapfunc)(struct trie_node *, void *), void *arg) &#123; if (trie_is_free_node(node)) &#123; mapfunc(node, arg); return; &#125; struct list_node *child = node->children->head; for (; child; child = child->next) trie_prefix_map_func2(child->data, mapfunc, arg); // node 本身也会被应用 mapfunc(node, arg); &#125; // 从前缀对应的节点开始调用 trie_prefix_map_func2 void trie_prefix_map_tuple(Trie *trie, const char *prefix, void (*mapfunc)(struct trie_node *, void *), void *arg) &#123; assert(trie); if (!prefix) &#123; trie_prefix_map_func2(trie->root, mapfunc, arg); &#125; else &#123; // 找到key对应的节点 struct trie_node *node = trie_node_find(trie->root, prefix); // 没有匹配到的节点 if (!node) return; // 通过递归让node和所有的子节点都应用 mapfunc trie_prefix_map_func2(node, mapfunc, arg); &#125; &#125; // 递归的, 从node开始向下全部释放并删除 void trie_node_free(struct trie_node *node, size_t *size) &#123; if (!node) return; // 这里的递归处理删除所有子节点 if (node->children) &#123; struct list_node *cur = node->children->head; for (; cur; cur = cur->next) trie_node_free(cur->data, size); list_release(node->children, 0); node->children = NULL; &#125; // 译者并没有看明白这里？也许是某种编程技巧？ if (node->data) &#123; free(node->data); if (*size > 0) (*size)--; &#125; else if (node->data) &#123; free(node->data); if (*size > 0) (*size)--; &#125; // 释放node本身 free(node); &#125; // 释放整个特里树 void trie_release(Trie *trie) &#123; if (!trie) return; trie_node_free(trie->root, &amp;(trie->size)); free(trie); &#125; 结尾写到这里，我们的工具基本上够用了。现在我们的项目又多了三个模块： sol/ ├── src/ │ ├── mqtt.h | ├── mqtt.c │ ├── network.h │ ├── network.c │ ├── list.h │ ├── list.c │ ├── hashtable.h │ ├── hashtable.c │ ├── trie.h │ ├── trie.c │ ├── util.h │ ├── util.c │ ├── pack.h │ └── pack.c ├── CHANGELOG ├── CMakeLists.txt ├── COPYING └── README.md","tags":[{"name":"网络编程","slug":"网络编程","permalink":"https://vitsumoc.github.io/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"name":"翻译","slug":"翻译","permalink":"https://vitsumoc.github.io/tags/%E7%BF%BB%E8%AF%91/"},{"name":"C","slug":"C","permalink":"https://vitsumoc.github.io/tags/C/"},{"name":"MQTT","slug":"MQTT","permalink":"https://vitsumoc.github.io/tags/MQTT/"},{"name":"物联网","slug":"物联网","permalink":"https://vitsumoc.github.io/tags/%E7%89%A9%E8%81%94%E7%BD%91/"},{"name":"数据结构","slug":"数据结构","permalink":"https://vitsumoc.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"[翻译]Sol - 从零开始的MQTT broker - 第四部分：数据结构","date":"2023-12-27T02:08:27.000Z","path":"translate-sol-4.html","text":"原文 Sol - An MQTT broker from scratch. Part 4 - Data structures 前言在继续实现所有的 handler 之前，我们先设计和实现一些最常用的数据结构，包括 哈希表(hashtable)，列表(list) 和 **特里树(trie)**。 特里树 不是我们当前就用到的东西，但是在我们后续处理 主题 时会用到他。 也许实现这些数据结构这件事情对于我们这个项目来说有点过于底层了，也确实有很多成熟的实现可以拿来用。但是我个人比较喜欢在稍微有些规模的项目中自己实现数据结构，一方面是这样方便于之后随着项目需求对这些数据结构进行改进，另一方面是，实现数据结构的过程也确实是一个非常好的学习和探索的机会。 哈希表让我们从一个简单的哈希表开始，哈希表本质上是一个数组，他使用哈希值（下图中的Hashval % Bucketsize）作为存储我们信息的索引，并且试图尽可能的减少冲突情况（例如两个key计算出了同样的哈希值）。 Buckets 是一个数组，一般情况下会是个动态扩容的数组，他通过 key 来关联存储的数据。 src/hashtable.h#include &lt;stdio.h> #include &lt;stdint.h> #include &lt;stdbool.h> // 状态码 #define HASHTABLE_OK 0 #define HASHTABLE_ERR 1 #define HASHTABLE_OOM 2 #define HASHTABLE_FULL 3 // 哈希表条目 // key 键 // val 存储的值 // taken 表示此索引是否已经被占用, 如果是则使用 index + 1 的位置存储 struct hashtable_entry &#123; const char *key; void *val; bool taken; &#125;; // 哈希表结构体, 包括最大尺寸、当前尺寸以及存储的数据 typedef struct hashtable HashTable; // 创建哈希表的函数 // 可以传入一个析构函数指针, 作为删除条目时释放资源的函数 // 如果资源比较简单(基础类型或数据流), 可以传NULL, 可以采用默认函数释放 HashTable *hashtable_create(int (*destructor)(struct hashtable_entry *)); // 通过对每个条目调用 `destructor` 来释放所有资源 void hashtable_release(HashTable *); // 哈希表当前大小 size_t hashtable_size(const HashTable *); // 查看哈希表中是否已经存在此key int hashtable_exists(HashTable *, const char *); // 插入数据, const char * 作为 key, void * 作为 value int hashtable_put(HashTable *, const char *, void *); // 通过 key 获取数据 void *hashtable_get(HashTable *, const char *); // 通过 key 删除数据 int hashtable_del(HashTable *, const char *); // 迭代所有的键值对, 使用传入的函数指针进行处理 int hashtable_map(HashTable *, int (*func)(struct hashtable_entry *)); // 迭代所有的键值对, 使用传入的函数指针进行处理, 并且可以额外传入一个参数 int hashtable_map2(HashTable *, int (*func)(struct hashtable_entry *, void *), void *); 我们通过 typedef struct hashtable HashTable; 这种方式将实际的哈希表的结构封装到的 .c 文件里，这样可以避免哈希表的使用者不使用我们提供的函数，而是直接访问我们的哈希表。这种方式可以被看作是c语言中的私有类。 src/hashtable.c#include &lt;stdio.h> #include &lt;stdlib.h> #include &lt;string.h> #include &lt;unistd.h> #include &lt;assert.h> #include \"util.h\" #include \"hashtable.h\" // 哈希表结构 struct hashtable &#123; // 最大容量 size_t table_size; // 当前数据量 size_t size; // 析构函数指针 int (*destructor)(struct hashtable_entry *); // 条目数组 struct hashtable_entry *entries; &#125;; const int INITIAL_SIZE = 4; const int MAX_CHAIN_LENGTH = 8; const unsigned long KNUTH_PRIME = 2654435761; static unsigned long crc32(const uint8_t *, unsigned int); // 通过输入的key 计算其在哈希表中的序号 // 此处仅进行数字运算, 不考虑冲突情况 static uint64_t hashtable_hash_int(HashTable *m, const uint8_t *keystr) &#123; assert(m &amp;&amp; keystr); uint64_t key = crc32(keystr, strlen((const char *) keystr)); /* Robert Jenkins' 32 bit Mix Function */ key += (key &lt;&lt; 12); key ^= (key >> 22); key += (key &lt;&lt; 4); key ^= (key >> 9); key += (key &lt;&lt; 10); key ^= (key >> 2); key += (key &lt;&lt; 7); key ^= (key >> 12); /* Knuth's Multiplicative Method */ key = (key >> 3) * KNUTH_PRIME; return key % m->table_size; &#125; // 通过输入的key 计算其在哈希表中的序号 // 此处考虑了冲突情况 // 如果哈希表已经满了, 返回 -HASHTABLE_FULL static int hashtable_hash(HashTable *table, const uint8_t *key) &#123; assert(table &amp;&amp; key); // 用量超过总额的 1/2 视为满 if (table->size >= (table->table_size / 2)) return -HASHTABLE_FULL; // 计算序号 uint64_t curr = hashtable_hash_int(table, key); char *k, *currk; // 避免序号冲突的情况 // 最大重复 MAX_CHAIN_LENGTH 次 // 意味着视冲突情况, key 被保存在 curr ~ curr + MAX_CHAIN_LENGTH 这个范围中某一点 for (int i = 0; i &lt; MAX_CHAIN_LENGTH; i++) &#123; // 序号未被占用直接返回 if (table->entries[curr].taken == false) return curr; k = (char *) table->entries[curr].key; currk = (char *) key; // 传入的 key 已存在的情况, 返回相同 key 的序号 if (table->entries[curr].taken == true &amp;&amp; STREQ(k, currk, strlen(k)) == true) return curr; curr = (curr + 1) % table->table_size; &#125; return -HASHTABLE_FULL; &#125; // 扩容, 容量 * 2, 重新排布所有的内容 static int hashtable_rehash(HashTable *table) &#123; assert(table); size_t old_size; struct hashtable_entry *curr; // 新数组空间 struct hashtable_entry *temp = calloc(2 * table->table_size, sizeof(*temp)); if (!temp) return -HASHTABLE_ERR; // 暂存旧数组 curr = table->entries; // 指向新数组 table->entries = temp; // 记录空间扩容 old_size = table->table_size; table->table_size = 2 * table->table_size; table->size = 0; int status; // 重新排布所有条目 for (size_t i = 0; i &lt; old_size; i++) &#123; if (curr[i].taken == false) continue; // 也很简单, 就是直接用 put 重新放一遍 if ((status = hashtable_put(table, curr[i].key, curr[i].val)) != HASHTABLE_OK) return status; &#125; // 释放旧数组 free(curr); return HASHTABLE_OK; &#125; // 默认的释放条目函数 static int destroy_entry(struct hashtable_entry *entry) &#123; if (!entry) return -HASHTABLE_ERR; // 释放 key if (entry->key) free((void *) entry->key); // 释放 val if (entry->val) free(entry->val); return HASHTABLE_OK; &#125; // 创建一个空的哈希表 // 新创建的哈希表被分配到堆中, 用完后必须手动释放 HashTable *hashtable_create(int (*destructor)(struct hashtable_entry *)) &#123; // 创建哈希表 HashTable *table = malloc(sizeof(HashTable)); if(!table) return NULL; // 初始化条目数组 table->entries = calloc(INITIAL_SIZE, sizeof(struct hashtable_entry)); if(!table->entries) &#123; hashtable_release(table); return NULL; &#125; // 选择析构函数 table->destructor = destructor ? destructor : destroy_entry; // 初始化数据 table->table_size = INITIAL_SIZE; table->size = 0; return table; &#125; // 当前数据量 size_t hashtable_size(const HashTable *table) &#123; return table->size; &#125; // 是否存在 key int hashtable_exists(HashTable *table, const char *key) &#123; void *ret = hashtable_get(table, key); return !ret ? 0 : 1; &#125; // 添加数据, 如果 key 的哈希值重复则序号 +1 int hashtable_put(HashTable *table, const char *key, void *val) &#123; assert(table &amp;&amp; key); // 获得可以存储的序号 int index = hashtable_hash(table, (const uint8_t *) key); // 如果满了 while (index == -HASHTABLE_FULL)&#123; // 尝试扩容 if (hashtable_rehash(table) == -HASHTABLE_ERR) return -HASHTABLE_ERR; index = hashtable_hash(table, (const uint8_t *) key); &#125; // 放置内容 table->entries[index].val = val; table->entries[index].key = key; // 标记使用, 如果是新增, 还需要添加计数 if (table->entries[index].taken == false) &#123; table->entries[index].taken = true; table->size++; &#125; // 译者觉得这里有一个问题, 当 put 使用了重复的 key 时, index会是这个 key 实际存放的索引 // 之后对 key 和 val 进行了赋值, 但是如果 key 是存在的, 那么原来 entry 中的 key 和 val 没有被释放 return HASHTABLE_OK; &#125; // 通过key获得val void *hashtable_get(HashTable *table, const char *key) &#123; assert(table &amp;&amp; key); // 查 key 哈希值对应的索引 uint64_t curr = hashtable_hash_int(table, (const uint8_t *) key); // 查 key 实际对应的索引 for (int i = 0; i &lt; MAX_CHAIN_LENGTH; i++)&#123; if (table->entries[curr].taken == true) &#123; if (STREQ(table->entries[curr].key, key, strlen(key)) == true) return table->entries[curr].val; &#125; curr = (curr + 1) % table->table_size; &#125; return NULL; &#125; // 删除一个条目 int hashtable_del(HashTable *table, const char *key) &#123; assert(table &amp;&amp; key); // 哈希值对应的索引 uint64_t curr = hashtable_hash_int(table, (const uint8_t *) key); // 找到实际 key 的索引 for (int i = 0; i &lt; MAX_CHAIN_LENGTH; i++) &#123; // 有数据 if (table->entries[curr].taken == true) &#123; // 且 key 一致 if (STREQ(table->entries[curr].key, key, strlen(key)) == true) &#123; // 标记无数据 table->entries[curr].taken = false; // 记录尺寸 table->size--; // 使用析构释放 table->destructor(&amp;table->entries[curr]); return HASHTABLE_OK; &#125; &#125; curr = (curr + 1) % table->table_size; &#125; // 未找到数据 return -HASHTABLE_ERR; &#125; // 通过传入的func迭代哈希表中的所有内容 int hashtable_map(HashTable *table, int (*func)(struct hashtable_entry *)) &#123; assert(func); // 空表不处理 if (!table || table->size &lt;= 0) return -HASHTABLE_ERR; // 就遍历 for (size_t i = 0; i &lt; table->table_size; i++) &#123; if (table->entries[i].taken == true) &#123; // 处理data struct hashtable_entry data = table->entries[i]; int status = func(&amp;data); // 要求传入函数正确时返回 HASHTABLE_OK if (status != HASHTABLE_OK) return status; &#125; &#125; return HASHTABLE_OK; &#125; // 另一个迭代器, 支持一个参数 int hashtable_map2(HashTable *table, int (*func)(struct hashtable_entry *, void *), void *param) &#123; assert(func); if (!table || table->size &lt;= 0) return -HASHTABLE_ERR; for (size_t i = 0; i &lt; table->table_size; i++) &#123; if (table->entries[i].taken == true) &#123; // 区别就是带了参数 struct hashtable_entry data = table->entries[i]; int status = func(&amp;data, param); if (status != HASHTABLE_OK) return status; &#125; &#125; return HASHTABLE_OK; &#125; // 使用预定义的析构函数释放哈希表 // 如果没有定义析构函数, 则使用默认函数 destroy_entry void hashtable_release(HashTable *table)&#123; if (!table) return; hashtable_map(table, table->destructor); if (!table || !table->entries) return; free(table->entries); free(table); &#125; /* The implementation here was originally done by Gary S. Brown. Slighltly * modified by Pete Warden, without any imposition on the reuse of the code. */ /* ============================================================= */ /* COPYRIGHT (C) 1986 Gary S. Brown. You may use this program, or */ /* code or tables extracted from it, as desired without restriction. */ /* */ /* First, the polynomial itself and its table of feedback terms. The */ /* polynomial is */ /* X^32+X^26+X^23+X^22+X^16+X^12+X^11+X^10+X^8+X^7+X^5+X^4+X^2+X^1+X^0 */ /* */ /* Note that we take it \"backwards\" and put the highest-order term in */ /* the lowest-order bit. The X^32 term is \"implied\"; the LSB is the */ /* X^31 term, etc. The X^0 term (usually shown as \"+1\") results in */ /* the MSB being 1. */ /* */ /* Note that the usual hardware shift register implementation, which */ /* is what we're using (we're merely optimizing it by doing eight-bit */ /* chunks at a time) shifts bits into the lowest-order term. In our */ /* implementation, that means shifting towards the right. Why do we */ /* do it this way? Because the calculated CRC must be transmitted in */ /* order from highest-order term to lowest-order term. UARTs transmit */ /* characters in order from LSB to MSB. By storing the CRC this way, */ /* we hand it to the UART in the order low-byte to high-byte; the UART */ /* sends each low-bit to hight-bit; and the result is transmission bit */ /* by bit from highest- to lowest-order term without requiring any bit */ /* shuffling on our part. Reception works similarly. */ /* */ /* The feedback terms table consists of 256, 32-bit entries. Notes: */ /* */ /* The table can be generated at runtime if desired; code to do so */ /* is shown later. It might not be obvious, but the feedback */ /* terms simply represent the results of eight shift/xor opera- */ /* tions for all combinations of data and CRC register values. */ /* */ /* The values must be right-shifted by eight bits by the \"updcrc\" */ /* logic; the shift must be unsigned (bring in zeroes). On some */ /* hardware you could probably optimize the shift in assembler by */ /* using byte-swap instructions. */ /* polynomial $edb88320 */ /* */ /* -------------------------------------------------------------------- */ static unsigned long crc32_tab[] = &#123; 0x00000000L, 0x77073096L, 0xee0e612cL, 0x990951baL, 0x076dc419L, 0x706af48fL, 0xe963a535L, 0x9e6495a3L, 0x0edb8832L, 0x79dcb8a4L, 0xe0d5e91eL, 0x97d2d988L, 0x09b64c2bL, 0x7eb17cbdL, 0xe7b82d07L, 0x90bf1d91L, 0x1db71064L, 0x6ab020f2L, 0xf3b97148L, 0x84be41deL, 0x1adad47dL, 0x6ddde4ebL, 0xf4d4b551L, 0x83d385c7L, 0x136c9856L, 0x646ba8c0L, 0xfd62f97aL, 0x8a65c9ecL, 0x14015c4fL, 0x63066cd9L, 0xfa0f3d63L, 0x8d080df5L, 0x3b6e20c8L, 0x4c69105eL, 0xd56041e4L, 0xa2677172L, 0x3c03e4d1L, 0x4b04d447L, 0xd20d85fdL, 0xa50ab56bL, 0x35b5a8faL, 0x42b2986cL, 0xdbbbc9d6L, 0xacbcf940L, 0x32d86ce3L, 0x45df5c75L, 0xdcd60dcfL, 0xabd13d59L, 0x26d930acL, 0x51de003aL, 0xc8d75180L, 0xbfd06116L, 0x21b4f4b5L, 0x56b3c423L, 0xcfba9599L, 0xb8bda50fL, 0x2802b89eL, 0x5f058808L, 0xc60cd9b2L, 0xb10be924L, 0x2f6f7c87L, 0x58684c11L, 0xc1611dabL, 0xb6662d3dL, 0x76dc4190L, 0x01db7106L, 0x98d220bcL, 0xefd5102aL, 0x71b18589L, 0x06b6b51fL, 0x9fbfe4a5L, 0xe8b8d433L, 0x7807c9a2L, 0x0f00f934L, 0x9609a88eL, 0xe10e9818L, 0x7f6a0dbbL, 0x086d3d2dL, 0x91646c97L, 0xe6635c01L, 0x6b6b51f4L, 0x1c6c6162L, 0x856530d8L, 0xf262004eL, 0x6c0695edL, 0x1b01a57bL, 0x8208f4c1L, 0xf50fc457L, 0x65b0d9c6L, 0x12b7e950L, 0x8bbeb8eaL, 0xfcb9887cL, 0x62dd1ddfL, 0x15da2d49L, 0x8cd37cf3L, 0xfbd44c65L, 0x4db26158L, 0x3ab551ceL, 0xa3bc0074L, 0xd4bb30e2L, 0x4adfa541L, 0x3dd895d7L, 0xa4d1c46dL, 0xd3d6f4fbL, 0x4369e96aL, 0x346ed9fcL, 0xad678846L, 0xda60b8d0L, 0x44042d73L, 0x33031de5L, 0xaa0a4c5fL, 0xdd0d7cc9L, 0x5005713cL, 0x270241aaL, 0xbe0b1010L, 0xc90c2086L, 0x5768b525L, 0x206f85b3L, 0xb966d409L, 0xce61e49fL, 0x5edef90eL, 0x29d9c998L, 0xb0d09822L, 0xc7d7a8b4L, 0x59b33d17L, 0x2eb40d81L, 0xb7bd5c3bL, 0xc0ba6cadL, 0xedb88320L, 0x9abfb3b6L, 0x03b6e20cL, 0x74b1d29aL, 0xead54739L, 0x9dd277afL, 0x04db2615L, 0x73dc1683L, 0xe3630b12L, 0x94643b84L, 0x0d6d6a3eL, 0x7a6a5aa8L, 0xe40ecf0bL, 0x9309ff9dL, 0x0a00ae27L, 0x7d079eb1L, 0xf00f9344L, 0x8708a3d2L, 0x1e01f268L, 0x6906c2feL, 0xf762575dL, 0x806567cbL, 0x196c3671L, 0x6e6b06e7L, 0xfed41b76L, 0x89d32be0L, 0x10da7a5aL, 0x67dd4accL, 0xf9b9df6fL, 0x8ebeeff9L, 0x17b7be43L, 0x60b08ed5L, 0xd6d6a3e8L, 0xa1d1937eL, 0x38d8c2c4L, 0x4fdff252L, 0xd1bb67f1L, 0xa6bc5767L, 0x3fb506ddL, 0x48b2364bL, 0xd80d2bdaL, 0xaf0a1b4cL, 0x36034af6L, 0x41047a60L, 0xdf60efc3L, 0xa867df55L, 0x316e8eefL, 0x4669be79L, 0xcb61b38cL, 0xbc66831aL, 0x256fd2a0L, 0x5268e236L, 0xcc0c7795L, 0xbb0b4703L, 0x220216b9L, 0x5505262fL, 0xc5ba3bbeL, 0xb2bd0b28L, 0x2bb45a92L, 0x5cb36a04L, 0xc2d7ffa7L, 0xb5d0cf31L, 0x2cd99e8bL, 0x5bdeae1dL, 0x9b64c2b0L, 0xec63f226L, 0x756aa39cL, 0x026d930aL, 0x9c0906a9L, 0xeb0e363fL, 0x72076785L, 0x05005713L, 0x95bf4a82L, 0xe2b87a14L, 0x7bb12baeL, 0x0cb61b38L, 0x92d28e9bL, 0xe5d5be0dL, 0x7cdcefb7L, 0x0bdbdf21L, 0x86d3d2d4L, 0xf1d4e242L, 0x68ddb3f8L, 0x1fda836eL, 0x81be16cdL, 0xf6b9265bL, 0x6fb077e1L, 0x18b74777L, 0x88085ae6L, 0xff0f6a70L, 0x66063bcaL, 0x11010b5cL, 0x8f659effL, 0xf862ae69L, 0x616bffd3L, 0x166ccf45L, 0xa00ae278L, 0xd70dd2eeL, 0x4e048354L, 0x3903b3c2L, 0xa7672661L, 0xd06016f7L, 0x4969474dL, 0x3e6e77dbL, 0xaed16a4aL, 0xd9d65adcL, 0x40df0b66L, 0x37d83bf0L, 0xa9bcae53L, 0xdebb9ec5L, 0x47b2cf7fL, 0x30b5ffe9L, 0xbdbdf21cL, 0xcabac28aL, 0x53b39330L, 0x24b4a3a6L, 0xbad03605L, 0xcdd70693L, 0x54de5729L, 0x23d967bfL, 0xb3667a2eL, 0xc4614ab8L, 0x5d681b02L, 0x2a6f2b94L, 0xb40bbe37L, 0xc30c8ea1L, 0x5a05df1bL, 0x2d02ef8dL &#125;; // 根据输入的字符串计算一个 64 位的 CRC static unsigned long crc32(const uint8_t *s, unsigned int len) &#123; unsigned int i; uint64_t crc32val; crc32val = 0LL; for (i = 0; i &lt; len; i ++) &#123; crc32val = crc32_tab[(crc32val ^ s[i]) &amp; 0xff] ^ (crc32val >> 8); &#125; return crc32val; &#125; 我们的哈希表使用 knuth multiplicative 方法将字符串转为CRC，另一个可用的方法是 Murmur3，但是我也不清楚什么才是最佳的哈希算法。 列表接下来我们会用到列表 list，虽然 vector 可以通过他的缓存友好性来提升一些性能，但是对于我们的需求来说也没有太大的收益。O(1)的数据插入复杂度对于我们来说完全足够使用了。我们的列表会基于一个单向链表，带有头部和尾部的指针，这样可以保证我们从两侧插入时的复杂度都为O(1)。 src/list.h// 节点 struct list_node &#123; void *data; struct list_node *next; &#125;; // 列表 typedef struct list &#123; struct list_node *head; // 头指针 struct list_node *tail; // 尾指针 unsigned long len; int (*destructor)(struct list_node *); &#125; List; // 比较函数接口, 用来比较两个节点 typedef int (*compare_func)(void *, void *); // 创建列表 List *list_create(int (*destructor)(struct list_node*)); // 释放链表, 通过一个 int 的标志来决定释放深度 // 例如：判断是否需要释放所有的节点中的数据 void list_release(List *, int); // 当前大小 unsigned long list_size(const List *); // 清空链表, 但保留链表本身, 根据 int 判断是否释放节点中的数据 void list_clear(List *, int); // 在头部插入数据 List *list_push(List *, void *); // 在尾部插入数据 List *list_push_back(List *, void *); // 通过传入的比较函数, 删除和第二参数相同的节点 void list_remove(List *, struct list_node *, compare_func); // 删除一个节点并返回被删除的节点 struct list_node *list_remove_node(List *, void *, compare_func); // 另一个比较函数接口, 用来进行合并或排序 typedef int cmp(void *, void *); // 再 cmp_func 计算的位置插入一个节点 struct list_node *list_sort_insert(struct list_node **, struct list_node *, compare_func); // 将 list 从中间分为两份 struct list_node *bisect_list(struct list_node *); src/list.c#include \"list.h\" #include &lt;stdlib.h> // 私有的删除节点函数 static struct list_node *list_node_remove(struct list_node *, struct list_node *, compare_func, int *); // 创建列表 List *list_create(int (*destructor)(struct list_node *)) &#123; List *l = malloc(sizeof(List)); if (!l) return NULL; // 默认值 l->head = l->tail = NULL; l->len = 0L; // TODO 默认析构 l->destructor = destructor; return l; &#125; // 释放列表 void list_release(List *l, int deep) &#123; if (!l) return; struct list_node *h = l->head; struct list_node *tmp; // 释放所有节点 while (l->len--) &#123; tmp = h->next; if (l->destructor) l->destructor(h); else &#123; if (h) &#123; // 如果需要释放数据 if (h->data &amp;&amp; deep == 1) free(h->data); free(h); &#125; &#125; h = tmp; &#125; // 释放列表本身 free(l); &#125; unsigned long list_size(const List *list) &#123; return list->len; &#125; // 清空链表, 但保留链表本身, 根据 int 判断是否释放节点中的数据 void list_clear(List *l, int deep) &#123; if (!l || !l->head) return; struct list_node *h = l->head; struct list_node *tmp; // 释放所有节点 while (l->len--) &#123; tmp = h->next; if (h) &#123; if (h->data &amp;&amp; deep == 1) free(h->data); free(h); &#125; h = tmp; &#125; l->head = l->tail = NULL; l->len = 0L; &#125; // 插入一个数据到头部 List *list_push(List *l, void *val) &#123; struct list_node *new_node = malloc(sizeof(struct list_node)); if (!new_node) return NULL; new_node->data = val; // 第一个数据即使头也是尾 if (l->len == 0) &#123; l->head = l->tail = new_node; new_node->next = NULL; // 插入为头部 &#125; else &#123; new_node->next = l->head; l->head = new_node; &#125; l->len++; return l; &#125; // 插入一个数据到尾部 List *list_push_back(List *l, void *val) &#123; struct list_node *new_node = malloc(sizeof(struct list_node)); if (!new_node) return NULL; new_node->data = val; new_node->next = NULL; if (l->len == 0) &#123; l->head = l->tail = new_node; &#125; else &#123; l->tail->next = new_node; l->tail = new_node; &#125; l->len++; return l; &#125; // 通过传入的比较函数, 删除一个节点 void list_remove(List *l, struct list_node *node, compare_func cmp) &#123; if (!l || !node) return; int counter = 0; // list_node_remove 会递归的一层一层返回下一个节点指针, 并在其中去除被删除的节点 l->head = list_node_remove(l->head, node, cmp, &amp;counter); l->len -= counter; &#125; // 删除节点的工具方法 // return 递归用的返回, 删除成功后的那次调用会返回被删除节点的 next // head 传入遍历起点 // node 需要删除的节点的样子 // cmp 比较函数, 用来比较遍历的节点和传入的node // counter 被删除节点的数量, 0 或者 1 static struct list_node *list_node_remove(struct list_node *head, struct list_node *node, compare_func cmp, int *counter) &#123; if (!head) return NULL; if (cmp(head, node) == 0) &#123; struct list_node *tmp_next = head->next; // 译者认为这里没有考虑节点的data也可能需要释放, 或者是作者觉得可以在cmp中释放？ free(head); head = NULL; // 匹配成功就 return 的话，这里实际只能删除第一个匹配的节点 (*counter)++; return tmp_next; &#125; head->next = list_node_remove(head->next, node, cmp, counter); return head; &#125; // 删除一个节点的工具方法 // return 递归的返回 // head 查询起点 // data 被删除的 node 的形状 // ret 返回被删除的 node // cmp 比较函数 static struct list_node *list_remove_single_node(struct list_node *head, void *data, struct list_node **ret, compare_func cmp) &#123; if (!head) return NULL; if (cmp(head, data) == 0 &amp;&amp; !*ret) &#123; struct list_node *tmp_next = head->next; *ret = head; return tmp_next; &#125; head->next = list_remove_single_node(head->next, data, ret, cmp); return head; &#125; // 删除一个节点并返回被删除的节点 struct list_node *list_remove_node(List *list, void *data, compare_func cmp) &#123; if (list->len == 0 || !list) return NULL; struct list_node *node = NULL; list_remove_single_node(list->head, data, &amp;node, cmp); if (node) &#123; list->len--; node->next = NULL; &#125; return node; &#125; // 在 cmp_func 计算的位置插入一个节点 struct list_node *list_sort_insert(struct list_node **head, struct list_node *new, cmp cmp_func) &#123; if (!*head || cmp_func(*head, new) >= 0) &#123; new->next = *head; *head = new; &#125; else &#123; struct list_node *cur; cur = *head; while (cur->next &amp;&amp; cmp_func(cur->next, new) &lt; 0) cur = cur->next; new->next = cur->next; cur->next = new; &#125; return *head; &#125; // 返回一个靠近中间的 node, 并且已经将原 list 从此处截断 struct list_node *bisect_list(struct list_node *head) &#123; // fast 的移动速度是 slow 的两倍 // prev 表示 slow的前一个节点, 也就是截取后的第一个 list 的最后一个节点 struct list_node *fast = head, *slow = head, *prev = NULL; while (fast != NULL &amp;&amp; fast->next != NULL) &#123; fast = fast->next->next; prev = slow; slow = slow->next; &#125; if (prev != NULL) prev->next = NULL; return slow; &#125; 结尾我们成功的实现了两个经典的数据结构，这样我们可以在项目中使用他们： 哈希表 列表 下一个要实现的数据结构是 特里树，他可以让我们轻松的维护我们的主题和主题的分层结构。","tags":[{"name":"网络编程","slug":"网络编程","permalink":"https://vitsumoc.github.io/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"name":"翻译","slug":"翻译","permalink":"https://vitsumoc.github.io/tags/%E7%BF%BB%E8%AF%91/"},{"name":"C","slug":"C","permalink":"https://vitsumoc.github.io/tags/C/"},{"name":"MQTT","slug":"MQTT","permalink":"https://vitsumoc.github.io/tags/MQTT/"},{"name":"物联网","slug":"物联网","permalink":"https://vitsumoc.github.io/tags/%E7%89%A9%E8%81%94%E7%BD%91/"},{"name":"数据结构","slug":"数据结构","permalink":"https://vitsumoc.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"[翻译]Sol - 从零开始的MQTT broker - 第三部分：服务","date":"2023-12-22T01:44:08.000Z","path":"translate-sol-3.html","text":"原文 Sol - An MQTT broker from scratch. Part 3 - Server 前言这一部分我们会实现我们程序中的服务功能，通过之前在 part-2 中实现的 network 模块，我们可以比较轻松的接收并处理在 part-1 中定义好的各种 MQTT 数据包。 服务端定义我们的头文件非常简单，唯一向外提供的函数只有 start_server，他也只需要接收两个参数： 一个IP地址 一个监听端口 我们还需要定义创建 epoll 时使用的两个常量，一个是单次监听的最大事件数量，另一个是 epoll 监听的超时时间。这两个常量的定义以后我们也可以轻松的移动到配置模块里，暂时就先放在 server 的头文件。 src/server.h// epoll 的默认配置 // 最大监听 256 事件 // -1 表示不超时, epoll 可以无限期的阻塞并监听 #define EPOLL_MAX_EVENTS 256 #define EPOLL_TIMEOUT -1 // 不同类型的错误码 // client disconnection 客户端断开 // error reading packet 读包错误 // error packet sent exceeds size defined by configuration 包过大 (限制默认 2M) #define ERRCLIENTDC 1 #define ERRPACKETERR 2 #define ERRMAXREQSIZE 3 // handler 的返回值, 表示对客户端读取后的下一个动作是读还是写 #define REARM_R 0 #define REARM_W 1 // 启动服务的函数 int start_server(const char *, const char *); 服务端实现实现的部分比我一开始预想的要庞大一些，所有我们所需的 处理器(handler) 和 回调函数都会在这里定义。所以我们首先来实现三个最基础的回调函数，这三个函数是任何服务器都必不可少的： 用于建立连接的 on_accept 用于读取事件的 on_read 用于发送数据的 on_write 我们还需要定义一些关于MQTT包处理的 handler，同样使用一个数组保存，并且使 handler 在其中的序号等于包类型码。（这个方式我们已经用过好几次了） src/server.c#define _POSIX_C_SOURCE 200809L #include &lt;time.h> #include &lt;errno.h> #include &lt;string.h> #include &lt;stdlib.h> #include &lt;unistd.h> #include &lt;arpa/inet.h> #include &lt;sys/epoll.h> #include &lt;sys/socket.h> #include \"pack.h\" #include \"util.h\" #include \"mqtt.h\" #include \"core.h\" #include \"network.h\" #include \"hashtable.h\" #include \"config.h\" #include \"server.h\" /* Seconds in a Sol, easter egg */ static const double SOL_SECONDS = 88775.24; // 服务器本身状态信息 // 所有数据都会通过一个周期性回调发布 static struct sol_info info; // broker 的全局实例, 包括了主题树和客户端的哈希表 static struct sol sol; // 处理器接口 // 内含客户端的 closure 与数据包 mqtt_packet typedef int handler(struct closure *, union mqtt_packet *); // 包处理器, 每个函数负责处理对应名称的包 static int connect_handler(struct closure *, union mqtt_packet *); static int disconnect_handler(struct closure *, union mqtt_packet *); static int subscribe_handler(struct closure *, union mqtt_packet *); static int unsubscribe_handler(struct closure *, union mqtt_packet *); static int publish_handler(struct closure *, union mqtt_packet *); static int puback_handler(struct closure *, union mqtt_packet *); static int pubrec_handler(struct closure *, union mqtt_packet *); static int pubrel_handler(struct closure *, union mqtt_packet *); static int pubcomp_handler(struct closure *, union mqtt_packet *); static int pingreq_handler(struct closure *, union mqtt_packet *); // 处理器数组, 同样使用 type 的值作为索引 static handler *handlers[15] = &#123; NULL, connect_handler, NULL, publish_handler, puback_handler, pubrec_handler, pubrel_handler, pubcomp_handler, subscribe_handler, NULL, unsubscribe_handler, NULL, pingreq_handler, NULL, disconnect_handler &#125;; // 本 module 内部使用的 conn 结构体, 用来接收新连接 struct connection &#123; char ip[INET_ADDRSTRLEN + 1]; int fd; &#125;; // I/O closures, 关于三个服务器主要操作的回调 // - 读取客户端发来的数据 // - 向客户端写数据 // - 接收新的客户端连接 static void on_read(struct evloop *, void *); static void on_write(struct evloop *, void *); static void on_accept(struct evloop *, void *); // 定时回调, 周期性发布服务器状态 static void publish_stats(struct evloop *, void *); // 从 sfd 接收一条新链接, 将他的 ip 和 fd 存入conn中 static int accept_new_client(int fd, struct connection *conn) &#123; if (!conn) return -1; // 获得新链接 int clientsock = accept_connection(fd); // 没有获取成功的话 if (clientsock == -1) return -1; // 就是检查一些新连接的属性 struct sockaddr_in addr; socklen_t addrlen = sizeof(addr); if (getpeername(clientsock, (struct sockaddr *) &amp;addr, &amp;addrlen) &lt; 0) return -1; char ip_buff[INET_ADDRSTRLEN + 1]; if (inet_ntop(AF_INET, &amp;addr.sin_addr, ip_buff, sizeof(ip_buff)) == NULL) return -1; struct sockaddr_in sin; socklen_t sinlen = sizeof(sin); if (getsockname(fd, (struct sockaddr *) &amp;sin, &amp;sinlen) &lt; 0) return -1; // 赋值我们要的 ip 和 fd conn->fd = clientsock; strcpy(conn->ip, ip_buff); return 0; &#125; // accept 的回调, 通过 sfd 获得 cfd, 然后对 cfd 添加 EPOLLIN 监听 // loop evloop实例 // arg server closure, 包括了 sfd 在其中, on_accept 其实就是 server closure 的 call 参数 static void on_accept(struct evloop *loop, void *arg) &#123; // arg 是 server closure struct closure *server = arg; struct connection conn; // 获得 conn accept_new_client(server->fd, &amp;conn); // 创建这个客户端的 closure struct closure *client_closure = malloc(sizeof(*client_closure)); if (!client_closure) return; // 填充内容 client_closure->fd = conn.fd; client_closure->obj = NULL; // 闭包的主要对象, 这个项目中是 client 对象, 在第六部分定义 client_closure->payload = NULL; client_closure->args = client_closure; // 拿自己当回调参数 client_closure->call = on_read; // 数据来时触发 on_read generate_uuid(client_closure->closure_id); // 生成uuid // 保存在一个哈希表里 hashtable_put(sol.closures, client_closure->closure_id, client_closure); // 将这个 closure 注册到 evloop, 事件是 EPOLLIN evloop_add_callback(loop, client_closure); // 重置 server fd, 让其可以继续接收新链接 evloop_rearm_callback_read(loop, server); // 记录新链接 info.nclients++; info.nconnections++; // 日志 sol_info(\"New connection from %s on port %s\", conn.ip, conf->port); &#125; 正如你所见，我定义了两个静态函数（在C语言中，当我们不严格的追究术语时，由于这种静态函数只能被同样.c文件里的函数访问，我们可以把这种函数看作是其他OOP语言中的私有方法。） accept_new_client 函数使用了上一篇文中 network 模块定义的 accept_connection 函数，得以从操作系统层级接收新连接并进行一些设置。on_accept 则是实际负责处理新链接的回调函数，他依赖 accept_new_client 函数。 accept_new_client 函数所需的参数结构 connection 是我从我其他项目的代码库复制过来的，并不是说必须要用这种方式。 src/server.c// 接收数据流组装成数据包的函数, 被 on_read 回调使用 // 解析数据包头, 至少会包括 Fixed Header, 因为每个数据包都至少有 2byte 的 Fixed Header, 其中会包括包类型和剩余长度 // 入参包括 // clientfd 客户端fd // buf 放置所有输入数据流 // command 表示mqtt包的第一个字节 static ssize_t recv_packet(int clientfd, unsigned char *buf, char *command) &#123; // 总计读取的字节数 ssize_t nbytes = 0; // 读取一个字节, 这里会包括 MQTT 类型字段 if ((nbytes = recv_bytes(clientfd, buf, 1)) &lt;= 0) return -ERRCLIENTDC; unsigned char byte = *buf; buf++; // 译者没有明白为何可以这样比较, 第一个byte应该是包括了 MQTT type 和 Flags 才对? if (DISCONNECT &lt; byte || CONNECT > byte) return -ERRPACKETERR; // 逐字节读取变长的 Remaining Length unsigned char buff[4]; int count = 0; int n = 0; do &#123; // 使用 buf 读取 if ((n = recv_bytes(clientfd, buf+count, 1)) &lt;= 0) return -ERRCLIENTDC; // 并为 buff 赋值 buff[count] = buf[count]; nbytes += n; // 根据高位判断是否有后续 &#125; while (buff[count++] &amp; (1 &lt;&lt; 7)); // 获得剩余长度的值 const unsigned char *pbuf = &amp;buff[0]; unsigned long long tlen = mqtt_decode_length(&amp;pbuf); // 判断是否过长 if (tlen > conf->max_request_size) &#123; nbytes = -ERRMAXREQSIZE; goto exit; &#125; // 读取所有剩余的字节数, 获得完整数据包字节流 // 译者认为这里 buf + 1 只考虑了 Remaining Length 长度为 1 的情况, 应改为 buf + count if ((n = recv_bytes(clientfd, buf + 1, tlen)) &lt; 0) goto err; nbytes += n; // 第一个字节赋值为 command *command = byte; exit: return nbytes; err: shutdown(clientfd, 0); close(clientfd); return nbytes; &#125; // 客户端输入数据的回调, 当 accepted 或 reply 之后等待 static void on_read(struct evloop *loop, void *arg) &#123; // 这里带着一些客户端信息 struct closure *cb = arg; // 使用最大数据包尺寸准备接收数据 默认2M unsigned char *buffer = malloc(conf->max_request_size); ssize_t bytes = 0; char command = 0; // 在此处必须完整的接收一个数据包的所有数据 // 通过数据包的 Remaining Length 我们可以了解这个数据包的长度到底应该是多少 bytes = recv_packet(cb->fd, buffer, &amp;command); // 链接断开处理 // TODO: 使用一个 error_handler 来处理 ERRMAXREQSIZE 将错误码返回给客户端 if (bytes == -ERRCLIENTDC || bytes == -ERRMAXREQSIZE) goto exit; // 当我们收到一个错误的包时, 我们需要清理 buffer, 并断开这个客户端连接 // 等客户端下次重连上来再处理 if (bytes == -ERRPACKETERR) goto errdc; // 收包计数器 info.bytes_recv++; // 将数据流解码为正确类型的mqtt包 union mqtt_packet packet; unpack_mqtt_packet(buffer, &amp;packet); union mqtt_header hdr = &#123; .byte = command &#125;; // 然后找到对应的 hander 来处理这个包 // 处理完的rc表示 int rc = handlers[hdr.bits.type](cb, &amp;packet); // 如果处理结果是需要发送一个包作为响应 if (rc == REARM_W) &#123; // 重置写入监听 // 当 fd 可写入时 epoll 就会触发 EPOLLOUT 事件 // cb 中的 call 会被执行, 也就是 on_write // 写入需要的参数, 会在 handlers 中会处理好, 之后由 cb 携带 cb->call = on_write; evloop_rearm_callback_write(loop, cb); &#125; else if (rc == REARM_R) &#123; // 重置读取监听, 后面有数据接着读 cb->call = on_read; evloop_rearm_callback_read(loop, cb); &#125; // Disconnect packet received exit: free(buffer); return; errdc: free(buffer); // 把客户端丢弃了 sol_error(\"Dropping client\"); shutdown(cb->fd, 0); close(cb->fd); // 清理哈希表 hashtable_del(sol.clients, ((struct sol_client *) cb->obj)->client_id); hashtable_del(sol.closures, cb->closure_id); // 记录信息 info.nclients--; info.nconnections--; return; &#125; // 写入回调, 当有需要写入的数据且 fd 可被写入时触发 static void on_write(struct evloop *loop, void *arg) &#123; struct closure *cb = arg; ssize_t sent; // cb 里包括了所有需要发送的内容 if ((sent = send_bytes(cb->fd, cb->payload->data, cb->payload->size)) &lt; 0) sol_error(\"Error writing on socket to client %s: %s\", ((struct sol_client *) cb->obj)->client_id, strerror(errno)); // 发包计数器 info.bytes_sent += sent; // 释放 bytestring_release(cb->payload); cb->payload = NULL; // 客户端的下一次触发肯定是 read (业务上来说服务端不可能连续发两个包) cb->call = on_read; evloop_rearm_callback_read(loop, cb); &#125; 我们又添加了三个静态函数，recv_packet 函数就像他的名字一样，依赖 mqtt 模块，负责持续接收数据流直到足够一个完整的 MQTT 包。另外两个分别是 on_read 和 on_write。 请注意，on_read 和 on_write 使用我们之前定义的函数不停的重置对 socket 的监听，就像来回打乒乓球一样。例如， on_read 可以通过 处理器 的返回值来决定下一次的操作是 read 还是 write，然后把客户端链接的下一个回调函数设置为 on_read 或者 on_write，当然也有可能是断开链接。比如说客户端发来的数据出现了错误，或者当客户端发来了 DISCONNECT 包，那么此时对应的 处理器 返回的值就既不是 REARM_W 也不是 REARM_R。 在 on_write 中我们看到 send_bytes 传入了一个带有大小和内容的 payload，这里使用了我定义的一个方便的工具结构 bytestring，我们现在就在 src/pack.h and src/pack.c 中添加他。 工具 bytestringsrc/pack.h// bytestring 结构体, 提供了一个便携的保存 bytes 的方法 // 他本质上提供了一个指向最后编辑位置的指针, 和 bytes 的总长度 struct bytestring &#123; size_t size; size_t last; unsigned char *data; &#125;; // bytestring 的初始化函数, 需要一个长度作为参数 // 为了简化, 我们直接采用固定长度, 并且不会再后续使用过程中扩容 struct bytestring *bytestring_create(size_t); void bytestring_init(struct bytestring *, size_t); void bytestring_release(struct bytestring *); void bytestring_reset(struct bytestring *); 这里是关于 bytestring 的实现。 src/pack.c// 创建 struct bytestring *bytestring_create(size_t len) &#123; struct bytestring *bstring = malloc(sizeof(*bstring)); bytestring_init(bstring, len); return bstring; &#125; // 初始化内部结构 void bytestring_init(struct bytestring *bstring, size_t size) &#123; if (!bstring) return; bstring->size = size; bstring->data = malloc(sizeof(unsigned char) * size); bytestring_reset(bstring); &#125; // 释放 void bytestring_release(struct bytestring *bstring) &#123; if (!bstring) return; free(bstring->data); free(bstring); &#125; // 清空数据 void bytestring_reset(struct bytestring *bstring) &#123; if (!bstring) return; bstring->last = 0; memset(bstring->data, 0, bstring->size); &#125; 日志和通用工具让我们稍微打断一下主线，按照我的经验，到这个阶段我们往往会需要一些工具函数，我一般会把他们统一放在 util 包中。我们刚才已经看到了一些 sol_info, sol_debug 或者 sol_error 这样的函数，其实就是 util 包中的定义。 我们的日志需求很简单，所以不需要专门做一个日志模块，就先放到 util 包里。 src/util.h#include &lt;stdio.h> #include &lt;stdint.h> #include &lt;stdbool.h> #include &lt;strings.h> #define UUID_LEN 37 // 36 + nul char #define MAX_LOG_SIZE 119 enum log_level &#123; DEBUG, INFORMATION, WARNING, ERROR &#125;; int number_len(size_t); int parse_int(const char *); int generate_uuid(char *); char *remove_occur(char *, char) ; char *append_string(char *, char *, size_t); // 日志相关 void sol_log_init(const char *); void sol_log_close(void); void sol_log(int, const char *, ...); #define log(...) sol_log( __VA_ARGS__ ) #define sol_debug(...) log(DEBUG, __VA_ARGS__) #define sol_warning(...) log(WARNING, __VA_ARGS__) #define sol_error(...) log(ERROR, __VA_ARGS__) #define sol_info(...) log(INFORMATION, __VA_ARGS__) #define STREQ(s1, s2, len) strncasecmp(s1, s2, len) == 0 ? true : false log函数设置了一些宏定义，方便我们使用不同级别的日志。我们还做了一个 STREQ 用来比较两个字符串是否相等。 src/util.c#include &lt;time.h> #include &lt;ctype.h> #include &lt;errno.h> #include &lt;assert.h> #include &lt;string.h> #include &lt;stdlib.h> #include &lt;stdarg.h> #include &lt;uuid/uuid.h> #include \"util.h\" #include \"config.h\" static FILE *fh = NULL; // 通过文件保存日志 void sol_log_init(const char *file) &#123; assert(file); fh = fopen(file, \"a+\"); if (!fh) printf(\"%lu * WARNING: Unable to open file %s\\n\", (unsigned long) time(NULL), file); &#125; void sol_log_close(void) &#123; if (fh) &#123; fflush(fh); fclose(fh); &#125; &#125; // 按级别写入内容 void sol_log(int level, const char *fmt, ...) &#123; assert(fmt); va_list ap; char msg[MAX_LOG_SIZE + 4]; if (level &lt; conf->loglevel) return; va_start(ap, fmt); vsnprintf(msg, sizeof(msg), fmt, ap); va_end(ap); // 过长的信息会被截取, 然后加 ... memcpy(msg + MAX_LOG_SIZE, \"...\", 3); msg[MAX_LOG_SIZE + 3] = '\\0'; // Distinguish message level prefix const char *mark = \"#i*!\"; // 同时写向标准输出和日志文件 FILE *fp = stdout; if (!fp) return; fprintf(fp, \"%lu %c %s\\n\", (unsigned long) time(NULL), mark[level], msg); if (fh) fprintf(fh, \"%lu %c %s\\n\", (unsigned long) time(NULL), mark[level], msg); fflush(fp); if (fh) fflush(fh); &#125; // 获得一个数字的字符串长度 如 number_len(321) => 3 int number_len(size_t number) &#123; int len = 1; while (number) &#123; len++; number /= 10; &#125; return len; &#125; // 解析字符串中的数字, 返回数字的值 int parse_int(const char *string) &#123; int n = 0; while (*string &amp;&amp; isdigit(*string)) &#123; n = (n * 10) + (*string - '0'); string++; &#125; return n; &#125; // 去除字符串中的某个字符 char *remove_occur(char *str, char c) &#123; char *p = str; char *pp = str; while (*p) &#123; // 当 p 指向内容 *pp = *p++; // 1. 使用 *p 赋值 *pp 2. p右移 (保证每次原字符串读取下一个字符) pp += (*pp != c); // 仅当 *pp != c 时, pp 右移 (意味着如果时c则会被下一次写入覆盖) &#125; *pp = '\\0'; // pp的最新位置作为结尾 return str; &#125; // 将一个字符串添加到另一个字符串后面 // 前面是 src 后面是 chunk char *append_string(char *src, char *chunk, size_t chunklen) &#123; size_t srclen = strlen(src); char *ret = malloc(srclen + chunklen + 1); memcpy(ret, src, srclen); memcpy(ret + srclen, chunk, chunklen); ret[srclen + chunklen] = '\\0'; return ret; &#125; // 创建 uuid int generate_uuid(char *uuid_placeholder) &#123; /* Generate random uuid */ uuid_t binuuid; uuid_generate_random(binuuid); uuid_unparse(binuuid, uuid_placeholder); return 0; &#125; 这些简单的函数足以支撑我们的日志系统，如果在启动时调用 sol_log_init 我们还能将日志存入日志文件。 服务入口实现终于我们要开始写 start_server 函数了，这个函数会调用所有我们之前写过的内容。他将作为程序的入口点，完成各种设置和全局实例的初始化，然后等待着客户端链接。 src/server.c// 系统状态主题, 根据配置文件每 n 秒发布一次 #define SYS_TOPICS 14 static const char *sys_topics[SYS_TOPICS] = &#123; \"$SOL/\", \"$SOL/broker/\", \"$SOL/broker/clients/\", \"$SOL/broker/bytes/\", \"$SOL/broker/messages/\", \"$SOL/broker/uptime/\", \"$SOL/broker/uptime/sol\", \"$SOL/broker/clients/connected/\", \"$SOL/broker/clients/disconnected/\", \"$SOL/broker/bytes/sent/\", \"$SOL/broker/bytes/received/\", \"$SOL/broker/messages/sent/\", \"$SOL/broker/messages/received/\", \"$SOL/broker/memory/used\" &#125;; // 一个阻塞的循环 static void run(struct evloop *loop) &#123; if (evloop_wait(loop) &lt; 0) &#123; sol_error(\"Event loop exited unexpectedly: %s\", strerror(loop->status)); evloop_free(loop); &#125; &#125; // 在全局哈希表中删除客户端时触发回调释放资源 static int client_destructor(struct hashtable_entry *entry) &#123; if (!entry) return -1; struct sol_client *client = entry->val; if (client->client_id) free(client->client_id); free(client); return 0; &#125; // 在全局哈希表中删除闭包时触发回调释放资源 static int closure_destructor(struct hashtable_entry *entry) &#123; if (!entry) return -1; struct closure *closure = entry->val; if (closure->payload) bytestring_release(closure->payload); free(closure); return 0; &#125; // 启动服务器 int start_server(const char *addr, const char *port) &#123; // 初始化 sol 全局实例 trie_init(&amp;sol.topics); // 确保所有的客户端和闭包都在哈希表中, 这样从哈希表删除时就可以使用回调释放资源 sol.clients = hashtable_create(client_destructor); sol.closures = hashtable_create(closure_destructor); // 服务端 closure struct closure server_closure; // 开启端口监听 server_closure.fd = make_listen(addr, port, conf->socket_family); server_closure.payload = NULL; server_closure.args = &amp;server_closure; // 唯一事件是接受客户端链接 server_closure.call = on_accept; generate_uuid(server_closure.closure_id); // 创建输出状态的基础 topic for (int i = 0; i &lt; SYS_TOPICS; i++) sol_topic_put(&amp;sol, topic_create(strdup(sys_topics[i]))); // 创建 evloop struct evloop *event_loop = evloop_create(EPOLL_MAX_EVENTS, EPOLL_TIMEOUT); // 将服务端 closure 放入 evloop evloop_add_callback(event_loop, &amp;server_closure); // 添加周期性事件 汇报服务器状态 // TODO 实现 struct closure sys_closure = &#123; .fd = 0, .payload = NULL, .args = &amp;sys_closure, .call = publish_stats &#125;; generate_uuid(sys_closure.closure_id); evloop_add_periodic_task(event_loop, conf->stats_pub_interval, 0, &amp;sys_closure); // 初始化完成 sol_info(\"Server start\"); info.start_time = time(NULL); // 进入事件循环 run(event_loop); // 释放资源 hashtable_release(sol.clients); hashtable_release(sol.closures); sol_info(\"Sol v%s exiting\", VERSION); return 0; &#125; 定时通报服务器状态好的，我们现在有了一个（几乎）功能齐全的服务器，它使用我们的回调系统来处理流量。 接下来我们需要在头文件上添加一些代码，例如我们刚才使用的 info 结构体，还有全局的名为 sol 的实例，这些我们都还没有定义。 src/server.h// 全局 info struct sol_info &#123; int nclients; // 当前客户端数 int nconnections; // 历史客户端总数 long long start_time; // 服务启动时间 long long bytes_recv; // 接收字节总数 long long bytes_sent; // 发送字节总数 long long messages_sent; // 发送消息总数 long long messages_recv; // 接收消息总数 &#125;; 这是刚才的 start_server 函数中我们添加的一个周期性任务。 // 添加周期性事件 汇报服务器状态 // TODO 实现 struct closure sys_closure = &#123; .fd = 0, .payload = NULL, .args = &amp;sys_closure, .call = publish_stats &#125;; generate_uuid(sys_closure.closure_id); evloop_add_periodic_task(event_loop, conf->stats_pub_interval, 0, &amp;sys_closure); publish_stats 函数会每隔 conf-&gt;stats_pub_interval 秒被调用一次， conf-&gt;stats_pub_interval 是一个全局的配置值，配置相关的内容我们稍后会去实现。 现在，让我们先实现这个回调函数： src/server.c// 发送消息的工具方法 static void publish_message(unsigned short pkt_id, unsigned short topiclen, const char *topic, unsigned short payloadlen, unsigned char *payload) &#123; // 从全局的 topic 表中获得我们需发送的 topic, 如果不存在则退出 struct topic *t = sol_topic_get(&amp;sol, topic); if (!t) return; // 制作一个 PUBLISH 包 union mqtt_packet pkt; struct mqtt_publish *p = mqtt_packet_publish(PUBLISH_BYTE, pkt_id, topiclen, (unsigned char *) topic, payloadlen, payload); pkt.publish = *p; size_t len; unsigned char *packed; // 通过TCP向所有订阅了该主题的客户端发送 payload struct list_node *cur = t->subscribers->head; size_t sent = 0L; for (; cur; cur = cur->next) &#123; sol_debug(\"Sending PUBLISH (d%i, q%u, r%i, m%u, %s, ... (%i bytes))\", pkt.publish.header.bits.dup, pkt.publish.header.bits.qos, pkt.publish.header.bits.retain, pkt.publish.pkt_id, pkt.publish.topic, pkt.publish.payloadlen); len = MQTT_HEADER_LEN + sizeof(uint16_t) + pkt.publish.topiclen + pkt.publish.payloadlen; struct subscriber *sub = cur->data; struct sol_client *sc = sub->client; // 根据订阅者设置的 qos 更改包中的 qos pkt.publish.header.bits.qos = sub->qos; if (pkt.publish.header.bits.qos > AT_MOST_ONCE) len += sizeof(uint16_t); int remaininglen_offset = 0; if ((len - 1) > 0x200000) remaininglen_offset = 3; else if ((len - 1) > 0x4000) remaininglen_offset = 2; else if ((len - 1) > 0x80) remaininglen_offset = 1; len += remaininglen_offset; // 实际打包发送 packed = pack_mqtt_packet(&amp;pkt, PUBLISH); if ((sent = send_bytes(sc->fd, packed, len)) &lt; 0) sol_error(\"Error publishing to %s: %s\", sc->client_id, strerror(errno)); // 统计信息 info.bytes_sent += sent; info.messages_sent++; free(packed); &#125; free(p); &#125; // 发送服务器状态的周期性任务 static void publish_stats(struct evloop *loop, void *args) &#123; char cclients[number_len(info.nclients) + 1]; sprintf(cclients, \"%d\", info.nclients); char bsent[number_len(info.bytes_sent) + 1]; sprintf(bsent, \"%lld\", info.bytes_sent); char msent[number_len(info.messages_sent) + 1]; sprintf(msent, \"%lld\", info.messages_sent); char mrecv[number_len(info.messages_recv) + 1]; sprintf(mrecv, \"%lld\", info.messages_recv); long long uptime = time(NULL) - info.start_time; char utime[number_len(uptime) + 1]; sprintf(utime, \"%lld\", uptime); double sol_uptime = (double)(time(NULL) - info.start_time) / SOL_SECONDS; char sutime[16]; sprintf(sutime, \"%.4f\", sol_uptime); publish_message(0, strlen(sys_topics[5]), sys_topics[5], strlen(utime), (unsigned char *) &amp;utime); publish_message(0, strlen(sys_topics[6]), sys_topics[6], strlen(sutime), (unsigned char *) &amp;sutime); publish_message(0, strlen(sys_topics[7]), sys_topics[7], strlen(cclients), (unsigned char *) &amp;cclients); publish_message(0, strlen(sys_topics[9]), sys_topics[9], strlen(bsent), (unsigned char *) &amp;bsent); publish_message(0, strlen(sys_topics[11]), sys_topics[11], strlen(msent), (unsigned char *) &amp;msent); publish_message(0, strlen(sys_topics[12]), sys_topics[12], strlen(mrecv), (unsigned char *) &amp;mrecv); &#125; 我们已经注册了我们第一个周期性回调，他会定时的发送 sys_topics 数组中主题的消息， 下面是一些我们需要的全局实例： src/server.c// info 实例, 其内容会被周期性回调发送 static struct sol_info info; // sol 实例, 包括 主题树 和 客户端哈希表 static struct sol sol; 结尾我们还需要补充一些代码，才能使我们上面的代码能够运行。比如，struct sol 的定义、closure_destructor 函数，哈希表的定义，比如 topic 的存储和解析方法。这一切我们都需要去完成。 在下一部分我们会编写处理各种MQTT数据包的 处理器，根据数据包的类型和内容不同，服务器会表现出不同的行为。","tags":[{"name":"网络编程","slug":"网络编程","permalink":"https://vitsumoc.github.io/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"name":"翻译","slug":"翻译","permalink":"https://vitsumoc.github.io/tags/%E7%BF%BB%E8%AF%91/"},{"name":"C","slug":"C","permalink":"https://vitsumoc.github.io/tags/C/"},{"name":"MQTT","slug":"MQTT","permalink":"https://vitsumoc.github.io/tags/MQTT/"},{"name":"物联网","slug":"物联网","permalink":"https://vitsumoc.github.io/tags/%E7%89%A9%E8%81%94%E7%BD%91/"}]},{"title":"[翻译]通过三个步骤简单理解epoll","date":"2023-12-20T07:46:49.000Z","path":"translate-epoll-in-3-steps.html","text":"原文 epoll() Tutorial – epoll() In 3 Easy Steps! 前言就在不久前，能够让一台服务器支持10000个并发连接还是一个很了不起的事情。有很多因素让这个行为成为可能，例如 nginx，他可以比他的前辈们更高效的处理更多连接。不过其中最大的因素应该还是大部分操作系统引入了恒定时间的轮询机制O1，用来监视系统中的文件描述符。 在 No Starch Press 的书《Linux 编程接口》中，第 63.4.5 节提供了一个表格，描述了通过一些最常见的轮询方法检查不同数量的文件描述符所需的时间。 如图所示，在10个文件描述符时，epoll 已经体现出了他的性能优势。随着描述符数量的增加，相比于 poll() 或 select()，这种性能优势体现的越来越大。 本教程将介绍在 Linux 2.6.27+ 上使用 epoll() 的一些基础知识。 预备知识本教程假设您熟悉并熟悉 Linux、C 语法以及类 UNIX 系统中文件描述符的使用。 开始创建一个新文件夹来开始我们的教程， Makefile 如下： all: epoll_example epoll_example: epoll_example.c gcc -Wall -Werror -o $@ epoll_example.c clean: @rm -v epoll_example 在这篇文章中，需要使用这些库： epoll_example.c#include &lt;stdio.h> // for fprintf() #include &lt;unistd.h> // for close(), read() #include &lt;sys/epoll.h> // for epoll_create1(), epoll_ctl(), struct epoll_event #include &lt;string.h> // for strncmp 第一步：创建 epoll 文件描述符从最基础开始，先尝试创建和关闭 epoll 实例。 epoll_example.c#include &lt;stdio.h> // for fprintf() #include &lt;unistd.h> // for close() #include &lt;sys/epoll.h> // for epoll_create1() int main() &#123; int epoll_fd = epoll_create1(0); if (epoll_fd == -1) &#123; fprintf(stderr, \"Failed to create epoll file descriptor\\n\"); return 1; &#125; if (close(epoll_fd)) &#123; fprintf(stderr, \"Failed to close epoll file descriptor\\n\"); return 1; &#125; return 0; &#125; 运行这段代码，正常来说应该直接返回并且不产生任何输出，如果你看到了错误消息，那么也许你可能正在运行一个非常旧的 Linux 内核。 第一个例子是使用 epoll_create1() 创建 epoll 实例，并且获得他的文件描述符。虽然我们没有用这个文件描述符做任何事情，我们仍然要记得在关闭程序之前清理他。就像和其他的 Linux 文件描述符一样，使用 close()。 电平触发（Level triggered）和边沿触发（edge triggered）电平触发和边沿触发 是从电子工程师那边借来的术语，但当我们使用 epoll 时，我们需要注意这两者的差别。在边沿触发模式下，我们只会在被监控文件描述符的状态变化时接收到事件；而在电平触发模式下，我们会持续接收事件，直到被监控的文件描述符不再处于 ready 状态。一般来说电平触发时默认状态，而且更加容易上手，我们的教程也会使用电平触发。但是我们也需要直到有边沿触发这回事。 第二步：添加被 epoll 监控的文件描述符接下来要做的事情就是，告诉 epoll 需要监控哪些文件描述符，以及需要监控哪种类型的事件。在这个例子里，我会使用Linux中我最爱的文件描述符，亲爱的 file descriptor 0（就是标准输入）。 epoll_example.c#include &lt;stdio.h> // for fprintf() #include &lt;unistd.h> // for close() #include &lt;sys/epoll.h> // for epoll_create1(), epoll_ctl(), struct epoll_event int main() &#123; struct epoll_event event; int epoll_fd = epoll_create1(0); if (epoll_fd == -1) &#123; fprintf(stderr, \"Failed to create epoll file descriptor\\n\"); return 1; &#125; event.events = EPOLLIN; event.data.fd = 0; if (epoll_ctl(epoll_fd, EPOLL_CTL_ADD, 0, &amp;event)) &#123; fprintf(stderr, \"Failed to add file descriptor to epoll\\n\"); close(epoll_fd); return 1; &#125; if (close(epoll_fd)) &#123; fprintf(stderr, \"Failed to close epoll file descriptor\\n\"); return 1; &#125; return 0; &#125; 这里我们创建了 epoll_event 的实例 event，并使用 epoll_ctl() 将 fd0 添加到 epoll 的实例 epoll_fd 中。最后一个参数 event 是为了让 epoll 知道我们只想关注输入事件（EPOLLIN），而且还能为事件提供一些我们自定义的数据（本例中 event.data.fd = 0）。 第三步：完整例子现在，让 epoll 发挥他的魔力吧 epoll_example.c#define MAX_EVENTS 5 #define READ_SIZE 10 #include &lt;stdio.h> // for fprintf() #include &lt;unistd.h> // for close(), read() #include &lt;sys/epoll.h> // for epoll_create1(), epoll_ctl(), struct epoll_event #include &lt;string.h> // for strncmp int main() &#123; // 是否运行中、当前并发事件数、计数器 int running = 1, event_count, i; // 接收数据长度 size_t bytes_read; // 接收输入 buffer char read_buffer[READ_SIZE + 1]; // event 是一个事件结构 events 是事件数组, 最多5个 struct epoll_event event, events[MAX_EVENTS]; // epoll 实例 int epoll_fd = epoll_create1(0); if (epoll_fd == -1) &#123; fprintf(stderr, \"Failed to create epoll file descriptor\\n\"); return 1; &#125; // 监听 EPOLLIN event.events = EPOLLIN; // 用户数据 fd = 0 event.data.fd = 0; // 使用 epoll_ctl 添加监听 if(epoll_ctl(epoll_fd, EPOLL_CTL_ADD, 0, &amp;event)) &#123; fprintf(stderr, \"Failed to add file descriptor to epoll\\n\"); close(epoll_fd); return 1; &#125; while (running) &#123; // 等待输入 printf(\"\\nPolling for input...\\n\"); // epoll_wait 等待事件发生 // 返回值：接收并发事件数 // 参数：epoll实例, 事件容器, 并发数, 超时时间 event_count = epoll_wait(epoll_fd, events, MAX_EVENTS, 30 * 1000); printf(\"%d ready events\\n\", event_count); for (i = 0; i &lt; event_count; i++) &#123; printf(\"Reading file descriptor '%d' -- \", events[i].data.fd); bytes_read = read(events[i].data.fd, read_buffer, READ_SIZE); printf(\"%zd bytes read.\\n\", bytes_read); read_buffer[bytes_read] = '\\0'; printf(\"Read '%s'\", read_buffer); // 输入为 stop 时结束 if(!strncmp(read_buffer, \"stop\\n\", 5)) running = 0; &#125; &#125; if (close(epoll_fd)) &#123; fprintf(stderr, \"Failed to close epoll file descriptor\\n\"); return 1; &#125; return 0; &#125; 我们添加了一些变量，用来支撑这个例子，同时使用了一个循环，持续读取标准输入直到读取内容为 stop。我们使用 epoll_wait() 来等待事件的发生，每个发生的事件都会被存储在 events 中，最大支持 MAX_EVENTS 个事件，并将超时事件设置为30秒。epoll_wait() 返回了本次触发了多少事件，然后我们只是在一个循环中打印这些事件而已。 使用实例接下来是一些使用示例： example:~/epoll_example$ ./epoll_example Polling for input... hello 1 ready events Reading file descriptor '0' -- 6 bytes read. Read 'hello ' Polling for input... to looooooooooooong 1 ready events Reading file descriptor '0' -- 10 bytes read. Read 'to loooooo' Polling for input... 1 ready events Reading file descriptor '0' -- 10 bytes read. Read 'ooooooong ' Polling for input... stop 1 ready events Reading file descriptor '0' -- 5 bytes read. Read 'stop ' 可以看到，第一次我们输入 hello，程序正确输出而且继续循环。 第二次当我们输入一个超过长度限制的输入 to looooooooooooong 时，电平触发机制帮助了我们。因为输入缓冲区一直有值，所以我们的事件就一直触发，直到读取完毕。在这种情况下，如果我们使用的是边沿触发，那么我们就只能收到一次通知，直到下次再有内容写入输入缓冲区时才会执行下一次事件了。 希望这篇文档能够帮助你使用 epoll()！","tags":[{"name":"网络编程","slug":"网络编程","permalink":"https://vitsumoc.github.io/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"name":"翻译","slug":"翻译","permalink":"https://vitsumoc.github.io/tags/%E7%BF%BB%E8%AF%91/"},{"name":"C","slug":"C","permalink":"https://vitsumoc.github.io/tags/C/"}]},{"title":"[翻译]Sol - 从零开始的MQTT broker - 第二部分：网络","date":"2023-12-19T09:13:46.000Z","path":"translate-sol-2.html","text":"原文 Sol - An MQTT broker from scratch. Part 2 - Networking 前言让我们继续之前的工作，在第一部分中我们实现了 MQTT v3.1.1 的数据结构和解码函数，接下来我们需要做一些组包和编码函数，让我们可以发送网络包。 顺带说明一下，我们并没有打算去编写完美的或者内存效率很高的代码，而且，过早的优化是万恶之源，以后我们有的是时间来提高我们的代码质量。 组包实现暂时我们只需要做 CONNACK SUBACK PUBLISH 包的组包工作，其他的各种 ACK 的结构都是一样的，之前我们已经用 typedef 让这些 ACK 引用了同一个函数。 union mqtt_header *mqtt_packet_header(unsigned char) 函数用来处理 Fixed Header，以及以下这些只有 Fixed Header 的包： PINGREQ PINGRESP DISCONNECT struct mqtt_ack *mqtt_packet_ack(unsigned char, unsigned short) 用来处理以下这些 类ACK 的包： PUBACK PUBREC PUBREL PUBCOMP UNSUBACK 其余的包都需要专门的函数来组包。再说一次，虽然可能有很多更优雅的代码或者更优化的方法，但是现在我们只要写能用的代码就行了，以后迟早会优化的。 mqtt.c/* * mqtt组包 */ // 头部1byte的组包实现 union mqtt_header *mqtt_packet_header(unsigned char byte) &#123; static union mqtt_header header; header.byte = byte; return &amp;header; &#125; // 各种ACK的组包实现 struct mqtt_ack *mqtt_packet_ack(unsigned char byte, unsigned short pkt_id) &#123; static struct mqtt_ack ack; ack.header.byte = byte; ack.pkt_id = pkt_id; return &amp;ack; &#125; // CONNACK 组包实现 struct mqtt_connack *mqtt_packet_connack(unsigned char byte, unsigned char cflags, unsigned char rc) &#123; static struct mqtt_connack connack; connack.header.byte = byte; connack.byte = cflags; connack.rc = rc; return &amp;connack; &#125; // SUBACK 组包实现 struct mqtt_suback *mqtt_packet_suback(unsigned char byte, unsigned short pkt_id, unsigned char *rcs, unsigned short rcslen) &#123; struct mqtt_suback *suback = malloc(sizeof(*suback)); suback->header.byte = byte; suback->pkt_id = pkt_id; suback->rcslen = rcslen; suback->rcs = malloc(rcslen); memcpy(suback->rcs, rcs, rcslen); return suback; &#125; // PUBLISH 组包实现 struct mqtt_publish *mqtt_packet_publish(unsigned char byte, unsigned short pkt_id, size_t topiclen, unsigned char *topic, size_t payloadlen, unsigned char *payload) &#123; struct mqtt_publish *publish = malloc(sizeof(*publish)); publish->header.byte = byte; publish->pkt_id = pkt_id; publish->topiclen = topiclen; publish->topic = topic; publish->payloadlen = payloadlen; publish->payload = payload; return publish; &#125; // 释放包资源 void mqtt_packet_release(union mqtt_packet *pkt, unsigned type) &#123; switch (type) &#123; case CONNECT: free(pkt->connect.payload.client_id); if (pkt->connect.bits.username == 1) free(pkt->connect.payload.username); if (pkt->connect.bits.password == 1) free(pkt->connect.payload.password); if (pkt->connect.bits.will == 1) &#123; free(pkt->connect.payload.will_message); free(pkt->connect.payload.will_topic); &#125; break; case SUBSCRIBE: case UNSUBSCRIBE: for (unsigned i = 0; i &lt; pkt->subscribe.tuples_len; i++) free(pkt->subscribe.tuples[i].topic); free(pkt->subscribe.tuples); break; case SUBACK: free(pkt->suback.rcs); break; case PUBLISH: free(pkt->publish.topic); free(pkt->publish.payload); break; default: break; &#125; &#125; 编码实现我们接下来处理编码函数，编码函数其实就是解码函数的反方向操作：我们使用内存对象创造一个字节流，之后可以通过socket发出去。 现在我们有一些函数返回指向 static struct 的指针（例如上方代码中的 mqtt_packet_header ），在单线程的情况下这是没什么问题的。 在多线程环境下，一定会出问题，每次这种函数的返回都会指向同一片内存区域，可能导致各种冲突。因此为了将来的改进，需要重构这些部分，使用 malloc 来为每次返回分配地址。 我们采用和之前解码函数一样的方式来映射编码函数。做一个静态数组，其中的序号恰好等于包类型。 src/mqtt.c // MQTT 编码函数接口 typedef unsigned char *mqtt_pack_handler(const union mqtt_packet *); // 编码函数数组, 其中索引和包类型id对应 static mqtt_pack_handler *pack_handlers[13] = &#123; NULL, NULL, pack_mqtt_connack, pack_mqtt_publish, pack_mqtt_ack, pack_mqtt_ack, pack_mqtt_ack, pack_mqtt_ack, NULL, pack_mqtt_suback, NULL, pack_mqtt_ack, NULL &#125;; // header 的编码实现 static unsigned char *pack_mqtt_header(const union mqtt_header *hdr) &#123; unsigned char *packed = malloc(MQTT_HEADER_LEN); unsigned char *ptr = packed; pack_u8(&amp;ptr, hdr->byte); // Remaining Length 1byte 值为0 mqtt_encode_length(ptr, 0); return packed; &#125; // ACK 的编码实现 static unsigned char *pack_mqtt_ack(const union mqtt_packet *pkt) &#123; unsigned char *packed = malloc(MQTT_ACK_LEN); // 4byte unsigned char *ptr = packed; pack_u8(&amp;ptr, pkt->ack.header.byte); mqtt_encode_length(ptr, MQTT_HEADER_LEN); // 这里指还有2byte 内容是 pkt_id ptr++; // 因为 mqtt_encode_length 不会移动指针, 只会返回 Remaining Length 的长度, 而这里长度显然为1 pack_u16(&amp;ptr, pkt->ack.pkt_id); return packed; &#125; // CONNACK 的编码实现 static unsigned char *pack_mqtt_connack(const union mqtt_packet *pkt) &#123; unsigned char *packed = malloc(MQTT_ACK_LEN); unsigned char *ptr = packed; pack_u8(&amp;ptr, pkt->connack.header.byte); mqtt_encode_length(ptr, MQTT_HEADER_LEN); ptr++; pack_u8(&amp;ptr, pkt->connack.byte); pack_u8(&amp;ptr, pkt->connack.rc); return packed; &#125; // SUBACK 的编码实现 static unsigned char *pack_mqtt_suback(const union mqtt_packet *pkt) &#123; // 计算总长度 size_t pktlen = MQTT_HEADER_LEN + sizeof(uint16_t) + pkt->suback.rcslen; unsigned char *packed = malloc(pktlen + 0); unsigned char *ptr = packed; // 编码固定头 pack_u8(&amp;ptr, pkt->suback.header.byte); // 剩余部分的长度 size_t len = sizeof(uint16_t) + pkt->suback.rcslen; // 变长表示剩余部分长度 int step = mqtt_encode_length(ptr, len); // 指针后移 ptr += step; // 剩余部分编码 pack_u16(&amp;ptr, pkt->suback.pkt_id); for (int i = 0; i &lt; pkt->suback.rcslen; i++) pack_u8(&amp;ptr, pkt->suback.rcs[i]); return packed; &#125; // PUBLISH 的编码实现 static unsigned char *pack_mqtt_publish(const union mqtt_packet *pkt) &#123; // pktlen 至少有这么多: 头部至少2byte(1byte头 + 至少1byte的Remaining Length) // sizeof(uint16_t) 表示 topiclen 的长度, 因为 payloadlen 是不被编码到字节流中的 // topiclen 和 payloadlen 的内容 size_t pktlen = MQTT_HEADER_LEN + sizeof(uint16_t) + pkt->publish.topiclen + pkt->publish.payloadlen; // 这里是去除 fixed header 之外的内容长度 size_t len = 0L; // qos > 0, 说明有pkt_id, 需要 +2byte if (pkt->header.bits.qos > AT_MOST_ONCE) pktlen += sizeof(uint16_t); // 这里是通过剩余长度计算变长部分还需要的长度, 前面已经预留了1byte int remaininglen_offset = 0; if ((pktlen - 1) > 0x200000) remaininglen_offset = 3; else if ((pktlen - 1) > 0x4000) remaininglen_offset = 2; else if ((pktlen - 1) > 0x80) remaininglen_offset = 1; // 这里是总包长 pktlen += remaininglen_offset; unsigned char *packed = malloc(pktlen); unsigned char *ptr = packed; pack_u8(&amp;ptr, pkt->publish.header.byte); // 除去 fixed header 之外剩余部分的长度 len += (pktlen - MQTT_HEADER_LEN - remaininglen_offset); // 编码 Remaining Length int step = mqtt_encode_length(ptr, len); ptr += step; // 编码 topiclen 和后续的 topic 内容 pack_u16(&amp;ptr, pkt->publish.topiclen); pack_bytes(&amp;ptr, pkt->publish.topic); // 当 QoS > 0 时, 编码 pkt_id if (pkt->header.bits.qos > AT_MOST_ONCE) pack_u16(&amp;ptr, pkt->publish.pkt_id); // 编码 payload 的内容 pack_bytes(&amp;ptr, pkt->publish.payload); return packed; &#125; // 编码函数入口 unsigned char *pack_mqtt_packet(const union mqtt_packet *pkt, unsigned type) &#123; if (type == PINGREQ || type == PINGRESP) return pack_mqtt_header(&amp;pkt->header); return pack_handlers[type](pkt); &#125; socket 封装我们计划创建一个单线程 TCP 服务器，使用 epoll 接口实现多路 I&#x2F;O。Epoll 是继 select 和 poll 之后内核 2.5.44 添加的最新的多路复用机制，也是性能最高、连接数最多的多路复用机制，它在 BSD 和 BSD-like (Mac OSX) 系统中的对应机制是 kqueue。 我们需要定义一些函数来管理我们的socket descriptor。 src/network.h#include &lt;stdio.h> #include &lt;stdint.h> #include &lt;sys/types.h> #include \"util.h\" // 地址族 #define UNIX 0 #define INET 1 // 设置为 non-blocking 模式 int set_nonblocking(int); // 将 TCP_NODELAY 设置为 true, 用来关闭 Nagle's algorithm, 关闭收包时的缓冲等待 int set_tcp_nodelay(int); // 创建 socket 服务的辅助函数 int create_and_bind(const char *, const char *, int); // 创建一个 non-blocking socket 并监听指定的地址和端口 int make_listen(const char *, const char *, int); // 接收链接并进行后续处理, 将链接分配到 epollfd int accept_connection(int); 我们定义了一些简单的辅助函数，用来创建和绑定 socket 端口，处理新链接并把 socket 设置为 non-blocking 模式（这样才能发挥 epoll 的复用能力）。 我不喜欢必须处理每个进出服务器的字节，在我写的涉及到TCP通信的程序中，我都会定义这两个函数： ssize_t send_bytes(int, const unsigned char *, size_t) 用于在while循环中持续发送数据，直到把数据全部发送完。正确捕获 EAGAIN 或 EWOUDLBLOCK 异常。 ssize_t recv_bytes(int, unsigned char *, size_t) 在while循环中获得任意长度的数据。正确捕获 EAGAIN 或 EWOUDLBLOCK 异常。 src/network.h// I/O 管理函数 // 在循环中发出所有数据, 避免内核buffer可用性造成的中断(EAGAIN EWOUDLBLOCK) ssize_t send_bytes(int, const unsigned char *, size_t); // 从 fd 中读取指定长度的数据进入 buffer ssize_t recv_bytes(int, unsigned char *, size_t); socket 封装实现接下来是 network.c 的实现。 src/network.c#define _DEFAULT_SOURCE #include &lt;stdlib.h> #include &lt;errno.h> #include &lt;netdb.h> #include &lt;unistd.h> #include &lt;fcntl.h> #include &lt;arpa/inet.h> #include &lt;sys/un.h> #include &lt;sys/epoll.h> #include &lt;sys/timerfd.h> #include &lt;netinet/in.h> #include &lt;netinet/tcp.h> #include &lt;sys/types.h> #include &lt;sys/socket.h> #include &lt;sys/eventfd.h> #include \"network.h\" #include \"config.h\" // 设置 non-blocking socket int set_nonblocking(int fd) &#123; int flags, result; flags = fcntl(fd, F_GETFL, 0); if (flags == -1) goto err; result = fcntl(fd, F_SETFL, flags | O_NONBLOCK); if (result == -1) goto err; return 0; err: perror(\"set_nonblocking\"); return -1; &#125; // 设置 TCP_NODELAY 用以关闭 Nagle's algorithm int set_tcp_nodelay(int fd) &#123; return setsockopt(fd, IPPROTO_TCP, TCP_NODELAY, &amp;(int) &#123;1&#125;, sizeof(int)); &#125; // UNIX socket 的绑定方法 // return fd // sockpath 文件路径 static int create_and_bind_unix(const char *sockpath) &#123; struct sockaddr_un addr; int fd; // 创建 socket if ((fd = socket(AF_UNIX, SOCK_STREAM, 0)) == -1) &#123; perror(\"socket error\"); return -1; &#125; // addr初始值全0 memset(&amp;addr, 0, sizeof(addr)); // 赋值 addr.sun_family = AF_UNIX; strncpy(addr.sun_path, sockpath, sizeof(addr.sun_path) - 1); // 译者没有明白为何 unlink 会出现在此处 unlink(sockpath); // 绑定 socket if (bind(fd, (struct sockaddr*) &amp;addr, sizeof(addr)) == -1) &#123; perror(\"bind error\"); return -1; &#125; return fd; &#125; // TCP socket 的绑定方法 // return fd // host TCP 地址 // port TCP 端口 static int create_and_bind_tcp(const char *host, const char *port) &#123; struct addrinfo hints = &#123; .ai_family = AF_UNSPEC, // 不指定协议族, 系统自定可以是IP4 或 IP6 .ai_socktype = SOCK_STREAM, // 面向流, 就是TCP .ai_flags = AI_PASSIVE // 被动模式, 可以监听任意地址端口 &#125;; // result 是 getaddrinfo 提供的 addrinfo, rp 指如果绑定不成功, 可以变成下一个 addrinfo struct addrinfo *result, *rp; int sfd; if (getaddrinfo(host, port, &amp;hints, &amp;result) != 0) &#123; perror(\"getaddrinfo error\"); return -1; &#125; for (rp = result; rp != NULL; rp = rp->ai_next) &#123; // 先使用 rp 生成 socket sfd = socket(rp->ai_family, rp->ai_socktype, rp->ai_protocol); // 如果失败就下一个 rp if (sfd == -1) continue; // 设置 SO_REUSEADDR 这样关闭进程后可以重用端口 if (setsockopt(sfd, SOL_SOCKET, SO_REUSEADDR, &amp;(int) &#123; 1 &#125;, sizeof(int)) &lt; 0) perror(\"SO_REUSEADDR\"); if ((bind(sfd, rp->ai_addr, rp->ai_addrlen)) == 0) &#123; // bind 成功 break; &#125; // 绑定失败记得关闭 socket close(sfd); &#125; if (rp == NULL) &#123; perror(\"Could not bind\"); return -1; &#125; freeaddrinfo(result); return sfd; &#125; // 绑定入口 int create_and_bind(const char *host, const char *port, int socket_family) &#123; int fd; if (socket_family == UNIX) fd = create_and_bind_unix(host); else fd = create_and_bind_tcp(host, port); return fd; &#125; // 创建一个 non-blocking socket, 监听指定的地址端口 // return server file descriptor // host 地址或UNIX path // port 端口 // socket_family 地址族 AF_UNIX 或 AF_INET int make_listen(const char *host, const char *port, int socket_family) &#123; int sfd; if ((sfd = create_and_bind(host, port, socket_family)) == -1) abort(); if ((set_nonblocking(sfd)) == -1) abort(); // 仅当 TCP链接时设置 TCP_NODELAY if (socket_family == INET) set_tcp_nodelay(sfd); // conf是本程序的配置文件 if ((listen(sfd, conf->tcp_backlog)) == -1) &#123; perror(\"listen\"); abort(); &#125; return sfd; &#125; // 接收链接后的处理 // return 客户端 fd // serversock 服务端fd int accept_connection(int serversock) &#123; int clientsock; struct sockaddr_in addr; socklen_t addrlen = sizeof(addr); if ((clientsock = accept(serversock, (struct sockaddr *) &amp;addr, &amp;addrlen)) &lt; 0) return -1; set_nonblocking(clientsock); // 仅当 TCP链接时设置 TCP_NODELAY if (conf->socket_family == INET) set_tcp_nodelay(clientsock); char ip_buff[INET_ADDRSTRLEN + 1]; // 将ip地址转为文本, 这里用作检查客户端地址 if (inet_ntop(AF_INET, &amp;addr.sin_addr, ip_buff, sizeof(ip_buff)) == NULL) &#123; close(clientsock); return -1; &#125; return clientsock; &#125; // 向 fd 发送指定长度的数据 // return 成功发送的数据长度 // fd 发送数据的目的 // buf 发送数据内容地址 // len 需要发送的数据长度 ssize_t send_bytes(int fd, const unsigned char *buf, size_t len) &#123; // 发送数据的总长度 size_t total = 0; // 剩余需要发送数据的长度 size_t bytesleft = len; // 单次发送数据长度 ssize_t n = 0; while (total &lt; len) &#123; // 发送 bytesleft 长度的数据 n = send(fd, buf + total, bytesleft, MSG_NOSIGNAL); if (n == -1) &#123; // 当 fd 被阻塞时, 直接返回已经发送的长度 if (errno == EAGAIN || errno == EWOULDBLOCK) break; else goto err; &#125; total += n; bytesleft -= n; &#125; return total; err: fprintf(stderr, \"send(2) - error sending data: %s\", strerror(errno)); return -1; &#125; // 从 fd 中获得指定长度的数据 // retrun 成功读取的长度 -1 表示异常 // fd 数据源 // buf 存放结果的指针 // bufsize 期望读取的数据长度 ssize_t recv_bytes(int fd, unsigned char *buf, size_t bufsize) &#123; // 单次获取的数据长度 ssize_t n = 0; // 获取的总数据长度 ssize_t total = 0; while (total &lt; (ssize_t) bufsize) &#123; // 使用 recv 函数获得最大 bufsize - total 的数据 if ((n = recv(fd, buf, bufsize - total, 0)) &lt; 0) &#123; // fd被阻塞了, 此时total的返回也许是小于 bufsize 的值, 调用者可以选择重试 if (errno == EAGAIN || errno == EWOULDBLOCK) &#123; break; &#125; else // 对于其他的异常则报错 goto err; &#125; if (n == 0) return 0; buf += n; total += n; &#125; return total; err: fprintf(stderr, \"recv(2) - error reading data: %s\", strerror(errno)); return -1; &#125; epoll 封装为了让 epoll API能够更加简单易用。我对 epoll 进行了一些的封装，让我们就可以通过注册回调函数的方式来响应事件。 网络上有很多使用 epoll 的示例，大部分都是描述基本用法：注册一个 socket 并启动一个循环来监听事件，每当 socket 需要被读写时，调用一个函数来使用它们。这些例子当然简单好用，但是并没有告诉我们如何通过回调的方式使用 epoll。经过思考后，我发现可以使用 epoll_event 自带的 epoll_data 来解决这个问题： typedef union epoll_data &#123; void *ptr; int fd; uint32_t u32; uint64_t u64; &#125; epoll_data_t; 正如你看到的，epoll_data 中有一个 void *，一个常常用来保存fd的 int，还有两个大小不同的 uint。我计划做一个自定义事件结构体，其中包括了fd、一些自定义数据和最关键的回调函数指针。然后我们可以把自定义事件结构体绑定到 epoll_data 的 void * 中，如此一来，每当事件发生时，我们都可以通过 epoll_data 获得所有我们需要的东西。 我想要定义两种类型的回调，一种是事件触发的回调，另一种是间隔触发的周期性回调。我们需要把 epoll 封装到一个自定义结构里，来实现这两种回调。对于这两种回调的处理，我们则会采用完全相同的方式：获得 epoll_data，在其中获得所有我们所需的数据和需要执行的回调函数。 接收数据包并使用 epoll_wait 处理的顺序图 我们需要定义两种结构体和一种函数指针 struct evloop 封装 epoll 实例的结构体，添加了各种参数用来实现我们的业务设计 struct closure 上文中提到的自定义事件结构体，封装了各种事件参数和回调函数的指针 **void callback(struct evloop , void ) 回调函数的接口，在 closure 里真正被执行的函数的接口 另外，我们需要在 .c 文件中实现一些对 evloop 的创建、删除和管理功能。 src/network.h// epoll 的业务包装，包括 epoll 实例本身和其他参数 // 使用 EPOLLONESHOT 处理事件，并且每次都需要手动重置，这样可以保证未来适应多线程架构 struct evloop &#123; int epollfd; // epoll 实例fd int max_events; // 单次处理事件最大数量 int timeout; // 事件等待超时事件 int status; // 运行状态(是否运行中) struct epoll_event *events; // 事件数组, 用来接收 epoll_wait 获得的一组并发事件 // 周期性任务控制相关 int periodic_maxsize; // 周期性任务数组初始大小 int periodic_nr; // 当前周期性任务数量 struct &#123; int timerfd; struct closure *closure; &#125; **periodic_tasks; // 周期性任务列表 timerfd &lt;-> closure &#125; evloop; // 回调函数接口 typedef void callback(struct evloop *, void *); // 自定义事件结构体 struct closure &#123; int fd; // 监听的 fd void *obj; // 存放一些需要的自定义数据 void *args; // 可以被callback使用的参数, 指向用户自定义结构, 实际调用时就是 call 的第二个参数 char closure_id[UUID_LEN]; // closure 的 UUID struct bytestring *payload; // callback 的结果, 可以被网络发送的数据流 callback *call; // 会被执行的回调函数 &#125;; // evloop 的创建、初始化、销毁函数 struct evloop *evloop_create(int, int); void evloop_init(struct evloop *, int, int); void evloop_free(struct evloop *); // 一个阻塞的循环, 监听各种触发并执行对应的回调 int evloop_wait(struct evloop *); // 添加一个 closure, 其中包含一个回调函数 // 回调函数是单次触发的(边沿触发), 但是每次触发后都会被重置, 这样下次依然可以触发 void evloop_add_callback(struct evloop *, struct closure *); // 添加一个周期性的 closure, 间隔指定事件触发 void evloop_add_periodic_task(struct evloop *, int, unsigned long long, struct closure *); // 注销一个 closure, 删除对其 fd 的监听 int evloop_del_callback(struct evloop *, struct closure *); // 重置该 closure 对 read 事件的监听 int evloop_rearm_callback_read(struct evloop *, struct closure *); // 重置该 closure 对 write 事件的监听 int evloop_rearm_callback_write(struct evloop *, struct closure *); // 以下三个函数是对 epoll 原始API的封装, 供上方的函数调用 // EPOLL_CTL_ADD 的封装, 向 epoll 添加监听 int epoll_add(int, int, int, void *); // EPOLL_CTL_MOD 的封装, 可以重置 EPOLLONESHOT, 让 closure 下次仍被触发 int epoll_mod(int, int, int, void *); // EPOLL_CTL_DEL 的封装, 删除对某个 fd 的监听 int epoll_del(int, int); epoll 封装实现在头文件中定义了我们网络所需的各种工具函数后，接下来我们开始进行函数实现。 让我们先从最简单的开始，evloop 实例的创建、初始化和删除。他包括了这些内容： epoll 的 fd 即 epollfd 单次处理的最大事件数量 一个毫秒单位的超时时间 loop是否正在运行的状态标识 动态大小的周期性任务数组 src/network.c/****************************** * EPOLL APIS * ******************************/ #define EVLOOP_INITIAL_SIZE 4 // 默认周期任务数组大小 // 创建并初始化 evloop struct evloop *evloop_create(int max_events, int timeout) &#123; struct evloop *loop = malloc(sizeof(*loop)); evloop_init(loop, max_events, timeout); return loop; &#125; void evloop_init(struct evloop *loop, int max_events, int timeout) &#123; loop->max_events = max_events; loop->events = malloc(sizeof(struct epoll_event) * max_events); loop->epollfd = epoll_create1(0); // 这里创建 epoll 实例 loop->timeout = timeout; loop->periodic_maxsize = EVLOOP_INITIAL_SIZE; loop->periodic_nr = 0; loop->periodic_tasks = malloc(EVLOOP_INITIAL_SIZE * sizeof(*loop->periodic_tasks)); loop->status = 0; &#125; // 释放 evloop void evloop_free(struct evloop *loop) &#123; free(loop->events); for (int i = 0; i &lt; loop->periodic_nr; i++) free(loop->periodic_tasks[i]); free(loop->periodic_tasks); free(loop); &#125; 接着，我们需要实现三个包装 epoll API的函数，用来创建、修改和删除 epoll 对 fd 的监听。我们封装函数的目的是为所有的 epoll 监听都添加 EPOLLET 和 EPOLLONESHOT 标识。EPOLLET 标识可以让 epoll 工作在边沿触发模式，EPOLLONESHOT 标识则可以确保 epoll 对某个事件触发仅产生一次（然后我们通过手动重置的方式让其可以继续响应）。 这样的设置可以避免未来我们在使用多线程架构时，一次事件的传入会唤醒所有等待中的线程，这被称为惊群效应(thundering herd problem)，不过这些都是后话，暂时可以不用深究。 src/network.c// 添加监听 // return 添加结果 // efd file descriptor // fd 被监听的 fd // evs 被监听的事件(可以是一个或一组) // data 传入自定义结构体 int epoll_add(int efd, int fd, int evs, void *data) &#123; struct epoll_event ev; // 在 epoll_data 中设置 fd ev.data.fd = fd; // 注意 epoll_data 是 union, 如果有data并在此处设置, 那么上一行的 ev.data.fd 就不能再使用(是随机数) if (data) ev.data.ptr = data; // 将所有事件都设置为 边沿触发(EPOLLET) 和 触发后取消监听(EPOLLONESHOT) ev.events = evs | EPOLLET | EPOLLONESHOT; return epoll_ctl(efd, EPOLL_CTL_ADD, fd, &amp;ev); &#125; // 修改监听 主要目的是让触发过的事件可以再次被触发 int epoll_mod(int efd, int fd, int evs, void *data) &#123; struct epoll_event ev; ev.data.fd = fd; // Being ev.data a union, in case of data != NULL, fd will be set to random if (data) ev.data.ptr = data; ev.events = evs | EPOLLET | EPOLLONESHOT; // 通过 EPOLL_CTL_MOD 可以让事件再次能被触发 return epoll_ctl(efd, EPOLL_CTL_MOD, fd, &amp;ev); &#125; // 删除监听 int epoll_del(int efd, int fd) &#123; return epoll_ctl(efd, EPOLL_CTL_DEL, fd, NULL); &#125; 这里有两件事需要注意： 第一，如前所述，epoll_event 中包括了一个 union epoll_data，其中可以保存一个 fd 或 一个 void *。我们选择了使用后者，传入了我们的 closure，这其中包含了更多有用的信息，也包括 fd 在内。 第二，刚才我们定义的添加和修改函数的第三个参数，可以接收一组事件，一般而言是 EPOLLIN 或 EPOLLOUT。同时我们添加了 EPOLLONESHOT 标识，这意味着当事件触发一次后就不会再次触发，除非我们手动重置该事件。这样做是为了保持对低级事件触发的某种程度的控制，并为将来的多线程实现留出空间。这篇文档精彩地阐述了 epoll 这种设计的好处，以及为什么最好使用 EPOLLONESHOT 标志。 epoll 循环实现我们继续实现我们的封装，接下来是一些回调函数的注册、周期回调的注册以及主循环。 src/network.c// 添加回调 // loop loop封装实例 // cb 自定义事件封装 closure void evloop_add_callback(struct evloop *loop, struct closure *cb) &#123; if (epoll_add(loop->epollfd, cb->fd, EPOLLIN, cb) &lt; 0) perror(\"Epoll register callback: \"); &#125; // 添加周期事件 // loop loop封装实例 // seconds 以秒为单位的到期时间或触发周期 // ns 以纳秒为单位的到期时间或触发周期 // cb 自定义事件封装 void evloop_add_periodic_task(struct evloop *loop, int seconds, unsigned long long ns, struct closure *cb) &#123; // 表示时间间隔或时间点的结构 struct itimerspec timervalue; int timerfd = timerfd_create(CLOCK_MONOTONIC, 0); memset(&amp;timervalue, 0x00, sizeof(timervalue)); // 设置初始的到期时间 (多久后执行 timervalue.it_value.tv_sec = seconds; timervalue.it_value.tv_nsec = ns; // 设置初始的触发周期 (间隔多久执行 timervalue.it_interval.tv_sec = seconds; timervalue.it_interval.tv_nsec = ns; // 设置好 timer if (timerfd_settime(timerfd, 0, &amp;timervalue, NULL) &lt; 0) &#123; perror(\"timerfd_settime\"); return; &#125; // 将 timer 添加到 epoll, 让其能够触发 struct epoll_event ev; ev.data.fd = timerfd; ev.events = EPOLLIN; if (epoll_ctl(loop->epollfd, EPOLL_CTL_ADD, timerfd, &amp;ev) &lt; 0) &#123; perror(\"epoll_ctl(2): EPOLLIN\"); return; &#125; // 将周期性任务的信息绑定到 loop // 如果周期性任务的数量大于periodic_maxsize, 动态扩容 if (loop->periodic_nr + 1 > loop->periodic_maxsize) &#123; loop->periodic_maxsize *= 2; loop->periodic_tasks = realloc(loop->periodic_tasks, loop->periodic_maxsize * sizeof(*loop->periodic_tasks)); &#125; // 存储周期性任务的内容 timerfd 和 自定义事件 loop->periodic_tasks[loop->periodic_nr] = malloc(sizeof(*loop->periodic_tasks[loop->periodic_nr])); loop->periodic_tasks[loop->periodic_nr]->closure = cb; loop->periodic_tasks[loop->periodic_nr]->timerfd = timerfd; // 记录当前绑定了多少周期性任务 loop->periodic_nr++; &#125; // epoll 主循环 int evloop_wait(struct evloop *el) &#123; int rc = 0; // 返回值 int events = 0; // 单次触发事件数 long int timer = 0L; // 拿到我们周期性事件的 timerfd int periodic_done = 0; // 标记是否是周期性事件并且已经执行 while (1) &#123; // 等待事件发生 events = epoll_wait(el->epollfd, el->events, el->max_events, el->timeout); // 有异常 if (events &lt; 0) &#123; // 系统中断, 暂时不管 if (errno == EINTR) continue; // 确实出了问题, 结束循环 rc = -1; el->status = errno; break; &#125; // 循环处理每个事件 for (int i = 0; i &lt; events; i++) &#123; // 错误校验 检查是否是错误事件 检查是否不是输入输出事件 if ((el->events[i].events &amp; EPOLLERR) || (el->events[i].events &amp; EPOLLHUP) || (!(el->events[i].events &amp; EPOLLIN) &amp;&amp; !(el->events[i].events &amp; EPOLLOUT))) &#123; // 总之这个 fd 上出现了一些异常, 我们把链接关了 perror (\"epoll_wait(2)\"); shutdown(el->events[i].data.fd, 0); close(el->events[i].data.fd); el->status = errno; continue; &#125; // 拿到我们的 closure struct closure *closure = el->events[i].data.ptr; // 标记没有完成周期事件 periodic_done = 0; // 当没有被标识完成时, 循环查找我们存储的周期事件 for (int i = 0; i &lt; el->periodic_nr &amp;&amp; periodic_done == 0; i++) &#123; // 找到了 if (el->events[i].data.fd == el->periodic_tasks[i]->timerfd) &#123; // 拿到 closure struct closure *c = el->periodic_tasks[i]->closure; // 读 timerfd (void) read(el->events[i].data.fd, &amp;timer, 8); // 执行回调 c->call(el, c->args); // 标记完成 periodic_done = 1; &#125; &#125; if (periodic_done == 1) continue; // 并不是完成了某个周期性事件 那就是触发事件了 这里执行回调 closure->call(el, closure->args); &#125; &#125; return rc; &#125; // 重置该 closure 对 read 事件的监听 int evloop_rearm_callback_read(struct evloop *el, struct closure *cb) &#123; return epoll_mod(el->epollfd, cb->fd, EPOLLIN, cb); &#125; // 重置该 closure 对 write 事件的监听 int evloop_rearm_callback_write(struct evloop *el, struct closure *cb) &#123; return epoll_mod(el->epollfd, cb->fd, EPOLLOUT, cb); &#125; // 删除回调函数 int evloop_del_callback(struct evloop *el, struct closure *cb) &#123; return epoll_del(el->epollfd, cb->fd); &#125; 在我们之前的所有代码中，evloop_wait 是最有意思的，他启动一个循环不停监视 epoll_wait，执行错误检查，区分本次触发是周期性的自动触发或是读写触发，然后执行我们设置的回调函数。 结尾我们的代码越写越多，这次我们又添加了一个模块。 此时我们的文件结构是这样的： sol/ ├── src/ │ ├── mqtt.h | ├── mqtt.c │ ├── network.h │ ├── network.c │ ├── pack.h │ └── pack.c ├── CHANGELOG ├── CMakeLists.txt ├── COPYING └── README.md","tags":[{"name":"网络编程","slug":"网络编程","permalink":"https://vitsumoc.github.io/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"name":"翻译","slug":"翻译","permalink":"https://vitsumoc.github.io/tags/%E7%BF%BB%E8%AF%91/"},{"name":"C","slug":"C","permalink":"https://vitsumoc.github.io/tags/C/"},{"name":"MQTT","slug":"MQTT","permalink":"https://vitsumoc.github.io/tags/MQTT/"},{"name":"物联网","slug":"物联网","permalink":"https://vitsumoc.github.io/tags/%E7%89%A9%E8%81%94%E7%BD%91/"}]},{"title":"[问题]Windows环境下nssm注册的mysql服务无法启动","date":"2023-12-15T01:30:00.000Z","path":"[问题]Windows环境下nssm注册的mysql服务无法启动.html","text":"环境手上有个项目上一直使用的一键安装包，包括了上位机、后端、前端、数据库、时序库、nginx等一系列东西。一直都是通过 nssm 将这些软件注册成自启动服务的。注册的方式大概是这样： install.bat:: 注册mysql nssm-2.24\\win64\\nssm install xxx-scada-mysql %cd%\\mysql-8.0.27-winx64\\bin\\mysqld.exe nssm-2.24\\win64\\nssm set xxx-scada-mysql AppDirectory %cd%\\mysql-8.0.27-winx64\\bin :: 启动mysql nssm-2.24\\win64\\nssm start xxx-scada-mysql 前两天我们需要在公司的一台测试服务器上安装这套项目软件，先检查了公司的服务器环境，发现已经有了 mysql 和 nginx 服务，于是手动停止这两个服务，之后使用一键安装包部署项目。 此时，系统中有一个之前已经安装的 mysql，称为 数据库A。数据库A 通过 mysqld install 命令安装了服务，称为 服务A， 服务A 已经被手动停止运行。一键安装包中又拷贝了一份 mysql 进去，称为 数据库B。通过 nssm 安装的 数据库B 服务称为 服务B。 问题过程 发现通过 nssm 注册的 服务B 无法启动，所以关闭 服务B。 手动运行 数据库B 中的 mysqld 程序，发现程序闪退，没有报错信息，也没有错误日志。 怀疑是依赖问题，尝试了更新 MSVC ，没有效果。 尝试使用 数据库B 中的 mysqld --log-error=my.err ，发现 mysqld 不再闪退，但是此时依然不能正常提供数据库服务，并且没有异常的错误日志。 同事启动了 服务A ，发现可以正常使用。 受同事启发，尝试删除 服务A，此时脑袋混乱，居然是使用 数据库B 执行的 mysqld --remove，没想到依然能删除 服务A。 发现删除 服务A 后，数据库B 中的 mysqld 可以正常使用了，再次尝试 服务B ，发现也可以正常使用。 思考本次问题的出现，主要原因还是我对 Windows 系统不熟悉，对于 Windows 系统中服务注册原理完全不懂。 长期使用 nssm 进行服务管理，让我们可以一直忽略 Windows 的服务管理细节，不断地向前走下去。同时也让我们失去了探索 Windows 服务管理的动力。其实，假如世界上没有 nssm ，也许需要一周，也许需要一两个月，我们总是能学会注册服务的方法。 因为工具过于方便导致失去了底层能力，这次的问题只是这个道理的再一次体现而已。","tags":[{"name":"项目实践","slug":"项目实践","permalink":"https://vitsumoc.github.io/tags/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"name":"Windows","slug":"Windows","permalink":"https://vitsumoc.github.io/tags/Windows/"}]},{"title":"[翻译]Sol - 从零开始的MQTT broker - 第一部分：协议","date":"2023-12-08T07:30:15.000Z","path":"translate-sol-1.html","text":"原文 Sol - An MQTT broker from scratch. Part 1 - The protocol 前言我已经在物联网领域工作有一段时间了，这段时间里我一直在处理物联网架构相关的工作，探索物联网系统开发的最佳模式，研究相关的协议和标准，例如MQTT。 因为我一直在渴望着提升我编程能力的机会，我觉得在物联网方向深入研究会很有趣也很有好处。因此，我再一次 git init 了一个项目，并且要通过写下这些博客来挑战我自己，强迫自己进步。 Sol 是一个C语言项目，一个超级简单的Linux平台的MQTT broker，支持MQTT 3.3.1，不兼容旧的版本，非常类似于轻量级的 Mosquitto （虽然这玩意已经是个轻量级软件了）。由于现在有很多种类的MQTT客户端，所以测试起来会比较简单。最终的成品可能会成为一个更简洁，功能更丰富的软件，我们要创造这个功能的最小化实现。顺便提一下，Sol 这个名字的来源有一半的原因是我对短名称的偏好，另一半的原因则是火星日 (The Martian docet)。或者说，Sol 可能代表Scrappy Ol’ Loser。emmmm 注意：这个项目一直到最后才会编译，你需要跟写所有的代码步骤。如果你想要在中途进行测试，我建议你自己建一个主函数来做这些测试或者修改。 一步一步来，我一般会创建一个这样的文件结构来初始化我的C项目： sol/ ├── src/ ├── CHANGELOG ├── CMakeLists.txt ├── COPYING └── README.md 这里是Github上的仓库。 我会尝试着一步一步描述 Sol 的开发过程，但我也不会贴上所有的代码，只会解释关键的地方。你想要学习的最好方式依然是亲自编写、编译、修改代码。 这将是一系列文章，每篇文章都将讨论并主要实施项目的一个概念&#x2F;模块： 第一部分 ： 协议 MQTT协议数据包处理的基础 第二部分 ： 网络 解决网络通讯的功能模块 第三部分 ： 服务 程序入口 第四部分 ： 数据结构 常用数据结构实现 第五部分 ： 主题树 通过特里树处理主题匹配 第六部分 ： 处理器 每种数据包的处理函数 特别篇 ： 多线程 各种改进、bug修复、应用多线程 我想说，虽然 sol 会是一个完全功能的 broker，但仍有很大改进和优化空间，以及可能的一些隐藏功能（俗称BUG）。 架构设计broker 的本质是一个中间件，它接受来自多个客户端（生产者）的输入，并使用抽象方法将其转发给一组目标客户端（消费者），这种抽象方法用于定义和管理这些客户端组，形式为 channel 或 topic（根据协议标准）。与 IRC 频道或通用聊天中的等效概念非常相似，每个消费者客户端都可以订阅 topic，以便接收其他客户端发布到这些 topic 的所有消息。 第一个想到的是建立在某种数据结构之上的服务器，这种数据结构可以轻松管理这些 topic 和连接的客户端（无论是生产者还是消费者）。客户端收到的每个消息都必须转发给所有订阅了该消息指定 topic 的其他已连接客户端。 让我们试试这种方法，使用一个 TCP 服务器和一个用于处理数据流的模块。实现服务器的方法有很多，包括线程、fork 进程和多路 I&#x2F;O，这次我将尝试用多路 I&#x2F;O 的方式。 我们先使用单线程多路 I&#x2F;O 服务器，未来有可能进行多线程拓展。实际上，用于多路复用的 epoll 接口是线程安全的。 MQTT结构首先，我们需要基于官方文档，制作一些描述 MQTT 协议数据包的结构体。 从 opcode 表和 MQTT 头开始，基于文档，每个数据包都包含以下三部分： fixed header（必选） variable header（可选） payload（可选） Fixed HeaderFixed Header的第一个字节包括了 MQTT type 和 Flags，第二到第五个字节使用可变编码的方式，存储剩余数据包的长度。 Fixed Header | Bit | 7 | 6 | 5 | 4 | 3 | 2 | 1 | 0 | |--------|---------------|---------------| | Byte 1 | MQTT type | Flags | |--------|-------------------------------| | Byte 2 | | | . | Remaining Length | | . | | | Byte 5 | | Flags并不是强制填写的，只是一些控制类数据，内容如下： Dup flag： 当消息被发送超过一次时使用 QoS level： 有以下三种取值 AT_MOST_ONCE&#x3D;0， AT_LEAST_ONCE&#x3D;1 and EXACTLY_ONCE&#x3D;2 Retain flag： 保留标志，有保留标志的消息被发布到主题时，消息会被保留，之后连接进来的客户端也可以收到该消息。保留消息可以被另一条保留消息覆盖。 所以，打开 Vim （或者其他任何你喜欢的IDE），创建名为 mqtt.h 的头文件，开始写关于 Fixed Header 的数据结构吧： src/mqtt.h#include &lt;stdio.h> #define MQTT_HEADER_LEN 2 #define MQTT_ACK_LEN 4 /* * 回复信息枚举，用于 Fixed Header 中的第一个字节 * 准确的说是只负责设置高位的4bit */ #define CONNACK_BYTE 0x20 #define PUBLISH_BYTE 0x30 #define PUBACK_BYTE 0x40 #define PUBREC_BYTE 0x50 #define PUBREL_BYTE 0x60 #define PUBCOMP_BYTE 0x70 #define SUBACK_BYTE 0x90 #define UNSUBACK_BYTE 0xB0 #define PINGRESP_BYTE 0xD0 /* 信息类型 */ enum packet_type &#123; CONNECT = 1, CONNACK = 2, PUBLISH = 3, PUBACK = 4, PUBREC = 5, PUBREL = 6, PUBCOMP = 7, SUBSCRIBE = 8, SUBACK = 9, UNSUBSCRIBE = 10, UNSUBACK = 11, PINGREQ = 12, PINGRESP = 13, DISCONNECT = 14 &#125;; enum qos_level &#123; AT_MOST_ONCE, AT_LEAST_ONCE, EXACTLY_ONCE &#125;; union mqtt_header &#123; unsigned char byte; // 将 header 视为一个byte操作 struct &#123; // 将 header 视为内部结构分开操作 unsigned retain : 1; // 保留标识 unsigned qos : 2; // qos标识 unsigned dup : 1; // 重复标识 unsigned type : 4; // 4bit Flags &#125; bits; &#125;; 最上方的两个 #define 定义了 MQTT Fixed Header 和 MQTT ACK 的长度。 正如你在代码中看到的，我们利用了 union——一种可以在内存中的同一位置存储多种表示形式的结构——来表示一个字节。换句话说，与普通的 struct 不同，union 中只能有一个字段具有值（在此例中是byte或bits）。它们的内存位置是共享的，因此，通过使用位字段，我们可以有效地操作单个比特或字节的一部分。 CONNECT我们要定义的第一个控制数据包是 CONNECT。 这是当客户端建立新连接时必须发送的第一个数据包，CONNECT 包必须是有且仅有一个，否则视为与协议不符，服务端需要断开连接。 对于每个 CONNECT，服务端需要在响应中回复 CONNACK。 src/mqtt.hstruct mqtt_connect &#123; union mqtt_header header; // 第一个byte是通用头 union &#123; // 第二个byte表示一些控制信息 unsigned char byte; struct &#123; int reserved : 1; unsigned clean_session : 1; // 为1时表示新session，否则表示已有session unsigned will : 1; // 表示是否有遗嘱 unsigned will_qos : 2; // 表示遗嘱的QOS unsigned will_retain : 1; // 表示遗嘱发布时是否保留 unsigned password : 1; // 表示是否有密码 unsigned username : 1; // 表示是否有用户名 &#125; bits; &#125;; struct &#123; // 载荷 unsigned short keepalive; // 会话保活时间，单位秒 unsigned char *client_id; unsigned char *username; unsigned char *password; unsigned char *will_topic; unsigned char *will_message; &#125; payload; &#125;; struct mqtt_connack &#123; union mqtt_header header; union &#123; unsigned char byte; struct &#123; unsigned session_present : 1; unsigned reserved : 7; &#125; bits; &#125;; unsigned char rc; // return code 返回值 &#125;; 按照这个模式，结合 MQTT v3.1.1 的文档，其他数据包的定义也比较简单了。 SUBSCRIBE UNSUBSCRIBE PUBLISH ACK等接下来我们处理 SUBSCRIBE，UNSUBSCRIBE 和 PUBLISH。SUBSCRIBE 必须要使用 SUBACK 来响应，其他的都可以使用通用 ACK，并设置 typedef 字段的值来响应。 src/mqtt.hstruct mqtt_subscribe &#123; union mqtt_header header; unsigned short pkt_id; unsigned short tuples_len; // 接下来数据元组的长度 struct &#123; unsigned short topic_len; // 接下来 topic 字符串的长度 unsigned char *topic; unsigned qos; &#125; *tuples; &#125;; struct mqtt_unsubscribe &#123; union mqtt_header header; unsigned short pkt_id; unsigned short tuples_len; struct &#123; unsigned short topic_len; unsigned char *topic; &#125; *tuples; &#125;; struct mqtt_suback &#123; // 针对 SUB 动作的响应 union mqtt_header header; unsigned short pkt_id; unsigned short rcslen; unsigned char *rcs; &#125;; struct mqtt_publish &#123; // 发布消息 union mqtt_header header; unsigned short pkt_id; unsigned short topiclen; unsigned char *topic; unsigned short payloadlen; unsigned char *payload; &#125;; struct mqtt_ack &#123; // 通用响应 union mqtt_header header; unsigned short pkt_id; &#125;; 剩余的这一类ACK包： PUBACK PUBREC PUBREL PUBCOMP UNSUBACK PINGREQ PINGRESP DISCONNECT 因为有相同的结构，所以都可以通过 typedef 来定义，只是语义有所不同。最后一个 DISCONNECT，虽然严格来说不是一个 ACK，但是也有相同的结构。 src/mqtt.htypedef struct mqtt_ack mqtt_puback; typedef struct mqtt_ack mqtt_pubrec; typedef struct mqtt_ack mqtt_pubrel; typedef struct mqtt_ack mqtt_pubcomp; typedef struct mqtt_ack mqtt_unsuback; typedef union mqtt_header mqtt_pingreq; typedef union mqtt_header mqtt_pingresp; typedef union mqtt_header mqtt_disconnect; MQTT最终我们可以定义一个通用 MQTT 包，包括上面的一切，后续我们所有的 MQTT 数据包都可以用这个结构来表示。 src/mqtt.hunion mqtt_packet &#123; struct mqtt_ack ack; // 通用ACK union mqtt_header header; // 通用头 struct mqtt_connect connect; // CONNECT包 (这种包里会包括一个通用头) struct mqtt_connack connack; // CONNACK包 struct mqtt_suback suback; // SUBBACK包 struct mqtt_publish publish; // PUBLISH包 struct mqtt_subscribe subscribe; // SUB包 struct mqtt_unsubscribe unsubscribe; // UNSUB包 &#125;; MQTT函数编码解码现在我们继续定义一些公共函数。在 src/mqtt.h 中，我们需要考虑其他模块使用 MQTT 协议时会用到哪些函数。 为了使用 MQTT 协议处理通信，我们基本上需要 4 个函数，其中客户端向服务端有 2 个，服务端向客户端也是 2 个： 一个编码函数（总之就是把内存里的数据做成二进制流，这里不讨论术语） 一个解码函数（就是从二进制流恢复成内存结构） 我们还需要 2 个函数来处理 fixed head 部分中变长的 Remaining Length 字段。 src/mqtt.h// 编码时生成 Remaining Length int mqtt_encode_length(unsigned char *, size_t); // size_t 指uint32 或 uint64 // 解码时解析 Remaining Length unsigned long long mqtt_decode_length(const unsigned char **); // 将char * 解码为 mqtt_packet * int unpack_mqtt_packet(const unsigned char *, union mqtt_packet *); // 将 mqtt_packet * 编码为 char * unsigned char *pack_mqtt_packet(const union mqtt_packet *, unsigned); // unsigned指 unsigned int 内存操作我们还需要一些工具函数，用来进行基于数据包的内存分配、释放，这里没啥特别的。 src/mqtt.h// 申请内存，制作各种MQTT包 union mqtt_header *mqtt_packet_header(unsigned char); struct mqtt_ack *mqtt_packet_ack(unsigned char , unsigned short); struct mqtt_connack *mqtt_packet_connack(unsigned char , unsigned char , unsigned char); struct mqtt_suback *mqtt_packet_suback(unsigned char, unsigned short, unsigned char *, unsigned short); struct mqtt_publish *mqtt_packet_publish(unsigned char, unsigned short, size_t, unsigned char *, size_t, unsigned char *); // 释放MQTT包 void mqtt_packet_release(union mqtt_packet *, unsigned); 函数实现MQTT包编解码接口好了，我们现在有一个不错的头文件了，定义了我们通讯协议中的所有内容，现在我们需要实现这些函数了。为了能够实现这些功能，首先我们要定义几个私有的帮助函数，用来进行编码和解码的动作。这些函数会被公有函数unpack_mqtt_packet 和 pack_mqtt_packet 调用。 src/mqtt.c#include &lt;stdlib.h> #include &lt;string.h> #include \"mqtt.h\" // 一系列对于具体类型包的 pack unpack 函数 static size_t unpack_mqtt_connect(const unsigned char *, union mqtt_header *, union mqtt_packet *); static size_t unpack_mqtt_publish(const unsigned char *, union mqtt_header *, union mqtt_packet *); static size_t unpack_mqtt_subscribe(const unsigned char *, union mqtt_header *, union mqtt_packet *); static size_t unpack_mqtt_unsubscribe(const unsigned char *, union mqtt_header *, union mqtt_packet *); static size_t unpack_mqtt_ack(const unsigned char *, union mqtt_header *, union mqtt_packet *); static unsigned char *pack_mqtt_header(const union mqtt_header *); static unsigned char *pack_mqtt_ack(const union mqtt_packet *); static unsigned char *pack_mqtt_connack(const union mqtt_packet *); static unsigned char *pack_mqtt_suback(const union mqtt_packet *); static unsigned char *pack_mqtt_publish(const union mqtt_packet *); 二进制流编解码实现在继续实现 src/mqtt.h 上所有定义的函数之前，我们需要实现一些辅助函数，以简化每个接收到的数据包的编码解码过程。 让我们快速搞定这部分，这一块只是简单的序列化和反序列化操作而已（记得用Big-endian就行）。 src/pack.h#include &lt;stdio.h> #include &lt;stdint.h> /* 从数据流中获得数据的方法 */ // bytes -> uint8_t uint8_t unpack_u8(const uint8_t **); // bytes -> uint16_t uint16_t unpack_u16(const uint8_t **); // bytes -> uint32_t uint32_t unpack_u32(const uint8_t **); // 读取定义的 len 个字节（用来读取字符串） uint8_t *unpack_bytes(const uint8_t **, size_t, uint8_t *); // 读取字符串前面的 ushort 长度，并申请 dest内存块存字符串 uint16_t unpack_string16(uint8_t **buf, uint8_t **dest) /* 将数据写入数据流的方法 */ // append a uint8_t -> bytes into the bytestring void pack_u8(uint8_t **, uint8_t); // append a uint16_t -> bytes into the bytestring void pack_u16(uint8_t **, uint16_t); // append a uint32_t -> bytes into the bytestring void pack_u32(uint8_t **, uint32_t); // 将 len 个字节追加到bytes中 void pack_bytes(uint8_t **, uint8_t *); 以及相应的实现 src/pack.c#include &lt;string.h> #include &lt;stdlib.h> #include &lt;arpa/inet.h> #include \"pack.h\" // Reading data uint8_t unpack_u8(const uint8_t **buf) &#123; uint8_t val = **buf; (*buf)++; return val; &#125; uint16_t unpack_u16(const uint8_t **buf) &#123; uint16_t val; memcpy(&amp;val, *buf, sizeof(uint16_t)); (*buf) += sizeof(uint16_t); return ntohs(val); &#125; uint32_t unpack_u32(const uint8_t **buf) &#123; uint32_t val; memcpy(&amp;val, *buf, sizeof(uint32_t)); (*buf) += sizeof(uint32_t); return ntohl(val); &#125; uint8_t *unpack_bytes(const uint8_t **buf, size_t len, uint8_t *str) &#123; memcpy(str, *buf, len); str[len] = '\\0'; (*buf) += len; return str; &#125; uint16_t unpack_string16(uint8_t **buf, uint8_t **dest) &#123; uint16_t len = unpack_u16(buf); *dest = malloc(len + 1); *dest = unpack_bytes(buf, len, *dest); return len; &#125; // Write data void pack_u8(uint8_t **buf, uint8_t val) &#123; **buf = val; (*buf) += sizeof(uint8_t); &#125; void pack_u16(uint8_t **buf, uint16_t val) &#123; uint16_t htonsval = htons(val); memcpy(*buf, &amp;htonsval, sizeof(uint16_t)); (*buf) += sizeof(uint16_t); &#125; void pack_u32(uint8_t **buf, uint32_t val) &#123; uint32_t htonlval = htonl(val); memcpy(*buf, &amp;htonlval, sizeof(uint32_t)); (*buf) += sizeof(uint32_t); &#125; void pack_bytes(uint8_t **buf, uint8_t *str) &#123; size_t len = strlen((char *) str); memcpy(*buf, str, len); (*buf) += len; &#125; 这样我们就完成了字节流和数据类型的双向转换工作。 Remaining Length编解码实现完成了 pack 部分后，我们需要把他们运用在我们的MQTT包里，首先当然是： src/mqtt.c#include \"pack.h\" 第一步我们可以实现对 Fixed Header 中的 Remaining Length 字段的操作。MQTT文档中提供了这一段实现的伪代码，我们可以仿写一下。 让我们来看看 Remaining Length 如何用1-4个变长的Byte来表示剩余包的长度。 Remaining Length 表示的是数据包剩余部分的长度，包括 variable header 和 payload。Remaining Length 中表示的长度不包括 Remaining Length 字段本身所占用的长度。 Remaining Length 的编码使用了一种可变长度编码方案，该方案对 127 以下的值使用单个字节。较大的值则按以下方式处理：每个字节的低 7 位编码数据，高位用于指示是否存在后续字节。因此，每个字节编码 128 个值和一个 “延续位”。Remaining Length 字段的最大字节数为 4。 MQTT的文档已经描述的非常清晰，我们只需要实现。 src/mqtt.c/* * 基于 MQTT v3.1.1，Fixed Header 中的 Remaining Length 最大为4byte */ static const int MAX_LEN_BYTES = 4; /* * 根据数据包长度制作变长的 Remaining Length * return Remaining Length 的字节长度 * buf Remaining Length 的数据流 * len Remaining Length 应该表示的值（可变头+载荷总长度） */ int mqtt_encode_length(unsigned char *buf, size_t len) &#123; // 字节长度 int bytes = 0; do &#123; if (bytes + 1 > MAX_LEN_BYTES) return bytes; short d = len % 128; len /= 128; // len > 0 表示还有后续位 if (len > 0) d |= 128; // 标记最高位 buf[bytes++] = d; &#125; while (len > 0); return bytes; &#125; /* * 解析数据流中的 Remaing Length 并将指针移动到下一个位置 * return Remaining Length 的值 * buf Remaining Length 的数据流 * * TODO Handle case where multiplier > 128 * 128 * 128 */ unsigned long long mqtt_decode_length(const unsigned char **buf) &#123; char c; // 乘数 int multiplier = 1; // 值 unsigned long long value = 0LL; do &#123; c = **buf; value += (c &amp; 127) * multiplier; multiplier *= 128; // 后移一位 (*buf)++; // 当没有后续位标识时结束 &#125; while ((c &amp; 128) != 0); return value; &#125; CONNECT 解码实现好了，现在我们可以完整的解析 Fixed Header 了，接下来我们试着解码 CONNECT 包。 CONNECT 是一个有很多flags的包，而且长度仅次于 PUBLISH 包。 CONNECT 包的内容包括： Fixed Header 中的 MQTT type + Flags，高4位（MQTT type）（称为MSB）的值是1，表示Connect type，低4位（Flags）（LSB）保留 Fixed Header 中的变长 Remaining Length，表示剩余部分的长度 Variable Header，由四个字段组成： Protocol Name Protocol Level Connect Flags Keep Alive 可能存在或者不存在的 payload（基于 Connect Flags 的设置） Protocol Name 是 UTF-8 编码的大写字符串 “MQTT”，这个字段的长度和内容在未来版本的MQTT协议中都不会再改变。 所以 3.1.1 版本的 Protocol Name 就是 “MQTT”，我们也不用去管旧版本的名字是什么了。 Connect flags 为一个byte，包含了一些关于客户端行为以及是否有 payload 段存在的标识： Connect flags 中的字段 大小 含义 Username flag 1bit 表示用户名存在与否 Password flag 1bit 表示密码存在与否 Will retain 1bit 表示遗嘱是否保留 Will QoS 2bit 表示遗嘱的QOS等级 Will flag 1bit 表示遗嘱存在与否 Clean Session 1bit 表示是否为新链接 Connect flags的最高位保留，其他所有位都被当作bool值初始化（除了Will QoS），这些bool值在 payload 部分也有相应的字段。比如当 Username 和 Password 的值为1，那么在 payload 中会有 2byte 的 username length，紧随其后的就是 username 字符串，Password也是相同的道理。 为了说明这件事，假设我们收到了这样一个 CONNECT 包： Connect flags 中的 username 和 password 都置为1 username &#x3D; “hello” password &#x3D; “nacho” client ID &#x3D; “danzan” 那么这个数据包应该长这样： 字段 大小 偏移量 描述 Packet type + Falgs 1 0 类型为Connect type 0x01，Flags为空 Length 1 1 后续总长度32Byte，小于127，所以可以用1Byte表示 Protocol name length 2 2 协议名长度，值固定为 0x04 Protocol name 4 4 ‘M’ ‘Q’ ‘T’ ‘T’ Protocol level 1 8 对于MQTT 3.1.1 此字段值为 0x04 Connect flags 1 9 包括 Username, password, will retain, will QoS, will flag, clean session Keepalive 2 10 ushort，保活时间，单位秒，最大值65536（18小时12分15秒） Client ID length 2 12 ushort, 此例中值为0x06 (danzan) Client ID 6 14 ‘d’ ‘a’ ‘n’ ‘z’ ‘a’ ‘n’ Username length 2 20 ushort, 此例中值为0x05 (hello) Username 5 22 ‘h’ ‘e’ ‘l’ ‘l’ ‘o’ Password length 2 27 ushort, 此例中值为0x05 (nacho) Password 5 29 ‘n’ ‘a’ ‘c’ ‘h’ ‘o’ 例如因为 Will Flags 被置为0，所以我们不需要在 payload 中解析这个字段（也压根没有），上例中我们要解析的内容总共就是包括 Fixed Header 在内的 34个byte。 src/mqtt.c/* * CONNECT 解码函数 * return Remaing Length 的值 * buf 数据流，从变长长度开始 * hdr 已经解码好的头部 * pkt 返回的解码后数据包 */ static size_t unpack_mqtt_connect(const unsigned char *buf, union mqtt_header *hdr, union mqtt_packet *pkt) &#123; // 制作一个connect结构体，并且用已经解码好的头部赋值 // 此处有一个已经解码好的头部，是因为数据作为二进制流进来的时候，肯定是要先解码出头部，然后再根据包类型分到不同的函数里做进一步解码的 struct mqtt_connect connect = &#123; .header = *hdr &#125;; // 将这个结构体赋值到pkt pkt->connect = connect; // 初始指针指向buf的首部 const unsigned char *init = buf; /* * 获得后续的变长总长度,同时将指针移动到 protocol name */ size_t len = mqtt_decode_length(&amp;buf); // 暂时忽略协议名称、保留字段等等，所以直接向后移动8byte // 这里 init 直接+8，暗示了变长长度字段的长度是1byte，所以才能+8后指向Connect flags buf = init + 8; // 读取 Connect flags pkt->connect.byte = unpack_u8((const uint8_t **) &amp;buf); // 读取 keepalive pkt->connect.payload.keepalive = unpack_u16((const uint8_t **) &amp;buf); // 读取 CID 长度（如果有CID则>0，否则为0） uint16_t cid_len = unpack_u16((const uint8_t **) &amp;buf); // 如果有，则读取CID if (cid_len > 0) &#123; pkt->connect.payload.client_id = malloc(cid_len + 1); unpack_bytes((const uint8_t **) &amp;buf, cid_len, pkt->connect.payload.client_id); &#125; // 如果有，则读取遗嘱 if (pkt->connect.bits.will == 1) &#123; unpack_string16(&amp;buf, &amp;pkt->connect.payload.will_topic); unpack_string16(&amp;buf, &amp;pkt->connect.payload.will_message); &#125; // 如果有，则读取用户名 if (pkt->connect.bits.username == 1) unpack_string16(&amp;buf, &amp;pkt->connect.payload.username); // 如果有，则读取密码 if (pkt->connect.bits.password == 1) unpack_string16(&amp;buf, &amp;pkt->connect.payload.password); return len; &#125; PUBLISH 解码实现以下是 PUBLISH 包的结构： | Bit | 7 | 6 | 5 | 4 | 3 | 2 | 1 | 0 | &lt;-- Fixed Header |----------|-----------------------|--------------------------| | Byte 1 | MQTT type 3 | dup | QoS | retain | |----------|--------------------------------------------------| | Byte 2 | | | . | Remaining Length | | . | | | Byte 5 | | |----------|--------------------------------------------------| &lt;-- Variable Header | Byte 6 | Topic len MSB | | Byte 7 | Topic len LSB | |-------------------------------------------------------------| | Byte 8 | | | . | Topic name | | Byte N | | |----------|--------------------------------------------------| | Byte N+1 | Packet Identifier MSB | | Byte N+2 | Packet Identifier LSB | |----------|--------------------------------------------------| &lt;-- Payload | Byte N+3 | Payload | | Byte N+M | | 仅当 QoS level &gt; 0 时，存在 Packet identifier MSB 和 LSB。当 QoS 被设置为 at most once （值为0）时，没有必要存在 packet ID。 Payload部分的长度通过 Remaining Length 减去其他所有内容计算得来。 src/mqtt.c/* * PUBLISH 解码函数 * return Remaing Length 的值 * buf 数据流，从变长长度开始 * hdr 已经解码好的头部 * pkt 返回的解码后数据包 */ static size_t unpack_mqtt_publish(const unsigned char *buf, union mqtt_header *hdr, union mqtt_packet *pkt) &#123; // 创建 PUBLISH 包并且使用已经解码好的 header 赋值 struct mqtt_publish publish = &#123; .header = *hdr &#125;; // 准备给返回值提供这个 PUBLISH 包 pkt->publish = publish; // 通过变长的 Remaing Length 字段获取剩余部分的长度 size_t len = mqtt_decode_length(&amp;buf); // 获得 topiclen 和 topic 内容 pkt->publish.topiclen = unpack_string16(&amp;buf, &amp;pkt->publish.topic); // 将 len 赋值, 并视为 payload 长度 uint16_t message_len = len; // 如果 QoS > 0, 需要读取pkt_id if (publish.header.bits.qos > AT_MOST_ONCE) &#123; pkt->publish.pkt_id = unpack_u16((const uint8_t **) &amp;buf); // 此时payload长度需要减去pkt_id message_len -= sizeof(uint16_t); &#125; // payload 长度需要减去 topic_len 字段长度和 topic 字段实际长度 message_len -= (sizeof(uint16_t) + topic_len); // 这里是正确的 payloadlen pkt->publish.payloadlen = message_len; // 读取 payload pkt->publish.payload = malloc(message_len + 1); unpack_bytes((const uint8_t **) &amp;buf, message_len, pkt->publish.payload); return len; &#125; SUBSCRIBE 和 UNSUBSCRIBE 解码实现SUBSCRIBE 包和 UNSUBSCRIBE 包的结构非常相似。他们的 payload 部分都是一个 topic 相关的元组列表，其中 SUBSCRIBE 的元组是 (topic_len, topic_filter, qos)，而 UNSUBSCRIBE 是 (topic_len, topic_filter)。 src/mqtt.c/* * SUBSCRIBE 解码函数 * return Remaing Length 的值 * buf 数据流，从变长长度开始 * hdr 已经解码好的头部 * pkt 返回的解码后数据包 */ static size_t unpack_mqtt_subscribe(const unsigned char *buf, union mqtt_header *hdr, union mqtt_packet *pkt) &#123; // 创建 SUBSCRIBE 包并且使用已经解码好的 header 赋值 struct mqtt_subscribe subscribe = &#123; .header = *hdr &#125;; // 通过变长的 Remaing Length 字段获取剩余部分的长度 size_t len = mqtt_decode_length(&amp;buf); size_t remaining_bytes = len; // 读取pkt_id subscribe.pkt_id = unpack_u16((const uint8_t **) &amp;buf); remaining_bytes -= sizeof(uint16_t); /* * 订阅频道列表, 由一系列三元组构成 * - topic length 主题字符串长度 * - topic filter (string) 主题filter * - qos */ int i = 0; while (remaining_bytes > 0) &#123; // 减去2byte, 是topic length的空间 remaining_bytes -= sizeof(uint16_t); // 给这个主题字符串分配内存 subscribe.tuples = realloc(subscribe.tuples, (i+1) * sizeof(*subscribe.tuples)); // 获得主题字符串长度, 获得主题字符串内容 subscribe.tuples[i].topic_len = unpack_string16(&amp;buf, &amp;subscribe.tuples[i].topic); // 减去主题字符串实际占用的空间 remaining_bytes -= subscribe.tuples[i].topic_len; // 获得主题qos subscribe.tuples[i].qos = unpack_u8((const uint8_t **) &amp;buf); // 减去主题 qos 的空间 len -= sizeof(uint8_t); // 操作下一个主题 i++; &#125; // 记录订阅主题数 subscribe.tuples_len = i; // 记录到 mqtt_packet pkt->subscribe = subscribe; return len; &#125; /* * UNSUBSCRIBE 解码函数 * return Remaing Length 的值 * buf 数据流，从变长长度开始 * hdr 已经解码好的头部 * pkt 返回的解码后数据包 */ static size_t unpack_mqtt_unsubscribe(const unsigned char *buf, union mqtt_header *hdr, union mqtt_packet *pkt) &#123; struct mqtt_unsubscribe unsubscribe = &#123; .header = *hdr &#125;; /* * Second byte of the fixed header, contains the length of remaining bytes * of the connect packet */ size_t len = mqtt_decode_length(&amp;buf); size_t remaining_bytes = len; /* Read packet id */ unsubscribe.pkt_id = unpack_u16((const uint8_t **) &amp;buf); remaining_bytes -= sizeof(uint16_t); /* * Read in a loop all remaining bytes specified by len of the Fixed Header. * From now on the payload consists of 2-tuples formed by: * - topic length * - topic filter (string) */ int i = 0; while (remaining_bytes > 0) &#123; /* Read length bytes of the first topic filter */ remaining_bytes -= sizeof(uint16_t); /* We have to make room for additional incoming tuples */ unsubscribe.tuples = realloc(unsubscribe.tuples, (i+1) * sizeof(*unsubscribe.tuples)); unsubscribe.tuples[i].topic_len = unpack_string16(&amp;buf, &amp;unsubscribe.tuples[i].topic); remaining_bytes -= unsubscribe.tuples[i].topic_len; i++; &#125; unsubscribe.tuples_len = i; pkt->unsubscribe = unsubscribe; return len; &#125; ACK 解码实现最终到了 ACK 包，MQTT 协议中没有设计通用 ACK，但是实际上每个 ACK 包的数据结构都是一样的，有一个 Fixed Header 和一个 packet_id组成。 MQTT 协议中有如下几种类型的ACK: PUBACK PUBREC PUBREL PUBCOMP UNSUBACK src/mqtt.c/* * ACK 解码函数 * return Remaing Length 的值 * buf 数据流，从变长长度开始 * hdr 已经解码好的头部 * pkt 返回的解码后数据包 */ static size_t unpack_mqtt_ack(const unsigned char *buf, union mqtt_header *hdr, union mqtt_packet *pkt) &#123; // 创建 ACK 包并且使用已经解码好的 header 赋值 struct mqtt_ack ack = &#123; .header = *hdr &#125;; // 通过变长的 Remaing Length 字段获取剩余部分的长度 size_t len = mqtt_decode_length(&amp;buf); // pkt_id ack.pkt_id = unpack_u16((const uint8_t **) &amp;buf); pkt->ack = ack; return len; &#125; MQTT包解码实现现在我们已经实现了 unpack_mqtt_packet 需要的所有工具函数，接下来我们先定义一个解码函数的接口，然后使用一个静态数组来索引所有的解码函数，这里我们直接使用 Control Packet type 的值来作为数组中的索引。 需要注意的是，DISCONNECT PINGREQ PINGRESP 这三种包只有一个byte，所以我们不需要编写解码工具函数。 src/mqtt.c// 解码函数接口 typedef size_t mqtt_unpack_handler(const unsigned char *, union mqtt_header *, union mqtt_packet *); // 所有解码函数的列表, 索引值和包类型对应 static mqtt_unpack_handler *unpack_handlers[11] = &#123; NULL, unpack_mqtt_connect, NULL, unpack_mqtt_publish, unpack_mqtt_ack, unpack_mqtt_ack, unpack_mqtt_ack, unpack_mqtt_ack, unpack_mqtt_subscribe, NULL, unpack_mqtt_unsubscribe &#125;; // MQTT 包解码入口 int unpack_mqtt_packet(const unsigned char *buf, union mqtt_packet *pkt) &#123; int rc = 0; // 第一个 byte 是 fiexd header 中的 mqttType + flags unsigned char type = *buf; // 第一个byte可以被作为header union mqtt_header header = &#123; .byte = type &#125;; // 对于这些包暂时无需解码 if (header.bits.type == DISCONNECT || header.bits.type == PINGREQ || header.bits.type == PINGRESP) pkt->header = header; else // 通过包类型找到解码函数, 执行解码操作后返回rc, 此时rc等于具体解码函数的返回值 rc = unpack_handlers[header.bits.type](++buf, &amp;header, pkt); return rc; &#125; 结尾从零开始MQTT broker的第一部分就这样结束了，我们做了两个模块，一个根据 OASIS 定义的标准描述MQTT协议结构，另一个则用来处理编解码操作。 此时我们的文件结构是这样的： sol/ ├── src/ │ ├── mqtt.h │ ├── mqtt.c │ ├── pack.h │ └── pack.c ├── CHANGELOG ├── CMakeLists.txt ├── COPYING └── README.md","tags":[{"name":"网络编程","slug":"网络编程","permalink":"https://vitsumoc.github.io/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"name":"翻译","slug":"翻译","permalink":"https://vitsumoc.github.io/tags/%E7%BF%BB%E8%AF%91/"},{"name":"C","slug":"C","permalink":"https://vitsumoc.github.io/tags/C/"},{"name":"MQTT","slug":"MQTT","permalink":"https://vitsumoc.github.io/tags/MQTT/"},{"name":"物联网","slug":"物联网","permalink":"https://vitsumoc.github.io/tags/%E7%89%A9%E8%81%94%E7%BD%91/"}]},{"title":"[翻译] n2n 常见问题","date":"2023-12-07T08:55:07.000Z","path":"n2n 常见问题.html","text":"原文 n2n Frequently Asked Questions n2n 常见问题发布哪里能找到Windows系统的n2n软件？我们没有在release中发布Windows版本的n2n，但是我们的自动化测试流程会创建他们。你可以点击项目界面中的 Actions，选择 Testing，进入最近一次的运行实例，在界面最下方的 Artifacts 处下载 binaries，其中就包括了编译好的windows版本n2n。通常来说你可以使用 x86_64-w64-mingw32\\usr\\sbin 路径下的版本。 此外，正如我们的README中提到的，luckytu 一直在更新n2n的Windows版本，你也可以在他那里直接下载编译后的软件。 Supernode我想部署一个私有的，有密码保护的supernode，需要怎么设置？你可以直接配置 community.list 文件，在其中设置一个 &lt;community name&gt; (输入单行文本即可) ，然后把这个 &lt;community name&gt; 当作您的密码。 在启动 supernode 时，记得加上 -c &lt;community file&gt; 参数指定配置文件。这样，只有设置了 -c &lt;community name&gt; 的 edge 可以使用 supernode。 此时，在您的 edge 向 supernode 注册的过程中，&lt;community name&gt; 是明文传递的。如果您想要对传输过程进行加密，需要在所有 edge 节点启动时添加 -H 参数。 另外，请参阅 n2n 附带的 community.list 文件以了解该文件的高级使用。 除了这个访问障碍之外，您可能希望在边缘使用有效负载加密 -A_。 只有边缘（而不是超级节点）能够解密有效负载数据。 因此，即使任何人都能够打破超级节点的访问障碍，有效负载仍然受到有效负载加密的保护，请参阅此文档了解详细信息。 除了上述的这些安全手段之外，您还可以在 edge 添加 -A_ 参数来加密传输的数据。数据的加密和解密都是 edge 进行的，所以即使是 supernode 节点也无法解密数据内容。因此，即使你的 supernode 节点被黑客入侵，你的数据内容依然是被加密算法保护的。更多细节可以参考这一篇关于加密的文档。 我可以在supernode查看接入的edge列表吗？可以，supernode 通过UDP提供了基本的管理接口，默认端口是5645，可以通过 -t 参数修改。 只需要发送一个新的行就可以查询当前状态，例如，在 supernode 本机（远程链接不可以）上按下[ENTER]键，然后输入如下命令： netcat -u localhost 5645 支持多个supernode节点的部署方式吗？支持，这篇文档描述了如何部署多个 supernode 节点来提升网络的可用性。 supernode可以监听多个UDP端口吗？supernode 本身只支持监听一个端口，但是你应该可以通过做NAT的方式将多个端口映射到同一个端口上，例如： sudo iptables -t nat -A PREROUTING -i &lt;network interface name&gt; -d &lt;supernode&#39;s ip address&gt; -p udp --dport &lt;additional port number&gt; -j REDIRECT --to-ports &lt;regular supernode port number&gt; 这条命令可以作为 ExecStartPost= 添加到 supernode 的 .service 文件中（不需要加sudo），如果需要映射多个端口，可以多加几行。 这个报错是怎么回事 “process_udp dropped a packet with seemingly encrypted header for which no matching community which uses encrypted headers was found”？这条报错的意思是 supernode 收到了一个无法使用的数据包。supernode 先将这个包视为一个未加密的包来处理，如果处理失败的话，supernode 会假定这是一个加密的数据包，之后 supernode 会尝试所有可以生成key的 community （排除明确没有加密的community）。如果任何 community 的key都无法解开此数据包，就会产生这条报错。 如果所有 edge 的 -H 参数配置是相同的（都有 -H 或者都没有 -H ），并且重启 supernode 后依然报错，最大的可能是 supernode 或者 edge 的版本不一致，导致了数据包格式不一致。 因此，请确保所有 edge 和 supernode 具有完全相同的版本，例如：最新的 _dev_ 分支。 Edge如何查看p2p链接的状态？edge 同样提供了一个本地的UDP管理端口，包括了 peers 这种已经建立的p2p链接，还有 pending peers 这种通过 supernode 中转的链接。 edge 的默认管理端口号是 5644，可以通过 -t 参数修改。可以在本机通过此命令查看： netcat -u localhost 5644 发送空行就可以查看链接信息，对于其他的命令行功能，请通过 help 查看。 edge 反复报错 “Authentication error. MAC or IP address already in use or not released yet by supernode”。是什么问题？Edge 遇到了 n2n 的防欺骗保护。 它可以防止一个边缘的身份（MAC 和 IP 地址）在原始边缘仍然在线时被其他边缘冒充，请参阅一些详细信息。 大多数情况下，有两种情况可以触发此操作： 这是触发了 n2n 的防欺骗保护机制，这个机制可以防止已经在线的 edge 节点被其他人冒充，这篇文档有更详细的描述。总之，大部分情况下，有两种可能触发这个机制： 你使用的 MAC 地址或 IP 地址已经被使用了，修改这些参数就可以了。 如果一个 edge 非正常退出，例如被 kill -9 ... 或 kill -SIGKILL ...，那么这个 edge 可能没有机会通知 supernode 取消注册，因此 supernode 仍然认为此 edge 在线，此时具有相同 MAC 或 IP 地址的注册就不会成功。 supernode 记录 edge 的超时时间是两分钟，所以可以等待两分钟，或者换不同的 MAC 和 IP 地址注册。 基本上来说，不管是 CTRL + C 或是 kill -SIGTERM ... 或者 kill -SIGINT ... 或者 kill ... 不带9，都可以正常的结束 edge，在管理接口下发 stop 命令也可以停止 edge ，所以大部分情况下无需使用 kill -9 ...。","tags":[{"name":"网络编程","slug":"网络编程","permalink":"https://vitsumoc.github.io/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"name":"网络工具","slug":"网络工具","permalink":"https://vitsumoc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7/"},{"name":"翻译","slug":"翻译","permalink":"https://vitsumoc.github.io/tags/%E7%BF%BB%E8%AF%91/"}]},{"title":"使用n2n连接不同局域网设备","date":"2023-12-06T06:37:00.000Z","path":"使用n2n连接不同局域网设备.html","text":"前言目的是想在办公室使用家里的服务器 家里有不固定的公网IP，办公室有固定的公网IP，因此打算使用办公室服务器做Server 为什么不用frp？：因为想获得一个完整的网络服务，而frp只能做端口映射，如果开发过程中新增端口，需要修改frp就很麻烦 n2n简介n2n 是一个开源项目，地址在这里： https://github.com/ntop/n2n n2n 是一个二层VPN技术，他能在家里的服务器和办公室的服务器之间创建一个局域网链接 n2n 网络由 supernode 和 edge 组成，可以简单理解为同一 supernode 下的所有 edge 都处在同一个局域网中。 网络环境办公室网络： 网段：192.168.34.0&#x2F;24 网关：192.168.34.1 网关公网地址：88.88.88.88 服务器地址：192.168.34.194 家庭网络 网段：192.168.0.0&#x2F;24 网关：192.168.0.1 网关公网地址：不固定 服务器地址：192.168.0.12 规划n2n网络由于办公室有固定的公网地址，就由办公室服务器充当 supernode，同时家庭服务器和办公室服务器都是此 supernode 下的 edgen2n 会形成一个新的局域网，规划如下： 网段：10.0.34.0&#x2F;24 网关：无 办公室服务器：10.0.34.21 家庭服务器：10.0.34.41 实施下载安装n2n在办公室服务器和家庭服务器都下载并安装 n2n： https://github.com/ntop/n2n/releases 安装完成后，服务器中会自动生成两个服务 supernode 和 edge 配置文件位于 /etc/n2n/ 配置办公室服务器办公室服务器需要承担三个职能：充当 supernode，充当 edge，转发其他办公室设备到家庭服务器的网络包 配置supernode配置 /etc/n2n/community.list 文件，指定community名称 community.listcom8888 # community名称 复制 supernode.conf.sample 文件，并修改配置内容 bashcp /etc/n2n/supernode.conf.sample /etc/n2n/supernode.conf bashvi /etc/n2n/supernode.conf supernode.conf-p&#x3D;7777 # 指定supernode服务端口 -c&#x3D;&#x2F;etc&#x2F;n2n&#x2F;community.list # 指定引用的community文件 启动supernode shellsystemctl enable supernode systemctl start supernode 之后可以看到 supernode 已经启动，并且在7777端口提供服务： 配置edge配置 edge 使办公室服务器成为 n2n 网络的成员 复制 edge.conf.sample 文件，并修改配置内容 bashcp /etc/n2n/edge.conf.sample /etc/n2n/edge.conf bashvi /etc/n2n/edge.conf edge.conf-d&#x3D;n2n0 # 指定虚拟网卡名称 -c&#x3D;com8888 # community名称 -k&#x3D;888888 # 通讯加密密钥 -a&#x3D;10.0.34.21 # 在n2n网络中的地址 -l&#x3D;127.0.0.1:7777 # supernode服务地址 -r # 允许通过n2n转发数据包 启动edge shellsystemctl enable edge systemctl start edge 启动后，可以看到 n2n 已经添加了虚拟网卡： 开启数据包转发功能需要通过办公室服务器转发办公室其他电脑到家庭服务器的流量，因此需要在办公室服务器上开启数据包转发功能 需要将 /etc/sysctl.conf 文件中的 net.ipv4.ip_forward 修改为 1 bashvi /etc/sysctl.conf sysctl.conf... net.ipv4.ip_forward&#x3D;1 ... 配置办公室网关添加静态路由其他办公室电脑没有到 n2n 网络的路由，因此数据包会发送到办公室网关 此时需要配置办公室网关，添加一条指向 n2n 网络的静态路由，下一条为办公室服务器的办公网地址 配置家庭服务器配置edge，设置自动添加路由家庭服务器的 edge 安装配置过程与办公室服务器的 edge 大致相同，但有两点需要注意： 无需添加-r参数，因为家庭服务器不需要将来自其他设备的包转发到n2n网络 需要添加-n参数，这样edge启动时会自动产生一条通过n2n网络到达办公室网络的路由 edge.conf-d&#x3D;n2n0 # 指定虚拟网卡名称 -c&#x3D;com8888 # community名称 -k&#x3D;888888 # 通讯加密密钥 -a&#x3D;10.0.34.41 # 在n2n网络中的地址 -l&#x3D;88.88.88.88:17777 # supernode公网地址 -n&#x3D;192.168.34.0&#x2F;24:10.0.34.21 验证n2n网络验证使用 n2n 网络地址从办公室服务器ping家庭服务器，或从家庭服务器ping办公室服务器，成功 此时数据包的实际流向是 办公室服务器-&gt;办公室网关-&gt;运营商网络-&gt;家庭网关-&gt;家庭服务器 由于 n2n vpn的配置，此时可以认为办公室服务器和家庭服务器处在同一局域网下，tracert也仅一跳可达 办公室电脑到家庭服务器网络验证办公室电脑ping家庭服务器，成功 此时数据包流向是 办公室电脑-&gt;办公室网关-&gt;办公室服务器-&gt;家庭服务器，其中办公室服务器到家庭服务器是 n2n 虚拟链路 tracert三跳可达 家庭服务器到办公室电脑家庭服务器ping办公室电脑，成功 此时数据包流向是 家庭服务器-&gt;办公室服务器-&gt;办公室电脑，其中家庭服务器到办公室服务器是 n2n 虚拟链路 tracert两跳可达","tags":[{"name":"网络编程","slug":"网络编程","permalink":"https://vitsumoc.github.io/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"name":"网络工具","slug":"网络工具","permalink":"https://vitsumoc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7/"}]},{"title":"工作周报可视化","date":"2023-12-05T03:31:51.000Z","path":"工作周报可视化.html","text":"起因这个项目是一个纯粹的小玩具，起因是我公司的工作周报都是 .doc 格式存储的，现在到年底了，我又比较想知道我一年都干了哪些工作。显而易见的一个方式就是提取所有周报文字内容做词频分析。 效果完成之后的效果还算不错，源码也放在了github上： https://github.com/vitsumoc/weekreport2chart 提取一段时间的工作周报内容，生成词云和河流图 可以直接过滤低频词汇，或手动操作删除某些虚词、连词等 相关库使用libreoffice将doc转为docx 使用结巴分词分词：https://github.com/fxsjy/jieba 使用wordcloudjs词云：https://wordcloud2-js.timdream.org/#love 使用echarts河流图","tags":[{"name":"小玩具","slug":"小玩具","permalink":"https://vitsumoc.github.io/tags/%E5%B0%8F%E7%8E%A9%E5%85%B7/"},{"name":"python","slug":"python","permalink":"https://vitsumoc.github.io/tags/python/"},{"name":"js","slug":"js","permalink":"https://vitsumoc.github.io/tags/js/"}]},{"title":"在Go中使用lua","date":"2023-12-05T03:25:15.000Z","path":"在Go中使用lua.html","text":"使用gopher-lua，在 Go 中使用lua。gopher-lua 项目地址： https://github.com/yuin/gopher-lua 使用示例仓库地址： https://github.com/vitsumoc/my-golua 示例列表： 最基础的用法 基础数据类型 在lua中调用go方法 在go中使用lua协程 示范如何手动开启模块 在lua中使用go模块 在 Go 中调用lua方法 在lua中使用 Go 数据 通过context控制停止 在有协程的情况下使用context控制 共享lua文件字节码, 减少开销 通过go协程跑lua的示例 可以把ch带到lua中 和相关限制 在lua中使用ch的例子 lua虚拟机池 在 Go 中提供钩子, 使lua可以注册脚本, 在脚本中获得并修改用户数据","tags":[{"name":"Go","slug":"Go","permalink":"https://vitsumoc.github.io/tags/Go/"},{"name":"lua","slug":"lua","permalink":"https://vitsumoc.github.io/tags/lua/"}]},{"title":"使用SSH包装Socks5代理","date":"2023-11-22T09:38:25.000Z","path":"使用SSH包装Socks5代理.html","text":"subSocks简介subSocks是Luyu Huang制作的纯 Go 网络代理软件。 这里是作者本人对此项目的介绍文档。 为什么要做SSH包装因为之前使用v2ray总是被封端口，但是VPS上的22端口始终建在，考虑到SSH协议比较复杂，包括了Shell，SFTP等多种应用。我认为使用SSH协议包装流量可以起到一定的伪装作用，减少端口被封的可能性。 subSocks项目的代码结构非常漂亮，添加SSH包装非常便捷。 实现过程首先需要了解subSocks的代码结构，Luyu Huang的文档中描述的非常详细，我只需要实现SSHWarpper和SSHStripper。 Go 已经提供了SSH的官方实现，参考文档。并且提供了使用SSH进行远程Shell的示例。 之后需要对SSH的通讯过程，Session Channel Request等等各种概念有基础的了解。 使用ssh包中的代码，在服务端使用TCP链接，创建SSH服务器，等待客户端链接后获取Channel，将Channel包装为Stripper。 客户端与服务端相似，需要使用TCP链接，向服务端完成握手过程，之后可获得Session，将Session包装成Wrapper。 源码改动的源码请参考我 fork 的仓库 使用为了能够使用ssh协议进行代理，并且能支持密码和密钥认证，配置文件添加了一些字段 客户端client.toml[client] # client configuration listen = \"127.0.0.1:1080\" username = \"subsocks\" password = \"subsocks\" server.protocol = \"ssh\" server.address = \"127.0.0.1:22\" ssh.key = \"./ssWithPass\" ssh.passphrase = \"123123\" server.protocol：当配置为 ssh 时使用 ssh 协议代理流量 username，password：这两个字段配置后，ssh协议可以使用账号密码的方式向服务端认证 ssh.key：配置后客户端可以使用密钥方式向服务端认证，这里配置客户端私钥文件，并把公钥文件存放在服务端 ssh.passphrase：如果私钥有密码的话，在这里配置 账号密码验证和密钥验证是选配的，配置其中一种或两者皆配置都可以。 服务端 server.toml[server] # server configuration protocol = \"ssh\" listen = \"0.0.0.0:22\" ssh.key = \"./ssWithPass\" ssh.passphrase = \"123123\" ssh.cert = \"./ssWithPass.pub\" [server.users] \"subsocks\" = \"subsocks\" protocol ：当配置为 ssh 时使用 ssh 协议代理流量 ssh.key：服务端的 ssh 私钥路径，必填 ssh.passphrase：服务端 ssh 私钥的密码，有密码就填 [server.users]：支持的账号密码对，配合客户端的账号密码校验 ssh.cert： 客户端 ssh 公钥路径，用来支持客户端和服务端之间的密钥认证 SSH私钥加密的说明由于 Go 中的ssh暂时还没有支持加密的PKCS#8 format，如果想要使用加密的私钥，需要选择PEM格式。可以用如下命令生成： ssh-keygen -t rsa -b 4096 -m PEM使用 ssh-keygen 的默认参数生成的带密码的私钥，在 ssh.ParsePrivateKeyWithPassphrase 过程中会报错。 情况参考：gaia-pipeline&#x2F;gaia#182 (comment) 验证通过抓包验证，握手过程正常，通讯过程与SSH相同，多条链接使用正常，所有数据均经过加密： 使用 SSH 代理看了一会视频网站，效果也不错，很流畅。","tags":[{"name":"网络编程","slug":"网络编程","permalink":"https://vitsumoc.github.io/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"name":"SSH","slug":"SSH","permalink":"https://vitsumoc.github.io/tags/SSH/"},{"name":"Go","slug":"Go","permalink":"https://vitsumoc.github.io/tags/Go/"}]},{"title":"Go与串口设备在项目中的运用","date":"2023-11-22T03:06:28.000Z","path":"Go与串口设备在项目中的运用.html","text":"需求简述硬件设备使用485Modbus通讯，需使用 Go 编写采集程序，将数据采集至平台。 方案简述使用串口服务器将485Modbus通讯转为TCPModbus，并将串口服务器设置为TCPserver。 使用 Go 编写采集器，定期向串口服务器建立TCP链接，采集数据。 技术点与实现点表通过struct实现点位表 这里使用Raw表示原始点表数据，和通讯协议一一对应 后续可将Raw结构封装至更高层的业务结构，用来实现业务数据的表示、嵌套能其他功能 gotype StructMcuRaw struct &#123; Ver [4]uint8 `json:\"ver\"` // 软件版本[4]char Id uint16 `json:\"id\"` // 通信箱id TargetAngle uint16 `json:\"targetAngle\" IEC104:\"yc\" IEC104Name:\"子阵目标角度\" IEC104Unit:\"°\" IEC104Factor:\"0.1\"` // 对整个子阵设置目标角度 InitSnowDepth uint16 `json:\"initSnowDepth\" IEC104:\"yx\" IEC104Name:\"标定初始雪深标志\"` // 标定初始雪深标志 PrecipitationType uint16 `json:\"precipitationType\"` // 降水类型 &#125; 读取二进制数据通过binary包，可以实现从buffer中读取数据向struct赋值 gofunc (p *StructMcuRaw) MCUFromByte(res *bytes.Buffer) &#123; // 软件版本[4]char for x := 0; x &lt; 4; x++ &#123; binary.Read(res, binary.BigEndian, p.Ver[x]) &#125; // 通信箱id binary.Read(res, binary.BigEndian, &amp;p.Id) // 对整个子阵设置目标角度 binary.Read(res, binary.BigEndian, &amp;p.TargetAngle) // 标定初始雪深标志 binary.Read(res, binary.BigEndian, &amp;p.InitSnowDepth) // 降水类型 binary.Read(res, binary.BigEndian, &amp;p.PrecipitationType) &#125; 封装为query在本项目中，query指对单个设备的采集方法 将数据读取封装成query方法，包括TCP采集过程、日志记录、包格式处理等 gofunc MCUQuery(conn *net.Conn, reader *bufio.Reader, buffer *[]byte, cb *rs.StructCommBox, mcu *rs.StructMcu) error &#123; // 查询地址 addInt, err := strconv.Atoi(mcu.Addr) if err != nil &#123; return err &#125; // 包编号 tcpSeq := TcpSeq() var query = []byte&#123; uint8(tcpSeq / 0x100), uint8(tcpSeq % 0x100), // 编号 0x00, 0x00, 0x00, 0x06, // 长度 byte(addInt), 0x03, 0x00, 0xa0, 0x00, 0x29&#125; // 指令 (*conn).SetWriteDeadline(time.Now().Add(rs.QUERY_DEFAULT_TIMEOUT)) _, err = (*conn).Write(query) if err != nil &#123; log.Log(true, cb.IpAddr, cb.Port, []byte&#123;&#125;) return err &#125; // 日志 log.Log(true, cb.IpAddr, cb.Port, query) // 接收 (*conn).SetReadDeadline(time.Now().Add(rs.QUERY_DEFAULT_TIMEOUT)) n, err := (*reader).Read(*buffer) if err != nil &#123; log.Log(false, cb.IpAddr, cb.Port, []byte&#123;&#125;) return err &#125; // 日志 log.Log(false, cb.IpAddr, cb.Port, (*buffer)[:n]) // 解析 res := bytes.NewBuffer(*buffer) // TCP头 var tcpHeader rs.StructTCPHeader tcpHeader.TCPHeaderFromByte(res) if tcpHeader.Seq != tcpSeq &#123; return errors.New(\"TCP异常\") &#125; if tcpHeader.Len != 85 &#123; return errors.New(\"TCP长度异常\") &#125; // modbus头 var mbHeader rs.StructMudbusHeader mbHeader.MudbusHeaderFromByte(res) // mcu内容 mcu.Raw.MCUFromByte(res) mcu.VUpdate = true // 标记更新 return nil &#125; 封装为采集过程最后需要将所有的采集query放置在统一的采集过程中 在一次采集过程中，创建一条TCP链接，完成所有采集动作，最后断开链接 gofunc Collect(cb *rs.StructCommBox) &#123; // 记录网络占用 NetCh &lt;- true defer func() &#123; &lt;-NetCh &#125;() // 初始化采集标识 eraseFlag(cb) // 采集结束后更新时标 defer func() &#123; updateTs(cb) &#125;() // 建链 conn, err := net.DialTimeout(\"tcp\", cb.IpAddr+\":\"+cb.Port, rs.QUERY_DEFAULT_TIMEOUT) if err != nil &#123; log.Log(true, cb.IpAddr, cb.Port, []byte&#123;&#125;) return &#125; cb.VUpdate = true defer conn.Close() // 读写缓存 readBuf := bufio.NewReader(conn) buffer := make([]byte, 256) // 按mcu查询 for x := 0; x &lt; len(cb.Mcus); x++ &#123; // 切换MCU预留时间, 提高成功率 time.Sleep(rs.QUERY_MCU_INTERVAL) // 查mcu信息 mcu := cb.Mcus[x] err = cmd.MCUQuery(&amp;conn, readBuf, &amp;buffer, cb, mcu) if err != nil &#123; return &#125; // 分次查跟踪器信息 for y := 0; y &lt; mcu.TracerNum; &#123; // 切换Tracer预留时间, 提高成功率 time.Sleep(rs.QUERY_TRACER_INTERVAL) // 查询长度 tracerLen := rs.QUERY_TRACER_COUNT if mcu.TracerNum-y &lt; rs.QUERY_TRACER_COUNT &#123; tracerLen = mcu.TracerNum - y &#125; err = cmd.TracerQuery(&amp;conn, readBuf, &amp;buffer, cb, mcu, y, tracerLen) if err != nil &#123; return &#125; y += tracerLen &#125; &#125; &#125; 总结使用 Go + 串口服务器 进行串口通讯，非常的简单、直观，易于开发维护。 在本次项目实践中，由于 Go 提供了方便的并发编程与控制机制，高负载环境下的性能也得到了充分保障。","tags":[{"name":"网络编程","slug":"网络编程","permalink":"https://vitsumoc.github.io/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"name":"项目实践","slug":"项目实践","permalink":"https://vitsumoc.github.io/tags/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"},{"name":"串口通讯","slug":"串口通讯","permalink":"https://vitsumoc.github.io/tags/%E4%B8%B2%E5%8F%A3%E9%80%9A%E8%AE%AF/"},{"name":"Go","slug":"Go","permalink":"https://vitsumoc.github.io/tags/Go/"}]},{"title":"SSH中的握手过程","date":"2023-11-20T01:20:06.000Z","path":"SSH中的握手过程.html","text":"RFChttps://datatracker.ietf.org/doc/html/rfc4253 SSH简介安全外壳协议（Secure Shell Protocol，简称SSH）是一种加密的网络传输协议，可在不安全的网络中为网络服务提供安全的传输环境。SSH通过在网络中建立安全隧道来实现SSH客户端与服务器之间的连接。SSH最常见的用途是远程登录系统，人们通常利用SSH来传输命令行界面和远程执行命令。 SSH数据包基本格式SSH的数据包加密后分块传输，每次传输的实际包长度都应为密码块大小的整数倍或8 每个加密后的数据包都由如下结构构成 cuint32 packet_length; byte padding_length; byte[n1] payload; // n1 = packet_length - padding_length - 1 byte[n2] random_padding; // n2 = padding_length byte[m] mac(Message_Authentication_Code - MAC); // m = mac_length packet_length：数据载荷的长度，不包括mac部分和packet_length本身。在进行加密协商完成后，传输的packet_length也会被加密 padding_length：random_padding块的大小 payload：数据载荷，根绝协商决定被加密或被压缩的方法 random padding： 0-255位随机填充 mac：信息认证码，用作信息完整性校验 SSH过程以下采用一个SSH抓包结果为例，描述SSH链接建立过程： |&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;| |&nbsp;&nbsp;&nbsp;客户端&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;服务端&nbsp;&nbsp;&nbsp;&nbsp;| |&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;| |&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;链接建立&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;| |1. 三次握手1|—————————————————————————————–&gt; &lt;—————————————————————————————-|2. 三次握手2| |3. 三次握手3|—————————————————————————————–&gt; |&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;协议协商&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;| &lt;—————————————————————————————-|4. 服务端协议| |5. 客户端协议|—————————————————————————————–&gt; |&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;算法协商&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;| &lt;————————————————————————————-|6. 服务端算法表| |7. 客户端算法表|————————————————————————————&gt; |&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;密钥交换&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;| |8. Diffie-Hellman Init|——————————————————————————&gt; &lt;————————————————|9. Diffie-Hellman Reply，New Keys，加密包| |10. New Keys|—————————————————————————————-&gt; |&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;加密通讯&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;| 链接建立（1）（2）（3）三次握手报文 TCP三次握手 协议协商（4）服务端协议报文 Hex内容 0x 53 53 48 2d 32 2e 30 2d 4f 70 65 6e 53 53 48 5f 38 2e 30 0d 0a 报文内容 SSH-2.0-OpenSSH_8.0&lt;CR&gt;&lt;LF&gt; 包括SSH、协议版本（2.0）、软件版本（OpenSSH_8.0） （5）客户端协议报文 Hex内容 0x 53 53 48 2d 32 2e 30 2d 6e 73 73 73 68 32 5f 37 2e 30 2e 30 30 33 33 20 4e 65 74 53 61 72 61 6e 67 20 43 6f 6d 70 75 74 65 72 2c 20 49 6e 63 2e 0d 0a 报文内容 SSH-2.0-nsssh2_7.0.0033 NetSarang Computer, Inc.&lt;CR&gt;&lt;LF&gt; 算法协商在算法协商的过程中，双方会各自发送自己支持的算法列表，最终对以下几个算法达成共识： kex_algorithms：密钥交换算法 server_host_key_algorithms：公钥算法 encryption_algorithms：加密算法 mac_algorithms：数据完整性算法 compression_algorithms：压缩算法 languages：语言标签（可选） first_kex_packet_follows：表示是否有猜测数据包 在达成共识的过程中，基本以客户端中的算法排序优先匹配 （6）服务端算法表报文 packet_length：0x00 00 04 14（1044） padding_length：0x05（5） SSH_MSG_SERVICE_ACCEPT：0x14（SSH_MSG_KEXINIT） Cookie：0xd7 86 29 66…(16Byte) kex_algorithms length：下方算法表长度 kex_algorithms list：算法表（字符串表示，逗号分隔） server_host_key_algorithms length：下方算法表长度 server_host_key_algorithms list：算法表（字符串表示，逗号分隔） encryption_algorithms_client_to_server length：下方算法表长度 encryption_algorithms_client_to_server list：算法表（字符串表示，逗号分隔） encryption_algorithms_server_to_client length：下方算法表长度 encryption_algorithms_server_to_client list：算法表（字符串表示，逗号分隔） mac_algorithms_client_to_server length：下方算法表长度 mac_algorithms_client_to_server list：算法表（字符串表示，逗号分隔） mac_algorithms_server_to_client length：下方算法表长度 mac_algorithms_server_to_client list：算法表（字符串表示，逗号分隔） compression_algorithms_client_to_server length：下方算法表长度 compression_algorithms_client_to_server list：算法表（字符串表示，逗号分隔） compression_algorithms_server_to_client length：下方算法表长度 compression_algorithms_server_to_client list：算法表（字符串表示，逗号分隔） languages_client_to_server length：下方算法表长度 languages_client_to_server list：算法表（字符串表示，逗号分隔） languages_server_to_client length：下方算法表长度 languages_server_to_client list：算法表（字符串表示，逗号分隔） first_kex_packet_follows：0x00 Reserved：0x00 00 00 00 Padding：0x00 00 00 00 00（padding_length长度） （7）客户端算法表报文 与服务端算法表格式相同 密钥交换通过双方协商，决定采用Elliptic Curve Diffie-Hellman方式进行密钥交换 （8）客户端Diffie-Hellman Init packet_length：0x00 00 00 2c padding_length：0x06 MSG：0x1e（Elliptic Curve Diffie-Hellman Key Exchange Init） 客户端公钥长度：0x00 00 00 20（32） 客户端公钥：0xd1 d9 b8 6c 84 67 55 0f ca 84 6e 8b 0e 67 25 27 6b 50 ae ed a4 6d dc 0b 73 4c 15 ad e9 f5 51 66 Padding：0x91 f0 e8 0c f4 9b （9）服务端Diffie-Hellman Reply，New Keys，加密包 服务端的回复包含三部分内容，Key Exchange Reply、New Keys、 加密包 其中，Key Exchange Reply包括了密钥交换的结果 packet_length：0x00 00 03 5c padding_length：0x08 MSG：0x1f（Elliptic Curve Diffie-Hellman Key Exchange Reply） Host Key Length：0x00 00 01 97 Host Key Type Length：0x00 00 00 07 Host Key Type：0x73 73 68 2d 72 73 21（ssh-rsa） Multi Precision Integer Length：0x00 00 00 03 RSA public exponent (e)：0x01 00 01 Multi Precision Integer Length：0x00 00 01 81 RSA Modulus (N)：0x00 be 1b 4b 73 9d f8 37 0e 33… ECDH server’s ephemeral public key length：0x00 00 00 20 ECDH server’s ephemeral public key (Q_S)：0x3a 2e 62 f6 ee… KEX H signature length：0x00 00 01 8f KEX H signature ：0x00 00 00 07 73 73 68 2d 72 73 61 00 00 01 80 a0… Padding：0x00 00 00 00 00 00 00 00 New Keys表示密钥交换完成，此后的内容都需要使用新密钥处理 packet_length：0x00 00 00 0c padding_length：0x0a MSG：0x15（SSH_MSG_NEWKEYS） Padding：0x00 00 00 00 00 00 00 00 00 00 后续的数据已经被加密，无法查看内容，推测是与客户端进行登录认证的协商 （10）客户端New Keys 客户端的New Keys包与服务端相同，后续客户端发送数据也都被加密处理","tags":[{"name":"网络编程","slug":"网络编程","permalink":"https://vitsumoc.github.io/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"name":"SSH","slug":"SSH","permalink":"https://vitsumoc.github.io/tags/SSH/"}]},{"title":"在Windows中使用Linux——WSL","date":"2023-11-17T08:36:34.000Z","path":"在Windows中使用Linux——WSL.html","text":"https://learn.microsoft.com/zh-cn/windows/wsl/","tags":[{"name":"豆知识","slug":"豆知识","permalink":"https://vitsumoc.github.io/tags/%E8%B1%86%E7%9F%A5%E8%AF%86/"},{"name":"环境配置","slug":"环境配置","permalink":"https://vitsumoc.github.io/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"},{"name":"Linux","slug":"Linux","permalink":"https://vitsumoc.github.io/tags/Linux/"}]}]